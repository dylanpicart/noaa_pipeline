[2024-10-23T02:18:03.055+0000] {processor.py:157} INFO - Started process (PID=1681) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:03.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:18:03.056+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:03.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:03.302+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.301+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:hadoop_spark_pipeline
[2024-10-23T02:18:03.310+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.310+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:hadoop_spark_pipeline
[2024-10-23T02:18:03.318+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.317+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:hadoop_spark_pipeline
[2024-10-23T02:18:03.332+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.332+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:18:03.343+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.343+0000] {dag.py:2747} INFO - Creating ORM DAG for hadoop_spark_pipeline
[2024-10-23T02:18:03.355+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:03.355+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:18:03.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.414 seconds
[2024-10-23T02:18:34.254+0000] {processor.py:157} INFO - Started process (PID=1683) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:34.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:18:34.255+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:34.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:34.269+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:34.294+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:34.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:18:34.319+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:34.319+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:18:34.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T02:18:40.295+0000] {processor.py:157} INFO - Started process (PID=1684) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:40.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:18:40.296+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:40.296+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:40.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:18:40.411+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:40.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:18:40.567+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:18:40.567+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:18:40.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.295 seconds
[2024-10-23T02:19:10.653+0000] {processor.py:157} INFO - Started process (PID=1686) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:19:10.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:19:10.655+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:19:10.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:19:10.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:19:10.706+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:19:10.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:19:10.741+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:19:10.741+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:19:10.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T02:19:40.963+0000] {processor.py:157} INFO - Started process (PID=1688) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:19:40.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:19:40.965+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:19:40.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:19:40.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:19:41.029+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:19:41.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:19:41.056+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:19:41.056+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:19:41.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T02:20:11.224+0000] {processor.py:157} INFO - Started process (PID=1690) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:20:11.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:20:11.225+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:20:11.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:20:11.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:20:11.261+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:20:11.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:20:11.283+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:20:11.283+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:20:11.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-23T02:20:41.438+0000] {processor.py:157} INFO - Started process (PID=1692) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:20:41.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:20:41.440+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:20:41.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:20:41.454+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:20:41.481+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:20:41.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:20:41.501+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:20:41.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:20:41.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T02:21:11.666+0000] {processor.py:157} INFO - Started process (PID=1694) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:21:11.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:21:11.667+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:21:11.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:21:11.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:21:11.709+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:21:11.709+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:21:11.733+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:21:11.733+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:21:11.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.196 seconds
[2024-10-23T02:21:41.900+0000] {processor.py:157} INFO - Started process (PID=1696) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:21:41.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:21:41.912+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:21:41.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:21:41.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:21:41.951+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:21:41.951+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:21:41.975+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:21:41.975+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:21:41.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T02:22:12.150+0000] {processor.py:157} INFO - Started process (PID=1698) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:22:12.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:22:12.152+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:22:12.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:22:12.171+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:22:12.209+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:22:12.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:22:12.236+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:22:12.235+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:22:12.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T02:22:42.383+0000] {processor.py:157} INFO - Started process (PID=1700) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:22:42.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:22:42.396+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:22:42.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:22:42.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:22:42.436+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:22:42.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:22:42.462+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:22:42.461+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:22:42.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T02:23:12.665+0000] {processor.py:157} INFO - Started process (PID=1702) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:23:12.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:23:12.666+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:23:12.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:23:12.678+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:23:12.705+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:23:12.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:23:12.725+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:23:12.725+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:23:12.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-23T02:23:42.905+0000] {processor.py:157} INFO - Started process (PID=1704) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:23:42.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:23:42.907+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:23:42.906+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:23:42.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:23:42.945+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:23:42.945+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:23:42.973+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:23:42.973+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:23:42.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T02:24:13.175+0000] {processor.py:157} INFO - Started process (PID=1706) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:24:13.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:24:13.176+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:24:13.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:24:13.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:24:13.212+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:24:13.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:24:13.235+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:24:13.235+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:24:13.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.171 seconds
[2024-10-23T02:24:43.377+0000] {processor.py:157} INFO - Started process (PID=1708) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:24:43.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:24:43.390+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:24:43.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:24:43.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:24:43.427+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:24:43.427+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:24:43.450+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:24:43.449+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:24:43.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-23T02:25:13.677+0000] {processor.py:157} INFO - Started process (PID=1710) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:25:13.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:25:13.679+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:25:13.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:25:13.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:25:13.728+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:25:13.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:25:13.752+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:25:13.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:25:13.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T02:25:43.960+0000] {processor.py:157} INFO - Started process (PID=1712) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:25:43.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:25:43.964+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:25:43.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:25:43.984+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:25:44.015+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:25:44.015+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:25:44.039+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:25:44.039+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:25:44.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T02:26:14.230+0000] {processor.py:157} INFO - Started process (PID=1714) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:26:14.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:26:14.231+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:26:14.231+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:26:14.242+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:26:14.271+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:26:14.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:26:14.293+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:26:14.292+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:26:14.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T02:26:44.463+0000] {processor.py:157} INFO - Started process (PID=1716) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:26:44.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:26:44.477+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:26:44.477+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:26:44.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:26:44.522+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:26:44.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:26:44.546+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:26:44.546+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:26:44.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T02:27:14.717+0000] {processor.py:157} INFO - Started process (PID=1718) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:27:14.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:27:14.718+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:27:14.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:27:14.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:27:14.753+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:27:14.752+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:27:14.774+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:27:14.774+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:27:14.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.174 seconds
[2024-10-23T02:27:45.053+0000] {processor.py:157} INFO - Started process (PID=1720) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:27:45.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:27:45.054+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:27:45.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:27:45.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:27:45.094+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:27:45.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:27:45.117+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:27:45.117+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:27:45.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T02:28:15.311+0000] {processor.py:157} INFO - Started process (PID=1722) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:28:15.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:28:15.312+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:28:15.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:28:15.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:28:15.354+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:28:15.354+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:28:15.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:28:15.378+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:28:15.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T02:28:45.570+0000] {processor.py:157} INFO - Started process (PID=1724) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:28:45.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:28:45.572+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:28:45.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:28:45.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:28:45.614+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:28:45.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:28:45.637+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:28:45.637+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:28:45.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T02:29:15.825+0000] {processor.py:157} INFO - Started process (PID=1726) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:29:15.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:29:15.827+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:29:15.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:29:15.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:29:15.876+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:29:15.876+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:29:15.899+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:29:15.899+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:29:15.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T02:29:46.084+0000] {processor.py:157} INFO - Started process (PID=1728) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:29:46.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:29:46.085+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:29:46.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:29:46.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:29:46.126+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:29:46.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:29:46.149+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:29:46.149+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:29:46.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T02:30:16.345+0000] {processor.py:157} INFO - Started process (PID=1730) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:30:16.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:30:16.346+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:30:16.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:30:16.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:30:16.385+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:30:16.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:30:16.518+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:30:16.518+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:30:16.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.191 seconds
[2024-10-23T02:30:46.708+0000] {processor.py:157} INFO - Started process (PID=1732) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:30:46.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:30:46.710+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:30:46.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:30:46.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:30:46.762+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:30:46.762+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:30:46.794+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:30:46.794+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:30:46.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T02:31:16.957+0000] {processor.py:157} INFO - Started process (PID=1734) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:31:16.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:31:16.958+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:31:16.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:31:16.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:31:17.003+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:31:17.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:31:17.027+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:31:17.026+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:31:17.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T02:31:47.215+0000] {processor.py:157} INFO - Started process (PID=1736) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:31:47.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:31:47.216+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:31:47.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:31:47.228+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:31:47.252+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:31:47.252+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:31:47.275+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:31:47.275+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:31:47.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T02:32:17.480+0000] {processor.py:157} INFO - Started process (PID=1738) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:32:17.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:32:17.481+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:32:17.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:32:17.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:32:17.523+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:32:17.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:32:17.544+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:32:17.544+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:32:17.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T02:32:47.725+0000] {processor.py:157} INFO - Started process (PID=1740) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:32:47.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:32:47.727+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:32:47.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:32:47.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:32:47.765+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:32:47.765+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:32:47.791+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:32:47.791+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:32:47.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T02:33:17.960+0000] {processor.py:157} INFO - Started process (PID=1742) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:33:17.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:33:17.961+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:33:17.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:33:17.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:33:18.002+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:33:18.002+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:33:18.110+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:33:18.110+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:33:18.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-23T02:33:48.275+0000] {processor.py:157} INFO - Started process (PID=1744) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:33:48.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:33:48.277+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:33:48.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:33:48.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:33:48.321+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:33:48.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:33:48.346+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:33:48.346+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:33:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T02:34:18.531+0000] {processor.py:157} INFO - Started process (PID=1746) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:34:18.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:34:18.532+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:34:18.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:34:18.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:34:18.572+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:34:18.572+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:34:18.594+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:34:18.593+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:34:18.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T02:34:48.809+0000] {processor.py:157} INFO - Started process (PID=1748) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:34:48.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:34:48.812+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:34:48.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:34:48.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:34:48.853+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:34:48.853+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:34:48.880+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:34:48.880+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:34:48.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T02:35:19.071+0000] {processor.py:157} INFO - Started process (PID=1750) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:35:19.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:35:19.072+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:35:19.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:35:19.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:35:19.120+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:35:19.120+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:35:19.141+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:35:19.141+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:35:19.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T02:35:49.337+0000] {processor.py:157} INFO - Started process (PID=1752) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:35:49.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:35:49.340+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:35:49.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:35:49.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:35:49.382+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:35:49.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:35:49.404+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:35:49.404+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:35:49.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-23T02:36:19.675+0000] {processor.py:157} INFO - Started process (PID=1754) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:36:19.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:36:19.676+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:36:19.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:36:19.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:36:19.717+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:36:19.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:36:19.836+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:36:19.836+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:36:19.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-23T02:36:49.884+0000] {processor.py:157} INFO - Started process (PID=1756) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:36:49.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:36:49.897+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:36:49.897+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:36:49.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:36:49.932+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:36:49.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:36:49.952+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:36:49.952+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:36:49.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T02:37:20.110+0000] {processor.py:157} INFO - Started process (PID=1758) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:37:20.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:37:20.111+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:37:20.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:37:20.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:37:20.150+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:37:20.150+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:37:20.171+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:37:20.171+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:37:20.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T02:37:50.339+0000] {processor.py:157} INFO - Started process (PID=1760) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:37:50.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:37:50.340+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:37:50.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:37:50.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:37:50.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:37:50.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:37:50.400+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:37:50.400+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:37:50.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-23T02:38:20.569+0000] {processor.py:157} INFO - Started process (PID=1762) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:38:20.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:38:20.570+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:38:20.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:38:20.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:38:20.610+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:38:20.610+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:38:20.630+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:38:20.630+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:38:20.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T02:38:50.787+0000] {processor.py:157} INFO - Started process (PID=1764) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:38:50.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:38:50.789+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:38:50.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:38:50.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:38:50.830+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:38:50.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:38:50.855+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:38:50.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:38:50.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.183 seconds
[2024-10-23T02:39:21.115+0000] {processor.py:157} INFO - Started process (PID=1766) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:39:21.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:39:21.117+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:39:21.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:39:21.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:39:21.154+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:39:21.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:39:21.262+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:39:21.262+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:39:21.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.165 seconds
[2024-10-23T02:39:51.451+0000] {processor.py:157} INFO - Started process (PID=1768) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:39:51.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:39:51.453+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:39:51.452+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:39:51.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:39:51.496+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:39:51.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:39:51.519+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:39:51.519+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:39:51.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T02:40:21.688+0000] {processor.py:157} INFO - Started process (PID=1770) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:40:21.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:40:21.689+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:40:21.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:40:21.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:40:21.727+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:40:21.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:40:21.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:40:21.748+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:40:21.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T02:40:51.905+0000] {processor.py:157} INFO - Started process (PID=1772) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:40:51.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:40:51.907+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:40:51.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:40:51.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:40:51.949+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:40:51.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:40:51.975+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:40:51.975+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:40:51.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T02:41:22.139+0000] {processor.py:157} INFO - Started process (PID=1774) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:41:22.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:41:22.140+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:41:22.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:41:22.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:41:22.187+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:41:22.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:41:22.211+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:41:22.211+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:41:22.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T02:41:52.403+0000] {processor.py:157} INFO - Started process (PID=1776) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:41:52.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:41:52.416+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:41:52.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:41:52.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:41:52.462+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:41:52.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:41:52.483+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:41:52.483+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:41:52.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.183 seconds
[2024-10-23T02:42:22.751+0000] {processor.py:157} INFO - Started process (PID=1778) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:42:22.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:42:22.753+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:42:22.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:42:22.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:42:22.799+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:42:22.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:42:22.825+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:42:22.824+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:42:22.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T02:42:53.039+0000] {processor.py:157} INFO - Started process (PID=1780) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:42:53.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:42:53.051+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:42:53.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:42:53.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:42:53.097+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:42:53.097+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:42:53.117+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:42:53.117+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:42:53.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T02:43:23.298+0000] {processor.py:157} INFO - Started process (PID=1782) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:43:23.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:43:23.299+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:43:23.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:43:23.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:43:23.342+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:43:23.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:43:23.366+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:43:23.366+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:43:23.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T02:43:53.551+0000] {processor.py:157} INFO - Started process (PID=1784) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:43:53.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:43:53.552+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:43:53.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:43:53.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:43:53.589+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:43:53.589+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:43:53.609+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:43:53.609+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:43:53.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.076 seconds
[2024-10-23T02:44:23.802+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:44:23.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:44:23.803+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:44:23.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:44:23.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:44:23.839+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:44:23.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:44:23.860+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:44:23.859+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:44:23.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T02:44:54.022+0000] {processor.py:157} INFO - Started process (PID=1788) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:44:54.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:44:54.025+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:44:54.024+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:44:54.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:44:54.079+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:44:54.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:44:54.196+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:44:54.196+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:44:54.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.196 seconds
[2024-10-23T02:45:24.361+0000] {processor.py:157} INFO - Started process (PID=1790) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:45:24.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:45:24.362+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:45:24.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:45:24.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:45:24.413+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:45:24.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:45:24.439+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:45:24.438+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:45:24.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T02:45:54.648+0000] {processor.py:157} INFO - Started process (PID=1792) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:45:54.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:45:54.650+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:45:54.650+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:45:54.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:45:54.690+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:45:54.690+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:45:54.716+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:45:54.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:45:54.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T02:46:24.888+0000] {processor.py:157} INFO - Started process (PID=1794) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:46:24.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:46:24.890+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:46:24.889+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:46:24.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:46:24.935+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:46:24.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:46:24.955+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:46:24.955+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:46:24.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-23T02:46:55.184+0000] {processor.py:157} INFO - Started process (PID=1796) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:46:55.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:46:55.186+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:46:55.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:46:55.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:46:55.221+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:46:55.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:46:55.244+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:46:55.244+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:46:55.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T02:47:25.336+0000] {processor.py:157} INFO - Started process (PID=1798) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:47:25.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:47:25.337+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:47:25.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:47:25.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:47:25.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:47:25.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:47:25.404+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:47:25.403+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:47:25.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.207 seconds
[2024-10-23T02:47:55.729+0000] {processor.py:157} INFO - Started process (PID=1800) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:47:55.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:47:55.742+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:47:55.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:47:55.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:47:55.780+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:47:55.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:47:55.888+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:47:55.888+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:47:55.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.183 seconds
[2024-10-23T02:48:26.083+0000] {processor.py:157} INFO - Started process (PID=1802) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:48:26.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:48:26.085+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:48:26.084+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:48:26.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:48:26.123+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:48:26.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:48:26.147+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:48:26.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:48:26.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T02:48:56.328+0000] {processor.py:157} INFO - Started process (PID=1804) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:48:56.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:48:56.330+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:48:56.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:48:56.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:48:56.367+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:48:56.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:48:56.388+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:48:56.388+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:48:56.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T02:49:26.584+0000] {processor.py:157} INFO - Started process (PID=1806) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:49:26.585+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:49:26.586+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:49:26.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:49:26.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:49:26.629+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:49:26.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:49:26.653+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:49:26.653+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:49:26.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T02:49:56.836+0000] {processor.py:157} INFO - Started process (PID=1808) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:49:56.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:49:56.838+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:49:56.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:49:56.850+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:49:56.876+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:49:56.876+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:49:56.898+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:49:56.898+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:49:56.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T02:50:27.091+0000] {processor.py:157} INFO - Started process (PID=1810) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:50:27.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:50:27.092+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:50:27.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:50:27.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:50:27.129+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:50:27.128+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:50:27.151+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:50:27.150+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:50:27.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.184 seconds
[2024-10-23T02:50:57.440+0000] {processor.py:157} INFO - Started process (PID=1812) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:50:57.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:50:57.442+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:50:57.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:50:57.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:50:57.479+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:50:57.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:50:57.587+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:50:57.586+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:50:57.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.165 seconds
[2024-10-23T02:51:27.760+0000] {processor.py:157} INFO - Started process (PID=1814) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:51:27.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:51:27.762+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:51:27.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:51:27.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:51:27.801+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:51:27.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:51:27.822+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:51:27.822+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:51:27.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T02:51:58.016+0000] {processor.py:157} INFO - Started process (PID=1816) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:51:58.028+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:51:58.029+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:51:58.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:51:58.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:51:58.064+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:51:58.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:51:58.089+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:51:58.089+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:51:58.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T02:52:28.269+0000] {processor.py:157} INFO - Started process (PID=1818) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:52:28.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:52:28.271+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:52:28.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:52:28.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:52:28.309+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:52:28.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:52:28.329+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:52:28.329+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:52:28.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T02:52:58.554+0000] {processor.py:157} INFO - Started process (PID=1820) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:52:58.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:52:58.556+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:52:58.556+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:52:58.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:52:58.605+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:52:58.605+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:52:58.631+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:52:58.631+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:52:58.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T02:53:28.810+0000] {processor.py:157} INFO - Started process (PID=1822) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:53:28.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:53:28.812+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:53:28.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:53:28.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:53:28.865+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:53:28.865+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:53:28.886+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:53:28.886+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:53:28.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.180 seconds
[2024-10-23T02:53:59.159+0000] {processor.py:157} INFO - Started process (PID=1824) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:53:59.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:53:59.161+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:53:59.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:53:59.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:53:59.204+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:53:59.204+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:53:59.315+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:53:59.315+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:53:59.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.176 seconds
[2024-10-23T02:54:29.492+0000] {processor.py:157} INFO - Started process (PID=1826) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:54:29.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:54:29.494+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:54:29.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:54:29.505+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:54:29.530+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:54:29.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:54:29.556+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:54:29.556+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:54:29.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-23T02:54:59.729+0000] {processor.py:157} INFO - Started process (PID=1828) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:54:59.729+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:54:59.730+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:54:59.730+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:54:59.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:54:59.772+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:54:59.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:54:59.796+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:54:59.796+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:54:59.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T02:55:29.991+0000] {processor.py:157} INFO - Started process (PID=1830) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:55:29.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T02:55:29.993+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:55:29.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:55:30.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T02:55:30.030+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:55:30.030+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T02:55:30.051+0000] {logging_mixin.py:149} INFO - [2024-10-23T02:55:30.050+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T02:55:30.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-23T03:16:02.306+0000] {processor.py:157} INFO - Started process (PID=1831) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:16:02.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:16:02.357+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:16:02.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:16:02.424+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:16:02.501+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:16:02.501+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:16:02.753+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:16:02.751+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:16:02.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.809 seconds
[2024-10-23T03:16:34.576+0000] {processor.py:157} INFO - Started process (PID=1836) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:16:34.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:16:34.631+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:16:34.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:16:35.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:16:35.580+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:16:35.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:16:35.629+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:16:35.629+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:16:35.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.685 seconds
[2024-10-23T03:17:06.112+0000] {processor.py:157} INFO - Started process (PID=1837) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:17:06.113+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:17:06.113+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:17:06.113+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:17:06.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:17:06.159+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:17:06.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:17:06.302+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:17:06.302+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:17:06.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.208 seconds
[2024-10-23T03:17:36.470+0000] {processor.py:157} INFO - Started process (PID=1839) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:17:36.481+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:17:36.482+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:17:36.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:17:36.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:17:36.523+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:17:36.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:17:36.545+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:17:36.545+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:17:36.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T03:18:06.738+0000] {processor.py:157} INFO - Started process (PID=1841) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:18:06.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:18:06.740+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:18:06.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:18:06.755+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:18:06.786+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:18:06.786+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:18:06.811+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:18:06.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:18:06.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T03:18:36.990+0000] {processor.py:157} INFO - Started process (PID=1843) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:18:36.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:18:36.992+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:18:36.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:18:37.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:18:37.117+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:18:37.116+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:18:37.144+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:18:37.144+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:18:37.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.175 seconds
[2024-10-23T03:19:07.315+0000] {processor.py:157} INFO - Started process (PID=1845) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:19:07.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:19:07.318+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:19:07.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:19:07.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:19:07.388+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:19:07.388+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:19:07.422+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:19:07.422+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:19:07.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-23T03:19:37.610+0000] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:19:37.611+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:19:37.612+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:19:37.612+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:19:37.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:19:37.657+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:19:37.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:19:37.682+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:19:37.682+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:19:37.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.205 seconds
[2024-10-23T03:20:07.975+0000] {processor.py:157} INFO - Started process (PID=1849) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:20:07.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:20:07.976+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:20:07.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:20:07.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:20:08.015+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:20:08.014+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:20:08.171+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:20:08.171+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:20:08.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.217 seconds
[2024-10-23T03:20:38.361+0000] {processor.py:157} INFO - Started process (PID=1851) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:20:38.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:20:38.372+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:20:38.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:20:38.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:20:38.417+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:20:38.417+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:20:38.445+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:20:38.445+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:20:38.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T03:21:08.551+0000] {processor.py:157} INFO - Started process (PID=1853) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:21:08.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:21:08.552+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:21:08.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:21:08.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:21:08.606+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:21:08.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:21:08.634+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:21:08.634+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:21:08.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T03:21:38.831+0000] {processor.py:157} INFO - Started process (PID=1855) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:21:38.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:21:38.833+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:21:38.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:21:38.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:21:38.873+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:21:38.872+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:21:38.896+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:21:38.896+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:21:38.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-23T03:22:09.014+0000] {processor.py:157} INFO - Started process (PID=1857) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:22:09.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:22:09.017+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:22:09.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:22:09.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:22:09.082+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:22:09.082+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:22:09.114+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:22:09.113+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:22:09.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.139 seconds
[2024-10-23T03:22:39.324+0000] {processor.py:157} INFO - Started process (PID=1859) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:22:39.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:22:39.326+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:22:39.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:22:39.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:22:39.384+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:22:39.384+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:22:39.570+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:22:39.570+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:22:39.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.270 seconds
[2024-10-23T03:23:09.751+0000] {processor.py:157} INFO - Started process (PID=1861) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:23:09.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:23:09.752+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:23:09.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:23:09.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:23:09.792+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:23:09.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:23:09.922+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:23:09.922+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:23:09.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-23T03:23:40.136+0000] {processor.py:157} INFO - Started process (PID=1863) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:23:40.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:23:40.139+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:23:40.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:23:40.150+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:23:40.180+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:23:40.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:23:40.209+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:23:40.209+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:23:40.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T03:24:10.401+0000] {processor.py:157} INFO - Started process (PID=1865) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:24:10.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:24:10.403+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:24:10.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:24:10.423+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:24:10.452+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:24:10.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:24:10.476+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:24:10.476+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:24:10.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T03:24:40.558+0000] {processor.py:157} INFO - Started process (PID=1867) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:24:40.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:24:40.560+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:24:40.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:24:40.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:24:40.605+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:24:40.605+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:24:40.633+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:24:40.632+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:24:40.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T03:25:10.836+0000] {processor.py:157} INFO - Started process (PID=1869) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:25:10.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:25:10.838+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:25:10.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:25:10.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:25:10.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:25:10.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:25:10.902+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:25:10.902+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:25:10.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T03:25:41.084+0000] {processor.py:157} INFO - Started process (PID=1871) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:25:41.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:25:41.086+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:25:41.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:25:41.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:25:41.126+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:25:41.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:25:41.259+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:25:41.259+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:25:41.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-23T03:26:11.427+0000] {processor.py:157} INFO - Started process (PID=1873) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:26:11.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:26:11.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:26:11.429+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:26:11.447+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:26:11.478+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:26:11.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:26:11.624+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:26:11.624+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:26:11.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.217 seconds
[2024-10-23T03:26:41.816+0000] {processor.py:157} INFO - Started process (PID=1875) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:26:41.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:26:41.817+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:26:41.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:26:41.829+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:26:41.856+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:26:41.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:26:41.877+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:26:41.877+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:26:41.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T03:27:11.998+0000] {processor.py:157} INFO - Started process (PID=1877) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:27:12.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:27:12.000+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:27:12.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:27:12.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:27:12.037+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:27:12.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:27:12.061+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:27:12.061+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:27:12.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-23T03:27:42.254+0000] {processor.py:157} INFO - Started process (PID=1879) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:27:42.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:27:42.256+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:27:42.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:27:42.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:27:42.301+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:27:42.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:27:42.329+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:27:42.329+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:27:42.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T03:28:12.426+0000] {processor.py:157} INFO - Started process (PID=1881) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:28:12.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:28:12.428+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:28:12.428+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:28:12.441+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:28:12.476+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:28:12.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:28:12.501+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:28:12.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:28:12.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.227 seconds
[2024-10-23T03:28:42.792+0000] {processor.py:157} INFO - Started process (PID=1883) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:28:42.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:28:42.793+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:28:42.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:28:42.807+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:28:42.834+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:28:42.834+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:28:42.982+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:28:42.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:28:43.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.214 seconds
[2024-10-23T03:29:13.183+0000] {processor.py:157} INFO - Started process (PID=1885) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:29:13.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:29:13.185+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:29:13.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:29:13.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:29:13.224+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:29:13.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:29:13.349+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:29:13.349+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:29:13.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.189 seconds
[2024-10-23T03:29:43.545+0000] {processor.py:157} INFO - Started process (PID=1887) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:29:43.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:29:43.546+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:29:43.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:29:43.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:29:43.593+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:29:43.593+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:29:43.618+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:29:43.618+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:29:43.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T03:30:13.801+0000] {processor.py:157} INFO - Started process (PID=1889) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:30:13.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:30:13.803+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:30:13.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:30:13.819+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:30:13.851+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:30:13.851+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:30:13.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:30:13.878+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:30:13.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-23T03:30:43.963+0000] {processor.py:157} INFO - Started process (PID=1891) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:30:43.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:30:43.965+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:30:43.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:30:43.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:30:44.016+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:30:44.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:30:44.045+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:30:44.045+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:30:44.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T03:31:14.223+0000] {processor.py:157} INFO - Started process (PID=1893) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:31:14.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:31:14.225+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:31:14.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:31:14.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:31:14.273+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:31:14.273+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:31:14.299+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:31:14.299+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:31:14.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.216 seconds
[2024-10-23T03:31:44.617+0000] {processor.py:157} INFO - Started process (PID=1895) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:31:44.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:31:44.619+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:31:44.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:31:44.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:31:44.665+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:31:44.665+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:31:44.801+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:31:44.801+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:31:44.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.204 seconds
[2024-10-23T03:32:14.982+0000] {processor.py:157} INFO - Started process (PID=1897) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:32:14.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:32:14.984+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:32:14.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:32:15.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:32:15.031+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:32:15.031+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:32:15.164+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:32:15.164+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:32:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.204 seconds
[2024-10-23T03:32:45.341+0000] {processor.py:157} INFO - Started process (PID=1899) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:32:45.342+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:32:45.343+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:32:45.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:32:45.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:32:45.396+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:32:45.396+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:32:45.431+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:32:45.431+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:32:45.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T03:33:15.632+0000] {processor.py:157} INFO - Started process (PID=1901) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:33:15.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:33:15.633+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:33:15.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:33:15.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:33:15.673+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:33:15.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:33:15.698+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:33:15.698+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:33:15.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T03:33:45.883+0000] {processor.py:157} INFO - Started process (PID=1903) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:33:45.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:33:45.885+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:33:45.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:33:45.897+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:33:45.928+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:33:45.928+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:33:45.963+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:33:45.963+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:33:45.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T03:34:16.053+0000] {processor.py:157} INFO - Started process (PID=1905) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:34:16.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:34:16.054+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:34:16.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:34:16.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:34:16.096+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:34:16.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:34:16.121+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:34:16.121+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:34:16.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.220 seconds
[2024-10-23T03:34:46.411+0000] {processor.py:157} INFO - Started process (PID=1907) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:34:46.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:34:46.412+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:34:46.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:34:46.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:34:46.457+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:34:46.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:34:46.585+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:34:46.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:34:46.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.196 seconds
[2024-10-23T03:35:16.745+0000] {processor.py:157} INFO - Started process (PID=1909) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:35:16.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:35:16.747+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:35:16.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:35:16.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:35:16.796+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:35:16.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:35:16.939+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:35:16.939+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:35:16.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.216 seconds
[2024-10-23T03:35:47.119+0000] {processor.py:157} INFO - Started process (PID=1911) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:35:47.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:35:47.122+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:35:47.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:35:47.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:35:47.174+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:35:47.174+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:35:47.209+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:35:47.209+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:35:47.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T03:36:17.298+0000] {processor.py:157} INFO - Started process (PID=1913) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:36:17.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:36:17.299+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:36:17.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:36:17.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:36:17.343+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:36:17.343+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:36:17.369+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:36:17.369+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:36:17.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T03:36:47.579+0000] {processor.py:157} INFO - Started process (PID=1915) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:36:47.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:36:47.581+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:36:47.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:36:47.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:36:47.622+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:36:47.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:36:47.644+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:36:47.644+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:36:47.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T03:37:17.751+0000] {processor.py:157} INFO - Started process (PID=1917) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:37:17.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:37:17.752+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:37:17.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:37:17.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:37:17.792+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:37:17.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:37:17.909+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:37:17.909+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:37:17.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.179 seconds
[2024-10-23T03:37:47.951+0000] {processor.py:157} INFO - Started process (PID=1919) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:37:47.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:37:47.953+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:37:47.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:37:47.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:37:47.998+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:37:47.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:37:48.113+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:37:48.113+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:37:48.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.181 seconds
[2024-10-23T03:38:18.293+0000] {processor.py:157} INFO - Started process (PID=1921) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:38:18.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:38:18.295+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:38:18.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:38:18.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:38:18.361+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:38:18.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:38:18.483+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:38:18.482+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:38:18.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.212 seconds
[2024-10-23T03:38:48.629+0000] {processor.py:157} INFO - Started process (PID=1923) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:38:48.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:38:48.631+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:38:48.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:38:48.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:38:48.684+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:38:48.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:38:48.715+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:38:48.714+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:38:48.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T03:39:18.786+0000] {processor.py:157} INFO - Started process (PID=1925) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:39:18.787+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:39:18.787+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:39:18.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:39:18.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:39:18.830+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:39:18.829+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:39:18.855+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:39:18.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:39:18.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T03:39:49.060+0000] {processor.py:157} INFO - Started process (PID=1927) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:39:49.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:39:49.062+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:39:49.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:39:49.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:39:49.103+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:39:49.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:39:49.126+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:39:49.126+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:39:49.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T03:40:19.338+0000] {processor.py:157} INFO - Started process (PID=1929) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:40:19.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:40:19.340+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:40:19.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:40:19.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:40:19.383+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:40:19.383+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:40:19.509+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:40:19.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:40:19.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.193 seconds
[2024-10-23T03:40:49.732+0000] {processor.py:157} INFO - Started process (PID=1931) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:40:49.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:40:49.733+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:40:49.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:40:49.745+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:40:49.770+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:40:49.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:40:49.884+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:40:49.884+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:40:49.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.170 seconds
[2024-10-23T03:41:19.921+0000] {processor.py:157} INFO - Started process (PID=1933) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:41:19.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:41:19.922+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:41:19.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:41:19.935+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:41:20.066+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:41:20.066+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:41:20.086+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:41:20.086+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:41:20.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-23T03:41:50.262+0000] {processor.py:157} INFO - Started process (PID=1935) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:41:50.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:41:50.275+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:41:50.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:41:50.286+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:41:50.314+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:41:50.314+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:41:50.336+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:41:50.336+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:41:50.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T03:42:20.441+0000] {processor.py:157} INFO - Started process (PID=1937) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:42:20.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:42:20.442+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:42:20.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:42:20.455+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:42:20.487+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:42:20.487+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:42:20.510+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:42:20.510+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:42:20.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T03:42:50.747+0000] {processor.py:157} INFO - Started process (PID=1939) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:42:50.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:42:50.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:42:50.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:42:50.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:42:50.793+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:42:50.793+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:42:50.820+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:42:50.819+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:42:50.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.208 seconds
[2024-10-23T03:43:21.134+0000] {processor.py:157} INFO - Started process (PID=1941) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:43:21.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:43:21.136+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:43:21.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:43:21.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:43:21.176+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:43:21.176+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:43:21.295+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:43:21.295+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:43:21.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.182 seconds
[2024-10-23T03:43:51.500+0000] {processor.py:157} INFO - Started process (PID=1943) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:43:51.501+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:43:51.502+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:43:51.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:43:51.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:43:51.539+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:43:51.539+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:43:51.658+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:43:51.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:43:51.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.177 seconds
[2024-10-23T03:44:21.851+0000] {processor.py:157} INFO - Started process (PID=1945) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:44:21.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:44:21.852+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:44:21.852+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:44:21.863+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:44:21.979+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:44:21.979+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:44:21.999+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:44:21.998+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:44:22.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.170 seconds
[2024-10-23T03:44:52.148+0000] {processor.py:157} INFO - Started process (PID=1947) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:44:52.150+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:44:52.150+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:44:52.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:44:52.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:44:52.189+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:44:52.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:44:52.213+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:44:52.212+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:44:52.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T03:45:22.413+0000] {processor.py:157} INFO - Started process (PID=1949) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:45:22.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:45:22.415+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:45:22.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:45:22.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:45:22.458+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:45:22.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:45:22.480+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:45:22.479+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:45:22.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T03:45:52.682+0000] {processor.py:157} INFO - Started process (PID=1951) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:45:52.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:45:52.683+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:45:52.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:45:52.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:45:52.720+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:45:52.719+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:45:52.742+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:45:52.742+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:45:52.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.171 seconds
[2024-10-23T03:46:22.874+0000] {processor.py:157} INFO - Started process (PID=1953) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:46:22.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:46:22.876+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:46:22.876+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:46:22.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:46:22.920+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:46:22.920+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:46:23.033+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:46:23.032+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:46:23.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.179 seconds
[2024-10-23T03:46:53.259+0000] {processor.py:157} INFO - Started process (PID=1955) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:46:53.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:46:53.263+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:46:53.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:46:53.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:46:53.303+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:46:53.303+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:46:53.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:46:53.429+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:46:53.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.200 seconds
[2024-10-23T03:47:23.577+0000] {processor.py:157} INFO - Started process (PID=1957) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:47:23.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:47:23.579+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:47:23.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:47:23.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:47:23.728+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:47:23.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:47:23.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:47:23.748+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:47:23.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.191 seconds
[2024-10-23T03:47:53.932+0000] {processor.py:157} INFO - Started process (PID=1959) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:47:53.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:47:53.934+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:47:53.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:47:53.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:47:53.980+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:47:53.980+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:47:54.002+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:47:54.001+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:47:54.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T03:48:24.107+0000] {processor.py:157} INFO - Started process (PID=1961) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:48:24.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:48:24.109+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:48:24.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:48:24.124+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:48:24.152+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:48:24.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:48:24.179+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:48:24.179+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:48:24.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T03:48:54.367+0000] {processor.py:157} INFO - Started process (PID=1963) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:48:54.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:48:54.368+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:48:54.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:48:54.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:48:54.409+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:48:54.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:48:54.433+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:48:54.433+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:48:54.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.173 seconds
[2024-10-23T03:49:24.737+0000] {processor.py:157} INFO - Started process (PID=1965) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:49:24.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:49:24.739+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:49:24.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:49:24.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:49:24.781+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:49:24.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:49:24.908+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:49:24.908+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:49:24.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-23T03:49:55.102+0000] {processor.py:157} INFO - Started process (PID=1967) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:49:55.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:49:55.103+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:49:55.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:49:55.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:49:55.146+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:49:55.145+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:49:55.251+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:49:55.251+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:49:55.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-23T03:50:25.405+0000] {processor.py:157} INFO - Started process (PID=1969) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:50:25.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:50:25.408+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:50:25.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:50:25.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:50:25.565+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:50:25.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:50:25.590+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:50:25.590+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:50:25.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.208 seconds
[2024-10-23T03:50:55.745+0000] {processor.py:157} INFO - Started process (PID=1971) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:50:55.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:50:55.747+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:50:55.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:50:55.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:50:55.794+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:50:55.793+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:50:55.820+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:50:55.819+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:50:55.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T03:51:26.040+0000] {processor.py:157} INFO - Started process (PID=1973) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:51:26.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:51:26.042+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:51:26.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:51:26.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:51:26.084+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:51:26.084+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:51:26.106+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:51:26.106+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:51:26.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T03:51:56.295+0000] {processor.py:157} INFO - Started process (PID=1975) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:51:56.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:51:56.297+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:51:56.296+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:51:56.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:51:56.349+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:51:56.348+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:51:56.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:51:56.377+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:51:56.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.218 seconds
[2024-10-23T03:52:26.640+0000] {processor.py:157} INFO - Started process (PID=1977) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:52:26.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:52:26.642+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:52:26.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:52:26.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:52:26.680+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:52:26.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:52:26.820+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:52:26.820+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:52:26.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.201 seconds
[2024-10-23T03:52:56.994+0000] {processor.py:157} INFO - Started process (PID=1979) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:52:56.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:52:56.995+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:52:56.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:52:57.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:52:57.040+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:52:57.040+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:52:57.173+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:52:57.173+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:52:57.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.203 seconds
[2024-10-23T03:53:27.338+0000] {processor.py:157} INFO - Started process (PID=1981) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:53:27.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:53:27.340+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:53:27.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:53:27.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:53:27.490+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:53:27.490+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:53:27.514+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:53:27.514+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:53:27.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-23T03:53:57.681+0000] {processor.py:157} INFO - Started process (PID=1983) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:53:57.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:53:57.682+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:53:57.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:53:57.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:53:57.724+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:53:57.723+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:53:57.747+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:53:57.747+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:53:57.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-23T03:54:27.872+0000] {processor.py:157} INFO - Started process (PID=1985) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:54:27.873+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:54:27.874+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:54:27.874+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:54:27.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:54:27.918+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:54:27.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:54:27.942+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:54:27.942+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:54:27.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T03:54:58.105+0000] {processor.py:157} INFO - Started process (PID=1987) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:54:58.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:54:58.106+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:54:58.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:54:58.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:54:58.148+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:54:58.148+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:54:58.265+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:54:58.265+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:54:58.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.178 seconds
[2024-10-23T03:55:28.464+0000] {processor.py:157} INFO - Started process (PID=1989) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:55:28.466+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:55:28.466+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:55:28.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:55:28.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:55:28.512+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:55:28.512+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:55:28.628+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:55:28.628+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:55:28.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.182 seconds
[2024-10-23T03:55:58.790+0000] {processor.py:157} INFO - Started process (PID=1991) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:55:58.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:55:58.792+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:55:58.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:55:58.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:55:58.835+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:55:58.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:55:58.988+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:55:58.988+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:55:59.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.216 seconds
[2024-10-23T03:56:29.181+0000] {processor.py:157} INFO - Started process (PID=1993) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:56:29.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:56:29.183+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:56:29.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:56:29.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:56:29.336+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:56:29.336+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:56:29.357+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:56:29.357+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:56:29.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-23T03:56:59.545+0000] {processor.py:157} INFO - Started process (PID=1995) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:56:59.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:56:59.546+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:56:59.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:56:59.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:56:59.594+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:56:59.594+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:56:59.617+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:56:59.616+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:56:59.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T03:57:29.805+0000] {processor.py:157} INFO - Started process (PID=1997) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:57:29.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:57:29.806+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:57:29.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:57:29.819+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:57:29.847+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:57:29.847+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:57:29.871+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:57:29.871+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:57:29.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.180 seconds
[2024-10-23T03:58:00.147+0000] {processor.py:157} INFO - Started process (PID=1999) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:58:00.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:58:00.148+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:58:00.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:58:00.161+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:58:00.190+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:58:00.190+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:58:00.306+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:58:00.306+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:58:00.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-23T03:58:30.494+0000] {processor.py:157} INFO - Started process (PID=2001) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:58:30.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:58:30.496+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:58:30.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:58:30.508+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:58:30.534+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:58:30.534+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:58:30.640+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:58:30.640+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:58:30.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-23T03:59:00.822+0000] {processor.py:157} INFO - Started process (PID=2003) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:59:00.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:59:00.823+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:59:00.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:59:00.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:59:00.947+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:59:00.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:59:00.966+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:59:00.966+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:59:00.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-23T03:59:31.115+0000] {processor.py:157} INFO - Started process (PID=2005) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:59:31.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T03:59:31.117+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:59:31.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:59:31.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T03:59:31.248+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:59:31.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T03:59:31.273+0000] {logging_mixin.py:149} INFO - [2024-10-23T03:59:31.273+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T03:59:31.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.178 seconds
[2024-10-23T04:00:01.454+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:00:01.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:00:01.456+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:00:01.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:00:01.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:00:01.623+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:00:01.623+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:00:01.650+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:00:01.650+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:00:01.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.218 seconds
[2024-10-23T04:00:31.803+0000] {processor.py:157} INFO - Started process (PID=2009) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:00:31.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:00:31.806+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:00:31.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:00:31.820+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:00:31.850+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:00:31.850+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:00:31.877+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:00:31.877+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:00:32.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.200 seconds
[2024-10-23T04:01:02.178+0000] {processor.py:157} INFO - Started process (PID=2011) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:01:02.179+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:01:02.179+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:01:02.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:01:02.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:01:02.223+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:01:02.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:01:02.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:01:02.377+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:01:02.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.223 seconds
[2024-10-23T04:01:32.531+0000] {processor.py:157} INFO - Started process (PID=2013) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:01:32.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:01:32.533+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:01:32.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:01:32.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:01:32.579+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:01:32.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:01:32.715+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:01:32.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:01:32.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.204 seconds
[2024-10-23T04:02:02.876+0000] {processor.py:157} INFO - Started process (PID=2015) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:02:02.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:02:02.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:02:02.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:02:02.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:02:03.024+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:02:03.024+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:02:03.047+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:02:03.047+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:02:03.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-23T04:02:33.196+0000] {processor.py:157} INFO - Started process (PID=2017) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:02:33.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:02:33.198+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:02:33.197+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:02:33.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:02:33.324+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:02:33.324+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:02:33.343+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:02:33.343+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:02:33.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.167 seconds
[2024-10-23T04:03:03.509+0000] {processor.py:157} INFO - Started process (PID=2019) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:03:03.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:03:03.511+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:03:03.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:03:03.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:03:03.557+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:03:03.557+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:03:03.585+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:03:03.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:03:03.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T04:03:33.789+0000] {processor.py:157} INFO - Started process (PID=2021) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:03:33.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:03:33.791+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:03:33.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:03:33.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:03:33.827+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:03:33.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:03:33.851+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:03:33.850+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:03:33.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.170 seconds
[2024-10-23T04:04:04.115+0000] {processor.py:157} INFO - Started process (PID=2023) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:04:04.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:04:04.117+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:04:04.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:04:04.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:04:04.163+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:04:04.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:04:04.277+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:04:04.277+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:04:04.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.183 seconds
[2024-10-23T04:04:34.479+0000] {processor.py:157} INFO - Started process (PID=2025) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:04:34.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:04:34.481+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:04:34.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:04:34.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:04:34.521+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:04:34.521+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:04:34.635+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:04:34.635+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:04:34.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.175 seconds
[2024-10-23T04:05:04.801+0000] {processor.py:157} INFO - Started process (PID=2027) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:05:04.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:05:04.810+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:05:04.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:05:04.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:05:04.930+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:05:04.929+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:05:04.951+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:05:04.950+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:05:04.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-23T04:05:35.101+0000] {processor.py:157} INFO - Started process (PID=2029) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:05:35.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:05:35.103+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:05:35.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:05:35.116+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:05:35.245+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:05:35.245+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:05:35.269+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:05:35.269+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:05:35.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.190 seconds
[2024-10-23T04:06:05.458+0000] {processor.py:157} INFO - Started process (PID=2031) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:06:05.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:06:05.461+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:06:05.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:06:05.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:06:05.502+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:06:05.502+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:06:05.534+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:06:05.534+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:06:05.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T04:06:35.614+0000] {processor.py:157} INFO - Started process (PID=2033) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:06:35.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:06:35.615+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:06:35.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:06:35.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:06:35.661+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:06:35.661+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:06:35.692+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:06:35.692+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:06:35.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.206 seconds
[2024-10-23T04:07:05.985+0000] {processor.py:157} INFO - Started process (PID=2035) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:07:05.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:07:05.987+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:07:05.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:07:06.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:07:06.080+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:07:06.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:07:06.278+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:07:06.278+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:07:06.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.315 seconds
[2024-10-23T04:07:36.482+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:07:36.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:07:36.486+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:07:36.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:07:36.510+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:07:36.552+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:07:36.552+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:07:36.823+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:07:36.823+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:07:36.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.390 seconds
[2024-10-23T04:08:07.043+0000] {processor.py:157} INFO - Started process (PID=2039) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:08:07.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:08:07.045+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:08:07.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:08:07.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:08:07.182+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:08:07.181+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:08:07.212+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:08:07.211+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:08:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-23T04:08:37.399+0000] {processor.py:157} INFO - Started process (PID=2041) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:08:37.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:08:37.400+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:08:37.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:08:37.530+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:08:37.554+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:08:37.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:08:37.579+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:08:37.578+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:08:37.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.202 seconds
[2024-10-23T04:09:07.758+0000] {processor.py:157} INFO - Started process (PID=2043) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:09:07.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:09:07.761+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:09:07.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:09:07.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:09:07.801+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:09:07.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:09:07.825+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:09:07.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:09:07.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T04:09:37.929+0000] {processor.py:157} INFO - Started process (PID=2045) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:09:37.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:09:37.930+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:09:37.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:09:37.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:09:37.967+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:09:37.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:09:38.091+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:09:38.091+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:09:38.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.183 seconds
[2024-10-23T04:10:08.289+0000] {processor.py:157} INFO - Started process (PID=2047) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:10:08.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:10:08.292+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:10:08.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:10:08.305+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:10:08.332+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:10:08.331+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:10:08.456+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:10:08.456+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:10:08.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.198 seconds
[2024-10-23T04:10:38.656+0000] {processor.py:157} INFO - Started process (PID=2049) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:10:38.657+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:10:38.658+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:10:38.658+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:10:38.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:10:38.704+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:10:38.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:10:38.853+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:10:38.853+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:10:38.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.216 seconds
[2024-10-23T04:11:09.058+0000] {processor.py:157} INFO - Started process (PID=2051) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:11:09.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:11:09.066+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:11:09.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:11:09.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:11:09.219+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:11:09.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:11:09.238+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:11:09.238+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:11:09.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-23T04:11:39.425+0000] {processor.py:157} INFO - Started process (PID=2053) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:11:39.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:11:39.426+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:11:39.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:11:39.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:11:39.554+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:11:39.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:11:39.583+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:11:39.583+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:11:39.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.180 seconds
[2024-10-23T04:12:09.917+0000] {processor.py:157} INFO - Started process (PID=2055) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:12:09.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:12:09.919+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:12:09.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:12:09.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:12:09.961+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:12:09.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:12:09.987+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:12:09.987+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:12:10.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T04:12:40.076+0000] {processor.py:157} INFO - Started process (PID=2057) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:12:40.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:12:40.078+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:12:40.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:12:40.094+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:12:40.126+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:12:40.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:12:40.154+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:12:40.154+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:12:40.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T04:13:10.328+0000] {processor.py:157} INFO - Started process (PID=2059) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:13:10.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:13:10.330+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:13:10.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:13:10.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:13:10.370+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:13:10.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:13:10.394+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:13:10.394+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:13:10.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T04:13:40.581+0000] {processor.py:157} INFO - Started process (PID=2061) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:13:40.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:13:40.583+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:13:40.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:13:40.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:13:40.623+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:13:40.623+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:13:40.645+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:13:40.645+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:13:40.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-23T04:14:10.758+0000] {processor.py:157} INFO - Started process (PID=2063) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:14:10.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:14:10.759+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:14:10.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:14:10.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:14:10.801+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:14:10.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:14:10.824+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:14:10.824+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:14:10.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T04:14:40.966+0000] {processor.py:157} INFO - Started process (PID=2065) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:14:40.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:14:40.968+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:14:40.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:14:40.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:14:41.008+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:14:41.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:14:41.029+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:14:41.029+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:14:41.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T04:15:11.116+0000] {processor.py:157} INFO - Started process (PID=2067) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:15:11.118+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:15:11.118+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:15:11.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:15:11.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:15:11.160+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:15:11.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:15:11.186+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:15:11.185+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:15:11.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T04:15:41.380+0000] {processor.py:157} INFO - Started process (PID=2069) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:15:41.380+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:15:41.381+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:15:41.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:15:41.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:15:41.426+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:15:41.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:15:41.450+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:15:41.450+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:15:41.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T04:16:11.549+0000] {processor.py:157} INFO - Started process (PID=2071) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:16:11.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:16:11.562+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:16:11.562+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:16:11.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:16:11.604+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:16:11.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:16:11.631+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:16:11.631+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:16:11.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T04:16:41.754+0000] {processor.py:157} INFO - Started process (PID=2073) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:16:41.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:16:41.755+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:16:41.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:16:41.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:16:41.798+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:16:41.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:16:41.821+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:16:41.821+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:16:41.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T04:17:11.959+0000] {processor.py:157} INFO - Started process (PID=2075) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:17:11.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:17:11.961+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:17:11.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:17:11.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:17:12.001+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:17:12.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:17:12.023+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:17:12.023+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:17:12.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T04:17:42.217+0000] {processor.py:157} INFO - Started process (PID=2077) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:17:42.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:17:42.219+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:17:42.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:17:42.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:17:42.261+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:17:42.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:17:42.284+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:17:42.284+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:17:42.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-23T04:18:12.379+0000] {processor.py:157} INFO - Started process (PID=2079) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:18:12.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:18:12.391+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:18:12.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:18:12.402+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:18:12.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:18:12.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:18:12.451+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:18:12.451+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:18:12.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T04:18:42.597+0000] {processor.py:157} INFO - Started process (PID=2081) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:18:42.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:18:42.599+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:18:42.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:18:42.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:18:42.773+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:18:42.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:18:42.794+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:18:42.794+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:18:42.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.216 seconds
[2024-10-23T04:19:12.852+0000] {processor.py:157} INFO - Started process (PID=2083) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:19:12.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:19:12.865+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:19:12.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:19:12.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:19:12.901+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:19:12.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:19:12.922+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:19:12.922+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:19:12.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T04:19:43.106+0000] {processor.py:157} INFO - Started process (PID=2085) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:19:43.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:19:43.108+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:19:43.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:19:43.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:19:43.152+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:19:43.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:19:43.184+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:19:43.183+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:19:43.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T04:20:13.377+0000] {processor.py:157} INFO - Started process (PID=2087) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:20:13.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:20:13.380+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:20:13.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:20:13.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:20:13.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:20:13.429+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:20:13.457+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:20:13.456+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:20:13.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T04:20:43.643+0000] {processor.py:157} INFO - Started process (PID=2089) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:20:43.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:20:43.644+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:20:43.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:20:43.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:20:43.691+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:20:43.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:20:43.727+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:20:43.726+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:20:43.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T04:21:13.955+0000] {processor.py:157} INFO - Started process (PID=2091) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:21:13.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:21:13.957+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:21:13.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:21:13.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:21:13.997+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:21:13.996+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:21:14.020+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:21:14.019+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:21:14.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T04:21:44.143+0000] {processor.py:157} INFO - Started process (PID=2093) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:21:44.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:21:44.145+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:21:44.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:21:44.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:21:44.211+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:21:44.210+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:21:44.246+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:21:44.246+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:21:44.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-23T04:22:14.445+0000] {processor.py:157} INFO - Started process (PID=2095) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:22:14.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:22:14.447+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:22:14.446+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:22:14.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:22:14.482+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:22:14.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:22:14.505+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:22:14.505+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:22:14.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T04:22:44.628+0000] {processor.py:157} INFO - Started process (PID=2097) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:22:44.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:22:44.630+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:22:44.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:22:44.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:22:44.667+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:22:44.667+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:22:44.690+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:22:44.690+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:22:44.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T04:23:14.893+0000] {processor.py:157} INFO - Started process (PID=2099) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:23:14.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:23:14.905+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:23:14.905+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:23:14.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:23:14.942+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:23:14.942+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:23:14.968+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:23:14.968+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:23:14.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T04:23:45.178+0000] {processor.py:157} INFO - Started process (PID=2101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:23:45.179+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:23:45.180+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:23:45.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:23:45.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:23:45.218+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:23:45.218+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:23:45.239+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:23:45.239+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:23:45.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T04:24:15.460+0000] {processor.py:157} INFO - Started process (PID=2103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:24:15.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:24:15.462+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:24:15.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:24:15.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:24:15.500+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:24:15.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:24:15.527+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:24:15.527+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:24:15.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T04:24:45.672+0000] {processor.py:157} INFO - Started process (PID=2105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:24:45.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:24:45.673+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:24:45.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:24:45.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:24:45.709+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:24:45.709+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:24:45.731+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:24:45.731+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:24:45.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T04:25:15.950+0000] {processor.py:157} INFO - Started process (PID=2107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:25:15.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:25:15.952+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:25:15.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:25:15.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:25:15.990+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:25:15.990+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:25:16.013+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:25:16.013+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:25:16.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T04:25:46.163+0000] {processor.py:157} INFO - Started process (PID=2109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:25:46.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:25:46.165+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:25:46.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:25:46.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:25:46.204+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:25:46.204+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:25:46.227+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:25:46.227+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:25:46.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T04:26:16.390+0000] {processor.py:157} INFO - Started process (PID=2111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:26:16.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:26:16.391+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:26:16.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:26:16.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:26:16.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:26:16.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:26:16.452+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:26:16.452+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:26:16.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T04:26:46.571+0000] {processor.py:157} INFO - Started process (PID=2113) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:26:46.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:26:46.573+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:26:46.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:26:46.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:26:46.609+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:26:46.609+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:26:46.630+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:26:46.630+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:26:46.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T04:27:16.833+0000] {processor.py:157} INFO - Started process (PID=2115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:27:16.834+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:27:16.835+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:27:16.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:27:16.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:27:16.873+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:27:16.872+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:27:16.894+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:27:16.894+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:27:16.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-23T04:27:47.083+0000] {processor.py:157} INFO - Started process (PID=2117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:27:47.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:27:47.085+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:27:47.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:27:47.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:27:47.126+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:27:47.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:27:47.148+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:27:47.148+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:27:47.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T04:28:17.243+0000] {processor.py:157} INFO - Started process (PID=2119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:28:17.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:28:17.244+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:28:17.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:28:17.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:28:17.287+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:28:17.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:28:17.312+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:28:17.312+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:28:17.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-23T04:28:47.471+0000] {processor.py:157} INFO - Started process (PID=2121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:28:47.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:28:47.475+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:28:47.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:28:47.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:28:47.536+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:28:47.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:28:47.574+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:28:47.574+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:28:47.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-23T04:29:17.630+0000] {processor.py:157} INFO - Started process (PID=2123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:29:17.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:29:17.632+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:29:17.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:29:17.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:29:17.674+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:29:17.674+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:29:17.698+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:29:17.698+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:29:17.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T04:29:47.895+0000] {processor.py:157} INFO - Started process (PID=2125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:29:47.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:29:47.897+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:29:47.897+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:29:47.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:29:47.940+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:29:47.940+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:29:47.963+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:29:47.963+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:29:47.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T04:30:18.064+0000] {processor.py:157} INFO - Started process (PID=2127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:30:18.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:30:18.066+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:30:18.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:30:18.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:30:18.115+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:30:18.115+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:30:18.144+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:30:18.144+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:30:18.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T04:30:48.340+0000] {processor.py:157} INFO - Started process (PID=2129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:30:48.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:30:48.342+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:30:48.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:30:48.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:30:48.380+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:30:48.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:30:48.401+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:30:48.401+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:30:48.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T04:31:18.531+0000] {processor.py:157} INFO - Started process (PID=2131) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:31:18.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:31:18.532+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:31:18.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:31:18.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:31:18.570+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:31:18.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:31:18.591+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:31:18.590+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:31:18.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-23T04:31:48.814+0000] {processor.py:157} INFO - Started process (PID=2133) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:31:48.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:31:48.827+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:31:48.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:31:48.839+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:31:48.865+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:31:48.865+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:31:48.886+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:31:48.886+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:31:48.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T04:32:18.994+0000] {processor.py:157} INFO - Started process (PID=2135) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:32:18.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:32:18.996+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:32:18.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:32:19.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:32:19.038+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:32:19.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:32:19.064+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:32:19.064+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:32:19.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T04:32:49.250+0000] {processor.py:157} INFO - Started process (PID=2137) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:32:49.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:32:49.262+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:32:49.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:32:49.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:32:49.301+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:32:49.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:32:49.324+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:32:49.324+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:32:49.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T04:33:19.422+0000] {processor.py:157} INFO - Started process (PID=2139) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:33:19.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:33:19.424+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:33:19.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:33:19.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:33:19.468+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:33:19.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:33:19.493+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:33:19.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:33:19.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T04:33:49.633+0000] {processor.py:157} INFO - Started process (PID=2141) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:33:49.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:33:49.635+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:33:49.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:33:49.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:33:49.673+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:33:49.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:33:49.699+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:33:49.699+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:33:49.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T04:34:19.877+0000] {processor.py:157} INFO - Started process (PID=2143) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:34:19.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:34:19.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:34:19.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:34:19.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:34:19.925+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:34:19.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:34:19.950+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:34:19.950+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:34:19.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T04:34:50.051+0000] {processor.py:157} INFO - Started process (PID=2145) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:34:50.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:34:50.052+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:34:50.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:34:50.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:34:50.100+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:34:50.100+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:34:50.128+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:34:50.128+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:34:50.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T04:35:20.243+0000] {processor.py:157} INFO - Started process (PID=2147) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:35:20.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:35:20.245+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:35:20.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:35:20.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:35:20.290+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:35:20.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:35:20.312+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:35:20.311+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:35:20.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T04:35:51.011+0000] {processor.py:157} INFO - Started process (PID=2149) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:35:51.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T04:35:51.013+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:35:51.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:35:51.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T04:35:51.107+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:35:51.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T04:35:51.141+0000] {logging_mixin.py:149} INFO - [2024-10-23T04:35:51.141+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T04:35:51.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.230 seconds
[2024-10-23T05:12:32.232+0000] {processor.py:157} INFO - Started process (PID=2151) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T05:12:32.233+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T05:12:32.234+0000] {logging_mixin.py:149} INFO - [2024-10-23T05:12:32.234+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T05:12:32.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T05:12:32.940+0000] {logging_mixin.py:149} INFO - [2024-10-23T05:12:32.940+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T05:12:33.056+0000] {logging_mixin.py:149} INFO - [2024-10-23T05:12:33.055+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T05:12:33.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.995 seconds
[2024-10-23T12:38:03.287+0000] {processor.py:157} INFO - Started process (PID=2157) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:38:03.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:38:03.290+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:38:03.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:38:03.488+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:38:03.863+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:38:03.863+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:38:03.977+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:38:03.976+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:38:04.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.072 seconds
[2024-10-23T12:38:34.306+0000] {processor.py:157} INFO - Started process (PID=2159) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:38:34.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:38:34.309+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:38:34.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:38:34.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:38:34.375+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:38:34.375+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:38:34.420+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:38:34.420+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:38:34.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-23T12:39:14.622+0000] {processor.py:157} INFO - Started process (PID=2161) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:39:14.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:39:14.624+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:39:14.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:39:14.638+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:39:14.668+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:39:14.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:39:14.697+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:39:14.697+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:39:14.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T12:39:44.933+0000] {processor.py:157} INFO - Started process (PID=2163) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:39:44.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:39:44.935+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:39:44.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:39:44.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:39:45.030+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:39:45.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:39:45.055+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:39:45.055+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:39:45.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-23T12:40:15.257+0000] {processor.py:157} INFO - Started process (PID=2165) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:40:15.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:40:15.259+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:40:15.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:40:15.273+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:40:15.306+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:40:15.306+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:40:15.348+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:40:15.348+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:40:15.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T12:40:45.428+0000] {processor.py:157} INFO - Started process (PID=2167) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:40:45.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:40:45.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:40:45.429+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:40:45.443+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:40:45.475+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:40:45.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:40:45.503+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:40:45.503+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:40:45.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T12:41:15.717+0000] {processor.py:157} INFO - Started process (PID=2169) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:41:15.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:41:15.719+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:41:15.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:41:15.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:41:15.768+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:41:15.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:41:15.804+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:41:15.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:41:15.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T12:41:46.016+0000] {processor.py:157} INFO - Started process (PID=2171) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:41:46.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:41:46.018+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:41:46.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:41:46.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:41:46.062+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:41:46.062+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:41:46.093+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:41:46.093+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:41:46.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T12:42:16.297+0000] {processor.py:157} INFO - Started process (PID=2173) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:42:16.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:42:16.310+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:42:16.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:42:16.328+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:42:16.364+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:42:16.364+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:42:16.395+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:42:16.395+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:42:16.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-23T12:42:46.465+0000] {processor.py:157} INFO - Started process (PID=2175) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:42:46.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:42:46.466+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:42:46.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:42:46.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:42:46.511+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:42:46.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:42:46.538+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:42:46.538+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:42:46.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T12:43:16.743+0000] {processor.py:157} INFO - Started process (PID=2177) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:43:16.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:43:16.766+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:43:16.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:43:16.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:43:16.849+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:43:16.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:43:16.873+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:43:16.873+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:43:16.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.150 seconds
[2024-10-23T12:43:47.070+0000] {processor.py:157} INFO - Started process (PID=2179) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:43:47.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:43:47.071+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:43:47.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:43:47.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:43:47.119+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:43:47.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:43:47.152+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:43:47.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:43:47.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T12:44:17.348+0000] {processor.py:157} INFO - Started process (PID=2181) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:44:17.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:44:17.350+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:44:17.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:44:17.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:44:17.397+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:44:17.397+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:44:17.427+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:44:17.427+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:44:17.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T12:44:47.498+0000] {processor.py:157} INFO - Started process (PID=2183) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:44:47.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:44:47.500+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:44:47.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:44:47.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:44:47.550+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:44:47.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:44:47.583+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:44:47.583+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:44:47.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T12:45:17.743+0000] {processor.py:157} INFO - Started process (PID=2185) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:45:17.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:45:17.746+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:45:17.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:45:17.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:45:17.791+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:45:17.791+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:45:17.819+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:45:17.818+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:45:17.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T12:45:47.905+0000] {processor.py:157} INFO - Started process (PID=2187) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:45:47.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:45:47.907+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:45:47.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:45:47.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:45:47.973+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:45:47.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:45:48.010+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:45:48.010+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:45:48.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-23T12:46:18.211+0000] {processor.py:157} INFO - Started process (PID=2189) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:46:18.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:46:18.224+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:46:18.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:46:18.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:46:18.267+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:46:18.267+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:46:18.299+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:46:18.299+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:46:18.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T12:46:48.375+0000] {processor.py:157} INFO - Started process (PID=2191) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:46:48.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:46:48.377+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:46:48.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:46:48.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:46:48.432+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:46:48.432+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:46:48.464+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:46:48.464+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:46:48.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T12:47:18.632+0000] {processor.py:157} INFO - Started process (PID=2193) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:47:18.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:47:18.634+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:47:18.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:47:18.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:47:18.683+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:47:18.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:47:18.708+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:47:18.708+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:47:18.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T12:47:48.913+0000] {processor.py:157} INFO - Started process (PID=2195) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:47:48.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:47:48.915+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:47:48.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:47:48.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:47:48.961+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:47:48.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:47:48.992+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:47:48.992+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:47:49.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T12:48:19.198+0000] {processor.py:157} INFO - Started process (PID=2197) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:48:19.199+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:48:19.200+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:48:19.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:48:19.214+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:48:19.244+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:48:19.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:48:19.271+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:48:19.271+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:48:19.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T12:48:49.456+0000] {processor.py:157} INFO - Started process (PID=2199) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:48:49.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:48:49.457+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:48:49.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:48:49.472+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:48:49.501+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:48:49.501+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:48:49.530+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:48:49.530+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:48:49.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T12:49:19.631+0000] {processor.py:157} INFO - Started process (PID=2201) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:49:19.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:49:19.633+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:49:19.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:49:19.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:49:19.680+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:49:19.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:49:19.706+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:49:19.706+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:49:19.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T12:49:49.902+0000] {processor.py:157} INFO - Started process (PID=2203) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:49:49.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:49:49.904+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:49:49.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:49:49.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:49:49.960+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:49:49.960+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:49:49.995+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:49:49.995+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:49:50.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T12:50:20.200+0000] {processor.py:157} INFO - Started process (PID=2205) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:50:20.213+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:50:20.214+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:50:20.213+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:50:20.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:50:20.261+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:50:20.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:50:20.292+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:50:20.292+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:50:20.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-23T12:50:50.365+0000] {processor.py:157} INFO - Started process (PID=2207) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:50:50.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:50:50.366+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:50:50.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:50:50.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:50:50.413+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:50:50.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:50:50.438+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:50:50.437+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:50:50.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T12:51:20.638+0000] {processor.py:157} INFO - Started process (PID=2209) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:51:20.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:51:20.640+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:51:20.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:51:20.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:51:20.690+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:51:20.690+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:51:20.724+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:51:20.724+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:51:20.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T12:51:50.805+0000] {processor.py:157} INFO - Started process (PID=2211) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:51:50.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:51:50.806+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:51:50.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:51:50.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:51:50.857+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:51:50.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:51:50.882+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:51:50.882+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:51:50.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T12:52:21.077+0000] {processor.py:157} INFO - Started process (PID=2213) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:52:21.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:52:21.080+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:52:21.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:52:21.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:52:21.124+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:52:21.124+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:52:21.150+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:52:21.149+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:52:21.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T12:52:51.253+0000] {processor.py:157} INFO - Started process (PID=2215) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:52:51.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:52:51.255+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:52:51.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:52:51.267+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:52:51.298+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:52:51.297+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:52:51.324+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:52:51.324+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:52:51.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T12:53:21.535+0000] {processor.py:157} INFO - Started process (PID=2217) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:53:21.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:53:21.548+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:53:21.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:53:21.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:53:21.596+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:53:21.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:53:21.624+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:53:21.624+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:53:21.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T12:53:51.721+0000] {processor.py:157} INFO - Started process (PID=2219) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:53:51.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:53:51.723+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:53:51.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:53:51.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:53:51.782+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:53:51.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:53:51.817+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:53:51.817+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:53:51.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-23T12:54:22.015+0000] {processor.py:157} INFO - Started process (PID=2221) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:54:22.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:54:22.021+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:54:22.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:54:22.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:54:22.077+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:54:22.077+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:54:22.110+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:54:22.110+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:54:22.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-23T12:54:52.328+0000] {processor.py:157} INFO - Started process (PID=2223) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:54:52.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:54:52.330+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:54:52.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:54:52.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:54:52.386+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:54:52.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:54:52.417+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:54:52.416+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:54:52.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T12:55:22.498+0000] {processor.py:157} INFO - Started process (PID=2225) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:55:22.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:55:22.501+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:55:22.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:55:22.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:55:22.547+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:55:22.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:55:22.573+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:55:22.572+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:55:22.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T12:55:52.783+0000] {processor.py:157} INFO - Started process (PID=2227) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:55:52.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:55:52.784+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:55:52.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:55:52.798+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:55:52.831+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:55:52.831+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:55:52.858+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:55:52.858+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:55:52.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-23T12:56:22.954+0000] {processor.py:157} INFO - Started process (PID=2229) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:56:22.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:56:22.966+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:56:22.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:56:22.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:56:23.009+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:56:23.009+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:56:23.041+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:56:23.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:56:23.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T12:56:53.194+0000] {processor.py:157} INFO - Started process (PID=2231) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:56:53.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:56:53.195+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:56:53.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:56:53.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:56:53.248+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:56:53.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:56:53.283+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:56:53.283+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:56:53.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T12:57:23.491+0000] {processor.py:157} INFO - Started process (PID=2233) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:57:23.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:57:23.500+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:57:23.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:57:23.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:57:23.543+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:57:23.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:57:23.571+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:57:23.571+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:57:23.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T12:57:53.775+0000] {processor.py:157} INFO - Started process (PID=2235) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:57:53.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:57:53.777+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:57:53.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:57:53.794+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:57:53.830+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:57:53.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:57:53.865+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:57:53.865+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:57:53.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T12:58:23.978+0000] {processor.py:157} INFO - Started process (PID=2237) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:58:23.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:58:23.981+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:58:23.981+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:58:23.998+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:58:24.033+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:58:24.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:58:24.066+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:58:24.066+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:58:24.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T12:58:54.253+0000] {processor.py:157} INFO - Started process (PID=2239) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:58:54.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:58:54.254+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:58:54.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:58:54.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:58:54.310+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:58:54.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:58:54.343+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:58:54.343+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:58:54.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T12:59:24.539+0000] {processor.py:157} INFO - Started process (PID=2241) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:59:24.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:59:24.541+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:59:24.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:59:24.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:59:24.590+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:59:24.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:59:24.615+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:59:24.615+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:59:24.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T12:59:54.702+0000] {processor.py:157} INFO - Started process (PID=2243) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:59:54.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T12:59:54.704+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:59:54.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:59:54.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T12:59:54.755+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:59:54.755+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T12:59:54.783+0000] {logging_mixin.py:149} INFO - [2024-10-23T12:59:54.783+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T12:59:54.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T13:00:24.986+0000] {processor.py:157} INFO - Started process (PID=2245) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:00:24.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:00:24.999+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:00:24.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:00:25.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:00:25.039+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:00:25.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:00:25.065+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:00:25.065+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:00:25.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T13:00:55.155+0000] {processor.py:157} INFO - Started process (PID=2247) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:00:55.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:00:55.157+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:00:55.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:00:55.173+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:00:55.209+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:00:55.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:00:55.240+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:00:55.240+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:00:55.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T13:01:25.440+0000] {processor.py:157} INFO - Started process (PID=2249) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:01:25.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:01:25.449+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:01:25.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:01:25.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:01:25.503+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:01:25.503+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:01:25.547+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:01:25.547+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:01:25.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.137 seconds
[2024-10-23T13:01:55.615+0000] {processor.py:157} INFO - Started process (PID=2251) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:01:55.616+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:01:55.617+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:01:55.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:01:55.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:01:55.682+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:01:55.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:01:55.725+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:01:55.725+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:01:55.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.141 seconds
[2024-10-23T13:02:25.925+0000] {processor.py:157} INFO - Started process (PID=2253) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:02:25.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:02:25.927+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:02:25.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:02:25.941+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:02:25.973+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:02:25.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:02:26.001+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:02:26.001+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:02:26.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T13:02:56.094+0000] {processor.py:157} INFO - Started process (PID=2255) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:02:56.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:02:56.095+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:02:56.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:02:56.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:02:56.147+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:02:56.146+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:02:56.200+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:02:56.200+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:02:56.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-23T13:03:26.406+0000] {processor.py:157} INFO - Started process (PID=2257) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:03:26.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:03:26.419+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:03:26.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:03:26.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:03:26.468+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:03:26.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:03:26.494+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:03:26.494+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:03:26.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T13:03:56.686+0000] {processor.py:157} INFO - Started process (PID=2259) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:03:56.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:03:56.688+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:03:56.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:03:56.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:03:56.735+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:03:56.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:03:56.764+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:03:56.764+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:03:56.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T13:04:26.865+0000] {processor.py:157} INFO - Started process (PID=2261) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:04:26.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:04:26.868+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:04:26.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:04:26.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:04:26.925+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:04:26.924+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:04:26.960+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:04:26.960+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:04:26.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T13:04:57.164+0000] {processor.py:157} INFO - Started process (PID=2263) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:04:57.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:04:57.166+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:04:57.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:04:57.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:04:57.213+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:04:57.213+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:04:57.242+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:04:57.241+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:04:57.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T13:05:27.354+0000] {processor.py:157} INFO - Started process (PID=2265) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:05:27.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:05:27.357+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:05:27.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:05:27.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:05:27.428+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:05:27.427+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:05:27.512+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:05:27.511+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:05:27.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.225 seconds
[2024-10-23T13:05:57.719+0000] {processor.py:157} INFO - Started process (PID=2267) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:05:57.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:05:57.720+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:05:57.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:05:57.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:05:57.766+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:05:57.766+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:05:57.793+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:05:57.793+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:05:57.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T13:06:28.012+0000] {processor.py:157} INFO - Started process (PID=2269) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:06:28.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:06:28.024+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:06:28.024+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:06:28.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:06:28.085+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:06:28.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:06:28.145+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:06:28.145+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:06:28.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.168 seconds
[2024-10-23T13:06:58.317+0000] {processor.py:157} INFO - Started process (PID=2271) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:06:58.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:06:58.319+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:06:58.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:06:58.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:06:58.366+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:06:58.366+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:06:58.398+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:06:58.398+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:06:58.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-23T13:07:28.600+0000] {processor.py:157} INFO - Started process (PID=2273) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:07:28.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:07:28.613+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:07:28.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:07:28.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:07:28.667+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:07:28.667+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:07:28.699+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:07:28.699+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:07:28.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-23T13:07:58.896+0000] {processor.py:157} INFO - Started process (PID=2275) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:07:58.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:07:58.898+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:07:58.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:07:58.913+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:07:58.943+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:07:58.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:07:58.969+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:07:58.969+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:07:58.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T13:08:29.202+0000] {processor.py:157} INFO - Started process (PID=2277) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:08:29.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:08:29.204+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:08:29.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:08:29.218+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:08:29.250+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:08:29.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:08:29.360+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:08:29.360+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:08:29.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-23T13:08:59.531+0000] {processor.py:157} INFO - Started process (PID=2279) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:08:59.533+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:08:59.534+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:08:59.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:08:59.581+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:08:59.694+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:08:59.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:08:59.737+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:08:59.737+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:08:59.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.243 seconds
[2024-10-23T13:09:29.986+0000] {processor.py:157} INFO - Started process (PID=2281) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:09:29.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:09:29.993+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:09:29.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:09:30.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:09:30.054+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:09:30.054+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:09:30.085+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:09:30.085+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:09:30.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.144 seconds
[2024-10-23T13:10:00.275+0000] {processor.py:157} INFO - Started process (PID=2283) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:10:00.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:10:00.277+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:10:00.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:10:00.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:10:00.330+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:10:00.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:10:00.366+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:10:00.366+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:10:00.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T13:10:30.568+0000] {processor.py:157} INFO - Started process (PID=2285) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:10:30.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:10:30.570+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:10:30.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:10:30.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:10:30.626+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:10:30.626+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:10:30.658+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:10:30.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:10:30.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T13:11:00.743+0000] {processor.py:157} INFO - Started process (PID=2287) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:11:00.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:11:00.746+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:11:00.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:11:00.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:11:00.802+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:11:00.802+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:11:00.840+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:11:00.840+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:11:00.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T13:11:31.033+0000] {processor.py:157} INFO - Started process (PID=2289) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:11:31.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:11:31.035+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:11:31.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:11:31.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:11:31.086+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:11:31.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:11:31.120+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:11:31.120+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:11:31.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T13:12:01.200+0000] {processor.py:157} INFO - Started process (PID=2291) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:12:01.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:12:01.202+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:12:01.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:12:01.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:12:01.254+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:12:01.254+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:12:01.291+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:12:01.290+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:12:01.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T13:12:31.585+0000] {processor.py:157} INFO - Started process (PID=2293) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:12:31.587+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:12:31.588+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:12:31.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:12:31.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:12:31.657+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:12:31.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:12:31.701+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:12:31.701+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:12:31.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.151 seconds
[2024-10-23T13:13:02.320+0000] {processor.py:157} INFO - Started process (PID=2295) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:13:02.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:13:02.325+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:13:02.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:13:02.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:13:02.440+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:13:02.439+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:13:02.517+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:13:02.517+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:13:02.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.278 seconds
[2024-10-23T13:13:32.774+0000] {processor.py:157} INFO - Started process (PID=2297) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:13:32.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:13:32.786+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:13:32.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:13:32.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:13:32.834+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:13:32.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:13:32.860+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:13:32.860+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:13:32.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T13:14:03.065+0000] {processor.py:157} INFO - Started process (PID=2299) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:14:03.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:14:03.069+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:14:03.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:14:03.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:14:03.149+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:14:03.149+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:14:03.195+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:14:03.195+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:14:03.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-23T13:14:33.387+0000] {processor.py:157} INFO - Started process (PID=2301) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:14:33.387+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:14:33.388+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:14:33.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:14:33.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:14:33.439+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:14:33.439+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:14:33.472+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:14:33.472+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:14:33.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T13:15:03.681+0000] {processor.py:157} INFO - Started process (PID=2303) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:15:03.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:15:03.691+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:15:03.690+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:15:03.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:15:03.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:15:03.749+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:15:03.783+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:15:03.783+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:15:03.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-23T13:15:33.867+0000] {processor.py:157} INFO - Started process (PID=2305) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:15:33.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:15:33.880+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:15:33.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:15:33.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:15:33.926+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:15:33.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:15:33.956+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:15:33.956+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:15:33.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T13:16:04.129+0000] {processor.py:157} INFO - Started process (PID=2307) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:16:04.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:16:04.131+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:16:04.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:16:04.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:16:04.179+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:16:04.179+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:16:04.211+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:16:04.210+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:16:04.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-23T13:16:34.410+0000] {processor.py:157} INFO - Started process (PID=2309) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:16:34.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:16:34.412+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:16:34.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:16:34.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:16:34.464+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:16:34.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:16:34.499+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:16:34.499+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:16:34.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T13:17:04.697+0000] {processor.py:157} INFO - Started process (PID=2311) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:17:04.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:17:04.698+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:17:04.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:17:04.715+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:17:04.747+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:17:04.747+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:17:04.776+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:17:04.776+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:17:04.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T13:17:34.869+0000] {processor.py:157} INFO - Started process (PID=2313) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:17:34.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:17:34.883+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:17:34.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:17:34.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:17:34.933+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:17:34.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:17:34.961+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:17:34.961+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:17:34.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T13:18:05.117+0000] {processor.py:157} INFO - Started process (PID=2315) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:18:05.118+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:18:05.119+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:18:05.119+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:18:05.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:18:05.171+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:18:05.171+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:18:05.199+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:18:05.198+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:18:05.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T13:18:35.305+0000] {processor.py:157} INFO - Started process (PID=2317) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:18:35.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:18:35.319+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:18:35.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:18:35.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:18:35.367+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:18:35.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:18:35.403+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:18:35.403+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:18:35.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-23T13:19:05.526+0000] {processor.py:157} INFO - Started process (PID=2319) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:19:05.527+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:19:05.528+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:19:05.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:19:05.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:19:05.573+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:19:05.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:19:05.600+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:19:05.600+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:19:05.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T13:19:35.809+0000] {processor.py:157} INFO - Started process (PID=2321) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:19:35.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:19:35.811+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:19:35.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:19:35.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:19:35.860+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:19:35.860+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:19:35.890+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:19:35.890+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:19:35.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-23T13:20:05.976+0000] {processor.py:157} INFO - Started process (PID=2323) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:20:05.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:20:05.977+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:20:05.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:20:05.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:20:06.026+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:20:06.025+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:20:06.066+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:20:06.066+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:20:06.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T13:20:36.264+0000] {processor.py:157} INFO - Started process (PID=2325) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:20:36.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:20:36.276+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:20:36.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:20:36.297+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:20:36.333+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:20:36.333+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:20:36.365+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:20:36.365+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:20:36.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T13:21:06.561+0000] {processor.py:157} INFO - Started process (PID=2327) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:21:06.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:21:06.563+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:21:06.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:21:06.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:21:06.622+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:21:06.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:21:06.654+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:21:06.654+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:21:06.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T13:21:36.740+0000] {processor.py:157} INFO - Started process (PID=2329) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:21:36.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:21:36.743+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:21:36.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:21:36.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:21:36.796+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:21:36.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:21:36.827+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:21:36.827+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:21:36.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T13:22:07.033+0000] {processor.py:157} INFO - Started process (PID=2331) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:22:07.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:22:07.035+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:22:07.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:22:07.053+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:22:07.090+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:22:07.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:22:07.120+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:22:07.120+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:22:07.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T13:22:37.225+0000] {processor.py:157} INFO - Started process (PID=2333) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:22:37.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:22:37.239+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:22:37.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:22:37.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:22:37.283+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:22:37.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:22:37.309+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:22:37.309+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:22:37.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T13:23:07.443+0000] {processor.py:157} INFO - Started process (PID=2335) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:23:07.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:23:07.445+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:23:07.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:23:07.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:23:07.493+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:23:07.493+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:23:07.521+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:23:07.521+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:23:07.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T13:23:37.736+0000] {processor.py:157} INFO - Started process (PID=2337) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:23:37.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:23:37.748+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:23:37.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:23:37.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:23:37.797+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:23:37.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:23:37.826+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:23:37.826+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:23:37.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T13:24:07.905+0000] {processor.py:157} INFO - Started process (PID=2339) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:24:07.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:24:07.907+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:24:07.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:24:07.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:24:07.953+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:24:07.953+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:24:07.981+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:24:07.981+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:24:08.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T13:24:38.191+0000] {processor.py:157} INFO - Started process (PID=2341) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:24:38.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:24:38.193+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:24:38.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:24:38.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:24:38.242+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:24:38.242+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:24:38.269+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:24:38.269+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:24:38.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T13:25:08.363+0000] {processor.py:157} INFO - Started process (PID=2343) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:25:08.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:25:08.365+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:25:08.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:25:08.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:25:08.416+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:25:08.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:25:08.449+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:25:08.448+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:25:08.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T13:25:38.647+0000] {processor.py:157} INFO - Started process (PID=2345) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:25:38.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:25:38.650+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:25:38.649+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:25:38.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:25:38.695+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:25:38.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:25:38.720+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:25:38.720+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:25:38.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T13:26:08.911+0000] {processor.py:157} INFO - Started process (PID=2347) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:26:08.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:26:08.912+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:26:08.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:26:08.926+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:26:08.959+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:26:08.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:26:08.985+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:26:08.985+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:26:09.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T13:26:39.089+0000] {processor.py:157} INFO - Started process (PID=2349) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:26:39.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:26:39.103+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:26:39.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:26:39.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:26:39.147+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:26:39.146+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:26:39.177+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:26:39.177+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:26:39.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T13:27:09.372+0000] {processor.py:157} INFO - Started process (PID=2351) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:27:09.373+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:27:09.374+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:27:09.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:27:09.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:27:09.422+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:27:09.422+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:27:09.448+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:27:09.448+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:27:09.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T13:27:39.552+0000] {processor.py:157} INFO - Started process (PID=2353) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:27:39.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:27:39.565+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:27:39.565+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:27:39.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:27:39.614+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:27:39.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:27:39.646+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:27:39.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:27:39.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T13:28:09.781+0000] {processor.py:157} INFO - Started process (PID=2355) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:28:09.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:28:09.782+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:28:09.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:28:09.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:28:09.831+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:28:09.831+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:28:09.856+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:28:09.856+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:28:09.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T13:28:39.954+0000] {processor.py:157} INFO - Started process (PID=2357) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:28:39.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:28:39.967+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:28:39.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:28:39.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:28:40.017+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:28:40.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:28:40.050+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:28:40.050+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:28:40.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T13:29:10.188+0000] {processor.py:157} INFO - Started process (PID=2359) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:29:10.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:29:10.190+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:29:10.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:29:10.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:29:10.254+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:29:10.253+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:29:10.302+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:29:10.301+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:29:10.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.165 seconds
[2024-10-23T13:29:40.365+0000] {processor.py:157} INFO - Started process (PID=2361) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:29:40.377+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:29:40.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:29:40.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:29:40.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:29:40.475+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:29:40.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:29:40.585+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:29:40.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:29:40.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.304 seconds
[2024-10-23T13:30:10.854+0000] {processor.py:157} INFO - Started process (PID=2363) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:30:10.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:30:10.862+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:30:10.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:30:10.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:30:10.994+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:30:10.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:30:11.048+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:30:11.048+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:30:11.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.227 seconds
[2024-10-23T13:30:41.250+0000] {processor.py:157} INFO - Started process (PID=2365) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:30:41.252+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:30:41.253+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:30:41.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:30:41.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:30:41.320+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:30:41.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:30:41.361+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:30:41.361+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:30:41.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.139 seconds
[2024-10-23T13:31:11.554+0000] {processor.py:157} INFO - Started process (PID=2367) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:31:11.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:31:11.556+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:31:11.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:31:11.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:31:11.608+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:31:11.608+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:31:11.636+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:31:11.636+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:31:11.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-23T13:31:41.845+0000] {processor.py:157} INFO - Started process (PID=2369) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:31:41.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:31:41.857+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:31:41.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:31:41.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:31:41.906+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:31:41.906+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:31:41.940+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:31:41.939+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:31:41.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T13:32:12.134+0000] {processor.py:157} INFO - Started process (PID=2371) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:32:12.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:32:12.135+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:32:12.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:32:12.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:32:12.178+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:32:12.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:32:12.203+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:32:12.203+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:32:12.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T13:32:42.422+0000] {processor.py:157} INFO - Started process (PID=2373) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:32:42.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:32:42.424+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:32:42.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:32:42.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:32:42.469+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:32:42.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:32:42.495+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:32:42.495+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:32:42.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T13:33:12.595+0000] {processor.py:157} INFO - Started process (PID=2375) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:33:12.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:33:12.596+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:33:12.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:33:12.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:33:12.638+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:33:12.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:33:12.665+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:33:12.665+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:33:12.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T13:33:42.861+0000] {processor.py:157} INFO - Started process (PID=2377) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:33:42.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:33:42.864+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:33:42.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:33:42.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:33:42.912+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:33:42.912+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:33:42.944+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:33:42.944+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:33:42.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T13:34:13.019+0000] {processor.py:157} INFO - Started process (PID=2379) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:34:13.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:34:13.021+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:34:13.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:34:13.038+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:34:13.073+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:34:13.073+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:34:13.105+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:34:13.104+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:34:13.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T13:34:43.295+0000] {processor.py:157} INFO - Started process (PID=2381) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:34:43.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:34:43.298+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:34:43.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:34:43.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:34:43.351+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:34:43.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:34:43.386+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:34:43.386+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:34:43.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T13:35:13.457+0000] {processor.py:157} INFO - Started process (PID=2383) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:35:13.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:35:13.458+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:35:13.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:35:13.472+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:35:13.500+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:35:13.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:35:13.527+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:35:13.527+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:35:13.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T13:35:43.724+0000] {processor.py:157} INFO - Started process (PID=2385) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:35:43.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:35:43.726+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:35:43.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:35:43.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:35:43.775+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:35:43.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:35:43.803+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:35:43.803+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:35:43.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T13:36:13.892+0000] {processor.py:157} INFO - Started process (PID=2387) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:36:13.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:36:13.894+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:36:13.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:36:13.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:36:13.937+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:36:13.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:36:13.962+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:36:13.961+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:36:13.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T13:36:44.151+0000] {processor.py:157} INFO - Started process (PID=2389) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:36:44.162+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:36:44.163+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:36:44.163+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:36:44.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:36:44.208+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:36:44.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:36:44.236+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:36:44.236+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:36:44.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-23T13:37:14.431+0000] {processor.py:157} INFO - Started process (PID=2391) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:37:14.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:37:14.433+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:37:14.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:37:14.447+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:37:14.476+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:37:14.476+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:37:14.502+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:37:14.502+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:37:14.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T13:37:44.696+0000] {processor.py:157} INFO - Started process (PID=2393) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:37:44.706+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:37:44.707+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:37:44.707+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:37:44.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:37:44.754+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:37:44.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:37:44.782+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:37:44.782+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:37:44.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T13:38:15.001+0000] {processor.py:157} INFO - Started process (PID=2395) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:38:15.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:38:15.003+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:38:15.003+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:38:15.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:38:15.069+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:38:15.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:38:15.102+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:38:15.102+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:38:15.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-23T13:38:45.166+0000] {processor.py:157} INFO - Started process (PID=2397) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:38:45.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:38:45.179+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:38:45.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:38:45.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:38:45.222+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:38:45.222+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:38:45.248+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:38:45.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:38:45.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T13:39:15.415+0000] {processor.py:157} INFO - Started process (PID=2399) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:39:15.416+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:39:15.416+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:39:15.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:39:15.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:39:15.476+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:39:15.476+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:39:15.510+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:39:15.510+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:39:15.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T13:39:45.709+0000] {processor.py:157} INFO - Started process (PID=2401) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:39:45.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:39:45.713+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:39:45.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:39:45.730+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:39:45.771+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:39:45.771+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:39:45.803+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:39:45.803+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:39:45.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T13:40:15.945+0000] {processor.py:157} INFO - Started process (PID=2403) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:40:15.946+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:40:15.947+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:40:15.947+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:40:15.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:40:15.990+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:40:15.990+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:40:16.012+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:40:16.012+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:40:16.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-23T13:40:46.118+0000] {processor.py:157} INFO - Started process (PID=2405) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:40:46.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:40:46.120+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:40:46.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:40:46.134+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:40:46.167+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:40:46.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:40:46.192+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:40:46.192+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:40:46.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T13:41:16.373+0000] {processor.py:157} INFO - Started process (PID=2407) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:41:16.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:41:16.375+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:41:16.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:41:16.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:41:16.423+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:41:16.423+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:41:16.454+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:41:16.453+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:41:16.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T13:41:46.665+0000] {processor.py:157} INFO - Started process (PID=2409) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:41:46.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:41:46.667+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:41:46.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:41:46.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:41:46.713+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:41:46.713+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:41:46.736+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:41:46.736+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:41:46.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T13:42:16.841+0000] {processor.py:157} INFO - Started process (PID=2411) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:42:16.842+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:42:16.843+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:42:16.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:42:16.856+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:42:16.883+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:42:16.882+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:42:16.909+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:42:16.909+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:42:16.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T13:42:47.125+0000] {processor.py:157} INFO - Started process (PID=2413) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:42:47.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:42:47.127+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:42:47.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:42:47.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:42:47.171+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:42:47.171+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:42:47.196+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:42:47.196+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:42:47.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T13:43:17.403+0000] {processor.py:157} INFO - Started process (PID=2415) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:43:17.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:43:17.405+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:43:17.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:43:17.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:43:17.450+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:43:17.450+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:43:17.475+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:43:17.475+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:43:17.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T13:43:47.693+0000] {processor.py:157} INFO - Started process (PID=2417) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:43:47.694+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:43:47.695+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:43:47.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:43:47.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:43:47.738+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:43:47.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:43:47.760+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:43:47.759+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:43:47.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T13:44:17.868+0000] {processor.py:157} INFO - Started process (PID=2419) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:44:17.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:44:17.870+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:44:17.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:44:17.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:44:17.910+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:44:17.910+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:44:17.932+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:44:17.932+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:44:17.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T13:44:48.130+0000] {processor.py:157} INFO - Started process (PID=2421) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:44:48.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:44:48.143+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:44:48.142+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:44:48.156+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:44:48.183+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:44:48.183+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:44:48.208+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:44:48.207+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:44:48.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T13:45:18.320+0000] {processor.py:157} INFO - Started process (PID=2423) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:45:18.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:45:18.323+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:45:18.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:45:18.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:45:18.371+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:45:18.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:45:18.399+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:45:18.399+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:45:18.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T13:45:48.624+0000] {processor.py:157} INFO - Started process (PID=2425) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:45:48.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:45:48.626+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:45:48.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:45:48.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:45:48.670+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:45:48.669+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:45:48.694+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:45:48.694+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:45:48.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T13:46:18.875+0000] {processor.py:157} INFO - Started process (PID=2427) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:46:18.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:46:18.877+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:46:18.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:46:18.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:46:18.917+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:46:18.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:46:18.940+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:46:18.940+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:46:18.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T13:46:49.050+0000] {processor.py:157} INFO - Started process (PID=2429) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:46:49.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:46:49.053+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:46:49.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:46:49.072+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:46:49.108+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:46:49.108+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:46:49.137+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:46:49.137+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:46:49.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T13:47:19.250+0000] {processor.py:157} INFO - Started process (PID=2431) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:47:19.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:47:19.252+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:47:19.252+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:47:19.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:47:19.296+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:47:19.296+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:47:19.328+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:47:19.327+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:47:19.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T13:47:49.543+0000] {processor.py:157} INFO - Started process (PID=2433) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:47:49.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:47:49.547+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:47:49.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:47:49.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:47:49.591+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:47:49.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:47:49.614+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:47:49.614+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:47:49.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T13:48:19.748+0000] {processor.py:157} INFO - Started process (PID=2435) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:48:19.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:48:19.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:48:19.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:48:19.777+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:48:19.819+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:48:19.819+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:48:19.850+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:48:19.850+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:48:19.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-23T13:48:50.089+0000] {processor.py:157} INFO - Started process (PID=2437) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:48:50.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:48:50.091+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:48:50.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:48:50.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:48:50.135+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:48:50.135+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:48:50.159+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:48:50.159+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:48:50.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T13:49:20.354+0000] {processor.py:157} INFO - Started process (PID=2439) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:49:20.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:49:20.356+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:49:20.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:49:20.373+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:49:20.402+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:49:20.402+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:49:20.426+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:49:20.426+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:49:20.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T13:49:50.643+0000] {processor.py:157} INFO - Started process (PID=2441) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:49:50.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:49:50.647+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:49:50.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:49:50.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:49:50.716+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:49:50.716+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:49:50.751+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:49:50.751+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:49:50.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-23T13:50:20.818+0000] {processor.py:157} INFO - Started process (PID=2443) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:50:20.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:50:20.819+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:50:20.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:50:20.837+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:50:20.869+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:50:20.869+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:50:20.910+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:50:20.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:50:20.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T13:50:51.099+0000] {processor.py:157} INFO - Started process (PID=2445) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:50:51.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:50:51.112+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:50:51.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:50:51.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:50:51.166+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:50:51.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:50:51.198+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:50:51.198+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:50:51.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-23T13:51:21.248+0000] {processor.py:157} INFO - Started process (PID=2447) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:51:21.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:51:21.249+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:51:21.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:51:21.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:51:21.298+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:51:21.297+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:51:21.327+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:51:21.327+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:51:21.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T13:51:51.516+0000] {processor.py:157} INFO - Started process (PID=2449) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:51:51.517+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:51:51.518+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:51:51.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:51:51.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:51:51.564+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:51:51.564+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:51:51.600+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:51:51.599+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:51:51.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-23T13:52:21.767+0000] {processor.py:157} INFO - Started process (PID=2451) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:52:21.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:52:21.769+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:52:21.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:52:21.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:52:21.815+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:52:21.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:52:21.842+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:52:21.842+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:52:21.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T13:52:52.067+0000] {processor.py:157} INFO - Started process (PID=2453) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:52:52.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:52:52.080+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:52:52.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:52:52.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:52:52.140+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:52:52.140+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:52:52.167+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:52:52.167+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:52:52.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-23T13:53:22.245+0000] {processor.py:157} INFO - Started process (PID=2455) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:53:22.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:53:22.247+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:53:22.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:53:22.259+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:53:22.286+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:53:22.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:53:22.311+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:53:22.310+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:53:22.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T13:53:52.511+0000] {processor.py:157} INFO - Started process (PID=2457) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:53:52.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:53:52.514+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:53:52.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:53:52.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:53:52.578+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:53:52.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:53:52.619+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:53:52.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:53:52.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.137 seconds
[2024-10-23T13:54:22.673+0000] {processor.py:157} INFO - Started process (PID=2459) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:54:22.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:54:22.675+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:54:22.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:54:22.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:54:22.725+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:54:22.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:54:22.758+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:54:22.757+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:54:22.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T13:54:52.953+0000] {processor.py:157} INFO - Started process (PID=2461) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:54:52.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:54:52.955+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:54:52.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:54:52.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:54:53.028+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:54:53.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:54:53.075+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:54:53.075+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:54:53.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.151 seconds
[2024-10-23T13:55:23.245+0000] {processor.py:157} INFO - Started process (PID=2463) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:55:23.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:55:23.246+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:55:23.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:55:23.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:55:23.296+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:55:23.295+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:55:23.324+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:55:23.323+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:55:23.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T13:55:53.521+0000] {processor.py:157} INFO - Started process (PID=2465) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:55:53.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:55:53.523+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:55:53.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:55:53.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:55:53.569+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:55:53.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:55:53.597+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:55:53.597+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:55:53.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T13:56:23.802+0000] {processor.py:157} INFO - Started process (PID=2467) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:56:23.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:56:23.803+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:56:23.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:56:23.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:56:23.844+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:56:23.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:56:23.877+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:56:23.876+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:56:23.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T13:56:54.069+0000] {processor.py:157} INFO - Started process (PID=2469) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:56:54.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:56:54.074+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:56:54.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:56:54.109+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:56:54.148+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:56:54.148+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:56:54.183+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:56:54.182+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:56:54.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-23T13:57:24.374+0000] {processor.py:157} INFO - Started process (PID=2471) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:57:24.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:57:24.376+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:57:24.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:57:24.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:57:24.416+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:57:24.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:57:24.439+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:57:24.438+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:57:24.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T13:57:54.655+0000] {processor.py:157} INFO - Started process (PID=2473) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:57:54.656+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:57:54.657+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:57:54.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:57:54.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:57:54.695+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:57:54.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:57:54.718+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:57:54.718+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:57:54.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T13:58:24.937+0000] {processor.py:157} INFO - Started process (PID=2475) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:58:24.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:58:24.939+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:58:24.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:58:24.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:58:24.982+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:58:24.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:58:25.005+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:58:25.005+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:58:25.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T13:58:55.135+0000] {processor.py:157} INFO - Started process (PID=2477) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:58:55.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:58:55.137+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:58:55.137+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:58:55.150+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:58:55.178+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:58:55.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:58:55.202+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:58:55.202+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:58:55.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T13:59:25.413+0000] {processor.py:157} INFO - Started process (PID=2479) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:59:25.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:59:25.415+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:59:25.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:59:25.428+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:59:25.456+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:59:25.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:59:25.480+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:59:25.479+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:59:25.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T13:59:55.679+0000] {processor.py:157} INFO - Started process (PID=2481) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:59:55.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T13:59:55.681+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:59:55.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:59:55.694+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T13:59:55.727+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:59:55.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T13:59:55.753+0000] {logging_mixin.py:149} INFO - [2024-10-23T13:59:55.753+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T13:59:55.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T14:00:25.835+0000] {processor.py:157} INFO - Started process (PID=2483) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:00:25.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:00:25.838+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:00:25.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:00:25.855+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:00:25.886+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:00:25.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:00:25.915+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:00:25.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:00:25.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T14:00:56.063+0000] {processor.py:157} INFO - Started process (PID=2485) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:00:56.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:00:56.065+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:00:56.065+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:00:56.085+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:00:56.125+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:00:56.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:00:56.159+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:00:56.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:00:56.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T14:01:26.356+0000] {processor.py:157} INFO - Started process (PID=2487) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:01:26.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:01:26.360+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:01:26.360+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:01:26.399+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:01:26.471+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:01:26.471+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:01:26.520+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:01:26.519+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:01:26.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.210 seconds
[2024-10-23T14:01:56.692+0000] {processor.py:157} INFO - Started process (PID=2489) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:01:56.694+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:01:56.695+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:01:56.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:01:56.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:01:56.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:01:56.749+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:01:56.773+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:01:56.773+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:01:56.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T14:02:26.998+0000] {processor.py:157} INFO - Started process (PID=2491) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:02:26.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:02:26.999+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:02:26.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:02:27.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:02:27.056+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:02:27.056+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:02:27.085+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:02:27.085+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:02:27.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T14:02:57.307+0000] {processor.py:157} INFO - Started process (PID=2493) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:02:57.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:02:57.309+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:02:57.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:02:57.322+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:02:57.351+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:02:57.351+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:02:57.382+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:02:57.381+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:02:57.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T14:03:27.605+0000] {processor.py:157} INFO - Started process (PID=2495) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:03:27.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:03:27.607+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:03:27.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:03:27.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:03:27.653+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:03:27.653+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:03:27.675+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:03:27.675+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:03:27.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-23T14:03:57.786+0000] {processor.py:157} INFO - Started process (PID=2497) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:03:57.787+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:03:57.788+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:03:57.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:03:57.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:03:57.827+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:03:57.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:03:57.850+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:03:57.850+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:03:57.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T14:04:28.043+0000] {processor.py:157} INFO - Started process (PID=2499) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:04:28.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:04:28.046+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:04:28.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:04:28.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:04:28.092+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:04:28.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:04:28.121+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:04:28.120+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:04:28.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T14:04:58.206+0000] {processor.py:157} INFO - Started process (PID=2501) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:04:58.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:04:58.208+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:04:58.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:04:58.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:04:58.262+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:04:58.262+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:04:58.293+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:04:58.293+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:04:58.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T14:05:28.420+0000] {processor.py:157} INFO - Started process (PID=2503) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:05:28.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:05:28.422+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:05:28.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:05:28.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:05:28.468+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:05:28.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:05:28.496+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:05:28.496+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:05:28.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-23T14:05:58.699+0000] {processor.py:157} INFO - Started process (PID=2505) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:05:58.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:05:58.701+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:05:58.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:05:58.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:05:58.740+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:05:58.740+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:05:58.769+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:05:58.769+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:05:58.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T14:06:28.871+0000] {processor.py:157} INFO - Started process (PID=2507) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:06:28.873+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:06:28.873+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:06:28.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:06:28.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:06:28.918+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:06:28.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:06:28.942+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:06:28.942+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:06:28.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T14:06:59.130+0000] {processor.py:157} INFO - Started process (PID=2509) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:06:59.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:06:59.132+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:06:59.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:06:59.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:06:59.175+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:06:59.175+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:06:59.203+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:06:59.203+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:06:59.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T14:07:29.313+0000] {processor.py:157} INFO - Started process (PID=2511) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:07:29.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:07:29.315+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:07:29.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:07:29.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:07:29.357+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:07:29.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:07:29.384+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:07:29.384+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:07:29.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T14:07:59.597+0000] {processor.py:157} INFO - Started process (PID=2513) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:07:59.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:07:59.599+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:07:59.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:07:59.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:07:59.637+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:07:59.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:07:59.659+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:07:59.659+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:07:59.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T14:08:29.796+0000] {processor.py:157} INFO - Started process (PID=2515) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:08:29.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:08:29.798+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:08:29.797+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:08:29.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:08:29.841+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:08:29.840+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:08:29.861+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:08:29.861+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:08:29.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T14:08:59.991+0000] {processor.py:157} INFO - Started process (PID=2517) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:08:59.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:08:59.993+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:08:59.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:09:00.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:09:00.036+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:09:00.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:09:00.063+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:09:00.062+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:09:00.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-23T14:09:30.258+0000] {processor.py:157} INFO - Started process (PID=2519) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:09:30.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:09:30.266+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:09:30.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:09:30.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:09:30.310+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:09:30.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:09:30.339+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:09:30.339+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:09:30.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T14:10:00.429+0000] {processor.py:157} INFO - Started process (PID=2521) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:10:00.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:10:00.431+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:10:00.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:10:00.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:10:00.475+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:10:00.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:10:00.500+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:10:00.500+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:10:00.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-23T14:10:30.656+0000] {processor.py:157} INFO - Started process (PID=2523) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:10:30.657+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:10:30.658+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:10:30.658+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:10:30.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:10:30.702+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:10:30.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:10:30.730+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:10:30.730+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:10:30.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T14:11:00.910+0000] {processor.py:157} INFO - Started process (PID=2525) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:11:00.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:11:00.912+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:11:00.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:11:00.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:11:00.957+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:11:00.957+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:11:00.983+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:11:00.983+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:11:01.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T14:11:31.104+0000] {processor.py:157} INFO - Started process (PID=2527) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:11:31.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:11:31.106+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:11:31.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:11:31.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:11:31.154+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:11:31.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:11:31.181+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:11:31.181+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:11:31.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-23T14:12:01.360+0000] {processor.py:157} INFO - Started process (PID=2529) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:12:01.361+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:12:01.362+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:12:01.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:12:01.373+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:12:01.401+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:12:01.401+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:12:01.423+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:12:01.422+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:12:01.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-23T14:12:31.566+0000] {processor.py:157} INFO - Started process (PID=2531) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:12:31.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:12:31.568+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:12:31.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:12:31.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:12:31.608+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:12:31.608+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:12:31.635+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:12:31.635+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:12:31.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T14:13:01.858+0000] {processor.py:157} INFO - Started process (PID=2533) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:13:01.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:13:01.860+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:13:01.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:13:01.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:13:01.904+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:13:01.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:13:01.927+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:13:01.927+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:13:01.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T14:13:32.159+0000] {processor.py:157} INFO - Started process (PID=2535) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:13:32.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:13:32.161+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:13:32.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:13:32.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:13:32.201+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:13:32.201+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:13:32.222+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:13:32.222+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:13:32.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T14:14:02.364+0000] {processor.py:157} INFO - Started process (PID=2537) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:14:02.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:14:02.365+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:14:02.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:14:02.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:14:02.405+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:14:02.404+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:14:02.427+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:14:02.427+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:14:02.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T14:14:32.652+0000] {processor.py:157} INFO - Started process (PID=2539) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:14:32.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:14:32.655+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:14:32.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:14:32.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:14:32.695+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:14:32.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:14:32.722+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:14:32.722+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:14:32.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T14:15:02.844+0000] {processor.py:157} INFO - Started process (PID=2541) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:15:02.845+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:15:02.845+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:15:02.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:15:02.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:15:02.883+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:15:02.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:15:02.905+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:15:02.905+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:15:02.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-23T14:15:33.137+0000] {processor.py:157} INFO - Started process (PID=2543) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:15:33.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:15:33.139+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:15:33.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:15:33.151+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:15:33.178+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:15:33.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:15:33.200+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:15:33.200+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:15:33.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-23T14:16:03.338+0000] {processor.py:157} INFO - Started process (PID=2545) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:16:03.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:16:03.339+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:16:03.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:16:03.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:16:03.378+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:16:03.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:16:03.399+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:16:03.399+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:16:03.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T14:16:33.625+0000] {processor.py:157} INFO - Started process (PID=2547) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:16:33.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:16:33.628+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:16:33.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:16:33.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:16:33.673+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:16:33.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:16:33.702+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:16:33.701+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:16:33.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T14:17:03.836+0000] {processor.py:157} INFO - Started process (PID=2549) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:17:03.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:17:03.837+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:17:03.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:17:03.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:17:03.879+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:17:03.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:17:03.904+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:17:03.903+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:17:03.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-23T14:17:34.088+0000] {processor.py:157} INFO - Started process (PID=2551) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:17:34.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:17:34.090+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:17:34.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:17:34.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:17:34.129+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:17:34.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:17:34.153+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:17:34.153+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:17:34.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T14:18:04.278+0000] {processor.py:157} INFO - Started process (PID=2553) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:18:04.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:18:04.279+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:18:04.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:18:04.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:18:04.321+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:18:04.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:18:04.344+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:18:04.344+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:18:04.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T14:18:34.587+0000] {processor.py:157} INFO - Started process (PID=2555) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:18:34.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:18:34.589+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:18:34.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:18:34.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:18:34.634+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:18:34.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:18:34.656+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:18:34.656+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:18:34.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T14:19:04.878+0000] {processor.py:157} INFO - Started process (PID=2557) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:19:04.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:19:04.880+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:19:04.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:19:04.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:19:04.922+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:19:04.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:19:04.943+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:19:04.943+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:19:04.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T14:19:35.061+0000] {processor.py:157} INFO - Started process (PID=2559) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:19:35.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:19:35.070+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:19:35.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:19:35.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:19:35.107+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:19:35.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:19:35.128+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:19:35.128+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:19:35.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T14:20:05.326+0000] {processor.py:157} INFO - Started process (PID=2561) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:20:05.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:20:05.327+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:20:05.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:20:05.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:20:05.367+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:20:05.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:20:05.389+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:20:05.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:20:05.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T14:20:35.623+0000] {processor.py:157} INFO - Started process (PID=2563) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:20:35.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:20:35.624+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:20:35.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:20:35.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:20:35.663+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:20:35.663+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:20:35.687+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:20:35.687+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:20:35.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-23T14:21:05.796+0000] {processor.py:157} INFO - Started process (PID=2565) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:21:05.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:21:05.798+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:21:05.797+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:21:05.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:21:05.837+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:21:05.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:21:05.862+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:21:05.862+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:21:05.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T14:21:36.075+0000] {processor.py:157} INFO - Started process (PID=2567) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:21:36.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:21:36.077+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:21:36.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:21:36.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:21:36.119+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:21:36.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:21:36.143+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:21:36.142+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:21:36.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-23T14:22:06.358+0000] {processor.py:157} INFO - Started process (PID=2569) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:22:06.359+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:22:06.360+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:22:06.360+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:22:06.373+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:22:06.403+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:22:06.403+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:22:06.429+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:22:06.428+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:22:06.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-23T14:22:36.553+0000] {processor.py:157} INFO - Started process (PID=2571) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:22:36.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:22:36.556+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:22:36.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:22:36.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:22:36.605+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:22:36.605+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:22:36.646+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:22:36.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:22:36.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T14:23:06.876+0000] {processor.py:157} INFO - Started process (PID=2573) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:23:06.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:23:06.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:23:06.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:23:06.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:23:06.915+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:23:06.914+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:23:06.936+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:23:06.936+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:23:06.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-23T14:23:37.099+0000] {processor.py:157} INFO - Started process (PID=2575) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:23:37.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:23:37.101+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:23:37.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:23:37.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:23:37.140+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:23:37.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:23:37.161+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:23:37.161+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:23:37.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-23T14:24:07.390+0000] {processor.py:157} INFO - Started process (PID=2577) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:24:07.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:24:07.391+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:24:07.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:24:07.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:24:07.431+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:24:07.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:24:07.454+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:24:07.454+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:24:07.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T14:24:37.681+0000] {processor.py:157} INFO - Started process (PID=2579) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:24:37.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:24:37.683+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:24:37.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:24:37.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:24:37.725+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:24:37.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:24:37.746+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:24:37.746+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:24:37.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-23T14:25:07.891+0000] {processor.py:157} INFO - Started process (PID=2581) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:25:07.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:25:07.892+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:25:07.892+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:25:07.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:25:07.930+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:25:07.930+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:25:07.953+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:25:07.953+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:25:07.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-23T14:25:38.081+0000] {processor.py:157} INFO - Started process (PID=2583) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:25:38.082+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T14:25:38.083+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:25:38.083+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:25:38.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T14:25:38.128+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:25:38.128+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T14:25:38.156+0000] {logging_mixin.py:149} INFO - [2024-10-23T14:25:38.156+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T14:25:38.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T15:21:40.277+0000] {processor.py:157} INFO - Started process (PID=2585) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:21:40.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T15:21:40.314+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:21:40.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:21:40.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:21:40.515+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:21:40.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T15:21:40.609+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:21:40.609+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T15:21:40.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.526 seconds
[2024-10-23T15:22:10.890+0000] {processor.py:157} INFO - Started process (PID=2589) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:22:10.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T15:22:10.901+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:22:10.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:22:10.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:22:10.956+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:22:10.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T15:22:10.990+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:22:10.990+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T15:22:11.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-23T15:27:43.724+0000] {processor.py:157} INFO - Started process (PID=2593) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:27:43.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T15:27:43.727+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:27:43.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:27:43.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T15:27:44.029+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:27:44.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T15:27:44.191+0000] {logging_mixin.py:149} INFO - [2024-10-23T15:27:44.191+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T15:27:44.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.580 seconds
[2024-10-23T16:42:54.784+0000] {processor.py:157} INFO - Started process (PID=2595) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:42:54.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:42:54.786+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:42:54.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:42:54.858+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:42:54.999+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:42:54.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:42:55.068+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:42:55.068+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:42:55.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.322 seconds
[2024-10-23T16:43:25.293+0000] {processor.py:157} INFO - Started process (PID=2599) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:43:25.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:43:25.300+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:43:25.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:43:25.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:43:25.389+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:43:25.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:43:25.420+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:43:25.420+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:43:25.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.157 seconds
[2024-10-23T16:43:55.580+0000] {processor.py:157} INFO - Started process (PID=2602) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:43:55.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:43:55.581+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:43:55.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:43:55.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:43:55.624+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:43:55.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:43:55.647+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:43:55.647+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:43:55.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T16:44:25.746+0000] {processor.py:157} INFO - Started process (PID=2603) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:44:25.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:44:25.748+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:44:25.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:44:25.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:44:25.798+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:44:25.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:44:25.824+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:44:25.824+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:44:25.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-23T16:44:56.008+0000] {processor.py:157} INFO - Started process (PID=2605) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:44:56.009+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:44:56.009+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:44:56.009+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:44:56.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:44:56.056+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:44:56.056+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:44:56.082+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:44:56.082+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:44:56.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-23T16:45:26.180+0000] {processor.py:157} INFO - Started process (PID=2607) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:45:26.181+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:45:26.182+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:45:26.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:45:26.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:45:26.232+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:45:26.232+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:45:26.258+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:45:26.258+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:45:26.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T16:45:56.460+0000] {processor.py:157} INFO - Started process (PID=2609) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:45:56.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:45:56.461+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:45:56.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:45:56.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:45:56.504+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:45:56.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:45:56.529+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:45:56.529+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:45:56.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T16:46:26.665+0000] {processor.py:157} INFO - Started process (PID=2611) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:46:26.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:46:26.668+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:46:26.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:46:26.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:46:26.710+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:46:26.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:46:26.732+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:46:26.732+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:46:26.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-23T16:46:57.030+0000] {processor.py:157} INFO - Started process (PID=2613) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:46:57.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:46:57.045+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:46:57.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:46:57.116+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:46:57.220+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:46:57.220+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:46:57.433+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:46:57.433+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:46:57.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.514 seconds
[2024-10-23T16:55:30.216+0000] {processor.py:157} INFO - Started process (PID=2617) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:55:30.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:55:30.219+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:55:30.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:55:30.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:55:30.406+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:55:30.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:55:30.537+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:55:30.536+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:55:30.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.414 seconds
[2024-10-23T16:56:00.781+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:56:00.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:56:00.784+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:56:00.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:56:00.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:56:00.841+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:56:00.840+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:56:00.880+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:56:00.880+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:56:00.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T16:56:30.950+0000] {processor.py:157} INFO - Started process (PID=2621) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:56:30.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:56:30.952+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:56:30.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:56:30.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:56:31.011+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:56:31.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:56:31.041+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:56:31.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:56:31.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T16:57:01.234+0000] {processor.py:157} INFO - Started process (PID=2623) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:57:01.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:57:01.237+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:57:01.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:57:01.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:57:01.289+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:57:01.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:57:01.318+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:57:01.318+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:57:01.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T16:57:31.508+0000] {processor.py:157} INFO - Started process (PID=2625) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:57:31.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:57:31.510+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:57:31.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:57:31.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:57:31.560+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:57:31.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:57:31.593+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:57:31.593+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:57:31.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T16:58:01.671+0000] {processor.py:157} INFO - Started process (PID=2627) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:58:01.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:58:01.673+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:58:01.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:58:01.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:58:01.720+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:58:01.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:58:01.751+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:58:01.751+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:58:01.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T16:58:31.961+0000] {processor.py:157} INFO - Started process (PID=2629) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:58:31.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:58:31.963+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:58:31.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:58:31.980+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:58:32.013+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:58:32.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:58:32.043+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:58:32.042+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:58:32.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-23T16:59:02.124+0000] {processor.py:157} INFO - Started process (PID=2631) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:59:02.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:59:02.128+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:59:02.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:59:02.142+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:59:02.177+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:59:02.176+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:59:02.206+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:59:02.206+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:59:02.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T16:59:32.395+0000] {processor.py:157} INFO - Started process (PID=2633) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:59:32.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T16:59:32.397+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:59:32.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:59:32.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T16:59:32.446+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:59:32.445+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T16:59:32.475+0000] {logging_mixin.py:149} INFO - [2024-10-23T16:59:32.475+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T16:59:32.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T17:00:02.688+0000] {processor.py:157} INFO - Started process (PID=2635) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:00:02.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:00:02.702+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:00:02.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:00:02.715+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:00:02.745+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:00:02.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:00:02.772+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:00:02.772+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:00:02.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T17:00:32.869+0000] {processor.py:157} INFO - Started process (PID=2637) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:00:32.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:00:32.870+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:00:32.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:00:32.882+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:00:32.912+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:00:32.912+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:00:32.941+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:00:32.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:00:32.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-23T17:01:03.131+0000] {processor.py:157} INFO - Started process (PID=2639) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:01:03.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:01:03.144+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:01:03.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:01:03.157+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:01:03.190+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:01:03.190+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:01:03.218+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:01:03.218+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:01:03.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T17:01:33.332+0000] {processor.py:157} INFO - Started process (PID=2641) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:01:33.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:01:33.333+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:01:33.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:01:33.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:01:33.393+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:01:33.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:01:33.426+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:01:33.425+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:01:33.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-23T17:02:03.547+0000] {processor.py:157} INFO - Started process (PID=2643) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:02:03.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:02:03.549+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:02:03.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:02:03.566+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:02:03.607+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:02:03.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:02:03.646+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:02:03.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:02:03.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-23T17:02:33.876+0000] {processor.py:157} INFO - Started process (PID=2645) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:02:33.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:02:33.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:02:33.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:02:33.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:02:33.926+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:02:33.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:02:33.962+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:02:33.962+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:02:33.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T17:03:04.050+0000] {processor.py:157} INFO - Started process (PID=2647) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:03:04.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:03:04.063+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:03:04.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:03:04.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:03:04.112+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:03:04.112+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:03:04.147+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:03:04.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:03:04.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T17:03:34.292+0000] {processor.py:157} INFO - Started process (PID=2649) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:03:34.293+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:03:34.294+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:03:34.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:03:34.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:03:34.348+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:03:34.347+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:03:34.382+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:03:34.381+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:03:34.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-23T17:04:04.592+0000] {processor.py:157} INFO - Started process (PID=2651) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:04:04.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:04:04.602+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:04:04.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:04:04.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:04:04.649+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:04:04.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:04:04.683+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:04:04.683+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:04:04.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T17:04:34.758+0000] {processor.py:157} INFO - Started process (PID=2653) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:04:34.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:04:34.760+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:04:34.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:04:34.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:04:34.810+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:04:34.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:04:34.843+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:04:34.842+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:04:34.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T17:05:05.008+0000] {processor.py:157} INFO - Started process (PID=2655) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:05:05.009+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:05:05.013+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:05:05.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:05:05.033+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:05:05.073+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:05:05.072+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:05:05.107+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:05:05.107+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:05:05.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-23T17:05:35.191+0000] {processor.py:157} INFO - Started process (PID=2657) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:05:35.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:05:35.193+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:05:35.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:05:35.215+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:05:35.255+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:05:35.255+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:05:35.290+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:05:35.289+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:05:35.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-23T17:06:05.480+0000] {processor.py:157} INFO - Started process (PID=2659) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:06:05.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:06:05.482+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:06:05.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:06:05.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:06:05.530+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:06:05.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:06:05.557+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:06:05.557+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:06:05.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T17:06:35.647+0000] {processor.py:157} INFO - Started process (PID=2661) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:06:35.648+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:06:35.648+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:06:35.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:06:35.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:06:35.696+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:06:35.696+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:06:35.729+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:06:35.728+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:06:35.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T17:07:05.895+0000] {processor.py:157} INFO - Started process (PID=2663) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:07:05.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:07:05.899+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:07:05.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:07:05.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:07:05.955+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:07:05.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:07:05.992+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:07:05.991+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:07:06.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-23T17:07:36.202+0000] {processor.py:157} INFO - Started process (PID=2665) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:07:36.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:07:36.205+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:07:36.205+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:07:36.227+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:07:36.270+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:07:36.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:07:36.310+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:07:36.310+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:07:36.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-23T17:08:06.508+0000] {processor.py:157} INFO - Started process (PID=2667) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:08:06.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:08:06.510+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:08:06.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:08:06.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:08:06.561+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:08:06.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:08:06.596+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:08:06.596+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:08:06.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T17:08:36.796+0000] {processor.py:157} INFO - Started process (PID=2669) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:08:36.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:08:36.799+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:08:36.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:08:36.818+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:08:36.856+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:08:36.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:08:36.889+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:08:36.889+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:08:36.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T17:09:06.968+0000] {processor.py:157} INFO - Started process (PID=2671) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:09:06.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:09:06.969+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:09:06.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:09:06.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:09:07.017+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:09:07.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:09:07.044+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:09:07.043+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:09:07.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-23T17:09:37.243+0000] {processor.py:157} INFO - Started process (PID=2673) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:09:37.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:09:37.245+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:09:37.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:09:37.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:09:37.298+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:09:37.297+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:09:37.324+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:09:37.324+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:09:37.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T17:10:07.523+0000] {processor.py:157} INFO - Started process (PID=2675) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:10:07.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:10:07.524+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:10:07.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:10:07.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:10:07.573+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:10:07.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:10:07.604+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:10:07.604+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:10:07.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T17:10:37.704+0000] {processor.py:157} INFO - Started process (PID=2677) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:10:37.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:10:37.718+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:10:37.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:10:37.735+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:10:37.777+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:10:37.777+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:10:37.813+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:10:37.813+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:10:37.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-23T17:11:07.917+0000] {processor.py:157} INFO - Started process (PID=2679) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:11:07.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:11:07.919+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:11:07.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:11:07.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:11:07.969+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:11:07.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:11:07.999+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:11:07.999+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:11:08.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T17:11:38.208+0000] {processor.py:157} INFO - Started process (PID=2681) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:11:38.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T17:11:38.221+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:11:38.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:11:38.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T17:11:38.263+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:11:38.262+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T17:11:38.291+0000] {logging_mixin.py:149} INFO - [2024-10-23T17:11:38.291+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T17:11:38.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T20:11:49.641+0000] {processor.py:157} INFO - Started process (PID=2684) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T20:11:49.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T20:11:49.653+0000] {logging_mixin.py:149} INFO - [2024-10-23T20:11:49.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T20:11:49.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T20:11:49.854+0000] {logging_mixin.py:149} INFO - [2024-10-23T20:11:49.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T20:11:49.989+0000] {logging_mixin.py:149} INFO - [2024-10-23T20:11:49.989+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T20:11:50.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.446 seconds
[2024-10-23T21:38:27.563+0000] {processor.py:157} INFO - Started process (PID=2687) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:38:27.621+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:38:27.744+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:38:27.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:38:27.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:38:28.062+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:38:28.061+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:38:28.219+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:38:28.219+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:38:28.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.911 seconds
[2024-10-23T21:38:58.601+0000] {processor.py:157} INFO - Started process (PID=2691) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:38:58.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:38:58.604+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:38:58.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:38:58.619+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:38:58.658+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:38:58.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:38:58.690+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:38:58.690+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:38:58.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T21:39:28.886+0000] {processor.py:157} INFO - Started process (PID=2693) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:39:28.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:39:28.888+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:39:28.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:39:28.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:39:28.940+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:39:28.939+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:39:28.972+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:39:28.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:39:28.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-23T21:39:59.164+0000] {processor.py:157} INFO - Started process (PID=2695) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:39:59.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:39:59.166+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:39:59.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:39:59.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:39:59.222+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:39:59.222+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:39:59.248+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:39:59.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:39:59.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T21:40:29.456+0000] {processor.py:157} INFO - Started process (PID=2697) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:40:29.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:40:29.458+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:40:29.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:40:29.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:40:29.505+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:40:29.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:40:29.531+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:40:29.530+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:40:29.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T21:40:59.731+0000] {processor.py:157} INFO - Started process (PID=2699) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:40:59.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:40:59.735+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:40:59.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:40:59.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:40:59.787+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:40:59.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:40:59.820+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:40:59.819+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:40:59.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T21:41:29.903+0000] {processor.py:157} INFO - Started process (PID=2701) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:41:29.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:41:29.905+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:41:29.905+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:41:29.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:41:29.963+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:41:29.963+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:41:30.002+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:41:30.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:41:30.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-23T21:42:00.206+0000] {processor.py:157} INFO - Started process (PID=2703) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:42:00.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:42:00.209+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:42:00.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:42:00.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:42:00.271+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:42:00.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:42:00.301+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:42:00.301+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:42:00.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-23T21:42:30.515+0000] {processor.py:157} INFO - Started process (PID=2705) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:42:30.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:42:30.517+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:42:30.517+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:42:30.549+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:42:30.594+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:42:30.594+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:42:30.637+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:42:30.637+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:42:30.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.154 seconds
[2024-10-23T21:43:00.681+0000] {processor.py:157} INFO - Started process (PID=2707) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:43:00.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:43:00.683+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:43:00.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:43:00.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:43:00.727+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:43:00.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:43:00.753+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:43:00.753+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:43:00.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-23T21:43:30.961+0000] {processor.py:157} INFO - Started process (PID=2709) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:43:30.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:43:30.962+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:43:30.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:43:30.979+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:43:31.016+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:43:31.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:43:31.050+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:43:31.050+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:43:31.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T21:44:01.252+0000] {processor.py:157} INFO - Started process (PID=2711) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:44:01.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:44:01.265+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:44:01.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:44:01.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:44:01.312+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:44:01.311+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:44:01.338+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:44:01.338+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:44:01.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T21:44:31.425+0000] {processor.py:157} INFO - Started process (PID=2713) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:44:31.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:44:31.427+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:44:31.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:44:31.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:44:31.474+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:44:31.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:44:31.506+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:44:31.505+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:44:31.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T21:45:01.662+0000] {processor.py:157} INFO - Started process (PID=2715) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:45:01.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:45:01.676+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:45:01.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:45:01.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:45:01.719+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:45:01.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:45:01.749+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:45:01.748+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:45:01.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T21:45:31.836+0000] {processor.py:157} INFO - Started process (PID=2717) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:45:31.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:45:31.837+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:45:31.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:45:31.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:45:31.886+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:45:31.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:45:31.920+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:45:31.920+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:45:31.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T21:46:02.112+0000] {processor.py:157} INFO - Started process (PID=2719) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:46:02.114+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:46:02.115+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:46:02.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:46:02.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:46:02.168+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:46:02.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:46:02.194+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:46:02.194+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:46:02.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T21:46:32.296+0000] {processor.py:157} INFO - Started process (PID=2721) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:46:32.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:46:32.298+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:46:32.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:46:32.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:46:32.353+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:46:32.353+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:46:32.384+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:46:32.384+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:46:32.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T21:47:02.577+0000] {processor.py:157} INFO - Started process (PID=2723) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:47:02.587+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:47:02.588+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:47:02.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:47:02.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:47:02.644+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:47:02.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:47:02.679+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:47:02.679+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:47:02.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-23T21:47:32.881+0000] {processor.py:157} INFO - Started process (PID=2725) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:47:32.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:47:32.883+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:47:32.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:47:32.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:47:32.933+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:47:32.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:47:32.962+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:47:32.962+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:47:32.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T21:48:03.151+0000] {processor.py:157} INFO - Started process (PID=2727) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:48:03.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:48:03.154+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:48:03.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:48:03.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:48:03.209+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:48:03.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:48:03.242+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:48:03.241+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:48:03.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T21:48:33.439+0000] {processor.py:157} INFO - Started process (PID=2729) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:48:33.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:48:33.441+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:48:33.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:48:33.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:48:33.496+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:48:33.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:48:33.537+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:48:33.537+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:48:33.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T21:49:03.630+0000] {processor.py:157} INFO - Started process (PID=2731) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:49:03.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:49:03.641+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:49:03.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:49:03.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:49:03.708+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:49:03.708+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:49:03.744+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:49:03.744+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:49:03.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.147 seconds
[2024-10-23T21:49:33.868+0000] {processor.py:157} INFO - Started process (PID=2733) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:49:33.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:49:33.870+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:49:33.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:49:33.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:49:33.932+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:49:33.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:49:33.971+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:49:33.971+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:49:34.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.137 seconds
[2024-10-23T21:50:04.180+0000] {processor.py:157} INFO - Started process (PID=2735) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:50:04.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:50:04.183+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:50:04.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:50:04.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:50:04.249+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:50:04.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:50:04.289+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:50:04.289+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:50:04.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.139 seconds
[2024-10-23T21:50:34.354+0000] {processor.py:157} INFO - Started process (PID=2737) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:50:34.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:50:34.355+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:50:34.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:50:34.375+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:50:34.409+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:50:34.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:50:34.446+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:50:34.443+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:50:34.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T21:51:04.643+0000] {processor.py:157} INFO - Started process (PID=2739) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:51:04.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:51:04.646+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:51:04.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:51:04.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:51:04.706+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:51:04.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:51:04.735+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:51:04.735+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:51:04.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T21:51:34.941+0000] {processor.py:157} INFO - Started process (PID=2741) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:51:34.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:51:34.943+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:51:34.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:51:34.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:51:35.001+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:51:35.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:51:35.046+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:51:35.045+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:51:35.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-23T21:52:05.104+0000] {processor.py:157} INFO - Started process (PID=2743) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:52:05.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:52:05.106+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:52:05.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:52:05.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:52:05.170+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:52:05.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:52:05.199+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:52:05.199+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:52:05.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-23T21:52:35.365+0000] {processor.py:157} INFO - Started process (PID=2745) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:52:35.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:52:35.367+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:52:35.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:52:35.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:52:35.430+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:52:35.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:52:35.461+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:52:35.460+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:52:35.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T21:53:05.533+0000] {processor.py:157} INFO - Started process (PID=2747) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:53:05.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:53:05.536+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:53:05.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:53:05.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:53:05.732+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:53:05.732+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:53:05.856+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:53:05.856+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:53:05.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.405 seconds
[2024-10-23T21:53:36.137+0000] {processor.py:157} INFO - Started process (PID=2749) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:53:36.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:53:36.139+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:53:36.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:53:36.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:53:36.299+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:53:36.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:53:36.407+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:53:36.407+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:53:36.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.336 seconds
[2024-10-23T21:54:06.616+0000] {processor.py:157} INFO - Started process (PID=2751) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:54:06.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:54:06.629+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:54:06.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:54:06.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:54:06.677+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:54:06.677+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:54:06.709+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:54:06.709+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:54:06.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-23T21:54:36.918+0000] {processor.py:157} INFO - Started process (PID=2753) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:54:36.920+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:54:36.922+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:54:36.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:54:36.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:54:36.974+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:54:36.974+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:54:37.005+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:54:37.005+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:54:37.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T21:55:07.195+0000] {processor.py:157} INFO - Started process (PID=2755) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:55:07.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:55:07.208+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:55:07.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:55:07.220+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:55:07.254+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:55:07.254+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:55:07.279+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:55:07.278+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:55:07.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T21:55:37.364+0000] {processor.py:157} INFO - Started process (PID=2757) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:55:37.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:55:37.366+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:55:37.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:55:37.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:55:37.415+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:55:37.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:55:37.439+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:55:37.439+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:55:37.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-23T21:56:07.630+0000] {processor.py:157} INFO - Started process (PID=2759) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:56:07.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:56:07.633+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:56:07.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:56:07.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:56:07.688+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:56:07.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:56:07.721+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:56:07.721+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:56:07.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T21:56:37.919+0000] {processor.py:157} INFO - Started process (PID=2761) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:56:37.920+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:56:37.921+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:56:37.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:56:37.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:56:37.984+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:56:37.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:56:38.025+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:56:38.024+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:56:38.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-23T21:57:08.217+0000] {processor.py:157} INFO - Started process (PID=2763) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:57:08.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:57:08.221+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:57:08.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:57:08.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:57:08.270+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:57:08.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:57:08.297+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:57:08.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:57:08.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T21:57:38.399+0000] {processor.py:157} INFO - Started process (PID=2765) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:57:38.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:57:38.400+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:57:38.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:57:38.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:57:38.454+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:57:38.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:57:38.489+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:57:38.489+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:57:38.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T21:58:08.613+0000] {processor.py:157} INFO - Started process (PID=2767) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:58:08.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:58:08.626+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:58:08.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:58:08.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:58:08.673+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:58:08.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:58:08.700+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:58:08.700+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:58:08.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T21:58:38.829+0000] {processor.py:157} INFO - Started process (PID=2769) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:58:38.830+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:58:38.831+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:58:38.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:58:38.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:58:38.891+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:58:38.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:58:38.924+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:58:38.923+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:58:38.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-23T21:59:09.022+0000] {processor.py:157} INFO - Started process (PID=2771) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:59:09.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:59:09.026+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:59:09.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:59:09.042+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:59:09.075+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:59:09.074+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:59:09.105+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:59:09.104+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:59:09.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-23T21:59:39.310+0000] {processor.py:157} INFO - Started process (PID=2773) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:59:39.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T21:59:39.312+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:59:39.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:59:39.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T21:59:39.358+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:59:39.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T21:59:39.384+0000] {logging_mixin.py:149} INFO - [2024-10-23T21:59:39.384+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T21:59:39.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T22:00:09.591+0000] {processor.py:157} INFO - Started process (PID=2775) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:00:09.592+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:00:09.593+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:00:09.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:00:09.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:00:09.641+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:00:09.641+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:00:09.665+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:00:09.665+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:00:09.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T22:00:39.873+0000] {processor.py:157} INFO - Started process (PID=2777) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:00:39.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:00:39.875+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:00:39.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:00:39.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:00:39.927+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:00:39.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:00:39.955+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:00:39.955+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:00:39.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T22:01:10.161+0000] {processor.py:157} INFO - Started process (PID=2779) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:01:10.162+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:01:10.163+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:01:10.163+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:01:10.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:01:10.231+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:01:10.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:01:10.263+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:01:10.263+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:01:10.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T22:01:40.336+0000] {processor.py:157} INFO - Started process (PID=2781) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:01:40.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:01:40.337+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:01:40.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:01:40.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:01:40.402+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:01:40.402+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:01:40.437+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:01:40.437+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:01:40.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T22:02:10.577+0000] {processor.py:157} INFO - Started process (PID=2783) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:02:10.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:02:10.590+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:02:10.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:02:10.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:02:10.633+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:02:10.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:02:10.667+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:02:10.667+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:02:10.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T22:02:40.758+0000] {processor.py:157} INFO - Started process (PID=2785) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:02:40.763+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:02:40.766+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:02:40.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:02:40.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:02:40.828+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:02:40.828+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:02:40.865+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:02:40.864+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:02:40.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.138 seconds
[2024-10-23T22:03:11.061+0000] {processor.py:157} INFO - Started process (PID=2787) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:03:11.063+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:03:11.064+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:03:11.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:03:11.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:03:11.127+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:03:11.127+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:03:11.162+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:03:11.161+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:03:11.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-23T22:03:41.241+0000] {processor.py:157} INFO - Started process (PID=2789) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:03:41.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:03:41.243+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:03:41.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:03:41.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:03:41.384+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:03:41.384+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:03:41.482+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:03:41.482+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:03:41.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.336 seconds
[2024-10-23T22:04:11.761+0000] {processor.py:157} INFO - Started process (PID=2791) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:04:11.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:04:11.774+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:04:11.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:04:11.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:04:11.816+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:04:11.816+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:04:11.844+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:04:11.844+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:04:11.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-23T22:04:41.950+0000] {processor.py:157} INFO - Started process (PID=2793) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:04:41.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:04:41.951+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:04:41.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:04:41.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:04:42.000+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:04:42.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:04:42.027+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:04:42.027+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:04:42.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T22:05:12.231+0000] {processor.py:157} INFO - Started process (PID=2795) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:05:12.232+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:05:12.233+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:05:12.233+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:05:12.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:05:12.284+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:05:12.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:05:12.311+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:05:12.310+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:05:12.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-23T22:05:42.406+0000] {processor.py:157} INFO - Started process (PID=2797) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:05:42.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:05:42.408+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:05:42.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:05:42.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:05:42.469+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:05:42.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:05:42.501+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:05:42.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:05:42.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-23T22:06:12.695+0000] {processor.py:157} INFO - Started process (PID=2799) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:06:12.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:06:12.697+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:06:12.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:06:12.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:06:12.748+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:06:12.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:06:12.779+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:06:12.778+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:06:12.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-23T22:06:42.869+0000] {processor.py:157} INFO - Started process (PID=2801) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:06:42.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:06:42.871+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:06:42.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:06:42.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:06:42.924+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:06:42.924+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:06:42.954+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:06:42.954+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:06:42.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T22:07:13.100+0000] {processor.py:157} INFO - Started process (PID=2803) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:07:13.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:07:13.103+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:07:13.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:07:13.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:07:13.152+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:07:13.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:07:13.184+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:07:13.184+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:07:13.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T22:07:43.382+0000] {processor.py:157} INFO - Started process (PID=2805) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:07:43.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:07:43.383+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:07:43.383+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:07:43.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:07:43.442+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:07:43.442+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:07:43.479+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:07:43.478+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:07:43.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-23T22:08:13.673+0000] {processor.py:157} INFO - Started process (PID=2807) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:08:13.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:08:13.686+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:08:13.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:08:13.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:08:13.735+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:08:13.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:08:13.763+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:08:13.763+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:08:13.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T22:08:43.858+0000] {processor.py:157} INFO - Started process (PID=2809) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:08:43.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:08:43.860+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:08:43.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:08:43.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:08:43.943+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:08:43.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:08:43.972+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:08:43.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:08:44.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-23T22:09:14.203+0000] {processor.py:157} INFO - Started process (PID=2811) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:09:14.210+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:09:14.211+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:09:14.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:09:14.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:09:14.260+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:09:14.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:09:14.298+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:09:14.297+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:09:14.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-23T22:09:44.503+0000] {processor.py:157} INFO - Started process (PID=2813) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:09:44.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:09:44.505+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:09:44.504+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:09:44.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:09:44.570+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:09:44.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:09:44.601+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:09:44.601+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:09:44.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T22:10:14.792+0000] {processor.py:157} INFO - Started process (PID=2815) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:10:14.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:10:14.806+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:10:14.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:10:14.817+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:10:14.848+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:10:14.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:10:14.875+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:10:14.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:10:14.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T22:10:44.970+0000] {processor.py:157} INFO - Started process (PID=2817) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:10:44.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:10:44.972+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:10:44.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:10:44.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:10:45.028+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:10:45.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:10:45.065+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:10:45.065+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:10:45.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-23T22:11:15.267+0000] {processor.py:157} INFO - Started process (PID=2819) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:11:15.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:11:15.269+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:11:15.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:11:15.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:11:15.328+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:11:15.328+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:11:15.358+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:11:15.358+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:11:15.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-23T22:11:45.570+0000] {processor.py:157} INFO - Started process (PID=2821) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:11:45.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:11:45.573+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:11:45.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:11:45.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:11:45.643+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:11:45.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:11:45.683+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:11:45.683+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:11:45.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-23T22:12:15.888+0000] {processor.py:157} INFO - Started process (PID=2823) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:12:15.901+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:12:15.901+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:12:15.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:12:15.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:12:15.954+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:12:15.954+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:12:15.987+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:12:15.987+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:12:16.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-23T22:12:46.069+0000] {processor.py:157} INFO - Started process (PID=2825) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:12:46.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:12:46.071+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:12:46.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:12:46.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:12:46.112+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:12:46.112+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:12:46.138+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:12:46.137+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:12:46.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-23T22:13:16.328+0000] {processor.py:157} INFO - Started process (PID=2827) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:13:16.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:13:16.341+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:13:16.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:13:16.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:13:16.383+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:13:16.383+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:13:16.411+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:13:16.411+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:13:16.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-23T22:13:46.517+0000] {processor.py:157} INFO - Started process (PID=2829) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:13:46.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:13:46.519+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:13:46.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:13:46.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:13:46.578+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:13:46.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:13:46.606+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:13:46.606+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:13:46.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-23T22:14:16.803+0000] {processor.py:157} INFO - Started process (PID=2831) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:14:16.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:14:16.805+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:14:16.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:14:16.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:14:16.865+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:14:16.865+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:14:16.907+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:14:16.907+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:14:16.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-23T22:14:46.988+0000] {processor.py:157} INFO - Started process (PID=2833) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:14:47.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:14:47.000+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:14:47.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:14:47.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:14:47.046+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:14:47.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:14:47.074+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:14:47.074+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:14:47.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T22:25:10.394+0000] {processor.py:157} INFO - Started process (PID=2835) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:25:10.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:25:10.398+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:25:10.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:25:10.460+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:25:10.681+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:25:10.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:25:10.843+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:25:10.843+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:25:10.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.568 seconds
[2024-10-23T22:25:41.115+0000] {processor.py:157} INFO - Started process (PID=2839) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:25:41.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:25:41.118+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:25:41.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:25:41.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:25:41.200+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:25:41.200+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:25:41.234+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:25:41.234+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:25:41.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.164 seconds
[2024-10-23T22:26:11.416+0000] {processor.py:157} INFO - Started process (PID=2841) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:26:11.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:26:11.417+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:26:11.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:26:11.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:26:11.472+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:26:11.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:26:11.509+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:26:11.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:26:11.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-23T22:26:41.577+0000] {processor.py:157} INFO - Started process (PID=2843) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:26:41.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:26:41.591+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:26:41.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:26:41.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:26:41.634+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:26:41.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:26:41.664+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:26:41.664+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:26:41.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-23T22:27:11.831+0000] {processor.py:157} INFO - Started process (PID=2845) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:27:11.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:27:11.833+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:27:11.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:27:11.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:27:11.878+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:27:11.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:27:11.905+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:27:11.905+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:27:11.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-23T22:27:42.092+0000] {processor.py:157} INFO - Started process (PID=2847) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:27:42.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:27:42.094+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:27:42.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:27:42.109+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:27:42.146+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:27:42.146+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:27:42.230+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:27:42.220+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:27:42.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.225 seconds
[2024-10-23T22:28:12.492+0000] {processor.py:157} INFO - Started process (PID=2849) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:28:12.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:28:12.494+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:28:12.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:28:12.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:28:12.550+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:28:12.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:28:12.581+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:28:12.581+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:28:12.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-23T22:34:08.276+0000] {processor.py:157} INFO - Started process (PID=2851) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:34:08.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:34:08.282+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:34:08.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:34:08.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:34:08.496+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:34:08.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:34:08.609+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:34:08.609+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:34:08.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.471 seconds
[2024-10-23T22:34:39.037+0000] {processor.py:157} INFO - Started process (PID=2855) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:34:39.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:34:39.040+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:34:39.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:34:39.065+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:34:39.107+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:34:39.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:34:39.139+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:34:39.139+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:34:39.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.138 seconds
[2024-10-23T22:35:09.220+0000] {processor.py:157} INFO - Started process (PID=2857) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:35:09.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:35:09.223+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:35:09.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:35:09.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:35:09.285+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:35:09.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:35:09.328+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:35:09.328+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:35:09.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.139 seconds
[2024-10-23T22:35:39.481+0000] {processor.py:157} INFO - Started process (PID=2859) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:35:39.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:35:39.484+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:35:39.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:35:39.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:35:39.539+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:35:39.539+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:35:39.575+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:35:39.575+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:35:39.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-23T22:36:09.799+0000] {processor.py:157} INFO - Started process (PID=2861) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:36:09.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:36:09.800+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:36:09.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:36:09.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:36:09.846+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:36:09.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:36:09.872+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:36:09.872+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:36:09.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-23T22:36:39.959+0000] {processor.py:157} INFO - Started process (PID=2863) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:36:39.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:36:39.961+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:36:39.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:36:39.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:36:40.008+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:36:40.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:36:40.037+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:36:40.037+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:36:40.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-23T22:37:10.187+0000] {processor.py:157} INFO - Started process (PID=2865) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:37:10.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:37:10.189+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:37:10.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:37:10.205+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:37:10.240+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:37:10.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:37:10.267+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:37:10.267+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:37:10.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T22:37:40.461+0000] {processor.py:157} INFO - Started process (PID=2867) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:37:40.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:37:40.473+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:37:40.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:37:40.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:37:40.524+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:37:40.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:37:40.553+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:37:40.553+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:37:40.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-23T22:38:10.621+0000] {processor.py:157} INFO - Started process (PID=2869) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:38:10.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:38:10.622+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:38:10.622+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:38:10.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:38:10.668+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:38:10.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:38:10.700+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:38:10.699+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:38:10.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-23T22:38:40.905+0000] {processor.py:157} INFO - Started process (PID=2871) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:38:40.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:38:40.907+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:38:40.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:38:40.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:38:40.967+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:38:40.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:38:41.002+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:38:41.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:38:41.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-23T22:39:11.078+0000] {processor.py:157} INFO - Started process (PID=2873) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:39:11.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:39:11.080+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:39:11.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:39:11.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:39:11.129+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:39:11.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:39:11.176+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:39:11.176+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:39:11.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.172 seconds
[2024-10-23T22:39:41.410+0000] {processor.py:157} INFO - Started process (PID=2875) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:39:41.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:39:41.423+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:39:41.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:39:41.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:39:41.474+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:39:41.473+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:39:41.539+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:39:41.539+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:39:41.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.153 seconds
[2024-10-23T22:40:11.580+0000] {processor.py:157} INFO - Started process (PID=2877) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:40:11.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:40:11.581+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:40:11.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:40:11.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:40:11.626+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:40:11.626+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:40:11.648+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:40:11.648+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:40:11.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-23T22:40:41.844+0000] {processor.py:157} INFO - Started process (PID=2879) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:40:41.845+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:40:41.846+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:40:41.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:40:41.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:40:41.895+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:40:41.895+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:40:41.929+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:40:41.929+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:40:41.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-23T22:41:12.119+0000] {processor.py:157} INFO - Started process (PID=2881) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:41:12.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-23T22:41:12.121+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:41:12.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:41:12.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-23T22:41:12.167+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:41:12.167+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-23T22:41:12.196+0000] {logging_mixin.py:149} INFO - [2024-10-23T22:41:12.196+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-23T22:41:12.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
