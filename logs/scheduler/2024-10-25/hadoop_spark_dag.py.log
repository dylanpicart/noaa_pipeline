[2024-10-25T00:00:24.595+0000] {processor.py:157} INFO - Started process (PID=5274) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:00:24.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:00:24.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:00:24.597+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:00:24.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:00:24.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:00:24.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:00:24.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:00:24.687+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:00:24.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T00:00:54.878+0000] {processor.py:157} INFO - Started process (PID=5276) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:00:54.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:00:54.880+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:00:54.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:00:54.897+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:00:54.932+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:00:54.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:00:54.966+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:00:54.966+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:00:54.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T00:01:25.145+0000] {processor.py:157} INFO - Started process (PID=5278) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:01:25.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:01:25.149+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:01:25.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:01:25.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:01:25.206+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:01:25.206+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:01:25.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:01:25.238+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:01:25.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T00:01:55.314+0000] {processor.py:157} INFO - Started process (PID=5280) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:01:55.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:01:55.318+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:01:55.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:01:55.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:01:55.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:01:55.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:01:55.398+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:01:55.398+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:01:55.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T00:02:25.568+0000] {processor.py:157} INFO - Started process (PID=5282) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:02:25.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:02:25.569+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:02:25.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:02:25.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:02:25.618+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:02:25.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:02:25.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:02:25.645+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:02:25.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-25T00:02:55.845+0000] {processor.py:157} INFO - Started process (PID=5284) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:02:55.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:02:55.847+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:02:55.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:02:55.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:02:55.897+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:02:55.897+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:02:55.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:02:55.940+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:02:55.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-25T00:03:26.124+0000] {processor.py:157} INFO - Started process (PID=5286) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:03:26.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:03:26.126+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:03:26.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:03:26.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:03:26.173+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:03:26.173+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:03:26.198+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:03:26.198+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:03:26.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T00:03:56.373+0000] {processor.py:157} INFO - Started process (PID=5288) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:03:56.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:03:56.377+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:03:56.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:03:56.393+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:03:56.427+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:03:56.427+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:03:56.462+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:03:56.462+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:03:56.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T00:04:26.520+0000] {processor.py:157} INFO - Started process (PID=5290) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:04:26.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:04:26.522+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:04:26.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:04:26.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:04:26.565+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:04:26.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:04:26.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:04:26.590+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:04:26.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T00:04:56.767+0000] {processor.py:157} INFO - Started process (PID=5292) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:04:56.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:04:56.769+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:04:56.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:04:56.782+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:04:56.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:04:56.812+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:04:56.838+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:04:56.838+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:04:56.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T00:05:27.018+0000] {processor.py:157} INFO - Started process (PID=5299) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:05:27.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:05:27.021+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:05:27.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:05:27.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:05:27.069+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:05:27.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:05:27.095+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:05:27.095+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:05:27.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T00:05:57.215+0000] {processor.py:157} INFO - Started process (PID=5301) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:05:57.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:05:57.218+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:05:57.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:05:57.242+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:05:57.288+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:05:57.288+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:05:57.322+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:05:57.322+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:05:57.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-25T00:06:27.494+0000] {processor.py:157} INFO - Started process (PID=5303) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:06:27.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:06:27.496+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:06:27.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:06:27.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:06:27.542+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:06:27.542+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:06:27.566+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:06:27.566+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:06:27.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T00:06:57.749+0000] {processor.py:157} INFO - Started process (PID=5305) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:06:57.750+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:06:57.751+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:06:57.751+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:06:57.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:06:57.792+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:06:57.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:06:57.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:06:57.818+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:06:57.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T00:07:27.892+0000] {processor.py:157} INFO - Started process (PID=5307) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:07:27.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:07:27.894+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:07:27.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:07:27.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:07:27.938+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:07:27.938+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:07:27.963+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:07:27.963+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:07:27.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T00:07:58.142+0000] {processor.py:157} INFO - Started process (PID=5309) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:07:58.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:07:58.145+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:07:58.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:07:58.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:07:58.188+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:07:58.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:07:58.215+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:07:58.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:07:58.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T00:08:28.387+0000] {processor.py:157} INFO - Started process (PID=5311) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:08:28.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:08:28.389+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:08:28.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:08:28.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:08:28.438+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:08:28.438+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:08:28.463+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:08:28.462+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:08:28.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T00:08:58.536+0000] {processor.py:157} INFO - Started process (PID=5313) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:08:58.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:08:58.538+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:08:58.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:08:58.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:08:58.580+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:08:58.580+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:08:58.606+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:08:58.606+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:08:58.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T00:09:28.781+0000] {processor.py:157} INFO - Started process (PID=5315) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:09:28.782+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:09:28.783+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:09:28.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:09:28.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:09:28.830+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:09:28.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:09:28.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:09:28.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:09:28.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T00:09:58.931+0000] {processor.py:157} INFO - Started process (PID=5317) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:09:58.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:09:58.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:09:58.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:09:58.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:09:58.977+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:09:58.977+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:09:59.002+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:09:59.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:09:59.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T00:10:29.187+0000] {processor.py:157} INFO - Started process (PID=5319) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:10:29.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:10:29.191+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:10:29.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:10:29.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:10:29.239+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:10:29.239+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:10:29.263+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:10:29.263+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:10:29.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T00:10:59.453+0000] {processor.py:157} INFO - Started process (PID=5321) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:10:59.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:10:59.455+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:10:59.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:10:59.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:10:59.505+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:10:59.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:10:59.531+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:10:59.531+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:10:59.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T00:11:29.703+0000] {processor.py:157} INFO - Started process (PID=5323) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:11:29.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:11:29.705+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:11:29.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:11:29.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:11:29.751+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:11:29.751+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:11:29.782+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:11:29.782+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:11:31.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.680 seconds
[2024-10-25T00:12:01.531+0000] {processor.py:157} INFO - Started process (PID=5325) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:12:01.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:12:01.533+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:12:01.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:12:01.553+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:12:01.588+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:12:01.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:12:01.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:12:01.620+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:12:01.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T00:12:31.678+0000] {processor.py:157} INFO - Started process (PID=5327) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:12:31.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:12:31.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:12:31.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:12:31.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:12:31.732+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:12:31.732+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:12:31.763+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:12:31.763+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:12:31.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T00:13:01.903+0000] {processor.py:157} INFO - Started process (PID=5329) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:13:01.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:13:01.907+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:13:01.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:13:01.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:13:01.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:13:01.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:13:01.977+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:13:01.977+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:13:01.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T00:13:32.152+0000] {processor.py:157} INFO - Started process (PID=5331) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:13:32.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:13:32.154+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:13:32.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:13:32.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:13:32.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:13:32.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:13:32.233+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:13:32.233+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:13:32.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T00:14:02.416+0000] {processor.py:157} INFO - Started process (PID=5333) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:14:02.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:14:02.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:14:02.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:14:02.432+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:14:02.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:14:02.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:14:02.487+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:14:02.487+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:14:02.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T00:14:32.570+0000] {processor.py:157} INFO - Started process (PID=5335) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:14:32.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:14:32.573+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:14:32.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:14:32.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:14:32.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:14:32.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:14:32.658+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:14:32.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:14:32.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.233 seconds
[2024-10-25T00:15:02.919+0000] {processor.py:157} INFO - Started process (PID=5337) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:15:02.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:15:02.921+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:15:02.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:15:02.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:15:02.969+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:15:02.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:15:03.003+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:15:03.003+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:15:03.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T00:15:33.189+0000] {processor.py:157} INFO - Started process (PID=5339) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:15:33.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:15:33.191+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:15:33.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:15:33.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:15:33.236+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:15:33.236+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:15:33.262+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:15:33.262+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:15:33.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T00:16:03.338+0000] {processor.py:157} INFO - Started process (PID=5341) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:16:03.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:16:03.340+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:16:03.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:16:03.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:16:03.404+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:16:03.403+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:16:03.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:16:03.433+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:16:03.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T00:16:33.533+0000] {processor.py:157} INFO - Started process (PID=5343) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:16:33.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:16:33.534+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:16:33.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:16:33.553+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:16:33.584+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:16:33.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:16:33.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:16:33.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:16:33.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T00:17:03.797+0000] {processor.py:157} INFO - Started process (PID=5345) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:17:03.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:17:03.799+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:17:03.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:17:03.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:17:03.846+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:17:03.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:17:03.875+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:17:03.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:17:03.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T00:17:33.935+0000] {processor.py:157} INFO - Started process (PID=5347) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:17:33.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:17:33.936+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:17:33.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:17:33.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:17:33.980+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:17:33.980+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:17:34.007+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:17:34.007+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:17:34.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.225 seconds
[2024-10-25T00:18:04.277+0000] {processor.py:157} INFO - Started process (PID=5349) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:18:04.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:18:04.279+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:18:04.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:18:04.294+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:18:04.323+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:18:04.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:18:04.349+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:18:04.349+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:18:04.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T00:18:34.525+0000] {processor.py:157} INFO - Started process (PID=5351) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:18:34.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:18:34.527+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:18:34.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:18:34.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:18:34.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:18:34.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:18:34.598+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:18:34.598+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:18:34.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T00:19:04.768+0000] {processor.py:157} INFO - Started process (PID=5353) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:19:04.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:19:04.769+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:19:04.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:19:04.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:19:04.816+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:19:04.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:19:04.841+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:19:04.841+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:19:04.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T00:19:34.914+0000] {processor.py:157} INFO - Started process (PID=5355) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:19:34.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:19:34.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:19:34.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:19:34.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:19:34.958+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:19:34.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:19:34.983+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:19:34.983+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:19:35.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T00:20:05.166+0000] {processor.py:157} INFO - Started process (PID=5357) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:20:05.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:20:05.168+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:20:05.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:20:05.186+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:20:05.222+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:20:05.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:20:05.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:20:05.250+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:20:05.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T00:20:35.430+0000] {processor.py:157} INFO - Started process (PID=5359) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:20:35.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:20:35.431+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:20:35.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:20:35.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:20:35.474+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:20:35.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:20:35.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:20:35.499+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:20:35.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.215 seconds
[2024-10-25T00:21:05.796+0000] {processor.py:157} INFO - Started process (PID=5361) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:21:05.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:21:05.799+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:21:05.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:21:05.817+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:21:05.853+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:21:05.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:21:05.892+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:21:05.892+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:21:05.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T00:21:35.948+0000] {processor.py:157} INFO - Started process (PID=5363) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:21:35.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:21:35.950+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:21:35.950+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:21:35.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:21:36.001+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:21:36.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:21:36.031+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:21:36.031+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:21:36.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T00:22:06.210+0000] {processor.py:157} INFO - Started process (PID=5365) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:22:06.212+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:22:06.212+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:22:06.212+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:22:06.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:22:06.256+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:22:06.256+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:22:06.286+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:22:06.286+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:22:06.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T00:37:10.148+0000] {processor.py:157} INFO - Started process (PID=5367) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:37:10.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:37:10.150+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:37:10.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:37:10.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:37:11.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:37:11.246+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:37:11.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:37:11.313+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:37:11.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 2.796 seconds
[2024-10-25T00:47:58.535+0000] {processor.py:157} INFO - Started process (PID=5371) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:47:58.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:47:58.537+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:47:58.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:47:58.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:47:58.665+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:47:58.665+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:47:58.779+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:47:58.779+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:47:58.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.314 seconds
[2024-10-25T00:48:29.021+0000] {processor.py:157} INFO - Started process (PID=5375) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:48:29.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:48:29.024+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:48:29.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:48:29.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:48:29.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:48:29.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:48:29.256+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:48:29.256+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:48:29.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.274 seconds
[2024-10-25T00:48:59.460+0000] {processor.py:157} INFO - Started process (PID=5377) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:48:59.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:48:59.462+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:48:59.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:48:59.480+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:48:59.511+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:48:59.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:48:59.882+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:48:59.881+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:48:59.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.445 seconds
[2024-10-25T00:49:30.056+0000] {processor.py:157} INFO - Started process (PID=5379) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:49:30.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:49:30.067+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:49:30.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:49:30.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:49:30.115+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:49:30.115+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:49:30.144+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:49:30.143+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:49:30.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T00:50:00.320+0000] {processor.py:157} INFO - Started process (PID=5381) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:50:00.321+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:50:00.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:50:00.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:50:00.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:50:00.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:50:00.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:50:00.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:50:00.391+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:50:00.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T00:50:30.574+0000] {processor.py:157} INFO - Started process (PID=5383) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:50:30.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:50:30.576+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:50:30.576+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:50:30.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:50:30.623+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:50:30.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:50:30.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:50:30.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:50:30.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T00:51:00.717+0000] {processor.py:157} INFO - Started process (PID=5385) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:51:00.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:51:00.718+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:51:00.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:51:00.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:51:00.771+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:51:00.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:51:00.804+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:51:00.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:51:00.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T00:51:30.969+0000] {processor.py:157} INFO - Started process (PID=5387) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:51:30.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:51:30.971+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:51:30.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:51:30.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:51:31.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:51:31.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:51:31.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:51:31.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:51:31.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T00:52:01.213+0000] {processor.py:157} INFO - Started process (PID=5389) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:52:01.213+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:52:01.214+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:52:01.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:52:01.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:52:01.259+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:52:01.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:52:01.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:52:01.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:52:01.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.245 seconds
[2024-10-25T00:52:31.581+0000] {processor.py:157} INFO - Started process (PID=5391) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:52:31.583+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:52:31.583+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:52:31.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:52:31.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:52:31.624+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:52:31.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:52:31.655+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:52:31.655+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:52:31.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T00:53:01.735+0000] {processor.py:157} INFO - Started process (PID=5393) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:53:01.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:53:01.737+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:53:01.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:53:01.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:53:01.783+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:53:01.782+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:53:01.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:53:01.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:53:01.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T00:53:31.978+0000] {processor.py:157} INFO - Started process (PID=5395) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:53:31.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:53:31.980+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:53:31.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:53:31.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:53:32.029+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:53:32.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:53:32.055+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:53:32.055+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:53:32.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T00:54:02.129+0000] {processor.py:157} INFO - Started process (PID=5397) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:54:02.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:54:02.131+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:54:02.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:54:02.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:54:02.177+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:54:02.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:54:02.207+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:54:02.207+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:54:02.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T00:54:32.326+0000] {processor.py:157} INFO - Started process (PID=5399) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:54:32.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:54:32.328+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:54:32.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:54:32.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:54:32.374+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:54:32.374+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:54:32.400+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:54:32.400+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:54:32.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.258 seconds
[2024-10-25T00:55:02.700+0000] {processor.py:157} INFO - Started process (PID=5401) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:55:02.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:55:02.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:55:02.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:55:02.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:55:02.750+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:55:02.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:55:02.888+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:55:02.887+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:55:02.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.207 seconds
[2024-10-25T00:55:33.026+0000] {processor.py:157} INFO - Started process (PID=5403) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:55:33.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:55:33.028+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:55:33.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:55:33.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:55:33.081+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:55:33.081+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:55:33.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:55:33.121+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:55:33.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-25T00:56:03.304+0000] {processor.py:157} INFO - Started process (PID=5405) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:56:03.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:56:03.305+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:56:03.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:56:03.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:56:03.358+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:56:03.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:56:03.393+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:56:03.392+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:56:03.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T00:56:33.559+0000] {processor.py:157} INFO - Started process (PID=5407) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:56:33.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:56:33.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:56:33.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:56:33.580+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:56:33.611+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:56:33.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:56:33.637+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:56:33.637+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:56:33.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T00:57:03.709+0000] {processor.py:157} INFO - Started process (PID=5409) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:57:03.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:57:03.722+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:57:03.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:57:03.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:57:03.768+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:57:03.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:57:03.795+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:57:03.795+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:57:03.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T00:57:33.898+0000] {processor.py:157} INFO - Started process (PID=5411) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:57:33.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:57:33.899+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:57:33.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:57:33.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:57:33.947+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:57:33.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:57:33.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:57:33.974+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:57:34.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.216 seconds
[2024-10-25T00:58:04.272+0000] {processor.py:157} INFO - Started process (PID=5413) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:58:04.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:58:04.273+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:58:04.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:58:04.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:58:04.319+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:58:04.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:58:04.443+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:58:04.443+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:58:04.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-25T00:58:34.584+0000] {processor.py:157} INFO - Started process (PID=5415) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:58:34.585+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:58:34.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:58:34.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:58:34.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:58:34.628+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:58:34.628+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:58:34.657+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:58:34.656+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:58:34.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T00:59:04.829+0000] {processor.py:157} INFO - Started process (PID=5417) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:59:04.830+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:59:04.831+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:59:04.831+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:59:04.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:59:04.879+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:59:04.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:59:04.902+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:59:04.902+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:59:04.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T00:59:34.979+0000] {processor.py:157} INFO - Started process (PID=5419) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:59:34.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T00:59:34.980+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:59:34.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:59:34.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T00:59:35.025+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:59:35.025+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T00:59:35.048+0000] {logging_mixin.py:149} INFO - [2024-10-25T00:59:35.048+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T00:59:35.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T01:00:05.168+0000] {processor.py:157} INFO - Started process (PID=5421) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:00:05.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:00:05.181+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:00:05.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:00:05.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:00:05.224+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:00:05.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:00:05.251+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:00:05.251+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:00:05.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T01:00:35.319+0000] {processor.py:157} INFO - Started process (PID=5423) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:00:35.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:00:35.320+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:00:35.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:00:35.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:00:35.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:00:35.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:00:35.395+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:00:35.395+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:00:35.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.230 seconds
[2024-10-25T01:01:05.695+0000] {processor.py:157} INFO - Started process (PID=5425) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:01:05.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:01:05.697+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:01:05.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:01:05.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:01:05.741+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:01:05.740+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:01:05.864+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:01:05.864+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:01:05.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.191 seconds
[2024-10-25T01:01:36.038+0000] {processor.py:157} INFO - Started process (PID=5427) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:01:36.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:01:36.040+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:01:36.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:01:36.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:01:36.088+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:01:36.088+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:01:36.113+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:01:36.113+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:01:36.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T01:02:06.187+0000] {processor.py:157} INFO - Started process (PID=5429) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:02:06.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:02:06.189+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:02:06.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:02:06.201+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:02:06.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:02:06.229+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:02:06.258+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:02:06.257+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:02:06.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T01:02:36.423+0000] {processor.py:157} INFO - Started process (PID=5431) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:02:36.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:02:36.425+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:02:36.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:02:36.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:02:36.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:02:36.473+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:02:36.498+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:02:36.498+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:02:36.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T01:03:06.673+0000] {processor.py:157} INFO - Started process (PID=5433) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:03:06.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:03:06.675+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:03:06.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:03:06.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:03:06.736+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:03:06.736+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:03:06.769+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:03:06.769+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:03:06.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T01:03:36.943+0000] {processor.py:157} INFO - Started process (PID=5435) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:03:36.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:03:36.945+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:03:36.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:03:36.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:03:36.992+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:03:36.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:03:37.132+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:03:37.132+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:03:37.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.221 seconds
[2024-10-25T01:26:57.330+0000] {processor.py:157} INFO - Started process (PID=5437) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:26:57.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:26:57.332+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:26:57.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:26:57.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:26:57.405+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:26:57.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:26:57.669+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:26:57.668+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:26:57.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.395 seconds
[2024-10-25T01:27:27.892+0000] {processor.py:157} INFO - Started process (PID=5441) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:27:27.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:27:27.895+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:27:27.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:27:27.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:27:27.940+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:27:27.940+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:27:27.966+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:27:27.966+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:27:27.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T01:27:58.154+0000] {processor.py:157} INFO - Started process (PID=5443) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:27:58.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:27:58.155+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:27:58.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:27:58.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:27:58.212+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:27:58.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:27:58.252+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:27:58.252+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:27:58.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T01:28:28.435+0000] {processor.py:157} INFO - Started process (PID=5445) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:28:28.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:28:28.437+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:28:28.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:28:28.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:28:28.481+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:28:28.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:28:28.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:28:28.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:28:28.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T01:28:58.677+0000] {processor.py:157} INFO - Started process (PID=5447) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:28:58.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:28:58.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:28:58.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:28:58.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:28:58.782+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:28:58.782+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:28:58.808+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:28:58.808+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:28:58.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.151 seconds
[2024-10-25T01:29:28.976+0000] {processor.py:157} INFO - Started process (PID=5449) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:29:28.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:29:28.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:29:28.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:29:29.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:29:29.034+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:29:29.034+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:29:29.063+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:29:29.062+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:29:29.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.214 seconds
[2024-10-25T01:29:59.349+0000] {processor.py:157} INFO - Started process (PID=5451) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:29:59.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:29:59.350+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:29:59.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:29:59.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:29:59.396+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:29:59.396+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:29:59.531+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:29:59.530+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:29:59.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.203 seconds
[2024-10-25T01:30:29.705+0000] {processor.py:157} INFO - Started process (PID=5453) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:30:29.707+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:30:29.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:30:29.707+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:30:29.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:30:29.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:30:29.752+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:30:29.781+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:30:29.781+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:30:29.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T01:30:59.854+0000] {processor.py:157} INFO - Started process (PID=5455) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:30:59.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:30:59.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:30:59.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:30:59.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:30:59.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:30:59.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:30:59.927+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:30:59.927+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:30:59.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T01:31:30.101+0000] {processor.py:157} INFO - Started process (PID=5457) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:31:30.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:31:30.103+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:31:30.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:31:30.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:31:30.151+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:31:30.150+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:31:30.178+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:31:30.178+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:31:30.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T01:32:00.248+0000] {processor.py:157} INFO - Started process (PID=5459) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:32:00.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:32:00.251+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:32:00.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:32:00.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:32:00.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:32:00.295+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:32:00.329+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:32:00.329+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:32:00.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T01:32:30.504+0000] {processor.py:157} INFO - Started process (PID=5461) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:32:30.505+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:32:30.506+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:32:30.506+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:32:30.523+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:32:30.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:32:30.553+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:32:30.591+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:32:30.591+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:32:30.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.230 seconds
[2024-10-25T01:33:00.882+0000] {processor.py:157} INFO - Started process (PID=5463) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:33:00.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:33:00.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:33:00.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:33:00.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:33:00.954+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:33:00.953+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:33:01.091+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:33:01.091+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:33:01.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.232 seconds
[2024-10-25T01:33:31.239+0000] {processor.py:157} INFO - Started process (PID=5465) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:33:31.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:33:31.241+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:33:31.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:33:31.258+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:33:31.299+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:33:31.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:33:31.331+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:33:31.331+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:33:31.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T01:34:01.515+0000] {processor.py:157} INFO - Started process (PID=5467) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:34:01.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:34:01.517+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:34:01.517+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:34:01.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:34:01.562+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:34:01.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:34:01.589+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:34:01.588+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:34:01.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T01:34:31.666+0000] {processor.py:157} INFO - Started process (PID=5469) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:34:31.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:34:31.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:34:31.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:34:31.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:34:31.712+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:34:31.712+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:34:31.739+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:34:31.739+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:34:31.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T01:35:01.916+0000] {processor.py:157} INFO - Started process (PID=5471) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:35:01.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:35:01.917+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:35:01.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:35:01.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:35:01.961+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:35:01.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:35:01.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:35:01.989+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:35:02.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T01:35:32.061+0000] {processor.py:157} INFO - Started process (PID=5473) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:35:32.063+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:35:32.063+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:35:32.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:35:32.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:35:32.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:35:32.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:35:32.137+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:35:32.137+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:35:32.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.229 seconds
[2024-10-25T01:36:02.410+0000] {processor.py:157} INFO - Started process (PID=5475) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:36:02.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:36:02.411+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:36:02.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:36:02.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:36:02.454+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:36:02.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:36:02.587+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:36:02.587+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:36:02.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.198 seconds
[2024-10-25T01:36:32.735+0000] {processor.py:157} INFO - Started process (PID=5477) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:36:32.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:36:32.737+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:36:32.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:36:32.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:36:32.786+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:36:32.786+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:36:32.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:36:32.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:36:32.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T01:37:03.004+0000] {processor.py:157} INFO - Started process (PID=5479) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:37:03.005+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:37:03.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:37:03.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:37:03.023+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:37:03.054+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:37:03.054+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:37:03.081+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:37:03.081+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:37:03.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T01:37:33.154+0000] {processor.py:157} INFO - Started process (PID=5481) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:37:33.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:37:33.156+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:37:33.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:37:33.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:37:33.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:37:33.196+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:37:33.222+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:37:33.222+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:37:33.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T01:38:03.395+0000] {processor.py:157} INFO - Started process (PID=5483) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:38:03.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:38:03.396+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:38:03.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:38:03.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:38:03.439+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:38:03.439+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:38:03.465+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:38:03.465+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:38:03.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T01:38:33.542+0000] {processor.py:157} INFO - Started process (PID=5485) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:38:33.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:38:33.544+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:38:33.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:38:33.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:38:33.587+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:38:33.586+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:38:33.721+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:38:33.721+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:38:33.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.202 seconds
[2024-10-25T01:39:03.867+0000] {processor.py:157} INFO - Started process (PID=5487) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:39:03.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:39:03.869+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:39:03.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:39:03.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:39:03.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:39:03.915+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:39:04.039+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:39:04.039+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:39:04.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.193 seconds
[2024-10-25T01:39:34.215+0000] {processor.py:157} INFO - Started process (PID=5489) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:39:34.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:39:34.217+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:39:34.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:39:34.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:39:34.264+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:39:34.264+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:39:34.298+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:39:34.298+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:39:34.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T01:40:04.365+0000] {processor.py:157} INFO - Started process (PID=5491) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:40:04.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:40:04.366+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:40:04.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:40:04.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:40:04.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:40:04.418+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:40:04.450+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:40:04.450+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:40:04.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T01:40:34.572+0000] {processor.py:157} INFO - Started process (PID=5493) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:40:34.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:40:34.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:40:34.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:40:34.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:40:34.617+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:40:34.617+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:40:34.641+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:40:34.641+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:40:34.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T01:41:04.813+0000] {processor.py:157} INFO - Started process (PID=5495) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:41:04.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:41:04.814+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:41:04.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:41:04.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:41:04.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:41:04.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:41:04.892+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:41:04.891+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:41:04.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T01:41:34.957+0000] {processor.py:157} INFO - Started process (PID=5497) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:41:34.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:41:34.959+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:41:34.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:41:34.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:41:35.007+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:41:35.006+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:41:35.166+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:41:35.166+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:41:35.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.229 seconds
[2024-10-25T01:42:05.348+0000] {processor.py:157} INFO - Started process (PID=5499) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:42:05.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:42:05.350+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:42:05.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:42:05.370+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:42:05.407+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:42:05.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:42:05.562+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:42:05.561+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:42:05.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.237 seconds
[2024-10-25T01:42:35.738+0000] {processor.py:157} INFO - Started process (PID=5501) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:42:35.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:42:35.740+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:42:35.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:42:35.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:42:35.791+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:42:35.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:42:35.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:42:35.817+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:42:35.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T01:43:05.994+0000] {processor.py:157} INFO - Started process (PID=5503) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:43:05.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:43:05.996+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:43:05.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:43:06.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:43:06.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:43:06.041+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:43:06.070+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:43:06.070+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:43:06.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T01:43:36.145+0000] {processor.py:157} INFO - Started process (PID=5505) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:43:36.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:43:36.148+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:43:36.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:43:36.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:43:36.192+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:43:36.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:43:36.227+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:43:36.227+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:43:36.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T01:44:06.415+0000] {processor.py:157} INFO - Started process (PID=5507) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:44:06.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:44:06.416+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:44:06.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:44:06.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:44:06.459+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:44:06.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:44:06.485+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:44:06.485+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:44:06.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.206 seconds
[2024-10-25T01:44:36.778+0000] {processor.py:157} INFO - Started process (PID=5509) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:44:36.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:44:36.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:44:36.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:44:36.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:44:36.830+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:44:36.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:44:36.954+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:44:36.954+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:44:36.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-25T01:45:07.095+0000] {processor.py:157} INFO - Started process (PID=5511) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:45:07.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:45:07.096+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:45:07.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:45:07.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:45:07.153+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:45:07.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:45:07.300+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:45:07.300+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:45:07.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.229 seconds
[2024-10-25T01:45:37.446+0000] {processor.py:157} INFO - Started process (PID=5513) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:45:37.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:45:37.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:45:37.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:45:37.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:45:37.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:45:37.493+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:45:37.521+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:45:37.521+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:45:37.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T01:46:07.701+0000] {processor.py:157} INFO - Started process (PID=5515) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:46:07.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:46:07.704+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:46:07.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:46:07.720+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:46:07.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:46:07.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:46:07.781+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:46:07.781+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:46:07.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T01:46:37.959+0000] {processor.py:157} INFO - Started process (PID=5517) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:46:37.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:46:37.972+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:46:37.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:46:37.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:46:38.018+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:46:38.017+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:46:38.052+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:46:38.052+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:46:38.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T01:47:08.123+0000] {processor.py:157} INFO - Started process (PID=5519) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:47:08.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:47:08.125+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:47:08.125+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:47:08.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:47:08.174+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:47:08.174+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:47:08.206+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:47:08.206+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:47:08.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.215 seconds
[2024-10-25T01:47:38.464+0000] {processor.py:157} INFO - Started process (PID=5521) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:47:38.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:47:38.466+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:47:38.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:47:38.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:47:38.514+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:47:38.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:47:38.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:47:38.647+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:47:38.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.206 seconds
[2024-10-25T01:48:08.793+0000] {processor.py:157} INFO - Started process (PID=5523) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:48:08.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:48:08.794+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:48:08.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:48:08.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:48:08.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:48:08.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:48:08.967+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:48:08.967+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:48:08.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.195 seconds
[2024-10-25T01:48:39.147+0000] {processor.py:157} INFO - Started process (PID=5525) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:48:39.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:48:39.149+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:48:39.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:48:39.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:48:39.193+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:48:39.193+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:48:39.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:48:39.220+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:48:39.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T01:49:09.404+0000] {processor.py:157} INFO - Started process (PID=5527) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:49:09.406+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:49:09.412+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:49:09.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:49:09.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:49:09.464+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:49:09.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:49:09.496+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:49:09.496+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:49:09.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T01:49:39.665+0000] {processor.py:157} INFO - Started process (PID=5529) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:49:39.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:49:39.667+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:49:39.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:49:39.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:49:39.709+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:49:39.709+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:49:39.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:49:39.735+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:49:39.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T01:50:09.913+0000] {processor.py:157} INFO - Started process (PID=5531) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:50:09.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:50:09.914+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:50:09.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:50:09.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:50:09.965+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:50:09.965+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:50:09.992+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:50:09.991+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:50:10.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T01:50:40.259+0000] {processor.py:157} INFO - Started process (PID=5533) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:50:40.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:50:40.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:50:40.261+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:50:40.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:50:40.310+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:50:40.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:50:40.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:50:40.447+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:50:40.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.212 seconds
[2024-10-25T01:51:10.634+0000] {processor.py:157} INFO - Started process (PID=5535) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:51:10.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:51:10.636+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:51:10.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:51:10.650+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:51:10.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:51:10.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:51:10.815+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:51:10.815+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:51:10.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.212 seconds
[2024-10-25T01:51:40.999+0000] {processor.py:157} INFO - Started process (PID=5537) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:51:41.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:51:41.001+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:51:41.001+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:51:41.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:51:41.053+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:51:41.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:51:41.079+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:51:41.078+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:51:41.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T01:52:11.163+0000] {processor.py:157} INFO - Started process (PID=5539) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:52:11.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:52:11.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:52:11.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:52:11.182+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:52:11.214+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:52:11.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:52:11.241+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:52:11.241+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:52:11.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T01:52:41.416+0000] {processor.py:157} INFO - Started process (PID=5541) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:52:41.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:52:41.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:52:41.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:52:41.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:52:41.476+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:52:41.476+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:52:41.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:52:41.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:52:41.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T01:53:11.679+0000] {processor.py:157} INFO - Started process (PID=5543) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:53:11.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:53:11.681+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:53:11.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:53:11.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:53:11.728+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:53:11.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:53:11.899+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:53:11.899+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:53:11.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.240 seconds
[2024-10-25T01:53:42.070+0000] {processor.py:157} INFO - Started process (PID=5545) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:53:42.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:53:42.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:53:42.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:53:42.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:53:42.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:53:42.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:53:42.254+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:53:42.254+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:53:42.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.204 seconds
[2024-10-25T01:54:12.404+0000] {processor.py:157} INFO - Started process (PID=5547) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:54:12.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:54:12.408+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:54:12.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:54:12.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:54:12.543+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:54:12.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:54:12.697+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:54:12.697+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:54:12.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.320 seconds
[2024-10-25T01:54:42.882+0000] {processor.py:157} INFO - Started process (PID=5549) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:54:42.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:54:42.886+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:54:42.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:54:42.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:54:42.949+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:54:42.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:54:42.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:54:42.981+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:54:43.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T01:55:13.166+0000] {processor.py:157} INFO - Started process (PID=5551) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:55:13.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:55:13.167+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:55:13.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:55:13.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:55:13.219+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:55:13.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:55:13.248+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:55:13.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:55:13.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T01:55:43.425+0000] {processor.py:157} INFO - Started process (PID=5553) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:55:43.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:55:43.427+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:55:43.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:55:43.443+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:55:43.470+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:55:43.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:55:43.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:55:43.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:55:43.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T01:56:13.670+0000] {processor.py:157} INFO - Started process (PID=5555) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:56:13.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:56:13.672+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:56:13.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:56:13.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:56:13.726+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:56:13.726+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:56:13.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:56:13.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:56:13.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.266 seconds
[2024-10-25T01:56:44.101+0000] {processor.py:157} INFO - Started process (PID=5557) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:56:44.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:56:44.103+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:56:44.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:56:44.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:56:44.144+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:56:44.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:56:44.270+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:56:44.270+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:56:44.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.189 seconds
[2024-10-25T01:57:14.478+0000] {processor.py:157} INFO - Started process (PID=5559) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:57:14.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:57:14.481+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:57:14.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:57:14.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:57:14.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:57:14.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:57:14.714+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:57:14.714+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:57:14.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.259 seconds
[2024-10-25T01:57:44.843+0000] {processor.py:157} INFO - Started process (PID=5561) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:57:44.844+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:57:44.845+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:57:44.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:57:44.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:57:44.889+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:57:44.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:57:44.920+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:57:44.920+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:57:44.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T01:58:14.985+0000] {processor.py:157} INFO - Started process (PID=5563) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:58:14.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:58:14.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:58:14.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:58:15.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:58:15.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:58:15.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:58:15.061+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:58:15.061+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:58:15.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T01:58:45.208+0000] {processor.py:157} INFO - Started process (PID=5565) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:58:45.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:58:45.210+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:58:45.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:58:45.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:58:45.253+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:58:45.253+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:58:45.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:58:45.277+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:58:45.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T01:59:15.563+0000] {processor.py:157} INFO - Started process (PID=5567) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:59:15.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:59:15.565+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:59:15.565+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:59:15.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:59:15.616+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:59:15.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:59:15.745+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:59:15.745+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:59:15.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.208 seconds
[2024-10-25T01:59:45.906+0000] {processor.py:157} INFO - Started process (PID=5569) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:59:45.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T01:59:45.908+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:59:45.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:59:45.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T01:59:45.955+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:59:45.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T01:59:46.082+0000] {logging_mixin.py:149} INFO - [2024-10-25T01:59:46.082+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T01:59:46.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.200 seconds
[2024-10-25T02:00:16.226+0000] {processor.py:157} INFO - Started process (PID=5571) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:00:16.227+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:00:16.227+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:00:16.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:00:16.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:00:16.360+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:00:16.360+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:00:16.383+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:00:16.383+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:00:16.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.177 seconds
[2024-10-25T02:00:46.553+0000] {processor.py:157} INFO - Started process (PID=5573) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:00:46.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:00:46.555+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:00:46.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:00:46.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:00:46.604+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:00:46.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:00:46.636+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:00:46.636+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:00:46.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T02:01:16.812+0000] {processor.py:157} INFO - Started process (PID=5575) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:01:16.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:01:16.813+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:01:16.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:01:16.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:01:16.870+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:01:16.869+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:01:16.899+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:01:16.899+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:01:16.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T02:01:46.954+0000] {processor.py:157} INFO - Started process (PID=5577) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:01:46.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:01:46.956+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:01:46.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:01:46.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:01:47.000+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:01:47.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:01:47.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:01:47.026+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:01:47.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.215 seconds
[2024-10-25T02:02:17.330+0000] {processor.py:157} INFO - Started process (PID=5579) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:02:17.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:02:17.333+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:02:17.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:02:17.349+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:02:17.380+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:02:17.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:02:17.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:02:17.503+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:02:17.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.198 seconds
[2024-10-25T02:02:47.643+0000] {processor.py:157} INFO - Started process (PID=5581) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:02:47.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:02:47.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:02:47.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:02:47.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:02:47.690+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:02:47.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:02:47.810+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:02:47.809+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:02:47.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-25T02:03:17.984+0000] {processor.py:157} INFO - Started process (PID=5583) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:03:17.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:03:17.988+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:03:17.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:03:18.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:03:18.123+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:03:18.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:03:18.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:03:18.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:03:18.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-25T02:03:48.288+0000] {processor.py:157} INFO - Started process (PID=5585) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:03:48.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:03:48.292+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:03:48.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:03:48.305+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:03:48.333+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:03:48.333+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:03:48.360+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:03:48.359+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:03:48.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T02:04:18.434+0000] {processor.py:157} INFO - Started process (PID=5587) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:04:18.435+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:04:18.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:04:18.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:04:18.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:04:18.479+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:04:18.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:04:18.505+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:04:18.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:04:18.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T02:04:48.642+0000] {processor.py:157} INFO - Started process (PID=5589) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:04:48.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:04:48.644+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:04:48.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:04:48.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:04:48.686+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:04:48.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:04:48.713+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:04:48.713+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:04:48.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.186 seconds
[2024-10-25T02:05:18.950+0000] {processor.py:157} INFO - Started process (PID=5591) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:05:18.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:05:18.951+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:05:18.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:05:18.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:05:18.997+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:05:18.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:05:19.112+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:05:19.111+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:05:19.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.182 seconds
[2024-10-25T02:05:49.252+0000] {processor.py:157} INFO - Started process (PID=5593) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:05:49.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:05:49.254+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:05:49.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:05:49.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:05:49.312+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:05:49.311+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:05:49.446+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:05:49.446+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:05:49.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.214 seconds
[2024-10-25T02:06:19.621+0000] {processor.py:157} INFO - Started process (PID=5595) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:06:19.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:06:19.623+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:06:19.623+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:06:19.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:06:19.763+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:06:19.763+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:06:19.787+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:06:19.787+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:06:19.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-25T02:06:49.925+0000] {processor.py:157} INFO - Started process (PID=5597) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:06:49.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:06:49.926+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:06:49.926+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:06:49.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:06:49.969+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:06:49.968+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:06:49.994+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:06:49.994+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:06:50.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T02:07:20.172+0000] {processor.py:157} INFO - Started process (PID=5599) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:07:20.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:07:20.173+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:07:20.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:07:20.190+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:07:20.217+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:07:20.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:07:20.242+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:07:20.242+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:07:20.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T02:07:50.323+0000] {processor.py:157} INFO - Started process (PID=5601) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:07:50.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:07:50.325+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:07:50.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:07:50.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:07:50.377+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:07:50.377+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:07:50.498+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:07:50.498+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:07:50.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.195 seconds
[2024-10-25T02:08:20.632+0000] {processor.py:157} INFO - Started process (PID=5603) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:08:20.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:08:20.634+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:08:20.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:08:20.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:08:20.676+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:08:20.675+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:08:20.798+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:08:20.798+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:08:20.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-25T02:08:50.940+0000] {processor.py:157} INFO - Started process (PID=5605) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:08:50.941+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:08:50.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:08:50.941+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:08:50.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:08:50.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:08:50.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:08:51.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:08:51.106+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:08:51.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-25T02:09:21.247+0000] {processor.py:157} INFO - Started process (PID=5607) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:09:21.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:09:21.248+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:09:21.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:09:21.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:09:21.387+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:09:21.387+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:09:21.409+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:09:21.409+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:09:21.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.182 seconds
[2024-10-25T02:09:51.551+0000] {processor.py:157} INFO - Started process (PID=5609) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:09:51.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:09:51.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:09:51.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:09:51.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:09:51.601+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:09:51.601+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:09:51.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:09:51.629+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:09:51.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T02:10:21.690+0000] {processor.py:157} INFO - Started process (PID=5611) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:10:21.691+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:10:21.692+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:10:21.692+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:10:21.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:10:21.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:10:21.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:10:21.764+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:10:21.764+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:10:21.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T02:10:51.909+0000] {processor.py:157} INFO - Started process (PID=5613) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:10:51.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:10:51.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:10:51.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:10:51.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:10:51.959+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:10:51.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:10:52.095+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:10:52.095+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:10:52.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.207 seconds
[2024-10-25T02:11:22.259+0000] {processor.py:157} INFO - Started process (PID=5615) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:11:22.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:11:22.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:11:22.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:11:22.276+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:11:22.304+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:11:22.304+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:11:22.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:11:22.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:11:22.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.199 seconds
[2024-10-25T02:11:52.577+0000] {processor.py:157} INFO - Started process (PID=5617) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:11:52.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T02:11:52.579+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:11:52.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:11:52.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T02:11:52.633+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:11:52.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T02:11:52.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T02:11:52.773+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T02:11:52.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.215 seconds
[2024-10-25T03:39:39.166+0000] {processor.py:157} INFO - Started process (PID=5619) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:39:39.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:39:39.181+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:39:39.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:39:39.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:39:41.029+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:39:41.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:39:41.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:39:41.313+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:39:41.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 2.757 seconds
[2024-10-25T03:46:49.799+0000] {processor.py:157} INFO - Started process (PID=5623) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:46:49.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:46:49.801+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:46:49.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:46:49.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:46:50.265+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:46:50.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:46:50.335+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:46:50.335+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:46:50.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.020 seconds
[2024-10-25T03:47:20.632+0000] {processor.py:157} INFO - Started process (PID=5628) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:47:20.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:47:20.634+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:47:20.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:47:20.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:47:20.672+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:47:20.672+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:47:20.700+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:47:20.700+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:47:20.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T03:47:50.809+0000] {processor.py:157} INFO - Started process (PID=5629) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:47:50.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:47:50.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:47:50.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:47:50.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:47:50.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:47:50.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:47:50.961+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:47:50.961+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:47:51.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.449 seconds
[2024-10-25T03:48:21.404+0000] {processor.py:157} INFO - Started process (PID=5631) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:48:21.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:48:21.405+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:48:21.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:48:21.420+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:48:21.455+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:48:21.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:48:21.605+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:48:21.605+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:48:21.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.228 seconds
[2024-10-25T03:48:51.792+0000] {processor.py:157} INFO - Started process (PID=5633) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:48:51.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:48:51.794+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:48:51.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:48:51.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:48:51.844+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:48:51.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:48:51.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:48:51.989+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:48:52.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.222 seconds
[2024-10-25T03:49:22.139+0000] {processor.py:157} INFO - Started process (PID=5635) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:49:22.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:49:22.141+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:49:22.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:49:22.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:49:22.294+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:49:22.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:49:22.314+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:49:22.314+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:49:22.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-25T03:49:52.495+0000] {processor.py:157} INFO - Started process (PID=5637) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:49:52.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:49:52.496+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:49:52.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:49:52.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:49:52.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:49:52.645+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:49:52.667+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:49:52.667+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:49:52.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-25T03:50:22.810+0000] {processor.py:157} INFO - Started process (PID=5639) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:50:22.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:50:22.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:50:22.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:50:22.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:50:22.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:50:22.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:50:22.885+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:50:22.885+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:50:22.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T03:50:52.953+0000] {processor.py:157} INFO - Started process (PID=5641) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:50:52.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:50:52.955+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:50:52.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:50:52.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:50:53.004+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:50:53.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:50:53.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:50:53.033+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:50:53.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.223 seconds
[2024-10-25T03:51:23.296+0000] {processor.py:157} INFO - Started process (PID=5643) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:51:23.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:51:23.298+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:51:23.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:51:23.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:51:23.340+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:51:23.340+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:51:23.479+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:51:23.478+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:51:23.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.205 seconds
[2024-10-25T03:51:53.674+0000] {processor.py:157} INFO - Started process (PID=5645) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:51:53.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:51:53.676+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:51:53.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:51:53.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:51:53.733+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:51:53.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:51:53.879+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:51:53.879+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:51:53.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.225 seconds
[2024-10-25T03:52:24.027+0000] {processor.py:157} INFO - Started process (PID=5647) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:52:24.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:52:24.029+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:52:24.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:52:24.044+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:52:24.172+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:52:24.172+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:52:24.193+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:52:24.193+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:52:24.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.191 seconds
[2024-10-25T03:52:54.368+0000] {processor.py:157} INFO - Started process (PID=5649) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:52:54.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:52:54.370+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:52:54.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:52:54.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:52:54.510+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:52:54.510+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:52:54.533+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:52:54.533+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:52:54.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.186 seconds
[2024-10-25T03:53:24.675+0000] {processor.py:157} INFO - Started process (PID=5651) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:53:24.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:53:24.677+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:53:24.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:53:24.691+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:53:24.724+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:53:24.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:53:24.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:53:24.751+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:53:24.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T03:53:54.816+0000] {processor.py:157} INFO - Started process (PID=5653) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:53:54.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:53:54.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:53:54.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:53:54.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:53:54.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:53:54.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:53:54.887+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:53:54.887+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:53:55.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.191 seconds
[2024-10-25T03:54:25.032+0000] {processor.py:157} INFO - Started process (PID=5655) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:54:25.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:54:25.035+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:54:25.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:54:25.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:54:25.079+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:54:25.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:54:25.215+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:54:25.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:54:25.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.204 seconds
[2024-10-25T03:54:55.389+0000] {processor.py:157} INFO - Started process (PID=5657) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:54:55.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:54:55.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:54:55.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:54:55.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:54:55.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:54:55.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:54:55.563+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:54:55.563+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:54:55.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.195 seconds
[2024-10-25T03:55:25.703+0000] {processor.py:157} INFO - Started process (PID=5659) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:55:25.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:55:25.705+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:55:25.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:55:25.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:55:25.849+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:55:25.849+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:55:25.876+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:55:25.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:55:25.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.193 seconds
[2024-10-25T03:55:56.068+0000] {processor.py:157} INFO - Started process (PID=5661) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:55:56.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:55:56.069+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:55:56.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:55:56.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:55:56.221+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:55:56.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:55:56.245+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:55:56.245+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:55:56.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.205 seconds
[2024-10-25T03:56:26.388+0000] {processor.py:157} INFO - Started process (PID=5663) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:56:26.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:56:26.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:56:26.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:56:26.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:56:26.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:56:26.434+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:56:26.462+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:56:26.462+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:56:26.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T03:56:56.576+0000] {processor.py:157} INFO - Started process (PID=5665) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:56:56.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:56:56.579+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:56:56.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:56:56.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:56:56.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:56:56.716+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:56:56.783+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:56:56.783+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:56:57.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.554 seconds
[2024-10-25T03:57:27.203+0000] {processor.py:157} INFO - Started process (PID=5667) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:57:27.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:57:27.205+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:57:27.205+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:57:27.220+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:57:27.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:57:27.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:57:27.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:57:27.376+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:57:27.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T03:57:57.546+0000] {processor.py:157} INFO - Started process (PID=5669) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:57:57.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:57:57.548+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:57:57.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:57:57.562+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:57:57.593+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:57:57.593+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:57:57.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:57:57.738+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:57:57.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.214 seconds
[2024-10-25T03:58:27.913+0000] {processor.py:157} INFO - Started process (PID=5671) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:58:27.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:58:27.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:58:27.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:58:27.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:58:28.059+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:58:28.059+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:58:28.080+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:58:28.079+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:58:28.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.186 seconds
[2024-10-25T03:58:58.248+0000] {processor.py:157} INFO - Started process (PID=5673) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:58:58.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:58:58.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:58:58.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:58:58.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:58:58.409+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:58:58.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:58:58.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:58:58.432+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:58:58.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.203 seconds
[2024-10-25T03:59:28.576+0000] {processor.py:157} INFO - Started process (PID=5675) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:59:28.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:59:28.584+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:59:28.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:59:28.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:59:28.638+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:59:28.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:59:28.664+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:59:28.664+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:59:28.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T03:59:58.737+0000] {processor.py:157} INFO - Started process (PID=5677) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:59:58.738+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T03:59:58.739+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:59:58.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:59:58.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T03:59:58.797+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:59:58.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T03:59:58.826+0000] {logging_mixin.py:149} INFO - [2024-10-25T03:59:58.826+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T03:59:58.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.205 seconds
[2024-10-25T04:00:29.062+0000] {processor.py:157} INFO - Started process (PID=5679) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:00:29.063+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:00:29.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:00:29.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:00:29.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:00:29.109+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:00:29.109+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:00:29.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:00:29.246+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:00:29.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.206 seconds
[2024-10-25T04:00:59.386+0000] {processor.py:157} INFO - Started process (PID=5681) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:00:59.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:00:59.387+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:00:59.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:00:59.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:00:59.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:00:59.433+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:00:59.554+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:00:59.554+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:00:59.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.188 seconds
[2024-10-25T04:01:29.726+0000] {processor.py:157} INFO - Started process (PID=5683) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:01:29.727+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:01:29.728+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:01:29.728+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:01:29.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:01:29.866+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:01:29.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:01:29.890+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:01:29.889+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:01:29.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.185 seconds
[2024-10-25T04:02:00.032+0000] {processor.py:157} INFO - Started process (PID=5685) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:02:00.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:02:00.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:02:00.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:02:00.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:02:00.177+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:02:00.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:02:00.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:02:00.199+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:02:00.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.188 seconds
[2024-10-25T04:02:30.338+0000] {processor.py:157} INFO - Started process (PID=5687) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:02:30.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:02:30.340+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:02:30.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:02:30.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:02:30.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:02:30.391+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:02:30.420+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:02:30.419+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:02:30.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T04:03:00.482+0000] {processor.py:157} INFO - Started process (PID=5689) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:03:00.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:03:00.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:03:00.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:03:00.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:03:00.532+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:03:00.532+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:03:00.653+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:03:00.653+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:03:00.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-25T04:03:30.698+0000] {processor.py:157} INFO - Started process (PID=5691) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:03:30.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:03:30.710+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:03:30.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:03:30.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:03:30.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:03:30.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:03:30.877+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:03:30.876+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:03:30.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.198 seconds
[2024-10-25T04:04:00.930+0000] {processor.py:157} INFO - Started process (PID=5693) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:04:00.931+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:04:00.931+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:04:00.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:04:00.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:04:00.973+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:04:00.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:04:01.105+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:04:01.105+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:04:01.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.196 seconds
[2024-10-25T04:04:31.275+0000] {processor.py:157} INFO - Started process (PID=5695) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:04:31.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:04:31.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:04:31.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:04:31.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:04:31.426+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:04:31.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:04:31.450+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:04:31.450+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:04:31.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-25T04:05:01.628+0000] {processor.py:157} INFO - Started process (PID=5697) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:05:01.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:05:01.631+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:05:01.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:05:01.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:05:01.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:05:01.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:05:01.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:05:01.796+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:05:01.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.189 seconds
[2024-10-25T04:05:31.964+0000] {processor.py:157} INFO - Started process (PID=5699) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:05:31.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:05:31.967+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:05:31.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:05:31.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:05:32.024+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:05:32.024+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:05:32.059+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:05:32.059+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:05:32.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T04:06:02.115+0000] {processor.py:157} INFO - Started process (PID=5701) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:06:02.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:06:02.117+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:06:02.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:06:02.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:06:02.164+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:06:02.163+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:06:02.198+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:06:02.197+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:06:02.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T04:06:32.380+0000] {processor.py:157} INFO - Started process (PID=5703) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:06:32.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:06:32.383+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:06:32.383+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:06:32.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:06:32.458+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:06:32.457+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:06:32.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:06:32.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:06:32.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.165 seconds
[2024-10-25T04:07:02.755+0000] {processor.py:157} INFO - Started process (PID=5705) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:07:02.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:07:02.761+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:07:02.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:07:02.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:07:02.859+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:07:02.858+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:07:02.946+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:07:02.946+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:07:02.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.242 seconds
[2024-10-25T04:07:33.180+0000] {processor.py:157} INFO - Started process (PID=5707) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:07:33.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:07:33.183+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:07:33.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:07:33.222+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:07:33.300+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:07:33.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:07:33.381+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:07:33.380+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:07:33.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.263 seconds
[2024-10-25T04:08:03.595+0000] {processor.py:157} INFO - Started process (PID=5709) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:08:03.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:08:03.599+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:08:03.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:08:03.630+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:08:03.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:08:03.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:08:03.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:08:03.738+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:08:03.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.190 seconds
[2024-10-25T04:08:33.980+0000] {processor.py:157} INFO - Started process (PID=5711) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:08:33.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:08:33.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:08:33.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:08:34.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:08:34.095+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:08:34.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:08:34.163+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:08:34.163+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:08:34.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.226 seconds
[2024-10-25T04:09:04.352+0000] {processor.py:157} INFO - Started process (PID=5713) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:09:04.353+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:09:04.355+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:09:04.354+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:09:04.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:09:04.447+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:09:04.447+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:09:04.492+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:09:04.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:09:04.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.172 seconds
[2024-10-25T04:09:34.666+0000] {processor.py:157} INFO - Started process (PID=5715) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:09:34.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:09:34.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:09:34.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:09:34.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:09:34.745+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:09:34.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:09:34.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:09:34.796+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:09:34.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-25T04:10:05.030+0000] {processor.py:157} INFO - Started process (PID=5717) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:10:05.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:10:05.032+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:10:05.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:10:05.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:10:05.090+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:10:05.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:10:05.135+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:10:05.135+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:10:05.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-25T04:10:35.187+0000] {processor.py:157} INFO - Started process (PID=5719) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:10:35.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:10:35.190+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:10:35.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:10:35.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:10:35.266+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:10:35.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:10:35.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:10:35.306+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:10:35.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.204 seconds
[2024-10-25T04:11:05.595+0000] {processor.py:157} INFO - Started process (PID=5721) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:11:05.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:11:05.600+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:11:05.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:11:05.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:11:05.704+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:11:05.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:11:05.749+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:11:05.748+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:11:05.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.224 seconds
[2024-10-25T04:11:35.977+0000] {processor.py:157} INFO - Started process (PID=5723) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:11:35.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:11:35.979+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:11:35.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:11:36.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:11:36.047+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:11:36.047+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:11:36.090+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:11:36.089+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:11:36.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.139 seconds
[2024-10-25T04:12:06.295+0000] {processor.py:157} INFO - Started process (PID=5725) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:12:06.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:12:06.297+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:12:06.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:12:06.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:12:06.357+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:12:06.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:12:06.394+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:12:06.394+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:12:06.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T04:12:36.458+0000] {processor.py:157} INFO - Started process (PID=5727) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:12:36.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:12:36.459+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:12:36.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:12:36.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:12:36.554+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:12:36.553+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:12:36.594+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:12:36.594+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:12:36.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-25T04:13:06.788+0000] {processor.py:157} INFO - Started process (PID=5729) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:13:06.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:13:06.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:13:06.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:13:06.806+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:13:06.841+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:13:06.841+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:13:06.884+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:13:06.884+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:13:06.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.137 seconds
[2024-10-25T04:13:36.949+0000] {processor.py:157} INFO - Started process (PID=5731) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:13:36.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:13:36.951+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:13:36.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:13:36.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:13:37.010+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:13:37.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:13:37.053+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:13:37.052+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:13:37.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-25T04:14:07.266+0000] {processor.py:157} INFO - Started process (PID=5733) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:14:07.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:14:07.268+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:14:07.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:14:07.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:14:07.315+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:14:07.315+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:14:07.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:14:07.339+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:14:07.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T04:14:37.432+0000] {processor.py:157} INFO - Started process (PID=5735) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:14:37.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:14:37.434+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:14:37.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:14:37.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:14:37.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:14:37.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:14:37.537+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:14:37.537+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:14:37.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-25T04:15:07.645+0000] {processor.py:157} INFO - Started process (PID=5737) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:15:07.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:15:07.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:15:07.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:15:07.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:15:07.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:15:07.700+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:15:07.737+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:15:07.736+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:15:07.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-25T04:15:37.930+0000] {processor.py:157} INFO - Started process (PID=5739) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:15:37.931+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:15:37.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:15:37.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:15:37.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:15:38.004+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:15:38.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:15:38.053+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:15:38.053+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:15:38.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-25T04:16:08.226+0000] {processor.py:157} INFO - Started process (PID=5741) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:16:08.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:16:08.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:16:08.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:16:08.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:16:08.278+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:16:08.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:16:08.302+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:16:08.302+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:16:08.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.201 seconds
[2024-10-25T04:16:38.583+0000] {processor.py:157} INFO - Started process (PID=5743) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:16:38.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:16:38.585+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:16:38.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:16:38.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:16:38.630+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:16:38.630+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:16:38.659+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:16:38.659+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:16:38.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T04:17:08.753+0000] {processor.py:157} INFO - Started process (PID=5745) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:17:08.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:17:08.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:17:08.754+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:17:08.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:17:08.805+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:17:08.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:17:08.831+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:17:08.831+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:17:08.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T04:17:38.937+0000] {processor.py:157} INFO - Started process (PID=5747) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:17:38.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:17:38.939+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:17:38.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:17:38.956+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:17:38.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:17:38.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:17:39.018+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:17:39.018+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:17:39.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T04:18:09.110+0000] {processor.py:157} INFO - Started process (PID=5749) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:18:09.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:18:09.112+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:18:09.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:18:09.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:18:09.159+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:18:09.159+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:18:09.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:18:09.195+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:18:09.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T04:18:39.425+0000] {processor.py:157} INFO - Started process (PID=5751) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:18:39.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:18:39.445+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:18:39.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:18:39.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:18:39.927+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:18:39.927+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:18:40.086+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:18:40.086+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:18:40.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.792 seconds
[2024-10-25T04:19:10.362+0000] {processor.py:157} INFO - Started process (PID=5753) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:19:10.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:19:10.364+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:19:10.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:19:10.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:19:10.408+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:19:10.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:19:10.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:19:10.432+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:19:10.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T04:19:40.612+0000] {processor.py:157} INFO - Started process (PID=5755) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:19:40.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:19:40.614+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:19:40.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:19:40.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:19:40.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:19:40.661+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:19:40.690+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:19:40.690+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:19:40.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T04:20:11.193+0000] {processor.py:157} INFO - Started process (PID=5757) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:20:11.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:20:11.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:20:11.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:20:11.214+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:20:11.253+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:20:11.253+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:20:11.280+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:20:11.279+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:20:11.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T04:20:41.458+0000] {processor.py:157} INFO - Started process (PID=5759) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:20:41.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:20:41.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:20:41.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:20:41.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:20:41.509+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:20:41.509+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:20:41.564+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:20:41.564+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:20:41.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-25T04:21:11.745+0000] {processor.py:157} INFO - Started process (PID=5761) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:21:11.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:21:11.747+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:21:11.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:21:11.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:21:11.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:21:11.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:21:11.819+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:21:11.819+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:21:11.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T04:21:41.991+0000] {processor.py:157} INFO - Started process (PID=5763) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:21:41.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:21:41.993+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:21:41.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:21:42.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:21:42.039+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:21:42.039+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:21:42.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:21:42.063+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:21:42.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:22:12.244+0000] {processor.py:157} INFO - Started process (PID=5765) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:22:12.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:22:12.245+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:22:12.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:22:12.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:22:12.289+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:22:12.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:22:12.316+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:22:12.316+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:22:12.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T04:22:42.484+0000] {processor.py:157} INFO - Started process (PID=5767) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:22:42.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:22:42.486+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:22:42.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:22:42.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:22:42.533+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:22:42.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:22:42.561+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:22:42.561+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:22:42.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T04:23:12.733+0000] {processor.py:157} INFO - Started process (PID=5769) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:23:12.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:23:12.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:23:12.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:23:12.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:23:12.785+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:23:12.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:23:12.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:23:12.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:23:12.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T04:23:42.977+0000] {processor.py:157} INFO - Started process (PID=5771) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:23:42.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:23:42.979+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:23:42.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:23:42.994+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:23:43.022+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:23:43.022+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:23:43.046+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:23:43.046+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:23:43.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T04:24:13.126+0000] {processor.py:157} INFO - Started process (PID=5773) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:24:13.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:24:13.127+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:24:13.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:24:13.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:24:13.172+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:24:13.172+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:24:13.197+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:24:13.196+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:24:13.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T04:24:43.375+0000] {processor.py:157} INFO - Started process (PID=5775) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:24:43.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:24:43.377+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:24:43.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:24:43.391+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:24:43.421+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:24:43.421+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:24:43.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:24:43.447+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:24:43.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T04:25:13.524+0000] {processor.py:157} INFO - Started process (PID=5777) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:25:13.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:25:13.526+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:25:13.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:25:13.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:25:13.576+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:25:13.576+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:25:13.600+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:25:13.600+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:25:13.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:25:43.716+0000] {processor.py:157} INFO - Started process (PID=5779) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:25:43.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:25:43.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:25:43.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:25:43.731+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:25:43.761+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:25:43.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:25:43.786+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:25:43.786+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:25:43.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T04:26:13.866+0000] {processor.py:157} INFO - Started process (PID=5781) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:26:13.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:26:13.867+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:26:13.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:26:13.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:26:13.908+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:26:13.908+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:26:13.939+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:26:13.939+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:26:13.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T04:26:44.105+0000] {processor.py:157} INFO - Started process (PID=5783) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:26:44.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:26:44.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:26:44.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:26:44.125+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:26:44.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:26:44.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:26:44.186+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:26:44.186+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:26:44.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T04:27:14.257+0000] {processor.py:157} INFO - Started process (PID=5785) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:27:14.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:27:14.258+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:27:14.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:27:14.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:27:14.302+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:27:14.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:27:14.329+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:27:14.329+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:27:14.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T04:27:44.495+0000] {processor.py:157} INFO - Started process (PID=5787) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:27:44.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:27:44.497+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:27:44.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:27:44.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:27:44.542+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:27:44.542+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:27:44.566+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:27:44.566+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:27:44.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T04:28:14.639+0000] {processor.py:157} INFO - Started process (PID=5789) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:28:14.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:28:14.640+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:28:14.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:28:14.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:28:14.685+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:28:14.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:28:14.711+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:28:14.711+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:28:14.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T04:28:44.880+0000] {processor.py:157} INFO - Started process (PID=5791) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:28:44.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:28:44.881+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:28:44.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:28:44.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:28:44.925+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:28:44.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:28:44.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:28:44.951+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:28:44.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:29:15.026+0000] {processor.py:157} INFO - Started process (PID=5793) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:29:15.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:29:15.028+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:29:15.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:29:15.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:29:15.075+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:29:15.074+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:29:15.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:29:15.100+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:29:15.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T04:29:45.277+0000] {processor.py:157} INFO - Started process (PID=5795) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:29:45.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:29:45.280+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:29:45.280+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:29:45.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:29:45.348+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:29:45.348+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:29:45.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:29:45.390+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:29:45.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-25T04:30:15.554+0000] {processor.py:157} INFO - Started process (PID=5797) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:30:15.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:30:15.555+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:30:15.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:30:15.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:30:15.602+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:30:15.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:30:15.628+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:30:15.628+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:30:15.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T04:30:45.704+0000] {processor.py:157} INFO - Started process (PID=5799) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:30:45.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:30:45.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:30:45.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:30:45.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:30:45.770+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:30:45.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:30:45.809+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:30:45.809+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:30:45.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-25T04:31:15.907+0000] {processor.py:157} INFO - Started process (PID=5801) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:31:15.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:31:15.908+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:31:15.908+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:31:15.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:31:15.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:31:15.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:31:16.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:31:16.011+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:31:16.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.186 seconds
[2024-10-25T04:31:46.224+0000] {processor.py:157} INFO - Started process (PID=5803) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:31:46.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:31:46.227+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:31:46.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:31:46.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:31:46.280+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:31:46.280+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:31:46.309+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:31:46.309+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:31:46.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T04:32:16.501+0000] {processor.py:157} INFO - Started process (PID=5805) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:32:16.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:32:16.503+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:32:16.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:32:16.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:32:16.551+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:32:16.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:32:16.583+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:32:16.583+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:32:16.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T04:32:46.642+0000] {processor.py:157} INFO - Started process (PID=5807) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:32:46.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:32:46.644+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:32:46.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:32:46.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:32:46.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:32:46.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:32:46.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:32:46.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:32:46.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:33:16.888+0000] {processor.py:157} INFO - Started process (PID=5809) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:33:16.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:33:16.889+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:33:16.889+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:33:16.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:33:16.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:33:16.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:33:16.978+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:33:16.978+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:33:17.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T04:33:47.159+0000] {processor.py:157} INFO - Started process (PID=5811) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:33:47.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:33:47.161+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:33:47.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:33:47.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:33:47.215+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:33:47.215+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:33:47.248+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:33:47.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:33:47.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T04:34:17.306+0000] {processor.py:157} INFO - Started process (PID=5813) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:34:17.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:34:17.308+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:34:17.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:34:17.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:34:17.353+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:34:17.353+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:34:17.381+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:34:17.381+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:34:17.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:34:47.555+0000] {processor.py:157} INFO - Started process (PID=5815) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:34:47.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:34:47.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:34:47.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:34:47.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:34:47.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:34:47.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:34:47.653+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:34:47.652+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:34:47.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T04:35:17.716+0000] {processor.py:157} INFO - Started process (PID=5817) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:35:17.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:35:17.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:35:17.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:35:17.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:35:17.771+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:35:17.771+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:35:17.805+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:35:17.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:35:17.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T04:35:47.931+0000] {processor.py:157} INFO - Started process (PID=5819) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:35:47.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:35:47.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:35:47.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:35:47.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:35:47.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:35:47.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:35:48.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:35:48.013+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:35:48.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T04:36:18.190+0000] {processor.py:157} INFO - Started process (PID=5821) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:36:18.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:36:18.203+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:36:18.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:36:18.217+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:36:18.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:36:18.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:36:18.275+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:36:18.275+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:36:18.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T04:36:48.334+0000] {processor.py:157} INFO - Started process (PID=5823) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:36:48.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:36:48.336+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:36:48.336+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:36:48.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:36:48.383+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:36:48.383+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:36:48.414+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:36:48.413+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:36:48.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T04:37:18.557+0000] {processor.py:157} INFO - Started process (PID=5825) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:37:18.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:37:18.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:37:18.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:37:18.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:37:18.604+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:37:18.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:37:18.630+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:37:18.630+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:37:18.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:37:48.701+0000] {processor.py:157} INFO - Started process (PID=5827) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:37:48.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:37:48.703+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:37:48.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:37:48.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:37:48.839+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:37:48.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:37:48.893+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:37:48.893+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:37:48.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.218 seconds
[2024-10-25T04:38:19.054+0000] {processor.py:157} INFO - Started process (PID=5829) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:38:19.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:38:19.056+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:38:19.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:38:19.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:38:19.099+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:38:19.099+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:38:19.125+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:38:19.124+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:38:19.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T04:38:49.301+0000] {processor.py:157} INFO - Started process (PID=5831) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:38:49.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:38:49.303+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:38:49.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:38:49.318+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:38:49.350+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:38:49.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:38:49.378+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:38:49.377+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:38:49.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:39:19.452+0000] {processor.py:157} INFO - Started process (PID=5833) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:39:19.453+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:39:19.454+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:39:19.453+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:39:19.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:39:19.501+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:39:19.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:39:19.530+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:39:19.530+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:39:19.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T04:39:49.681+0000] {processor.py:157} INFO - Started process (PID=5835) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:39:49.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:39:49.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:39:49.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:39:49.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:39:49.742+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:39:49.741+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:39:49.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:39:49.772+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:39:49.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.142 seconds
[2024-10-25T04:40:19.952+0000] {processor.py:157} INFO - Started process (PID=5837) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:40:19.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:40:19.955+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:40:19.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:40:19.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:40:20.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:40:20.005+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:40:20.035+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:40:20.035+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:40:20.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T04:40:50.196+0000] {processor.py:157} INFO - Started process (PID=5839) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:40:50.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:40:50.197+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:40:50.197+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:40:50.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:40:50.244+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:40:50.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:40:50.269+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:40:50.269+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:40:50.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:41:20.351+0000] {processor.py:157} INFO - Started process (PID=5841) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:41:20.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:41:20.356+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:41:20.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:41:20.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:41:20.400+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:41:20.400+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:41:20.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:41:20.432+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:41:20.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T04:41:50.605+0000] {processor.py:157} INFO - Started process (PID=5843) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:41:50.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:41:50.606+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:41:50.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:41:50.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:41:50.658+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:41:50.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:41:50.685+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:41:50.684+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:41:50.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T04:42:20.767+0000] {processor.py:157} INFO - Started process (PID=5845) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:42:20.770+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:42:20.774+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:42:20.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:42:20.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:42:20.824+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:42:20.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:42:20.852+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:42:20.852+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:42:20.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T04:42:51.019+0000] {processor.py:157} INFO - Started process (PID=5847) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:42:51.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:42:51.021+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:42:51.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:42:51.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:42:51.068+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:42:51.068+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:42:51.097+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:42:51.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:42:51.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T04:43:21.170+0000] {processor.py:157} INFO - Started process (PID=5849) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:43:21.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:43:21.172+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:43:21.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:43:21.187+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:43:21.223+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:43:21.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:43:21.253+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:43:21.253+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:43:21.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T04:43:51.371+0000] {processor.py:157} INFO - Started process (PID=5851) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:43:51.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:43:51.373+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:43:51.373+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:43:51.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:43:51.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:43:51.417+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:43:51.445+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:43:51.445+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:43:51.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:44:21.533+0000] {processor.py:157} INFO - Started process (PID=5853) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:44:21.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:44:21.535+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:44:21.535+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:44:21.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:44:21.579+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:44:21.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:44:21.608+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:44:21.608+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:44:21.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T04:44:51.789+0000] {processor.py:157} INFO - Started process (PID=5855) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:44:51.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:44:51.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:44:51.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:44:51.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:44:51.837+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:44:51.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:44:51.864+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:44:51.864+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:44:51.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:45:21.941+0000] {processor.py:157} INFO - Started process (PID=5857) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:45:21.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:45:21.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:45:21.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:45:21.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:45:21.988+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:45:21.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:45:22.018+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:45:22.017+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:45:22.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:45:52.145+0000] {processor.py:157} INFO - Started process (PID=5859) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:45:52.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:45:52.146+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:45:52.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:45:52.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:45:52.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:45:52.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:45:52.225+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:45:52.225+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:45:52.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T04:46:22.423+0000] {processor.py:157} INFO - Started process (PID=5861) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:46:22.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:46:22.426+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:46:22.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:46:22.441+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:46:22.529+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:46:22.529+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:46:22.563+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:46:22.563+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:46:22.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-25T04:46:52.678+0000] {processor.py:157} INFO - Started process (PID=5863) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:46:52.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:46:52.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:46:52.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:46:52.694+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:46:52.727+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:46:52.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:46:52.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:46:52.754+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:46:52.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T04:47:22.843+0000] {processor.py:157} INFO - Started process (PID=5865) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:47:22.845+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:47:22.845+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:47:22.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:47:22.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:47:22.894+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:47:22.894+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:47:22.926+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:47:22.926+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:47:22.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T04:47:53.025+0000] {processor.py:157} INFO - Started process (PID=5867) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:47:53.026+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:47:53.027+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:47:53.027+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:47:53.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:47:53.081+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:47:53.081+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:47:53.112+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:47:53.111+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:47:53.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T04:48:23.199+0000] {processor.py:157} INFO - Started process (PID=5869) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:48:23.200+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:48:23.201+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:48:23.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:48:23.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:48:23.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:48:23.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:48:23.278+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:48:23.277+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:48:23.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T04:48:53.447+0000] {processor.py:157} INFO - Started process (PID=5871) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:48:53.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:48:53.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:48:53.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:48:53.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:48:53.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:48:53.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:48:53.528+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:48:53.528+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:48:53.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T04:49:23.699+0000] {processor.py:157} INFO - Started process (PID=5873) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:49:23.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:49:23.712+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:49:23.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:49:23.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:49:23.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:49:23.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:49:23.780+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:49:23.780+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:49:23.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T04:49:53.853+0000] {processor.py:157} INFO - Started process (PID=5875) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:49:53.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:49:53.854+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:49:53.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:49:53.869+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:49:53.902+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:49:53.902+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:49:53.929+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:49:53.929+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:49:53.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:50:24.104+0000] {processor.py:157} INFO - Started process (PID=5877) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:50:24.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:50:24.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:50:24.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:50:24.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:50:24.157+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:50:24.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:50:24.195+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:50:24.194+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:50:24.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T04:50:54.254+0000] {processor.py:157} INFO - Started process (PID=5879) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:50:54.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:50:54.255+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:50:54.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:50:54.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:50:54.302+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:50:54.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:50:54.329+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:50:54.329+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:50:54.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T04:51:24.503+0000] {processor.py:157} INFO - Started process (PID=5881) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:51:24.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:51:24.505+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:51:24.504+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:51:24.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:51:24.550+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:51:24.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:51:24.577+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:51:24.577+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:51:24.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T04:51:54.654+0000] {processor.py:157} INFO - Started process (PID=5883) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:51:54.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:51:54.656+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:51:54.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:51:54.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:51:54.722+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:51:54.722+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:51:54.758+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:51:54.758+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:51:54.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-25T04:52:24.857+0000] {processor.py:157} INFO - Started process (PID=5885) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:52:24.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:52:24.860+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:52:24.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:52:24.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:52:24.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:52:24.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:52:24.938+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:52:24.938+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:52:24.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T04:52:55.025+0000] {processor.py:157} INFO - Started process (PID=5887) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:52:55.026+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:52:55.027+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:52:55.027+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:52:55.040+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:52:55.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:52:55.072+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:52:55.103+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:52:55.103+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:52:55.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:53:25.269+0000] {processor.py:157} INFO - Started process (PID=5889) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:53:25.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:53:25.282+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:53:25.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:53:25.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:53:25.324+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:53:25.324+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:53:25.353+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:53:25.353+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:53:25.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T04:53:55.416+0000] {processor.py:157} INFO - Started process (PID=5891) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:53:55.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:53:55.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:53:55.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:53:55.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:53:55.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:53:55.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:53:55.481+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:53:55.480+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:53:55.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T04:54:25.648+0000] {processor.py:157} INFO - Started process (PID=5893) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:54:25.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:54:25.650+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:54:25.650+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:54:25.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:54:25.698+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:54:25.698+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:54:25.722+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:54:25.721+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:54:25.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T04:54:55.794+0000] {processor.py:157} INFO - Started process (PID=5895) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:54:55.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:54:55.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:54:55.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:54:55.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:54:55.837+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:54:55.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:54:55.865+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:54:55.864+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:54:55.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T04:55:26.039+0000] {processor.py:157} INFO - Started process (PID=5897) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:55:26.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:55:26.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:55:26.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:55:26.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:55:26.096+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:55:26.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:55:26.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:55:26.120+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:55:26.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T04:55:56.196+0000] {processor.py:157} INFO - Started process (PID=5899) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:55:56.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:55:56.198+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:55:56.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:55:56.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:55:56.241+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:55:56.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:55:56.271+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:55:56.271+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:55:56.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:56:26.447+0000] {processor.py:157} INFO - Started process (PID=5901) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:56:26.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:56:26.449+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:56:26.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:56:26.466+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:56:26.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:56:26.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:56:26.530+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:56:26.530+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:56:26.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T04:56:56.605+0000] {processor.py:157} INFO - Started process (PID=5903) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:56:56.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:56:56.606+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:56:56.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:56:56.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:56:56.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:56:56.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:56:56.674+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:56:56.674+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:56:56.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T04:57:26.839+0000] {processor.py:157} INFO - Started process (PID=5905) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:57:26.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:57:26.841+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:57:26.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:57:26.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:57:26.886+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:57:26.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:57:26.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:57:26.916+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:57:26.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:57:56.982+0000] {processor.py:157} INFO - Started process (PID=5907) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:57:56.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:57:56.984+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:57:56.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:57:56.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:57:57.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:57:57.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:57:57.059+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:57:57.059+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:57:57.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T04:58:27.228+0000] {processor.py:157} INFO - Started process (PID=5909) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:58:27.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:58:27.230+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:58:27.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:58:27.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:58:27.276+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:58:27.276+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:58:27.302+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:58:27.302+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:58:27.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T04:58:57.372+0000] {processor.py:157} INFO - Started process (PID=5911) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:58:57.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:58:57.373+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:58:57.373+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:58:57.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:58:57.426+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:58:57.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:58:57.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:58:57.461+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:58:57.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T04:59:27.566+0000] {processor.py:157} INFO - Started process (PID=5913) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:59:27.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:59:27.568+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:59:27.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:59:27.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:59:27.617+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:59:27.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:59:27.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:59:27.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:59:27.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T04:59:57.730+0000] {processor.py:157} INFO - Started process (PID=5915) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:59:57.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T04:59:57.732+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:59:57.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:59:57.747+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T04:59:57.781+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:59:57.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T04:59:57.811+0000] {logging_mixin.py:149} INFO - [2024-10-25T04:59:57.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T04:59:57.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T05:00:27.923+0000] {processor.py:157} INFO - Started process (PID=5917) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:00:27.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:00:27.925+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:00:27.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:00:27.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:00:27.968+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:00:27.968+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:00:27.998+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:00:27.997+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:00:28.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T05:00:58.069+0000] {processor.py:157} INFO - Started process (PID=5919) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:00:58.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:00:58.071+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:00:58.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:00:58.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:00:58.123+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:00:58.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:00:58.150+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:00:58.150+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:00:58.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T05:01:28.326+0000] {processor.py:157} INFO - Started process (PID=5921) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:01:28.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:01:28.329+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:01:28.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:01:28.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:01:28.380+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:01:28.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:01:28.406+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:01:28.406+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:01:28.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T05:01:58.585+0000] {processor.py:157} INFO - Started process (PID=5923) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:01:58.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:01:58.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:01:58.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:01:58.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:01:58.631+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:01:58.631+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:01:58.661+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:01:58.661+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:01:58.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T05:02:28.730+0000] {processor.py:157} INFO - Started process (PID=5925) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:02:28.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:02:28.732+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:02:28.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:02:28.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:02:28.777+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:02:28.777+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:02:28.804+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:02:28.803+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:02:28.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T05:02:58.922+0000] {processor.py:157} INFO - Started process (PID=5927) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:02:58.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:02:58.924+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:02:58.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:02:58.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:02:58.978+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:02:58.978+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:02:59.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:02:59.011+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:02:59.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T05:03:29.080+0000] {processor.py:157} INFO - Started process (PID=5929) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:03:29.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:03:29.082+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:03:29.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:03:29.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:03:29.126+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:03:29.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:03:29.154+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:03:29.154+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:03:29.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T05:03:59.324+0000] {processor.py:157} INFO - Started process (PID=5931) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:03:59.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:03:59.326+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:03:59.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:03:59.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:03:59.372+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:03:59.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:03:59.402+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:03:59.402+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:03:59.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T05:04:29.470+0000] {processor.py:157} INFO - Started process (PID=5933) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:04:29.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:04:29.474+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:04:29.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:04:29.489+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:04:29.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:04:29.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:04:29.557+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:04:29.557+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:04:29.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T05:04:59.730+0000] {processor.py:157} INFO - Started process (PID=5935) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:04:59.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:04:59.731+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:04:59.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:04:59.747+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:04:59.780+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:04:59.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:04:59.803+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:04:59.803+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:04:59.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T05:05:29.879+0000] {processor.py:157} INFO - Started process (PID=5937) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:05:29.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:05:29.892+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:05:29.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:05:29.903+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:05:29.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:05:29.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:05:29.960+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:05:29.960+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:05:29.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T05:06:00.124+0000] {processor.py:157} INFO - Started process (PID=5939) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:06:00.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:06:00.126+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:06:00.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:06:00.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:06:00.173+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:06:00.173+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:06:00.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:06:00.199+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:06:00.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T05:06:30.266+0000] {processor.py:157} INFO - Started process (PID=5941) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:06:30.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:06:30.278+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:06:30.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:06:30.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:06:30.325+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:06:30.325+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:06:30.352+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:06:30.352+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:06:30.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T05:07:00.459+0000] {processor.py:157} INFO - Started process (PID=5943) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:07:00.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:07:00.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:07:00.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:07:00.472+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:07:00.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:07:00.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:07:00.525+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:07:00.524+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:07:00.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T05:07:30.697+0000] {processor.py:157} INFO - Started process (PID=5945) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:07:30.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:07:30.698+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:07:30.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:07:30.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:07:30.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:07:30.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:07:30.763+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:07:30.763+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:07:30.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T05:08:00.936+0000] {processor.py:157} INFO - Started process (PID=5947) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:08:00.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:08:00.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:08:00.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:08:00.951+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:08:00.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:08:00.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:08:01.012+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:08:01.012+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:08:01.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:08:31.086+0000] {processor.py:157} INFO - Started process (PID=5949) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:08:31.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:08:31.088+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:08:31.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:08:31.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:08:31.133+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:08:31.133+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:08:31.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:08:31.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:08:31.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T05:09:01.325+0000] {processor.py:157} INFO - Started process (PID=5951) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:09:01.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:09:01.326+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:09:01.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:09:01.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:09:01.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:09:01.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:09:01.394+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:09:01.394+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:09:01.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T05:09:31.559+0000] {processor.py:157} INFO - Started process (PID=5953) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:09:31.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:09:31.572+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:09:31.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:09:31.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:09:31.611+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:09:31.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:09:31.635+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:09:31.635+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:09:31.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T05:10:01.707+0000] {processor.py:157} INFO - Started process (PID=5955) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:10:01.708+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:10:01.709+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:10:01.709+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:10:01.724+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:10:01.758+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:10:01.758+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:10:01.788+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:10:01.788+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:10:01.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T05:10:31.899+0000] {processor.py:157} INFO - Started process (PID=5957) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:10:31.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:10:31.901+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:10:31.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:10:31.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:10:31.945+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:10:31.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:10:31.973+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:10:31.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:10:31.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T05:11:02.137+0000] {processor.py:157} INFO - Started process (PID=5959) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:11:02.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:11:02.138+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:11:02.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:11:02.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:11:02.182+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:11:02.182+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:11:02.213+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:11:02.213+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:11:02.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T05:11:32.386+0000] {processor.py:157} INFO - Started process (PID=5961) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:11:32.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:11:32.388+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:11:32.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:11:32.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:11:32.434+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:11:32.434+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:11:32.467+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:11:32.466+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:11:32.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T05:12:02.652+0000] {processor.py:157} INFO - Started process (PID=5963) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:12:02.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:12:02.654+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:12:02.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:12:02.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:12:02.702+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:12:02.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:12:02.729+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:12:02.729+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:12:02.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T05:12:32.805+0000] {processor.py:157} INFO - Started process (PID=5965) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:12:32.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:12:32.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:12:32.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:12:32.833+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:12:32.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:12:32.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:12:32.889+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:12:32.888+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:12:32.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T05:13:03.062+0000] {processor.py:157} INFO - Started process (PID=5967) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:13:03.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:13:03.063+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:13:03.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:13:03.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:13:03.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:13:03.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:13:03.134+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:13:03.134+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:13:03.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T05:13:33.315+0000] {processor.py:157} INFO - Started process (PID=5969) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:13:33.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:13:33.317+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:13:33.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:13:33.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:13:33.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:13:33.375+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:13:33.411+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:13:33.410+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:13:33.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T05:14:03.466+0000] {processor.py:157} INFO - Started process (PID=5971) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:14:03.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:14:03.469+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:14:03.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:14:03.494+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:14:03.547+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:14:03.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:14:03.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:14:03.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:14:03.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-25T05:14:33.687+0000] {processor.py:157} INFO - Started process (PID=5973) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:14:33.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:14:33.689+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:14:33.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:14:33.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:14:33.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:14:33.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:14:33.787+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:14:33.787+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:14:33.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-25T05:15:03.962+0000] {processor.py:157} INFO - Started process (PID=5975) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:15:03.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:15:03.963+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:15:03.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:15:03.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:15:04.014+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:15:04.014+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:15:04.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:15:04.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:15:04.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:15:34.219+0000] {processor.py:157} INFO - Started process (PID=5977) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:15:34.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:15:34.221+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:15:34.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:15:34.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:15:34.267+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:15:34.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:15:34.293+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:15:34.293+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:15:34.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T05:16:04.369+0000] {processor.py:157} INFO - Started process (PID=5979) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:16:04.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:16:04.371+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:16:04.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:16:04.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:16:04.423+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:16:04.422+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:16:04.456+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:16:04.456+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:16:04.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T05:16:34.629+0000] {processor.py:157} INFO - Started process (PID=5981) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:16:34.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:16:34.632+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:16:34.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:16:34.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:16:34.682+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:16:34.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:16:34.710+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:16:34.710+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:16:34.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T05:17:04.786+0000] {processor.py:157} INFO - Started process (PID=5983) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:17:04.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:17:04.787+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:17:04.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:17:04.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:17:04.827+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:17:04.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:17:04.855+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:17:04.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:17:04.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T05:17:35.041+0000] {processor.py:157} INFO - Started process (PID=5985) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:17:35.043+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:17:35.044+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:17:35.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:17:35.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:17:35.092+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:17:35.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:17:35.123+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:17:35.122+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:17:35.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:18:05.290+0000] {processor.py:157} INFO - Started process (PID=5987) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:18:05.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:18:05.292+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:18:05.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:18:05.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:18:05.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:18:05.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:18:05.374+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:18:05.374+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:18:05.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T05:18:35.557+0000] {processor.py:157} INFO - Started process (PID=5989) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:18:35.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:18:35.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:18:35.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:18:35.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:18:35.607+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:18:35.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:18:35.638+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:18:35.638+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:18:35.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T05:19:05.815+0000] {processor.py:157} INFO - Started process (PID=5991) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:19:05.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:19:05.817+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:19:05.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:19:05.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:19:05.866+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:19:05.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:19:05.896+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:19:05.896+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:19:05.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T05:19:35.969+0000] {processor.py:157} INFO - Started process (PID=5993) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:19:35.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:19:35.971+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:19:35.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:19:35.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:19:36.019+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:19:36.018+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:19:36.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:19:36.051+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:19:36.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T05:20:06.223+0000] {processor.py:157} INFO - Started process (PID=5995) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:20:06.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:20:06.225+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:20:06.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:20:06.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:20:06.271+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:20:06.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:20:06.298+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:20:06.298+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:20:06.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T05:20:36.467+0000] {processor.py:157} INFO - Started process (PID=5997) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:20:36.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:20:36.469+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:20:36.468+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:20:36.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:20:36.516+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:20:36.516+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:20:36.543+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:20:36.543+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:20:36.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T05:21:06.734+0000] {processor.py:157} INFO - Started process (PID=5999) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:21:06.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:21:06.736+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:21:06.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:21:06.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:21:06.785+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:21:06.785+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:21:06.815+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:21:06.814+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:21:06.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:21:36.881+0000] {processor.py:157} INFO - Started process (PID=6001) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:21:36.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:21:36.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:21:36.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:21:36.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:21:36.928+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:21:36.927+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:21:36.957+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:21:36.957+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:21:36.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T05:22:07.109+0000] {processor.py:157} INFO - Started process (PID=6003) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:22:07.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:22:07.111+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:22:07.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:22:07.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:22:07.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:22:07.164+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:22:07.201+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:22:07.200+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:22:07.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T05:22:37.266+0000] {processor.py:157} INFO - Started process (PID=6005) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:22:37.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:22:37.268+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:22:37.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:22:37.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:22:37.314+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:22:37.314+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:22:37.342+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:22:37.342+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:22:37.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T05:23:07.520+0000] {processor.py:157} INFO - Started process (PID=6007) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:23:07.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:23:07.522+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:23:07.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:23:07.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:23:07.565+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:23:07.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:23:07.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:23:07.589+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:23:07.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T05:23:37.761+0000] {processor.py:157} INFO - Started process (PID=6009) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:23:37.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:23:37.762+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:23:37.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:23:37.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:23:37.811+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:23:37.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:23:37.839+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:23:37.839+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:23:37.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:24:07.911+0000] {processor.py:157} INFO - Started process (PID=6011) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:24:07.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:24:07.913+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:24:07.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:24:07.926+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:24:07.956+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:24:07.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:24:07.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:24:07.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:24:08.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T05:24:38.155+0000] {processor.py:157} INFO - Started process (PID=6013) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:24:38.156+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:24:38.157+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:24:38.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:24:38.172+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:24:38.207+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:24:38.207+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:24:38.244+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:24:38.244+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:24:38.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T05:25:08.305+0000] {processor.py:157} INFO - Started process (PID=6015) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:25:08.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:25:08.307+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:25:08.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:25:08.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:25:08.363+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:25:08.363+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:25:08.395+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:25:08.395+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:25:08.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T05:25:38.520+0000] {processor.py:157} INFO - Started process (PID=6017) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:25:38.520+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:25:38.521+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:25:38.521+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:25:38.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:25:38.563+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:25:38.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:25:38.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:25:38.590+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:25:38.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T05:26:08.762+0000] {processor.py:157} INFO - Started process (PID=6019) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:26:08.763+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:26:08.764+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:26:08.763+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:26:08.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:26:08.808+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:26:08.808+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:26:08.839+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:26:08.839+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:26:08.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:26:38.910+0000] {processor.py:157} INFO - Started process (PID=6021) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:26:38.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:26:38.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:26:38.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:26:38.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:26:38.958+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:26:38.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:26:38.986+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:26:38.986+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:26:39.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T05:27:09.166+0000] {processor.py:157} INFO - Started process (PID=6023) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:27:09.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:27:09.178+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:27:09.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:27:09.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:27:09.217+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:27:09.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:27:09.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:27:09.246+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:27:09.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T05:27:39.309+0000] {processor.py:157} INFO - Started process (PID=6025) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:27:39.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:27:39.311+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:27:39.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:27:39.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:27:39.358+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:27:39.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:27:39.389+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:27:39.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:27:39.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T05:28:09.518+0000] {processor.py:157} INFO - Started process (PID=6027) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:28:09.530+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:28:09.530+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:28:09.530+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:28:09.544+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:28:09.572+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:28:09.572+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:28:09.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:28:09.597+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:28:09.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T05:28:39.672+0000] {processor.py:157} INFO - Started process (PID=6029) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:28:39.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:28:39.674+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:28:39.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:28:39.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:28:39.714+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:28:39.714+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:28:39.740+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:28:39.739+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:28:39.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T05:29:09.914+0000] {processor.py:157} INFO - Started process (PID=6031) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:29:09.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:29:09.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:29:09.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:29:09.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:29:09.963+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:29:09.962+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:29:09.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:29:09.989+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:29:10.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T05:29:40.059+0000] {processor.py:157} INFO - Started process (PID=6033) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:29:40.060+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:29:40.061+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:29:40.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:29:40.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:29:40.109+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:29:40.109+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:29:40.137+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:29:40.137+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:29:40.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T05:30:10.263+0000] {processor.py:157} INFO - Started process (PID=6035) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:30:10.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:30:10.265+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:30:10.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:30:10.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:30:10.317+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:30:10.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:30:10.353+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:30:10.353+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:30:10.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T05:30:40.419+0000] {processor.py:157} INFO - Started process (PID=6037) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:30:40.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:30:40.421+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:30:40.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:30:40.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:30:40.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:30:40.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:30:40.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:30:40.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:30:40.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T05:31:10.668+0000] {processor.py:157} INFO - Started process (PID=6039) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:31:10.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:31:10.670+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:31:10.670+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:31:10.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:31:10.718+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:31:10.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:31:10.755+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:31:10.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:31:10.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T05:31:40.932+0000] {processor.py:157} INFO - Started process (PID=6041) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:31:40.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:31:40.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:31:40.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:31:40.946+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:31:40.978+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:31:40.977+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:31:41.008+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:31:41.008+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:31:41.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T05:32:11.187+0000] {processor.py:157} INFO - Started process (PID=6043) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:32:11.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:32:11.189+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:32:11.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:32:11.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:32:11.234+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:32:11.234+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:32:11.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:32:11.261+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:32:11.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T05:32:41.439+0000] {processor.py:157} INFO - Started process (PID=6045) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:32:41.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:32:41.441+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:32:41.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:32:41.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:32:41.496+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:32:41.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:32:41.531+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:32:41.530+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:32:41.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T05:33:11.590+0000] {processor.py:157} INFO - Started process (PID=6047) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:33:11.592+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:33:11.592+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:33:11.592+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:33:11.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:33:11.648+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:33:11.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:33:11.676+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:33:11.675+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:33:11.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T05:33:41.852+0000] {processor.py:157} INFO - Started process (PID=6049) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:33:41.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:33:41.855+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:33:41.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:33:41.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:33:41.909+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:33:41.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:33:41.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:33:41.943+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:33:41.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T05:34:12.009+0000] {processor.py:157} INFO - Started process (PID=6051) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:34:12.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:34:12.010+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:34:12.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:34:12.027+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:34:12.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:34:12.058+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:34:12.084+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:34:12.084+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:34:12.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T05:34:42.273+0000] {processor.py:157} INFO - Started process (PID=6053) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:34:42.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:34:42.276+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:34:42.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:34:42.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:34:42.330+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:34:42.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:34:42.359+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:34:42.359+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:34:42.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T05:35:12.418+0000] {processor.py:157} INFO - Started process (PID=6055) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:35:12.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:35:12.420+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:35:12.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:35:12.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:35:12.467+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:35:12.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:35:12.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:35:12.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:35:12.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T05:35:42.665+0000] {processor.py:157} INFO - Started process (PID=6057) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:35:42.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:35:42.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:35:42.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:35:42.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:35:42.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:35:42.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:35:42.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:35:42.754+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:35:42.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T05:36:12.958+0000] {processor.py:157} INFO - Started process (PID=6059) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:36:12.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:36:12.961+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:36:12.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:36:12.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:36:13.007+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:36:13.007+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:36:13.030+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:36:13.030+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:36:13.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T05:36:43.201+0000] {processor.py:157} INFO - Started process (PID=6061) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:36:43.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:36:43.204+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:36:43.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:36:43.223+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:36:43.264+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:36:43.263+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:36:43.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:36:43.295+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:36:43.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T05:37:13.481+0000] {processor.py:157} INFO - Started process (PID=6063) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:37:13.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:37:13.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:37:13.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:37:13.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:37:13.534+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:37:13.534+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:37:13.566+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:37:13.566+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:37:13.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T05:37:43.627+0000] {processor.py:157} INFO - Started process (PID=6065) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:37:43.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:37:43.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:37:43.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:37:43.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:37:43.674+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:37:43.674+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:37:43.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:37:43.701+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:37:43.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T05:38:13.870+0000] {processor.py:157} INFO - Started process (PID=6067) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:38:13.872+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:38:13.873+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:38:13.872+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:38:13.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:38:13.921+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:38:13.921+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:38:13.961+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:38:13.960+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:38:13.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T05:38:44.020+0000] {processor.py:157} INFO - Started process (PID=6069) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:38:44.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:38:44.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:38:44.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:38:44.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:38:44.078+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:38:44.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:38:44.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:38:44.107+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:38:44.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T05:39:14.240+0000] {processor.py:157} INFO - Started process (PID=6071) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:39:14.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:39:14.242+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:39:14.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:39:14.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:39:14.287+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:39:14.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:39:14.315+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:39:14.315+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:39:14.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:39:44.416+0000] {processor.py:157} INFO - Started process (PID=6073) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:39:44.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:39:44.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:39:44.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:39:44.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:39:44.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:39:44.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:39:44.488+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:39:44.488+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:39:44.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T05:40:14.638+0000] {processor.py:157} INFO - Started process (PID=6075) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:40:14.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:40:14.641+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:40:14.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:40:14.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:40:14.685+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:40:14.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:40:14.711+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:40:14.711+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:40:14.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T05:40:44.790+0000] {processor.py:157} INFO - Started process (PID=6077) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:40:44.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:40:44.792+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:40:44.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:40:44.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:40:44.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:40:44.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:40:44.873+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:40:44.873+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:40:44.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T05:41:15.047+0000] {processor.py:157} INFO - Started process (PID=6079) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:41:15.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:41:15.049+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:41:15.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:41:15.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:41:15.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:41:15.101+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:41:15.130+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:41:15.130+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:41:15.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T05:41:45.304+0000] {processor.py:157} INFO - Started process (PID=6081) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:41:45.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:41:45.307+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:41:45.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:41:45.324+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:41:45.357+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:41:45.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:41:45.383+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:41:45.383+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:41:45.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T05:42:15.457+0000] {processor.py:157} INFO - Started process (PID=6083) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:42:15.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:42:15.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:42:15.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:42:15.477+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:42:15.508+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:42:15.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:42:15.544+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:42:15.544+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:42:15.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T05:42:45.716+0000] {processor.py:157} INFO - Started process (PID=6085) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:42:45.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:42:45.718+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:42:45.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:42:45.735+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:42:45.768+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:42:45.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:42:45.802+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:42:45.802+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:42:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T05:43:15.965+0000] {processor.py:157} INFO - Started process (PID=6087) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:43:15.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:43:15.967+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:43:15.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:43:15.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:43:16.012+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:43:16.012+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:43:16.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:43:16.037+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:43:16.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T05:43:46.216+0000] {processor.py:157} INFO - Started process (PID=6089) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:43:46.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:43:46.219+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:43:46.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:43:46.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:43:46.270+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:43:46.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:43:46.298+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:43:46.298+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:43:46.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T05:44:16.373+0000] {processor.py:157} INFO - Started process (PID=6091) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:44:16.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:44:16.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:44:16.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:44:16.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:44:16.420+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:44:16.420+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:44:16.449+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:44:16.448+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:44:16.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T05:44:46.624+0000] {processor.py:157} INFO - Started process (PID=6093) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:44:46.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:44:46.626+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:44:46.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:44:46.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:44:46.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:44:46.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:44:46.711+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:44:46.711+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:44:46.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T05:45:16.774+0000] {processor.py:157} INFO - Started process (PID=6095) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:45:16.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:45:16.777+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:45:16.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:45:16.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:45:16.819+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:45:16.819+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:45:16.845+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:45:16.845+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:45:16.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T05:45:47.020+0000] {processor.py:157} INFO - Started process (PID=6097) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:45:47.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:45:47.022+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:45:47.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:45:47.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:45:47.063+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:45:47.062+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:45:47.095+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:45:47.095+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:45:47.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T05:46:17.332+0000] {processor.py:157} INFO - Started process (PID=6099) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:46:17.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:46:17.334+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:46:17.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:46:17.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:46:17.401+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:46:17.401+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:46:17.449+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:46:17.449+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:46:17.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.201 seconds
[2024-10-25T05:46:47.686+0000] {processor.py:157} INFO - Started process (PID=6101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:46:47.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:46:47.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:46:47.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:46:47.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:46:47.758+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:46:47.757+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:46:47.787+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:46:47.787+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:46:47.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-25T05:47:17.966+0000] {processor.py:157} INFO - Started process (PID=6103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:47:17.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:47:17.967+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:47:17.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:47:17.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:47:18.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:47:18.011+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:47:18.036+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:47:18.036+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:47:18.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T05:47:48.125+0000] {processor.py:157} INFO - Started process (PID=6105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:47:48.127+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:47:48.127+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:47:48.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:47:48.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:47:48.182+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:47:48.182+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:47:48.213+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:47:48.213+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:47:48.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T05:48:18.399+0000] {processor.py:157} INFO - Started process (PID=6107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:48:18.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:48:18.401+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:48:18.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:48:18.419+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:48:18.450+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:48:18.449+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:48:18.483+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:48:18.483+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:48:18.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T05:48:48.549+0000] {processor.py:157} INFO - Started process (PID=6109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:48:48.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:48:48.551+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:48:48.551+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:48:48.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:48:48.620+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:48:48.620+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:48:48.664+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:48:48.664+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:48:48.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.141 seconds
[2024-10-25T05:49:18.758+0000] {processor.py:157} INFO - Started process (PID=6111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:49:18.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:49:18.760+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:49:18.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:49:18.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:49:18.804+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:49:18.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:49:18.829+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:49:18.828+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:49:18.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T05:49:48.997+0000] {processor.py:157} INFO - Started process (PID=6113) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:49:48.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:49:48.999+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:49:48.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:49:49.026+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:49:49.071+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:49:49.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:49:49.120+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:49:49.120+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:49:49.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.158 seconds
[2024-10-25T05:50:19.311+0000] {processor.py:157} INFO - Started process (PID=6115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:50:19.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:50:19.324+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:50:19.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:50:19.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:50:19.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:50:19.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:50:19.399+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:50:19.399+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:50:19.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T05:50:49.455+0000] {processor.py:157} INFO - Started process (PID=6117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:50:49.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:50:49.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:50:49.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:50:49.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:50:49.498+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:50:49.498+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:50:49.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:50:49.523+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:50:49.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T05:51:19.693+0000] {processor.py:157} INFO - Started process (PID=6119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:51:19.694+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:51:19.695+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:51:19.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:51:19.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:51:19.739+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:51:19.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:51:19.767+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:51:19.767+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:51:19.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T05:51:49.934+0000] {processor.py:157} INFO - Started process (PID=6121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:51:49.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:51:49.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:51:49.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:51:49.949+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:51:49.977+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:51:49.976+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:51:50.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:51:50.004+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:51:50.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T05:52:20.077+0000] {processor.py:157} INFO - Started process (PID=6123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:52:20.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:52:20.079+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:52:20.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:52:20.091+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:52:20.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:52:20.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:52:20.148+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:52:20.148+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:52:20.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T05:52:50.273+0000] {processor.py:157} INFO - Started process (PID=6125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:52:50.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:52:50.276+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:52:50.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:52:50.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:52:50.326+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:52:50.326+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:52:50.356+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:52:50.356+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:52:50.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T05:53:20.488+0000] {processor.py:157} INFO - Started process (PID=6127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:53:20.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T05:53:20.497+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:53:20.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:53:20.530+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T05:53:20.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:53:20.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T05:53:20.623+0000] {logging_mixin.py:149} INFO - [2024-10-25T05:53:20.622+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T05:53:20.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-25T08:53:30.970+0000] {processor.py:157} INFO - Started process (PID=6129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T08:53:30.973+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T08:53:30.974+0000] {logging_mixin.py:149} INFO - [2024-10-25T08:53:30.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T08:53:31.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T08:53:31.413+0000] {logging_mixin.py:149} INFO - [2024-10-25T08:53:31.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T08:53:31.535+0000] {logging_mixin.py:149} INFO - [2024-10-25T08:53:31.535+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T08:53:31.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.827 seconds
[2024-10-25T12:14:55.289+0000] {processor.py:157} INFO - Started process (PID=6133) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:14:55.295+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:14:55.304+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:14:55.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:14:55.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:14:55.642+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:14:55.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:14:55.814+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:14:55.814+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:14:56.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.795 seconds
[2024-10-25T12:15:26.201+0000] {processor.py:157} INFO - Started process (PID=6137) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:15:26.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:15:26.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:15:26.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:15:26.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:15:26.387+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:15:26.386+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:15:26.472+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:15:26.472+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:15:26.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.306 seconds
[2024-10-25T12:15:56.692+0000] {processor.py:157} INFO - Started process (PID=6139) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:15:56.694+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:15:56.695+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:15:56.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:15:56.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:15:56.780+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:15:56.780+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:15:56.859+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:15:56.859+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:15:56.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.206 seconds
[2024-10-25T12:16:27.052+0000] {processor.py:157} INFO - Started process (PID=6141) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:16:27.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:16:27.055+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:16:27.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:16:27.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:16:27.153+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:16:27.153+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:16:27.200+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:16:27.200+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:16:27.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.183 seconds
[2024-10-25T12:16:57.402+0000] {processor.py:157} INFO - Started process (PID=6143) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:16:57.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:16:57.404+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:16:57.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:16:57.419+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:16:57.454+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:16:57.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:16:57.488+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:16:57.488+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:16:57.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-25T12:17:27.690+0000] {processor.py:157} INFO - Started process (PID=6145) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:17:27.691+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:17:27.692+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:17:27.692+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:17:27.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:17:27.744+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:17:27.744+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:17:27.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:17:27.773+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:17:27.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T12:17:57.960+0000] {processor.py:157} INFO - Started process (PID=6147) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:17:57.961+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:17:57.963+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:17:57.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:17:57.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:17:58.012+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:17:58.011+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:17:58.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:17:58.037+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:17:58.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T12:18:28.216+0000] {processor.py:157} INFO - Started process (PID=6149) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:18:28.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:18:28.218+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:18:28.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:18:28.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:18:28.268+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:18:28.268+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:18:28.297+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:18:28.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:18:28.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T12:18:58.376+0000] {processor.py:157} INFO - Started process (PID=6151) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:18:58.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:18:58.379+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:18:58.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:18:58.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:18:58.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:18:58.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:18:58.509+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:18:58.508+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:18:58.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.175 seconds
[2024-10-25T12:19:28.715+0000] {processor.py:157} INFO - Started process (PID=6153) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:19:28.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:19:28.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:19:28.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:19:28.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:19:28.770+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:19:28.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:19:28.798+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:19:28.798+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:19:28.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T12:19:58.996+0000] {processor.py:157} INFO - Started process (PID=6155) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:19:58.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:19:58.998+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:19:58.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:19:59.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:19:59.069+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:19:59.068+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:19:59.103+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:19:59.103+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:19:59.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.148 seconds
[2024-10-25T12:20:29.293+0000] {processor.py:157} INFO - Started process (PID=6157) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:20:29.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:20:29.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:20:29.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:20:29.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:20:29.347+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:20:29.347+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:20:29.384+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:20:29.384+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:20:29.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T12:20:59.580+0000] {processor.py:157} INFO - Started process (PID=6159) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:20:59.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:20:59.583+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:20:59.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:20:59.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:20:59.634+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:20:59.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:20:59.672+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:20:59.672+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:20:59.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T12:21:29.743+0000] {processor.py:157} INFO - Started process (PID=6161) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:21:29.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:21:29.745+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:21:29.745+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:21:29.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:21:29.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:21:29.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:21:29.832+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:21:29.832+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:21:29.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T12:21:59.974+0000] {processor.py:157} INFO - Started process (PID=6163) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:21:59.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:21:59.976+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:21:59.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:21:59.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:22:00.029+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:22:00.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:22:00.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:22:00.058+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:22:00.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:22:30.132+0000] {processor.py:157} INFO - Started process (PID=6165) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:22:30.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:22:30.134+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:22:30.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:22:30.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:22:30.193+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:22:30.193+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:22:30.227+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:22:30.227+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:22:30.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T12:23:00.410+0000] {processor.py:157} INFO - Started process (PID=6167) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:23:00.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:23:00.412+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:23:00.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:23:00.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:23:00.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:23:00.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:23:00.492+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:23:00.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:23:00.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:23:30.671+0000] {processor.py:157} INFO - Started process (PID=6169) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:23:30.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:23:30.673+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:23:30.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:23:30.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:23:30.720+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:23:30.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:23:30.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:23:30.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:23:30.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:24:00.825+0000] {processor.py:157} INFO - Started process (PID=6171) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:24:00.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:24:00.837+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:24:00.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:24:00.855+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:24:00.887+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:24:00.887+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:24:00.920+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:24:00.919+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:24:00.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T12:24:31.084+0000] {processor.py:157} INFO - Started process (PID=6173) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:24:31.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:24:31.086+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:24:31.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:24:31.103+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:24:31.139+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:24:31.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:24:31.169+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:24:31.169+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:24:31.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T12:25:01.326+0000] {processor.py:157} INFO - Started process (PID=6175) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:25:01.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:25:01.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:25:01.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:25:01.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:25:01.384+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:25:01.384+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:25:01.416+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:25:01.415+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:25:01.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T12:25:31.475+0000] {processor.py:157} INFO - Started process (PID=6177) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:25:31.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:25:31.477+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:25:31.477+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:25:31.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:25:31.531+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:25:31.531+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:25:31.567+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:25:31.567+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:25:31.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T12:26:01.767+0000] {processor.py:157} INFO - Started process (PID=6179) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:26:01.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:26:01.769+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:26:01.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:26:01.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:26:01.831+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:26:01.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:26:01.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:26:01.861+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:26:01.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-25T12:26:32.056+0000] {processor.py:157} INFO - Started process (PID=6181) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:26:32.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:26:32.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:26:32.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:26:32.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:26:32.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:26:32.110+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:26:32.140+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:26:32.140+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:26:32.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:27:02.218+0000] {processor.py:157} INFO - Started process (PID=6183) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:27:02.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:27:02.221+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:27:02.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:27:02.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:27:02.272+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:27:02.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:27:02.301+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:27:02.301+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:27:02.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T12:27:32.473+0000] {processor.py:157} INFO - Started process (PID=6185) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:27:32.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:27:32.475+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:27:32.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:27:32.494+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:27:32.529+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:27:32.528+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:27:32.564+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:27:32.564+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:27:32.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T12:28:02.650+0000] {processor.py:157} INFO - Started process (PID=6187) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:28:02.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:28:02.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:28:02.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:28:02.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:28:02.727+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:28:02.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:28:02.942+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:28:02.942+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:28:03.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.664 seconds
[2024-10-25T12:28:33.474+0000] {processor.py:157} INFO - Started process (PID=6189) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:28:33.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:28:33.480+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:28:33.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:28:33.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:28:33.536+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:28:33.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:28:33.568+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:28:33.568+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:28:33.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T12:29:03.746+0000] {processor.py:157} INFO - Started process (PID=6191) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:29:03.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:29:03.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:29:03.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:29:03.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:29:03.801+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:29:03.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:29:03.837+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:29:03.837+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:29:03.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T12:29:34.024+0000] {processor.py:157} INFO - Started process (PID=6193) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:29:34.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:29:34.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:29:34.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:29:34.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:29:34.080+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:29:34.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:29:34.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:29:34.110+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:29:34.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T12:30:04.192+0000] {processor.py:157} INFO - Started process (PID=6195) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:30:04.194+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:30:04.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:30:04.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:30:04.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:30:04.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:30:04.246+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:30:04.301+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:30:04.300+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:30:04.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.148 seconds
[2024-10-25T12:30:34.404+0000] {processor.py:157} INFO - Started process (PID=6197) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:30:34.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:30:34.407+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:30:34.406+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:30:34.424+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:30:34.459+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:30:34.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:30:34.498+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:30:34.497+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:30:34.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-25T12:31:04.683+0000] {processor.py:157} INFO - Started process (PID=6199) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:31:04.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:31:04.685+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:31:04.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:31:04.700+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:31:04.731+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:31:04.731+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:31:04.759+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:31:04.759+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:31:04.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T12:31:34.836+0000] {processor.py:157} INFO - Started process (PID=6201) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:31:34.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:31:34.849+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:31:34.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:31:34.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:31:34.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:31:34.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:31:34.938+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:31:34.938+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:31:34.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-25T12:32:05.056+0000] {processor.py:157} INFO - Started process (PID=6203) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:32:05.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:32:05.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:32:05.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:32:05.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:32:05.109+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:32:05.109+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:32:05.143+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:32:05.143+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:32:05.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T12:32:35.231+0000] {processor.py:157} INFO - Started process (PID=6205) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:32:35.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:32:35.243+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:32:35.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:32:35.260+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:32:35.288+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:32:35.288+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:32:35.320+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:32:35.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:32:35.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T12:33:05.439+0000] {processor.py:157} INFO - Started process (PID=6207) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:33:05.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:33:05.440+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:33:05.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:33:05.455+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:33:05.491+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:33:05.491+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:33:05.521+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:33:05.521+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:33:05.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:33:35.610+0000] {processor.py:157} INFO - Started process (PID=6209) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:33:35.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:33:35.612+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:33:35.612+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:33:35.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:33:35.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:33:35.662+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:33:35.697+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:33:35.697+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:33:35.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T12:34:05.823+0000] {processor.py:157} INFO - Started process (PID=6211) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:34:05.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:34:05.824+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:34:05.824+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:34:05.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:34:05.872+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:34:05.872+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:34:05.900+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:34:05.900+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:34:05.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T12:34:35.976+0000] {processor.py:157} INFO - Started process (PID=6213) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:34:35.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:34:35.990+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:34:35.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:34:36.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:34:36.039+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:34:36.039+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:34:36.068+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:34:36.068+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:34:36.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T12:35:06.206+0000] {processor.py:157} INFO - Started process (PID=6215) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:35:06.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:35:06.208+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:35:06.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:35:06.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:35:06.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:35:06.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:35:06.294+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:35:06.293+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:35:06.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T12:35:36.490+0000] {processor.py:157} INFO - Started process (PID=6217) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:35:36.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:35:36.492+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:35:36.492+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:35:36.510+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:35:36.543+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:35:36.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:35:36.576+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:35:36.576+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:35:36.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T12:36:06.651+0000] {processor.py:157} INFO - Started process (PID=6219) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:36:06.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:36:06.652+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:36:06.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:36:06.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:36:06.699+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:36:06.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:36:06.728+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:36:06.727+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:36:06.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T12:36:36.913+0000] {processor.py:157} INFO - Started process (PID=6221) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:36:36.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:36:36.926+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:36:36.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:36:36.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:36:36.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:36:36.974+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:36:37.008+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:36:37.008+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:36:37.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T12:37:07.069+0000] {processor.py:157} INFO - Started process (PID=6223) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:37:07.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:37:07.071+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:37:07.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:37:07.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:37:07.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:37:07.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:37:07.152+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:37:07.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:37:07.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T12:37:37.340+0000] {processor.py:157} INFO - Started process (PID=6225) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:37:37.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:37:37.342+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:37:37.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:37:37.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:37:37.398+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:37:37.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:37:37.431+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:37:37.431+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:37:37.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T12:38:07.643+0000] {processor.py:157} INFO - Started process (PID=6227) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:38:07.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:38:07.646+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:38:07.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:38:07.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:38:07.704+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:38:07.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:38:07.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:38:07.734+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:38:07.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T12:38:37.803+0000] {processor.py:157} INFO - Started process (PID=6229) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:38:37.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:38:37.805+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:38:37.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:38:37.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:38:37.857+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:38:37.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:38:37.896+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:38:37.895+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:38:37.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T12:39:08.023+0000] {processor.py:157} INFO - Started process (PID=6231) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:39:08.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:39:08.025+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:39:08.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:39:08.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:39:08.084+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:39:08.084+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:39:08.114+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:39:08.114+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:39:08.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T12:39:38.185+0000] {processor.py:157} INFO - Started process (PID=6233) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:39:38.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:39:38.198+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:39:38.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:39:38.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:39:38.247+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:39:38.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:39:38.282+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:39:38.282+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:39:38.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T12:40:08.417+0000] {processor.py:157} INFO - Started process (PID=6235) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:40:08.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:40:08.431+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:40:08.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:40:08.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:40:08.481+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:40:08.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:40:08.514+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:40:08.514+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:40:08.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-25T12:40:38.572+0000] {processor.py:157} INFO - Started process (PID=6237) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:40:38.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:40:38.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:40:38.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:40:38.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:40:38.619+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:40:38.619+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:40:38.648+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:40:38.648+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:40:38.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T12:41:08.839+0000] {processor.py:157} INFO - Started process (PID=6239) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:41:08.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:41:08.840+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:41:08.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:41:08.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:41:08.892+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:41:08.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:41:08.925+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:41:08.925+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:41:08.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T12:41:38.998+0000] {processor.py:157} INFO - Started process (PID=6241) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:41:39.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:41:39.001+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:41:39.001+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:41:39.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:41:39.056+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:41:39.056+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:41:39.094+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:41:39.094+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:41:39.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T12:42:09.223+0000] {processor.py:157} INFO - Started process (PID=6243) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:42:09.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:42:09.236+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:42:09.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:42:09.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:42:09.289+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:42:09.288+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:42:09.322+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:42:09.322+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:42:09.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T12:42:39.391+0000] {processor.py:157} INFO - Started process (PID=6245) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:42:39.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:42:39.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:42:39.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:42:39.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:42:39.446+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:42:39.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:42:39.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:42:39.484+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:42:39.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T12:43:09.665+0000] {processor.py:157} INFO - Started process (PID=6247) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:43:09.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:43:09.678+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:43:09.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:43:09.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:43:09.751+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:43:09.751+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:43:09.779+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:43:09.779+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:43:09.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-25T12:43:39.952+0000] {processor.py:157} INFO - Started process (PID=6249) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:43:39.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:43:39.954+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:43:39.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:43:39.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:43:40.006+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:43:40.006+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:43:40.031+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:43:40.031+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:43:40.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T12:44:10.124+0000] {processor.py:157} INFO - Started process (PID=6251) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:44:10.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:44:10.127+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:44:10.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:44:10.146+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:44:10.184+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:44:10.183+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:44:10.221+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:44:10.220+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:44:10.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-25T12:44:40.407+0000] {processor.py:157} INFO - Started process (PID=6253) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:44:40.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:44:40.419+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:44:40.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:44:40.433+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:44:40.468+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:44:40.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:44:40.501+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:44:40.500+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:44:40.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T12:45:10.593+0000] {processor.py:157} INFO - Started process (PID=6255) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:45:10.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:45:10.606+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:45:10.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:45:10.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:45:10.661+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:45:10.661+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:45:10.694+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:45:10.694+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:45:10.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T12:45:40.870+0000] {processor.py:157} INFO - Started process (PID=6257) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:45:40.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:45:40.872+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:45:40.872+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:45:40.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:45:40.926+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:45:40.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:45:40.959+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:45:40.959+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:45:40.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T12:46:11.036+0000] {processor.py:157} INFO - Started process (PID=6259) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:46:11.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:46:11.039+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:46:11.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:46:11.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:46:11.105+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:46:11.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:46:11.150+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:46:11.150+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:46:11.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-25T12:46:41.341+0000] {processor.py:157} INFO - Started process (PID=6261) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:46:41.342+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:46:41.343+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:46:41.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:46:41.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:46:41.407+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:46:41.406+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:46:41.455+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:46:41.454+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:46:41.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-25T12:47:11.642+0000] {processor.py:157} INFO - Started process (PID=6263) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:47:11.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:47:11.644+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:47:11.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:47:11.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:47:11.700+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:47:11.700+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:47:11.732+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:47:11.732+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:47:11.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T12:47:41.913+0000] {processor.py:157} INFO - Started process (PID=6265) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:47:41.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:47:41.925+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:47:41.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:47:41.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:47:41.972+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:47:41.972+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:47:42.004+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:47:42.004+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:47:42.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T12:48:12.068+0000] {processor.py:157} INFO - Started process (PID=6267) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:48:12.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:48:12.071+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:48:12.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:48:12.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:48:12.117+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:48:12.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:48:12.151+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:48:12.151+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:48:12.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T12:48:42.295+0000] {processor.py:157} INFO - Started process (PID=6269) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:48:42.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:48:42.308+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:48:42.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:48:42.324+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:48:42.359+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:48:42.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:48:42.389+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:48:42.388+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:48:42.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T12:49:12.456+0000] {processor.py:157} INFO - Started process (PID=6271) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:49:12.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:49:12.470+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:49:12.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:49:12.482+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:49:12.517+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:49:12.517+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:49:12.547+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:49:12.547+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:49:12.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T12:49:42.681+0000] {processor.py:157} INFO - Started process (PID=6273) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:49:42.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:49:42.683+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:49:42.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:49:42.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:49:42.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:49:42.734+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:49:42.759+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:49:42.759+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:49:42.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T12:50:12.956+0000] {processor.py:157} INFO - Started process (PID=6275) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:50:12.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:50:12.960+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:50:12.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:50:12.975+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:50:13.039+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:50:13.039+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:50:13.102+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:50:13.101+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:50:13.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.195 seconds
[2024-10-25T12:50:43.338+0000] {processor.py:157} INFO - Started process (PID=6277) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:50:43.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:50:43.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:50:43.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:50:43.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:50:43.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:50:43.390+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:50:43.421+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:50:43.421+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:50:43.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:51:13.498+0000] {processor.py:157} INFO - Started process (PID=6279) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:51:13.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:51:13.500+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:51:13.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:51:13.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:51:13.551+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:51:13.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:51:13.582+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:51:13.582+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:51:13.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T12:51:43.770+0000] {processor.py:157} INFO - Started process (PID=6281) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:51:43.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:51:43.772+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:51:43.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:51:43.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:51:43.824+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:51:43.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:51:43.855+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:51:43.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:51:43.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T12:52:13.943+0000] {processor.py:157} INFO - Started process (PID=6283) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:52:13.955+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:52:13.956+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:52:13.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:52:13.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:52:14.009+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:52:14.009+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:52:14.044+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:52:14.043+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:52:14.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-25T12:52:44.166+0000] {processor.py:157} INFO - Started process (PID=6285) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:52:44.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:52:44.168+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:52:44.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:52:44.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:52:44.226+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:52:44.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:52:44.270+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:52:44.270+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:52:44.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-25T12:53:14.473+0000] {processor.py:157} INFO - Started process (PID=6287) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:53:14.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:53:14.476+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:53:14.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:53:14.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:53:14.522+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:53:14.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:53:14.555+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:53:14.555+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:53:14.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T12:53:44.753+0000] {processor.py:157} INFO - Started process (PID=6289) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:53:44.754+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:53:44.755+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:53:44.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:53:44.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:53:44.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:53:44.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:53:44.865+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:53:44.865+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:53:44.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.151 seconds
[2024-10-25T12:54:15.071+0000] {processor.py:157} INFO - Started process (PID=6291) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:54:15.083+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:54:15.084+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:54:15.084+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:54:15.100+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:54:15.135+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:54:15.135+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:54:15.174+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:54:15.174+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:54:15.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-25T12:54:45.240+0000] {processor.py:157} INFO - Started process (PID=6293) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:54:45.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:54:45.242+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:54:45.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:54:45.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:54:45.301+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:54:45.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:54:45.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:54:45.339+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:54:45.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-25T12:55:15.562+0000] {processor.py:157} INFO - Started process (PID=6295) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:55:15.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:55:15.564+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:55:15.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:55:15.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:55:15.613+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:55:15.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:55:15.644+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:55:15.643+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:55:15.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T12:55:45.718+0000] {processor.py:157} INFO - Started process (PID=6297) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:55:45.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:55:45.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:55:45.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:55:45.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:55:45.769+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:55:45.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:55:45.806+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:55:45.805+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:55:45.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T12:56:15.988+0000] {processor.py:157} INFO - Started process (PID=6299) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:56:15.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:56:15.991+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:56:15.990+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:56:16.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:56:16.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:56:16.041+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:56:16.071+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:56:16.071+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:56:16.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T12:56:46.140+0000] {processor.py:157} INFO - Started process (PID=6301) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:56:46.141+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:56:46.142+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:56:46.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:56:46.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:56:46.188+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:56:46.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:56:46.223+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:56:46.222+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:56:46.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T12:57:16.366+0000] {processor.py:157} INFO - Started process (PID=6303) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:57:16.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:57:16.379+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:57:16.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:57:16.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:57:16.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:57:16.433+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:57:16.468+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:57:16.468+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:57:16.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-25T12:57:46.659+0000] {processor.py:157} INFO - Started process (PID=6305) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:57:46.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:57:46.660+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:57:46.660+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:57:46.678+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:57:46.709+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:57:46.708+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:57:46.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:57:46.738+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:57:46.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T12:58:16.820+0000] {processor.py:157} INFO - Started process (PID=6307) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:58:16.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:58:16.833+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:58:16.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:58:16.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:58:16.879+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:58:16.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:58:16.907+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:58:16.907+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:58:16.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T12:58:47.026+0000] {processor.py:157} INFO - Started process (PID=6309) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:58:47.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:58:47.028+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:58:47.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:58:47.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:58:47.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:58:47.101+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:58:47.132+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:58:47.132+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:58:47.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-25T12:59:17.207+0000] {processor.py:157} INFO - Started process (PID=6311) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:59:17.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:59:17.209+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:59:17.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:59:17.227+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:59:17.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:59:17.260+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:59:17.294+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:59:17.294+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:59:17.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T12:59:47.477+0000] {processor.py:157} INFO - Started process (PID=6313) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:59:47.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T12:59:47.480+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:59:47.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:59:47.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T12:59:47.531+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:59:47.531+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T12:59:47.562+0000] {logging_mixin.py:149} INFO - [2024-10-25T12:59:47.562+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T12:59:47.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T13:00:17.650+0000] {processor.py:157} INFO - Started process (PID=6315) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:00:17.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:00:17.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:00:17.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:00:17.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:00:17.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:00:17.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:00:17.749+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:00:17.749+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:00:17.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T13:00:47.866+0000] {processor.py:157} INFO - Started process (PID=6317) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:00:47.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:00:47.868+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:00:47.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:00:47.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:00:47.920+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:00:47.920+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:00:47.953+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:00:47.953+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:00:47.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T13:01:18.053+0000] {processor.py:157} INFO - Started process (PID=6319) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:01:18.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:01:18.057+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:01:18.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:01:18.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:01:18.126+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:01:18.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:01:18.170+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:01:18.170+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:01:18.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.149 seconds
[2024-10-25T13:01:48.262+0000] {processor.py:157} INFO - Started process (PID=6321) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:01:48.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:01:48.264+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:01:48.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:01:48.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:01:48.316+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:01:48.315+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:01:48.349+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:01:48.349+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:01:48.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T13:02:18.558+0000] {processor.py:157} INFO - Started process (PID=6323) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:02:18.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:02:18.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:02:18.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:02:18.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:02:18.612+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:02:18.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:02:18.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:02:18.647+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:02:18.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T13:02:48.722+0000] {processor.py:157} INFO - Started process (PID=6325) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:02:48.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:02:48.724+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:02:48.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:02:48.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:02:48.779+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:02:48.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:02:48.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:02:48.812+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:02:48.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T13:03:18.942+0000] {processor.py:157} INFO - Started process (PID=6327) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:03:18.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:03:18.944+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:03:18.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:03:18.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:03:18.992+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:03:18.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:03:19.023+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:03:19.023+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:03:19.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T13:03:49.108+0000] {processor.py:157} INFO - Started process (PID=6329) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:03:49.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:03:49.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:03:49.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:03:49.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:03:49.167+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:03:49.167+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:03:49.204+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:03:49.203+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:03:49.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-25T13:04:19.387+0000] {processor.py:157} INFO - Started process (PID=6331) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:04:19.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:04:19.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:04:19.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:04:19.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:04:19.442+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:04:19.442+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:04:19.474+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:04:19.474+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:04:19.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T13:04:49.584+0000] {processor.py:157} INFO - Started process (PID=6333) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:04:49.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:04:49.587+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:04:49.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:04:49.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:04:49.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:04:49.645+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:04:49.689+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:04:49.689+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:04:49.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.164 seconds
[2024-10-25T13:05:19.915+0000] {processor.py:157} INFO - Started process (PID=6335) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:05:19.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:05:19.919+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:05:19.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:05:19.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:05:20.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:05:20.063+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:05:20.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:05:20.165+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:05:20.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.316 seconds
[2024-10-25T13:05:50.410+0000] {processor.py:157} INFO - Started process (PID=6337) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:05:50.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:05:50.411+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:05:50.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:05:50.428+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:05:50.466+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:05:50.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:05:50.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:05:50.499+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:05:50.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.138 seconds
[2024-10-25T13:06:20.877+0000] {processor.py:157} INFO - Started process (PID=6339) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:06:20.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:06:20.882+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:06:20.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:06:20.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:06:20.942+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:06:20.941+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:06:20.977+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:06:20.977+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:06:21.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.153 seconds
[2024-10-25T13:06:51.185+0000] {processor.py:157} INFO - Started process (PID=6341) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:06:51.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:06:51.186+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:06:51.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:06:51.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:06:51.244+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:06:51.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:06:51.280+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:06:51.280+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:06:51.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-25T13:07:21.490+0000] {processor.py:157} INFO - Started process (PID=6343) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:07:21.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:07:21.503+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:07:21.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:07:21.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:07:21.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:07:21.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:07:21.593+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:07:21.593+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:07:21.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-25T13:07:51.787+0000] {processor.py:157} INFO - Started process (PID=6345) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:07:51.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:07:51.791+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:07:51.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:07:51.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:07:51.854+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:07:51.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:07:51.900+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:07:51.899+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:07:51.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.144 seconds
[2024-10-25T13:08:21.956+0000] {processor.py:157} INFO - Started process (PID=6347) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:08:21.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:08:21.959+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:08:21.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:08:21.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:08:22.029+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:08:22.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:08:22.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:08:22.072+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:08:22.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.151 seconds
[2024-10-25T13:08:52.268+0000] {processor.py:157} INFO - Started process (PID=6349) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:08:52.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:08:52.269+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:08:52.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:08:52.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:08:52.323+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:08:52.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:08:52.354+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:08:52.354+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:08:52.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T13:09:22.422+0000] {processor.py:157} INFO - Started process (PID=6351) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:09:22.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:09:22.424+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:09:22.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:09:22.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:09:22.468+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:09:22.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:09:22.492+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:09:22.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:09:22.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:09:52.661+0000] {processor.py:157} INFO - Started process (PID=6353) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:09:52.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:09:52.663+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:09:52.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:09:52.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:09:52.709+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:09:52.708+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:09:52.733+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:09:52.733+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:09:52.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:10:22.919+0000] {processor.py:157} INFO - Started process (PID=6355) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:10:22.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:10:22.922+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:10:22.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:10:22.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:10:23.008+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:10:23.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:10:23.030+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:10:23.030+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:10:23.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-25T13:10:53.177+0000] {processor.py:157} INFO - Started process (PID=6357) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:10:53.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:10:53.179+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:10:53.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:10:53.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:10:53.228+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:10:53.228+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:10:53.256+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:10:53.255+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:10:53.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T13:11:23.432+0000] {processor.py:157} INFO - Started process (PID=6359) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:11:23.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:11:23.434+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:11:23.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:11:23.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:11:23.485+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:11:23.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:11:23.522+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:11:23.522+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:11:23.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T13:11:53.698+0000] {processor.py:157} INFO - Started process (PID=6361) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:11:53.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:11:53.699+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:11:53.699+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:11:53.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:11:53.740+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:11:53.740+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:11:53.770+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:11:53.770+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:11:53.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T13:12:23.850+0000] {processor.py:157} INFO - Started process (PID=6363) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:12:23.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:12:23.853+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:12:23.852+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:12:23.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:12:23.905+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:12:23.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:12:23.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:12:23.933+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:12:23.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T13:12:54.110+0000] {processor.py:157} INFO - Started process (PID=6365) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:12:54.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:12:54.112+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:12:54.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:12:54.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:12:54.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:12:54.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:12:54.186+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:12:54.185+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:12:54.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T13:13:24.268+0000] {processor.py:157} INFO - Started process (PID=6367) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:13:24.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:13:24.270+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:13:24.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:13:24.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:13:24.316+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:13:24.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:13:24.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:13:24.345+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:13:24.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T13:13:54.519+0000] {processor.py:157} INFO - Started process (PID=6369) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:13:54.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:13:54.532+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:13:54.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:13:54.544+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:13:54.571+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:13:54.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:13:54.599+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:13:54.599+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:13:54.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T13:14:24.667+0000] {processor.py:157} INFO - Started process (PID=6371) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:14:24.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:14:24.669+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:14:24.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:14:24.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:14:24.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:14:24.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:14:24.743+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:14:24.743+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:14:24.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T13:14:54.931+0000] {processor.py:157} INFO - Started process (PID=6373) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:14:54.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:14:54.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:14:54.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:14:54.949+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:14:54.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:14:54.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:14:55.015+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:14:55.015+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:14:55.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T13:15:25.093+0000] {processor.py:157} INFO - Started process (PID=6375) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:15:25.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:15:25.095+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:15:25.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:15:25.108+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:15:25.141+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:15:25.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:15:25.166+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:15:25.166+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:15:25.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T13:15:55.343+0000] {processor.py:157} INFO - Started process (PID=6377) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:15:55.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:15:55.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:15:55.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:15:55.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:15:55.393+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:15:55.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:15:55.424+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:15:55.424+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:15:55.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T13:16:25.511+0000] {processor.py:157} INFO - Started process (PID=6379) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:16:25.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:16:25.512+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:16:25.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:16:25.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:16:25.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:16:25.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:16:25.585+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:16:25.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:16:25.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T13:16:55.758+0000] {processor.py:157} INFO - Started process (PID=6381) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:16:55.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:16:55.760+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:16:55.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:16:55.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:16:55.806+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:16:55.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:16:55.834+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:16:55.834+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:16:55.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T13:17:25.909+0000] {processor.py:157} INFO - Started process (PID=6383) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:17:25.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:17:25.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:17:25.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:17:25.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:17:25.956+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:17:25.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:17:25.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:17:25.987+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:17:26.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T13:17:56.158+0000] {processor.py:157} INFO - Started process (PID=6385) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:17:56.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:17:56.160+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:17:56.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:17:56.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:17:56.224+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:17:56.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:17:56.266+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:17:56.266+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:17:56.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-25T13:18:26.317+0000] {processor.py:157} INFO - Started process (PID=6387) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:18:26.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:18:26.319+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:18:26.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:18:26.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:18:26.375+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:18:26.374+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:18:26.410+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:18:26.410+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:18:26.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T13:18:56.598+0000] {processor.py:157} INFO - Started process (PID=6389) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:18:56.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:18:56.601+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:18:56.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:18:56.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:18:56.660+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:18:56.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:18:56.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:18:56.700+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:18:56.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-25T13:19:26.893+0000] {processor.py:157} INFO - Started process (PID=6391) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:19:26.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:19:26.895+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:19:26.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:19:26.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:19:26.951+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:19:26.951+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:19:26.983+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:19:26.983+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:19:27.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T13:19:57.159+0000] {processor.py:157} INFO - Started process (PID=6393) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:19:57.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:19:57.161+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:19:57.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:19:57.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:19:57.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:19:57.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:19:57.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:19:57.228+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:19:57.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T13:20:27.415+0000] {processor.py:157} INFO - Started process (PID=6395) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:20:27.416+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:20:27.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:20:27.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:20:27.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:20:27.463+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:20:27.463+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:20:27.487+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:20:27.487+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:20:27.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:20:57.562+0000] {processor.py:157} INFO - Started process (PID=6397) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:20:57.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:20:57.563+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:20:57.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:20:57.601+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:20:57.660+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:20:57.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:20:57.721+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:20:57.721+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:20:57.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.257 seconds
[2024-10-25T13:21:27.929+0000] {processor.py:157} INFO - Started process (PID=6399) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:21:27.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:21:27.932+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:21:27.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:21:27.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:21:27.973+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:21:27.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:21:27.998+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:21:27.998+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:21:28.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T13:21:58.091+0000] {processor.py:157} INFO - Started process (PID=6401) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:21:58.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:21:58.092+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:21:58.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:21:58.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:21:58.138+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:21:58.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:21:58.167+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:21:58.166+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:21:58.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T13:22:28.340+0000] {processor.py:157} INFO - Started process (PID=6403) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:22:28.342+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:22:28.342+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:22:28.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:22:28.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:22:28.384+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:22:28.384+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:22:28.412+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:22:28.412+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:22:28.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T13:22:58.594+0000] {processor.py:157} INFO - Started process (PID=6405) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:22:58.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:22:58.595+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:22:58.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:22:58.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:22:58.638+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:22:58.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:22:58.663+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:22:58.663+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:22:58.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:23:28.751+0000] {processor.py:157} INFO - Started process (PID=6407) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:23:28.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:23:28.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:23:28.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:23:28.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:23:28.801+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:23:28.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:23:28.832+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:23:28.831+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:23:28.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T13:23:58.950+0000] {processor.py:157} INFO - Started process (PID=6409) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:23:58.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:23:58.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:23:58.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:23:58.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:23:59.004+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:23:59.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:23:59.034+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:23:59.034+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:23:59.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T13:24:29.209+0000] {processor.py:157} INFO - Started process (PID=6411) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:24:29.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:24:29.211+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:24:29.211+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:24:29.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:24:29.251+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:24:29.251+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:24:29.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:24:29.277+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:24:29.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T13:24:59.459+0000] {processor.py:157} INFO - Started process (PID=6413) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:24:59.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:24:59.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:24:59.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:24:59.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:24:59.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:24:59.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:24:59.534+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:24:59.534+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:24:59.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T13:25:29.603+0000] {processor.py:157} INFO - Started process (PID=6415) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:25:29.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:25:29.604+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:25:29.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:25:29.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:25:29.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:25:29.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:25:29.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:25:29.678+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:25:29.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T13:25:59.814+0000] {processor.py:157} INFO - Started process (PID=6417) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:25:59.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:25:59.817+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:25:59.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:25:59.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:25:59.862+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:25:59.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:25:59.888+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:25:59.887+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:25:59.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T13:26:30.061+0000] {processor.py:157} INFO - Started process (PID=6419) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:26:30.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:26:30.066+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:26:30.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:26:30.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:26:30.184+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:26:30.183+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:26:30.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:26:30.249+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:26:30.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.221 seconds
[2024-10-25T13:27:00.488+0000] {processor.py:157} INFO - Started process (PID=6421) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:27:00.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:27:00.497+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:27:00.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:27:00.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:27:00.682+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:27:00.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:27:00.742+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:27:00.742+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:27:00.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.339 seconds
[2024-10-25T13:27:30.938+0000] {processor.py:157} INFO - Started process (PID=6423) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:27:30.939+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:27:30.940+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:27:30.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:27:30.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:27:30.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:27:30.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:27:31.007+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:27:31.007+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:27:31.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T13:28:01.181+0000] {processor.py:157} INFO - Started process (PID=6425) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:28:01.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:28:01.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:28:01.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:28:01.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:28:01.236+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:28:01.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:28:01.259+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:28:01.259+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:28:01.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T13:28:31.422+0000] {processor.py:157} INFO - Started process (PID=6427) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:28:31.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:28:31.424+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:28:31.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:28:31.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:28:31.466+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:28:31.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:28:31.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:28:31.499+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:28:31.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T13:29:01.681+0000] {processor.py:157} INFO - Started process (PID=6429) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:29:01.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:29:01.683+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:29:01.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:29:01.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:29:01.723+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:29:01.723+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:29:01.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:29:01.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:29:01.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T13:29:31.928+0000] {processor.py:157} INFO - Started process (PID=6431) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:29:31.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:29:31.929+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:29:31.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:29:31.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:29:31.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:29:31.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:29:32.003+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:29:32.003+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:29:32.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T13:30:02.094+0000] {processor.py:157} INFO - Started process (PID=6433) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:30:02.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:30:02.096+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:30:02.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:30:02.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:30:02.151+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:30:02.150+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:30:02.189+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:30:02.189+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:30:02.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T13:30:32.366+0000] {processor.py:157} INFO - Started process (PID=6435) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:30:32.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:30:32.368+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:30:32.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:30:32.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:30:32.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:30:32.417+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:30:32.449+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:30:32.449+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:30:32.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T13:31:02.512+0000] {processor.py:157} INFO - Started process (PID=6437) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:31:02.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:31:02.514+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:31:02.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:31:02.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:31:02.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:31:02.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:31:02.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:31:02.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:31:02.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T13:31:32.756+0000] {processor.py:157} INFO - Started process (PID=6439) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:31:32.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:31:32.758+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:31:32.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:31:32.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:31:32.800+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:31:32.800+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:31:32.827+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:31:32.827+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:31:32.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T13:32:03.000+0000] {processor.py:157} INFO - Started process (PID=6441) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:32:03.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:32:03.003+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:32:03.003+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:32:03.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:32:03.053+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:32:03.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:32:03.085+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:32:03.085+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:32:03.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T13:32:33.151+0000] {processor.py:157} INFO - Started process (PID=6443) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:32:33.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:32:33.153+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:32:33.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:32:33.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:32:33.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:32:33.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:32:33.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:32:33.219+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:32:33.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T13:33:03.391+0000] {processor.py:157} INFO - Started process (PID=6445) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:33:03.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:33:03.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:33:03.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:33:03.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:33:03.439+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:33:03.439+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:33:03.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:33:03.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:33:03.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T13:33:33.539+0000] {processor.py:157} INFO - Started process (PID=6447) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:33:33.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:33:33.542+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:33:33.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:33:33.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:33:33.592+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:33:33.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:33:33.627+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:33:33.627+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:33:33.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T13:34:03.797+0000] {processor.py:157} INFO - Started process (PID=6449) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:34:03.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:34:03.798+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:34:03.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:34:03.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:34:03.842+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:34:03.842+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:34:03.870+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:34:03.869+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:34:03.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T13:34:33.941+0000] {processor.py:157} INFO - Started process (PID=6451) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:34:33.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:34:33.954+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:34:33.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:34:33.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:34:34.001+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:34:34.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:34:34.029+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:34:34.029+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:34:34.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-25T13:35:04.149+0000] {processor.py:157} INFO - Started process (PID=6453) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:35:04.150+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:35:04.151+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:35:04.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:35:04.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:35:04.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:35:04.193+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:35:04.222+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:35:04.221+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:35:04.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:35:34.304+0000] {processor.py:157} INFO - Started process (PID=6455) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:35:34.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:35:34.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:35:34.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:35:34.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:35:34.349+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:35:34.349+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:35:34.375+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:35:34.375+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:35:34.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:36:04.503+0000] {processor.py:157} INFO - Started process (PID=6457) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:36:04.503+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:36:04.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:36:04.504+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:36:04.517+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:36:04.547+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:36:04.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:36:04.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:36:04.574+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:36:04.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T13:36:34.653+0000] {processor.py:157} INFO - Started process (PID=6459) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:36:34.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:36:34.655+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:36:34.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:36:34.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:36:34.702+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:36:34.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:36:34.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:36:34.734+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:36:34.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T13:37:04.914+0000] {processor.py:157} INFO - Started process (PID=6461) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:37:04.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:37:04.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:37:04.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:37:04.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:37:04.966+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:37:04.966+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:37:04.993+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:37:04.993+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:37:05.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T13:37:35.239+0000] {processor.py:157} INFO - Started process (PID=6463) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:37:35.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:37:35.241+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:37:35.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:37:35.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:37:35.289+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:37:35.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:37:35.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:37:35.321+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:37:35.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-25T13:38:05.510+0000] {processor.py:157} INFO - Started process (PID=6465) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:38:05.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:38:05.512+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:38:05.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:38:05.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:38:05.562+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:38:05.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:38:05.598+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:38:05.598+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:38:05.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T13:38:35.785+0000] {processor.py:157} INFO - Started process (PID=6467) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:38:35.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:38:35.787+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:38:35.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:38:35.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:38:35.846+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:38:35.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:38:35.879+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:38:35.879+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:38:35.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T13:39:06.055+0000] {processor.py:157} INFO - Started process (PID=6469) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:39:06.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:39:06.057+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:39:06.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:39:06.071+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:39:06.104+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:39:06.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:39:06.131+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:39:06.131+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:39:06.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T13:39:36.311+0000] {processor.py:157} INFO - Started process (PID=6471) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:39:36.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:39:36.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:39:36.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:39:36.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:39:36.356+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:39:36.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:39:36.381+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:39:36.381+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:39:36.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T13:40:06.565+0000] {processor.py:157} INFO - Started process (PID=6473) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:40:06.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:40:06.566+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:40:06.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:40:06.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:40:06.619+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:40:06.619+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:40:06.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:40:06.649+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:40:06.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T13:40:36.716+0000] {processor.py:157} INFO - Started process (PID=6475) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:40:36.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:40:36.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:40:36.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:40:36.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:40:36.765+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:40:36.765+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:40:36.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:40:36.796+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:40:36.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T13:41:06.940+0000] {processor.py:157} INFO - Started process (PID=6477) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:41:06.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:41:06.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:41:06.941+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:41:06.956+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:41:06.997+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:41:06.995+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:41:07.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:41:07.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:41:07.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T13:41:37.098+0000] {processor.py:157} INFO - Started process (PID=6479) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:41:37.099+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:41:37.100+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:41:37.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:41:37.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:41:37.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:41:37.147+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:41:37.180+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:41:37.180+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:41:37.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T13:42:07.357+0000] {processor.py:157} INFO - Started process (PID=6481) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:42:07.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:42:07.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:42:07.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:42:07.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:42:07.443+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:42:07.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:42:07.472+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:42:07.472+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:42:07.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-25T13:42:37.517+0000] {processor.py:157} INFO - Started process (PID=6483) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:42:37.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:42:37.519+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:42:37.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:42:37.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:42:37.575+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:42:37.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:42:37.608+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:42:37.608+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:42:37.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T13:43:07.781+0000] {processor.py:157} INFO - Started process (PID=6485) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:43:07.782+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:43:07.782+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:43:07.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:43:07.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:43:07.828+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:43:07.828+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:43:07.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:43:07.856+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:43:07.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T13:43:37.992+0000] {processor.py:157} INFO - Started process (PID=6487) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:43:37.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:43:37.994+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:43:37.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:43:38.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:43:38.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:43:38.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:43:38.066+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:43:38.066+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:43:38.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T13:44:08.239+0000] {processor.py:157} INFO - Started process (PID=6489) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:44:08.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:44:08.241+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:44:08.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:44:08.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:44:08.284+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:44:08.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:44:08.309+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:44:08.309+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:44:08.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T13:44:38.484+0000] {processor.py:157} INFO - Started process (PID=6491) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:44:38.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:44:38.486+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:44:38.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:44:38.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:44:38.527+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:44:38.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:44:38.552+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:44:38.552+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:44:38.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T13:45:08.649+0000] {processor.py:157} INFO - Started process (PID=6493) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:45:08.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:45:08.651+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:45:08.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:45:08.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:45:08.702+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:45:08.701+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:45:08.736+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:45:08.736+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:45:08.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T13:45:38.908+0000] {processor.py:157} INFO - Started process (PID=6495) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:45:38.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:45:38.913+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:45:38.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:45:38.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:45:38.960+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:45:38.960+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:45:38.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:45:38.986+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:45:39.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T13:46:09.167+0000] {processor.py:157} INFO - Started process (PID=6497) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:46:09.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:46:09.169+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:46:09.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:46:09.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:46:09.215+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:46:09.215+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:46:09.242+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:46:09.242+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:46:09.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T13:46:39.321+0000] {processor.py:157} INFO - Started process (PID=6499) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:46:39.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:46:39.323+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:46:39.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:46:39.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:46:39.365+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:46:39.365+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:46:39.393+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:46:39.393+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:46:39.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T13:47:09.569+0000] {processor.py:157} INFO - Started process (PID=6501) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:47:09.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:47:09.570+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:47:09.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:47:09.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:47:09.614+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:47:09.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:47:09.640+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:47:09.639+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:47:09.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:47:39.720+0000] {processor.py:157} INFO - Started process (PID=6503) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:47:39.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:47:39.722+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:47:39.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:47:39.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:47:39.767+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:47:39.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:47:39.791+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:47:39.791+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:47:39.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T13:48:09.964+0000] {processor.py:157} INFO - Started process (PID=6505) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:48:09.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:48:09.966+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:48:09.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:48:09.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:48:10.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:48:10.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:48:10.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:48:10.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:48:10.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T13:48:40.115+0000] {processor.py:157} INFO - Started process (PID=6507) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:48:40.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:48:40.116+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:48:40.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:48:40.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:48:40.162+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:48:40.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:48:40.188+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:48:40.188+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:48:40.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T13:49:10.326+0000] {processor.py:157} INFO - Started process (PID=6509) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:49:10.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:49:10.327+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:49:10.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:49:10.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:49:10.371+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:49:10.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:49:10.396+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:49:10.396+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:49:10.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T13:49:40.481+0000] {processor.py:157} INFO - Started process (PID=6511) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:49:40.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:49:40.483+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:49:40.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:49:40.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:49:40.527+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:49:40.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:49:40.554+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:49:40.554+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:49:40.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:50:10.743+0000] {processor.py:157} INFO - Started process (PID=6513) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:50:10.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:50:10.744+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:50:10.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:50:10.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:50:10.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:50:10.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:50:10.815+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:50:10.815+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:50:10.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T13:50:40.893+0000] {processor.py:157} INFO - Started process (PID=6515) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:50:40.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:50:40.895+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:50:40.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:50:40.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:50:40.936+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:50:40.936+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:50:40.962+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:50:40.962+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:50:40.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T13:51:11.143+0000] {processor.py:157} INFO - Started process (PID=6517) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:51:11.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:51:11.144+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:51:11.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:51:11.156+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:51:11.184+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:51:11.184+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:51:11.208+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:51:11.208+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:51:11.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T13:51:41.300+0000] {processor.py:157} INFO - Started process (PID=6519) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:51:41.301+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:51:41.302+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:51:41.302+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:51:41.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:51:41.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:51:41.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:51:41.371+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:51:41.371+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:51:41.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T13:52:11.487+0000] {processor.py:157} INFO - Started process (PID=6521) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:52:11.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:52:11.488+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:52:11.488+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:52:11.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:52:11.530+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:52:11.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:52:11.555+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:52:11.555+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:52:11.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T13:52:41.742+0000] {processor.py:157} INFO - Started process (PID=6523) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:52:41.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:52:41.744+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:52:41.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:52:41.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:52:41.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:52:41.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:52:41.825+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:52:41.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:52:41.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T13:53:12.000+0000] {processor.py:157} INFO - Started process (PID=6525) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:53:12.001+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:53:12.002+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:53:12.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:53:12.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:53:12.048+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:53:12.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:53:12.078+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:53:12.077+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:53:12.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T13:53:42.249+0000] {processor.py:157} INFO - Started process (PID=6527) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:53:42.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:53:42.253+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:53:42.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:53:42.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:53:42.336+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:53:42.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:53:42.366+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:53:42.366+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:53:42.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.142 seconds
[2024-10-25T13:54:12.545+0000] {processor.py:157} INFO - Started process (PID=6529) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:54:12.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:54:12.547+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:54:12.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:54:12.568+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:54:12.607+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:54:12.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:54:12.638+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:54:12.638+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:54:12.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T13:54:42.817+0000] {processor.py:157} INFO - Started process (PID=6531) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:54:42.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:54:42.830+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:54:42.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:54:42.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:54:42.876+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:54:42.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:54:42.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:54:42.903+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:54:42.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T13:55:12.977+0000] {processor.py:157} INFO - Started process (PID=6533) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:55:12.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:55:12.978+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:55:12.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:55:12.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:55:13.021+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:55:13.020+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:55:13.048+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:55:13.047+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:55:13.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T13:55:43.225+0000] {processor.py:157} INFO - Started process (PID=6535) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:55:43.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:55:43.227+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:55:43.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:55:43.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:55:43.266+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:55:43.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:55:43.290+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:55:43.290+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:55:43.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T13:56:13.372+0000] {processor.py:157} INFO - Started process (PID=6537) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:56:13.373+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:56:13.373+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:56:13.373+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:56:13.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:56:13.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:56:13.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:56:13.442+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:56:13.442+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:56:13.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T13:56:43.624+0000] {processor.py:157} INFO - Started process (PID=6539) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:56:43.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:56:43.626+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:56:43.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:56:43.650+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:56:43.695+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:56:43.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:56:43.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:56:43.747+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:56:43.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.157 seconds
[2024-10-25T13:57:13.942+0000] {processor.py:157} INFO - Started process (PID=6541) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:57:13.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:57:13.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:57:13.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:57:13.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:57:13.994+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:57:13.994+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:57:14.021+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:57:14.021+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:57:14.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T13:57:44.093+0000] {processor.py:157} INFO - Started process (PID=6543) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:57:44.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:57:44.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:57:44.105+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:57:44.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:57:44.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:57:44.147+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:57:44.174+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:57:44.174+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:57:44.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T13:58:14.294+0000] {processor.py:157} INFO - Started process (PID=6545) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:58:14.295+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:58:14.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:58:14.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:58:14.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:58:14.352+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:58:14.352+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:58:14.382+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:58:14.381+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:58:14.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T13:58:44.455+0000] {processor.py:157} INFO - Started process (PID=6547) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:58:44.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:58:44.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:58:44.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:58:44.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:58:44.509+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:58:44.508+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:58:44.540+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:58:44.539+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:58:44.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T13:59:14.714+0000] {processor.py:157} INFO - Started process (PID=6549) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:59:14.714+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:59:14.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:59:14.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:59:14.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:59:14.760+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:59:14.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:59:14.785+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:59:14.785+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:59:14.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T13:59:44.873+0000] {processor.py:157} INFO - Started process (PID=6551) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:59:44.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T13:59:44.875+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:59:44.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:59:44.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T13:59:44.919+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:59:44.919+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T13:59:44.944+0000] {logging_mixin.py:149} INFO - [2024-10-25T13:59:44.944+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T13:59:44.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T14:00:15.137+0000] {processor.py:157} INFO - Started process (PID=6553) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:00:15.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:00:15.138+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:00:15.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:00:15.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:00:15.180+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:00:15.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:00:15.205+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:00:15.205+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:00:15.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T14:00:45.288+0000] {processor.py:157} INFO - Started process (PID=6555) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:00:45.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:00:45.290+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:00:45.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:00:45.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:00:45.350+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:00:45.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:00:45.385+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:00:45.384+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:00:45.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T14:01:15.556+0000] {processor.py:157} INFO - Started process (PID=6557) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:01:15.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:01:15.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:01:15.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:01:15.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:01:15.614+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:01:15.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:01:15.646+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:01:15.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:01:15.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T14:01:45.834+0000] {processor.py:157} INFO - Started process (PID=6559) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:01:45.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:01:45.836+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:01:45.836+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:01:45.851+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:01:45.884+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:01:45.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:01:45.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:01:45.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:01:45.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T14:02:16.092+0000] {processor.py:157} INFO - Started process (PID=6561) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:02:16.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:02:16.093+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:02:16.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:02:16.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:02:16.136+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:02:16.136+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:02:16.166+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:02:16.166+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:02:16.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:02:46.344+0000] {processor.py:157} INFO - Started process (PID=6563) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:02:46.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:02:46.346+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:02:46.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:02:46.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:02:46.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:02:46.391+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:02:46.422+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:02:46.422+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:02:46.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T14:03:16.601+0000] {processor.py:157} INFO - Started process (PID=6565) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:03:16.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:03:16.603+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:03:16.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:03:16.623+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:03:16.655+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:03:16.654+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:03:16.682+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:03:16.682+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:03:16.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T14:03:46.759+0000] {processor.py:157} INFO - Started process (PID=6567) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:03:46.770+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:03:46.771+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:03:46.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:03:46.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:03:46.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:03:46.812+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:03:46.842+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:03:46.842+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:03:46.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:04:16.972+0000] {processor.py:157} INFO - Started process (PID=6569) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:04:16.974+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:04:16.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:04:16.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:04:17.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:04:17.043+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:04:17.042+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:04:17.073+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:04:17.072+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:04:17.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-25T14:04:47.131+0000] {processor.py:157} INFO - Started process (PID=6571) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:04:47.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:04:47.134+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:04:47.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:04:47.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:04:47.200+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:04:47.200+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:04:47.231+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:04:47.231+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:04:47.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T14:05:17.421+0000] {processor.py:157} INFO - Started process (PID=6573) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:05:17.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:05:17.423+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:05:17.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:05:17.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:05:17.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:05:17.473+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:05:17.508+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:05:17.508+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:05:17.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T14:05:47.574+0000] {processor.py:157} INFO - Started process (PID=6575) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:05:47.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:05:47.587+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:05:47.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:05:47.600+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:05:47.634+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:05:47.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:05:47.663+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:05:47.663+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:05:47.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-25T14:06:17.856+0000] {processor.py:157} INFO - Started process (PID=6577) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:06:17.857+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:06:17.858+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:06:17.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:06:17.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:06:17.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:06:17.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:06:17.929+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:06:17.929+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:06:17.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T14:06:48.007+0000] {processor.py:157} INFO - Started process (PID=6579) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:06:48.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:06:48.009+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:06:48.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:06:48.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:06:48.067+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:06:48.067+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:06:48.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:06:48.106+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:06:48.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T14:07:18.218+0000] {processor.py:157} INFO - Started process (PID=6581) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:07:18.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:07:18.225+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:07:18.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:07:18.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:07:18.309+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:07:18.308+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:07:18.385+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:07:18.385+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:07:18.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.235 seconds
[2024-10-25T14:07:48.614+0000] {processor.py:157} INFO - Started process (PID=6583) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:07:48.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:07:48.616+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:07:48.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:07:48.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:07:48.680+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:07:48.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:07:48.714+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:07:48.714+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:07:48.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-25T14:08:18.884+0000] {processor.py:157} INFO - Started process (PID=6585) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:08:18.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:08:18.886+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:08:18.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:08:18.903+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:08:18.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:08:18.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:08:18.968+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:08:18.968+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:08:18.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T14:08:49.145+0000] {processor.py:157} INFO - Started process (PID=6587) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:08:49.146+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:08:49.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:08:49.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:08:49.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:08:49.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:08:49.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:08:49.230+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:08:49.230+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:08:49.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T14:09:19.295+0000] {processor.py:157} INFO - Started process (PID=6589) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:09:19.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:09:19.297+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:09:19.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:09:19.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:09:19.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:09:19.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:09:19.375+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:09:19.375+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:09:19.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T14:09:49.512+0000] {processor.py:157} INFO - Started process (PID=6591) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:09:49.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:09:49.514+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:09:49.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:09:49.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:09:49.567+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:09:49.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:09:49.600+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:09:49.600+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:09:49.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T14:10:19.783+0000] {processor.py:157} INFO - Started process (PID=6593) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:10:19.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:10:19.786+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:10:19.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:10:19.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:10:19.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:10:19.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:10:19.869+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:10:19.868+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:10:19.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:10:50.044+0000] {processor.py:157} INFO - Started process (PID=6595) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:10:50.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:10:50.046+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:10:50.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:10:50.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:10:50.089+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:10:50.088+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:10:50.118+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:10:50.117+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:10:50.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:11:20.192+0000] {processor.py:157} INFO - Started process (PID=6597) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:11:20.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:11:20.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:11:20.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:11:20.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:11:20.244+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:11:20.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:11:20.272+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:11:20.272+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:11:20.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:11:50.455+0000] {processor.py:157} INFO - Started process (PID=6599) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:11:50.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:11:50.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:11:50.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:11:50.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:11:50.512+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:11:50.512+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:11:50.541+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:11:50.541+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:11:50.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:12:20.606+0000] {processor.py:157} INFO - Started process (PID=6601) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:12:20.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:12:20.612+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:12:20.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:12:20.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:12:20.658+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:12:20.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:12:20.686+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:12:20.686+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:12:20.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T14:12:50.818+0000] {processor.py:157} INFO - Started process (PID=6603) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:12:50.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:12:50.820+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:12:50.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:12:50.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:12:50.869+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:12:50.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:12:50.901+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:12:50.901+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:12:50.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T14:13:20.971+0000] {processor.py:157} INFO - Started process (PID=6605) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:13:20.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:13:20.983+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:13:20.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:13:20.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:13:21.028+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:13:21.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:13:21.056+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:13:21.055+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:13:21.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:13:51.185+0000] {processor.py:157} INFO - Started process (PID=6607) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:13:51.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:13:51.187+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:13:51.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:13:51.200+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:13:51.232+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:13:51.231+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:13:51.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:13:51.260+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:13:51.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T14:14:21.434+0000] {processor.py:157} INFO - Started process (PID=6609) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:14:21.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:14:21.447+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:14:21.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:14:21.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:14:21.489+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:14:21.489+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:14:21.516+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:14:21.516+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:14:21.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:14:51.581+0000] {processor.py:157} INFO - Started process (PID=6611) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:14:51.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:14:51.582+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:14:51.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:14:51.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:14:51.630+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:14:51.630+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:14:51.657+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:14:51.657+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:14:51.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:15:21.809+0000] {processor.py:157} INFO - Started process (PID=6613) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:15:21.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:15:21.822+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:15:21.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:15:21.833+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:15:21.868+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:15:21.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:15:21.899+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:15:21.899+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:15:21.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T14:15:51.957+0000] {processor.py:157} INFO - Started process (PID=6615) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:15:51.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:15:51.958+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:15:51.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:15:51.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:15:52.002+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:15:52.002+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:15:52.032+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:15:52.032+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:15:52.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T14:16:22.200+0000] {processor.py:157} INFO - Started process (PID=6617) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:16:22.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:16:22.201+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:16:22.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:16:22.217+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:16:22.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:16:22.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:16:22.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:16:22.276+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:16:22.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T14:16:52.350+0000] {processor.py:157} INFO - Started process (PID=6619) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:16:52.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:16:52.351+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:16:52.351+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:16:52.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:16:52.397+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:16:52.397+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:16:52.424+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:16:52.423+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:16:52.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:17:22.595+0000] {processor.py:157} INFO - Started process (PID=6621) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:17:22.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:17:22.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:17:22.597+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:17:22.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:17:22.646+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:17:22.646+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:17:22.675+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:17:22.675+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:17:22.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:17:52.748+0000] {processor.py:157} INFO - Started process (PID=6623) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:17:52.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:17:52.749+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:17:52.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:17:52.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:17:52.792+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:17:52.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:17:52.825+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:17:52.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:17:52.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T14:18:22.945+0000] {processor.py:157} INFO - Started process (PID=6625) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:18:22.946+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:18:22.947+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:18:22.947+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:18:22.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:18:22.994+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:18:22.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:18:23.022+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:18:23.022+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:18:23.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:18:53.101+0000] {processor.py:157} INFO - Started process (PID=6627) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:18:53.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:18:53.103+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:18:53.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:18:53.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:18:53.152+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:18:53.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:18:53.185+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:18:53.185+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:18:53.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:19:23.293+0000] {processor.py:157} INFO - Started process (PID=6629) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:19:23.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:19:23.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:19:23.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:19:23.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:19:23.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:19:23.339+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:19:23.366+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:19:23.366+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:19:23.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:19:53.545+0000] {processor.py:157} INFO - Started process (PID=6631) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:19:53.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:19:53.546+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:19:53.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:19:53.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:19:53.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:19:53.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:19:53.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:19:53.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:19:53.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:20:23.699+0000] {processor.py:157} INFO - Started process (PID=6633) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:20:23.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:20:23.712+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:20:23.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:20:23.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:20:23.757+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:20:23.756+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:20:23.784+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:20:23.784+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:20:23.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T14:20:53.897+0000] {processor.py:157} INFO - Started process (PID=6635) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:20:53.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:20:53.898+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:20:53.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:20:53.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:20:53.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:20:53.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:20:53.972+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:20:53.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:20:53.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T14:21:24.145+0000] {processor.py:157} INFO - Started process (PID=6637) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:21:24.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:21:24.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:21:24.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:21:24.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:21:24.190+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:21:24.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:21:24.219+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:21:24.219+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:21:24.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T14:21:54.297+0000] {processor.py:157} INFO - Started process (PID=6639) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:21:54.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:21:54.299+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:21:54.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:21:54.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:21:54.342+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:21:54.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:21:54.371+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:21:54.371+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:21:54.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:22:24.544+0000] {processor.py:157} INFO - Started process (PID=6641) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:22:24.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:22:24.545+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:22:24.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:22:24.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:22:24.592+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:22:24.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:22:24.618+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:22:24.618+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:22:24.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:22:54.693+0000] {processor.py:157} INFO - Started process (PID=6643) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:22:54.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:22:54.694+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:22:54.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:22:54.707+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:22:54.737+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:22:54.737+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:22:54.765+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:22:54.765+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:22:54.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:23:24.936+0000] {processor.py:157} INFO - Started process (PID=6645) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:23:24.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:23:24.938+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:23:24.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:23:24.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:23:24.985+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:23:24.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:23:25.014+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:23:25.014+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:23:25.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:23:55.087+0000] {processor.py:157} INFO - Started process (PID=6647) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:23:55.088+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:23:55.088+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:23:55.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:23:55.103+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:23:55.131+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:23:55.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:23:55.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:23:55.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:23:55.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:24:25.332+0000] {processor.py:157} INFO - Started process (PID=6649) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:24:25.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:24:25.334+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:24:25.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:24:25.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:24:25.384+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:24:25.384+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:24:25.416+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:24:25.416+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:24:25.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:24:55.591+0000] {processor.py:157} INFO - Started process (PID=6651) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:24:55.592+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:24:55.594+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:24:55.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:24:55.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:24:55.639+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:24:55.639+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:24:55.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:24:55.668+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:24:55.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:25:25.988+0000] {processor.py:157} INFO - Started process (PID=6653) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:25:26.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:25:26.019+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:25:26.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:25:26.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:25:26.906+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:25:26.906+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:25:27.139+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:25:27.138+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:25:27.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.331 seconds
[2024-10-25T14:25:57.357+0000] {processor.py:157} INFO - Started process (PID=6655) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:25:57.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:25:57.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:25:57.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:25:57.391+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:25:57.465+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:25:57.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:25:57.658+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:25:57.657+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:25:57.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.421 seconds
[2024-10-25T14:26:27.993+0000] {processor.py:157} INFO - Started process (PID=6657) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:26:27.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:26:27.996+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:26:27.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:26:28.089+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:26:28.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:26:28.196+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:26:28.252+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:26:28.252+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:26:28.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.337 seconds
[2024-10-25T14:26:58.438+0000] {processor.py:157} INFO - Started process (PID=6659) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:26:58.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:26:58.440+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:26:58.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:26:58.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:26:58.495+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:26:58.494+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:26:58.533+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:26:58.532+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:26:58.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T14:27:28.709+0000] {processor.py:157} INFO - Started process (PID=6661) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:27:28.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:27:28.711+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:27:28.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:27:28.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:27:28.758+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:27:28.758+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:27:28.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:27:28.789+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:27:28.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T14:27:58.861+0000] {processor.py:157} INFO - Started process (PID=6663) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:27:58.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:27:58.863+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:27:58.862+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:27:58.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:27:58.909+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:27:58.908+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:27:58.939+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:27:58.939+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:27:58.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T14:28:29.120+0000] {processor.py:157} INFO - Started process (PID=6665) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:28:29.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:28:29.122+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:28:29.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:28:29.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:28:29.168+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:28:29.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:28:29.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:28:29.194+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:28:29.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T14:28:59.366+0000] {processor.py:157} INFO - Started process (PID=6667) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:28:59.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:28:59.368+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:28:59.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:28:59.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:28:59.443+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:28:59.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:28:59.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:28:59.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:28:59.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.139 seconds
[2024-10-25T14:29:29.624+0000] {processor.py:157} INFO - Started process (PID=6669) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:29:29.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:29:29.626+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:29:29.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:29:29.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:29:29.677+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:29:29.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:29:29.708+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:29:29.708+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:29:29.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T14:29:59.878+0000] {processor.py:157} INFO - Started process (PID=6671) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:29:59.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:29:59.879+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:29:59.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:29:59.924+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:30:00.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:30:00.005+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:30:00.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:30:00.064+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:30:00.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.225 seconds
[2024-10-25T14:30:30.261+0000] {processor.py:157} INFO - Started process (PID=6673) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:30:30.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:30:30.263+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:30:30.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:30:30.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:30:30.310+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:30:30.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:30:30.341+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:30:30.341+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:30:30.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:31:00.514+0000] {processor.py:157} INFO - Started process (PID=6675) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:31:00.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:31:00.515+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:31:00.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:31:00.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:31:00.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:31:00.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:31:00.588+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:31:00.588+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:31:00.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:31:30.663+0000] {processor.py:157} INFO - Started process (PID=6677) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:31:30.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:31:30.665+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:31:30.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:31:30.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:31:30.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:31:30.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:31:30.771+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:31:30.771+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:31:30.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-25T14:32:00.868+0000] {processor.py:157} INFO - Started process (PID=6679) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:32:00.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:32:00.870+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:32:00.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:32:00.882+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:32:00.914+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:32:00.914+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:32:00.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:32:00.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:32:00.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T14:32:31.115+0000] {processor.py:157} INFO - Started process (PID=6681) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:32:31.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:32:31.118+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:32:31.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:32:31.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:32:31.164+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:32:31.164+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:32:31.191+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:32:31.191+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:32:31.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:33:01.262+0000] {processor.py:157} INFO - Started process (PID=6683) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:33:01.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:33:01.264+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:33:01.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:33:01.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:33:01.308+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:33:01.308+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:33:01.348+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:33:01.347+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:33:01.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T14:33:31.524+0000] {processor.py:157} INFO - Started process (PID=6685) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:33:31.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:33:31.526+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:33:31.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:33:31.538+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:33:31.567+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:33:31.567+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:33:31.599+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:33:31.599+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:33:31.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:34:01.676+0000] {processor.py:157} INFO - Started process (PID=6687) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:34:01.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:34:01.677+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:34:01.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:34:01.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:34:01.723+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:34:01.722+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:34:01.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:34:01.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:34:01.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:34:31.920+0000] {processor.py:157} INFO - Started process (PID=6689) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:34:31.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:34:31.922+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:34:31.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:34:31.935+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:34:31.968+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:34:31.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:34:31.998+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:34:31.998+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:34:32.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T14:35:02.070+0000] {processor.py:157} INFO - Started process (PID=6691) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:35:02.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:35:02.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:35:02.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:35:02.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:35:02.118+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:35:02.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:35:02.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:35:02.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:35:02.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:35:32.315+0000] {processor.py:157} INFO - Started process (PID=6693) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:35:32.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:35:32.317+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:35:32.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:35:32.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:35:32.362+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:35:32.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:35:32.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:35:32.390+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:35:32.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:36:02.466+0000] {processor.py:157} INFO - Started process (PID=6695) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:36:02.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:36:02.467+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:36:02.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:36:02.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:36:02.514+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:36:02.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:36:02.541+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:36:02.541+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:36:02.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:36:32.662+0000] {processor.py:157} INFO - Started process (PID=6697) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:36:32.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:36:32.664+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:36:32.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:36:32.678+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:36:32.712+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:36:32.712+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:36:32.740+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:36:32.740+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:36:32.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:37:02.913+0000] {processor.py:157} INFO - Started process (PID=6699) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:37:02.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:37:02.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:37:02.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:37:02.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:37:02.957+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:37:02.957+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:37:02.985+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:37:02.985+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:37:03.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T14:37:33.061+0000] {processor.py:157} INFO - Started process (PID=6701) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:37:33.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:37:33.063+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:37:33.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:37:33.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:37:33.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:37:33.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:37:33.133+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:37:33.133+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:37:33.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T14:38:03.308+0000] {processor.py:157} INFO - Started process (PID=6703) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:38:03.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:38:03.310+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:38:03.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:38:03.328+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:38:03.361+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:38:03.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:38:03.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:38:03.390+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:38:03.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T14:38:33.454+0000] {processor.py:157} INFO - Started process (PID=6705) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:38:33.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:38:33.456+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:38:33.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:38:33.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:38:33.500+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:38:33.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:38:33.529+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:38:33.529+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:38:33.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T14:39:03.660+0000] {processor.py:157} INFO - Started process (PID=6707) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:39:03.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:39:03.661+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:39:03.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:39:03.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:39:03.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:39:03.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:39:03.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:39:03.735+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:39:03.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:39:33.910+0000] {processor.py:157} INFO - Started process (PID=6709) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:39:33.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:39:33.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:39:33.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:39:33.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:39:33.960+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:39:33.960+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:39:33.988+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:39:33.988+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:39:34.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:40:04.174+0000] {processor.py:157} INFO - Started process (PID=6711) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:40:04.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:40:04.176+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:40:04.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:40:04.188+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:40:04.221+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:40:04.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:40:04.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:40:04.249+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:40:04.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T14:40:34.421+0000] {processor.py:157} INFO - Started process (PID=6713) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:40:34.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:40:34.422+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:40:34.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:40:34.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:40:34.466+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:40:34.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:40:34.492+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:40:34.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:40:34.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:41:04.669+0000] {processor.py:157} INFO - Started process (PID=6715) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:41:04.670+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:41:04.671+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:41:04.671+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:41:04.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:41:04.718+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:41:04.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:41:04.747+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:41:04.747+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:41:04.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:41:34.814+0000] {processor.py:157} INFO - Started process (PID=6717) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:41:34.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:41:34.815+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:41:34.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:41:34.829+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:41:34.860+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:41:34.860+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:41:34.886+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:41:34.886+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:41:34.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T14:42:05.084+0000] {processor.py:157} INFO - Started process (PID=6719) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:42:05.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:42:05.086+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:42:05.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:42:05.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:42:05.134+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:42:05.133+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:42:05.164+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:42:05.164+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:42:05.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T14:42:35.333+0000] {processor.py:157} INFO - Started process (PID=6721) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:42:35.334+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:42:35.335+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:42:35.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:42:35.349+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:42:35.381+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:42:35.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:42:35.410+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:42:35.410+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:42:35.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:43:05.588+0000] {processor.py:157} INFO - Started process (PID=6723) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:43:05.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:43:05.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:43:05.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:43:05.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:43:05.635+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:43:05.635+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:43:05.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:43:05.662+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:43:05.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T14:43:35.825+0000] {processor.py:157} INFO - Started process (PID=6725) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:43:35.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:43:35.826+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:43:35.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:43:35.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:43:35.867+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:43:35.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:43:35.895+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:43:35.895+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:43:35.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T14:44:05.973+0000] {processor.py:157} INFO - Started process (PID=6727) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:44:05.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:44:05.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:44:05.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:44:05.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:44:06.025+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:44:06.025+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:44:06.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:44:06.057+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:44:06.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T14:44:36.224+0000] {processor.py:157} INFO - Started process (PID=6729) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:44:36.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:44:36.226+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:44:36.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:44:36.242+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:44:36.275+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:44:36.274+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:44:36.307+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:44:36.307+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:44:36.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T14:45:06.388+0000] {processor.py:157} INFO - Started process (PID=6731) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:45:06.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:45:06.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:45:06.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:45:06.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:45:06.478+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:45:06.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:45:06.540+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:45:06.539+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:45:06.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T14:45:36.724+0000] {processor.py:157} INFO - Started process (PID=6733) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:45:36.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:45:36.726+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:45:36.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:45:36.742+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:45:36.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:45:36.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:45:36.799+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:45:36.799+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:45:36.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T14:46:06.972+0000] {processor.py:157} INFO - Started process (PID=6735) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:46:06.973+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:46:06.974+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:46:06.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:46:06.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:46:07.021+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:46:07.021+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:46:07.052+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:46:07.052+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:46:07.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T14:46:37.119+0000] {processor.py:157} INFO - Started process (PID=6737) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:46:37.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:46:37.120+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:46:37.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:46:37.134+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:46:37.169+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:46:37.169+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:46:37.197+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:46:37.197+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:46:37.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:47:07.369+0000] {processor.py:157} INFO - Started process (PID=6739) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:47:07.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:47:07.371+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:47:07.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:47:07.398+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:47:07.444+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:47:07.444+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:47:07.472+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:47:07.472+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:47:07.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T14:47:37.514+0000] {processor.py:157} INFO - Started process (PID=6741) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:47:37.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:47:37.516+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:47:37.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:47:37.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:47:37.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:47:37.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:47:37.594+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:47:37.594+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:47:37.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T14:48:07.765+0000] {processor.py:157} INFO - Started process (PID=6743) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:48:07.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:48:07.767+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:48:07.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:48:07.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:48:07.814+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:48:07.814+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:48:07.847+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:48:07.847+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:48:07.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T14:48:37.926+0000] {processor.py:157} INFO - Started process (PID=6745) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:48:37.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:48:37.928+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:48:37.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:48:37.949+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:48:37.994+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:48:37.994+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:48:38.020+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:48:38.020+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:48:38.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T14:49:08.127+0000] {processor.py:157} INFO - Started process (PID=6747) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:49:08.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:49:08.128+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:49:08.128+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:49:08.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:49:08.171+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:49:08.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:49:08.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:49:08.199+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:49:08.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T14:49:38.413+0000] {processor.py:157} INFO - Started process (PID=6749) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:49:38.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:49:38.415+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:49:38.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:49:38.432+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:49:38.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:49:38.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:49:38.488+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:49:38.488+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:49:38.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T14:50:08.570+0000] {processor.py:157} INFO - Started process (PID=6751) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:50:08.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:50:08.573+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:50:08.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:50:08.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:50:08.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:50:08.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:50:08.651+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:50:08.650+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:50:08.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T14:50:38.831+0000] {processor.py:157} INFO - Started process (PID=6753) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:50:38.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:50:38.833+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:50:38.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:50:38.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:50:38.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:50:38.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:50:38.910+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:50:38.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:50:38.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T14:51:08.983+0000] {processor.py:157} INFO - Started process (PID=6755) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:51:08.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:51:08.986+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:51:08.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:51:09.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:51:09.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:51:09.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:51:09.062+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:51:09.062+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:51:09.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T14:51:39.178+0000] {processor.py:157} INFO - Started process (PID=6757) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:51:39.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:51:39.179+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:51:39.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:51:39.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:51:39.230+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:51:39.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:51:39.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:51:39.260+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:51:39.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T14:52:09.435+0000] {processor.py:157} INFO - Started process (PID=6759) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:52:09.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:52:09.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:52:09.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:52:09.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:52:09.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:52:09.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:52:09.510+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:52:09.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:52:09.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:52:39.679+0000] {processor.py:157} INFO - Started process (PID=6761) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:52:39.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:52:39.680+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:52:39.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:52:39.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:52:39.721+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:52:39.721+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:52:39.747+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:52:39.747+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:52:39.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T14:53:09.826+0000] {processor.py:157} INFO - Started process (PID=6763) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:53:09.827+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:53:09.828+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:53:09.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:53:09.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:53:09.874+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:53:09.874+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:53:09.902+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:53:09.902+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:53:09.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:53:40.022+0000] {processor.py:157} INFO - Started process (PID=6765) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:53:40.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:53:40.024+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:53:40.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:53:40.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:53:40.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:53:40.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:53:40.102+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:53:40.102+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:53:40.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T14:54:10.283+0000] {processor.py:157} INFO - Started process (PID=6767) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:54:10.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:54:10.285+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:54:10.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:54:10.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:54:10.335+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:54:10.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:54:10.364+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:54:10.364+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:54:10.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T14:54:40.433+0000] {processor.py:157} INFO - Started process (PID=6769) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:54:40.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:54:40.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:54:40.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:54:40.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:54:40.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:54:40.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:54:40.514+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:54:40.513+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:54:40.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T14:55:10.691+0000] {processor.py:157} INFO - Started process (PID=6771) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:55:10.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:55:10.693+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:55:10.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:55:10.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:55:10.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:55:10.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:55:10.764+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:55:10.764+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:55:10.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:55:40.842+0000] {processor.py:157} INFO - Started process (PID=6773) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:55:40.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:55:40.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:55:40.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:55:40.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:55:40.918+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:55:40.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:55:40.964+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:55:40.963+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:55:40.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.158 seconds
[2024-10-25T14:56:11.157+0000] {processor.py:157} INFO - Started process (PID=6775) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:56:11.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:56:11.177+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:56:11.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:56:11.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:56:11.225+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:56:11.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:56:11.258+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:56:11.258+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:56:11.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-25T14:56:41.304+0000] {processor.py:157} INFO - Started process (PID=6777) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:56:41.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:56:41.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:56:41.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:56:41.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:56:41.350+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:56:41.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:56:41.379+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:56:41.378+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:56:41.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T14:57:11.551+0000] {processor.py:157} INFO - Started process (PID=6779) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:57:11.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:57:11.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:57:11.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:57:11.568+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:57:11.598+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:57:11.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:57:11.627+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:57:11.627+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:57:11.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T14:57:41.794+0000] {processor.py:157} INFO - Started process (PID=6781) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:57:41.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:57:41.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:57:41.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:57:41.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:57:41.839+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:57:41.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:57:41.869+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:57:41.869+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:57:41.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T14:58:12.038+0000] {processor.py:157} INFO - Started process (PID=6783) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:58:12.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:58:12.050+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:58:12.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:58:12.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:58:12.090+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:58:12.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:58:12.116+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:58:12.116+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:58:12.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T14:58:42.186+0000] {processor.py:157} INFO - Started process (PID=6785) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:58:42.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:58:42.187+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:58:42.187+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:58:42.201+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:58:42.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:58:42.229+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:58:42.254+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:58:42.254+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:58:42.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T14:59:12.425+0000] {processor.py:157} INFO - Started process (PID=6787) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:59:12.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:59:12.428+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:59:12.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:59:12.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:59:12.478+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:59:12.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:59:12.508+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:59:12.507+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:59:12.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T14:59:42.574+0000] {processor.py:157} INFO - Started process (PID=6789) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:59:42.575+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T14:59:42.575+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:59:42.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:59:42.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T14:59:42.618+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:59:42.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T14:59:42.650+0000] {logging_mixin.py:149} INFO - [2024-10-25T14:59:42.650+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T14:59:42.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T15:00:13.651+0000] {processor.py:157} INFO - Started process (PID=6791) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:00:13.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:00:13.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:00:13.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:00:13.883+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:00:14.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:00:14.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:00:14.694+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:00:14.692+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:00:15.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.477 seconds
[2024-10-25T15:00:45.215+0000] {processor.py:157} INFO - Started process (PID=6793) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:00:45.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:00:45.216+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:00:45.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:00:45.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:00:45.294+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:00:45.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:00:45.331+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:00:45.330+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:00:45.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-25T15:01:15.482+0000] {processor.py:157} INFO - Started process (PID=6795) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:01:15.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:01:15.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:01:15.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:01:15.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:01:15.532+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:01:15.532+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:01:15.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:01:15.560+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:01:15.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T15:01:45.737+0000] {processor.py:157} INFO - Started process (PID=6797) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:01:45.738+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:01:45.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:01:45.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:01:45.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:01:45.789+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:01:45.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:01:45.817+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:01:45.817+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:01:45.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:02:15.881+0000] {processor.py:157} INFO - Started process (PID=6799) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:02:15.883+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:02:15.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:02:15.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:02:15.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:02:15.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:02:15.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:02:15.965+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:02:15.964+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:02:15.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T15:02:46.159+0000] {processor.py:157} INFO - Started process (PID=6801) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:02:46.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:02:46.161+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:02:46.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:02:46.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:02:46.226+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:02:46.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:02:46.257+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:02:46.257+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:02:46.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-25T15:03:16.336+0000] {processor.py:157} INFO - Started process (PID=6803) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:03:16.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:03:16.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:03:16.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:03:16.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:03:16.382+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:03:16.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:03:16.407+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:03:16.407+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:03:16.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:03:46.581+0000] {processor.py:157} INFO - Started process (PID=6805) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:03:46.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:03:46.582+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:03:46.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:03:46.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:03:46.623+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:03:46.623+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:03:46.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:03:46.649+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:03:46.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:04:16.743+0000] {processor.py:157} INFO - Started process (PID=6807) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:04:16.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:04:16.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:04:16.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:04:16.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:04:16.797+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:04:16.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:04:16.830+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:04:16.830+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:04:16.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T15:04:46.935+0000] {processor.py:157} INFO - Started process (PID=6809) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:04:46.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:04:46.936+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:04:46.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:04:46.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:04:46.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:04:46.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:04:47.003+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:04:47.003+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:04:47.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T15:05:17.188+0000] {processor.py:157} INFO - Started process (PID=6811) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:05:17.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:05:17.190+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:05:17.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:05:17.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:05:17.231+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:05:17.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:05:17.257+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:05:17.257+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:05:17.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:05:47.430+0000] {processor.py:157} INFO - Started process (PID=6813) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:05:47.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:05:47.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:05:47.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:05:47.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:05:47.479+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:05:47.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:05:47.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:05:47.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:05:47.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T15:06:17.588+0000] {processor.py:157} INFO - Started process (PID=6815) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:06:17.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:06:17.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:06:17.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:06:17.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:06:17.639+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:06:17.639+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:06:17.665+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:06:17.664+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:06:17.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T15:06:47.782+0000] {processor.py:157} INFO - Started process (PID=6817) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:06:47.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:06:47.783+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:06:47.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:06:47.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:06:47.827+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:06:47.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:06:47.854+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:06:47.854+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:06:47.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T15:07:18.032+0000] {processor.py:157} INFO - Started process (PID=6819) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:07:18.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:07:18.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:07:18.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:07:18.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:07:18.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:07:18.072+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:07:18.097+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:07:18.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:07:18.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T15:07:48.268+0000] {processor.py:157} INFO - Started process (PID=6821) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:07:48.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:07:48.270+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:07:48.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:07:48.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:07:48.311+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:07:48.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:07:48.334+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:07:48.334+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:07:48.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T15:08:18.506+0000] {processor.py:157} INFO - Started process (PID=6823) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:08:18.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:08:18.508+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:08:18.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:08:18.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:08:18.557+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:08:18.557+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:08:18.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:08:18.590+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:08:18.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T15:08:48.663+0000] {processor.py:157} INFO - Started process (PID=6825) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:08:48.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:08:48.664+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:08:48.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:08:48.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:08:48.704+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:08:48.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:08:48.730+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:08:48.730+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:08:48.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T15:09:18.865+0000] {processor.py:157} INFO - Started process (PID=6827) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:09:18.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:09:18.866+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:09:18.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:09:18.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:09:18.909+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:09:18.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:09:18.935+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:09:18.934+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:09:18.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T15:09:49.024+0000] {processor.py:157} INFO - Started process (PID=6829) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:09:49.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:09:49.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:09:49.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:09:49.040+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:09:49.073+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:09:49.073+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:09:49.098+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:09:49.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:09:49.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T15:10:19.295+0000] {processor.py:157} INFO - Started process (PID=6831) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:10:19.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:10:19.307+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:10:19.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:10:19.318+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:10:19.344+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:10:19.344+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:10:19.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:10:19.367+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:10:19.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T15:10:49.546+0000] {processor.py:157} INFO - Started process (PID=6833) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:10:49.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:10:49.549+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:10:49.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:10:49.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:10:49.648+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:10:49.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:10:49.681+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:10:49.681+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:10:49.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-25T15:11:19.841+0000] {processor.py:157} INFO - Started process (PID=6835) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:11:19.842+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:11:19.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:11:19.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:11:19.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:11:19.889+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:11:19.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:11:19.920+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:11:19.920+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:11:19.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T15:11:49.998+0000] {processor.py:157} INFO - Started process (PID=6837) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:11:49.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:11:49.999+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:11:49.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:11:50.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:11:50.042+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:11:50.042+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:11:50.066+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:11:50.066+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:11:50.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T15:12:20.192+0000] {processor.py:157} INFO - Started process (PID=6839) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:12:20.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:12:20.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:12:20.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:12:20.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:12:20.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:12:20.238+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:12:20.263+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:12:20.263+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:12:20.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:12:50.356+0000] {processor.py:157} INFO - Started process (PID=6841) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:12:50.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:12:50.358+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:12:50.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:12:50.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:12:50.414+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:12:50.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:12:50.443+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:12:50.442+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:12:50.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T15:13:20.546+0000] {processor.py:157} INFO - Started process (PID=6843) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:13:20.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:13:20.548+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:13:20.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:13:20.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:13:20.593+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:13:20.593+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:13:20.619+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:13:20.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:13:20.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T15:13:50.715+0000] {processor.py:157} INFO - Started process (PID=6845) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:13:50.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:13:50.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:13:50.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:13:50.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:13:50.761+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:13:50.761+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:13:50.792+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:13:50.792+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:13:50.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T15:14:20.904+0000] {processor.py:157} INFO - Started process (PID=6847) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:14:20.905+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:14:20.905+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:14:20.905+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:14:20.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:14:20.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:14:20.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:14:20.978+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:14:20.978+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:14:20.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T15:14:51.069+0000] {processor.py:157} INFO - Started process (PID=6849) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:14:51.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:14:51.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:14:51.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:14:51.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:14:51.142+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:14:51.142+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:14:51.172+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:14:51.172+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:14:51.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-25T15:15:21.260+0000] {processor.py:157} INFO - Started process (PID=6851) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:15:21.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:15:21.267+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:15:21.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:15:21.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:15:21.325+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:15:21.325+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:15:21.362+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:15:21.362+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:15:21.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-25T15:15:51.542+0000] {processor.py:157} INFO - Started process (PID=6853) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:15:51.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:15:51.544+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:15:51.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:15:51.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:15:51.596+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:15:51.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:15:51.630+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:15:51.630+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:15:51.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T15:16:21.697+0000] {processor.py:157} INFO - Started process (PID=6855) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:16:21.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:16:21.699+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:16:21.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:16:21.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:16:21.746+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:16:21.746+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:16:21.775+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:16:21.775+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:16:21.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T15:16:51.918+0000] {processor.py:157} INFO - Started process (PID=6857) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:16:51.920+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:16:51.920+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:16:51.920+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:16:51.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:16:51.977+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:16:51.977+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:16:52.010+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:16:52.010+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:16:52.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T15:17:22.070+0000] {processor.py:157} INFO - Started process (PID=6859) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:17:22.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:17:22.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:17:22.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:17:22.089+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:17:22.118+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:17:22.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:17:22.144+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:17:22.144+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:17:22.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T15:17:52.314+0000] {processor.py:157} INFO - Started process (PID=6861) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:17:52.315+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:17:52.316+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:17:52.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:17:52.330+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:17:52.359+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:17:52.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:17:52.387+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:17:52.387+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:17:52.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T15:18:22.572+0000] {processor.py:157} INFO - Started process (PID=6863) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:18:22.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:18:22.573+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:18:22.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:18:22.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:18:22.615+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:18:22.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:18:22.641+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:18:22.641+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:18:22.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T15:18:52.704+0000] {processor.py:157} INFO - Started process (PID=6865) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:18:52.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:18:52.706+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:18:52.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:18:52.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:18:52.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:18:52.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:18:52.779+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:18:52.779+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:18:52.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T15:19:22.951+0000] {processor.py:157} INFO - Started process (PID=6867) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:19:22.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:19:22.958+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:19:22.957+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:19:22.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:19:23.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:19:23.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:19:23.124+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:19:23.123+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:19:23.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.210 seconds
[2024-10-25T15:19:53.306+0000] {processor.py:157} INFO - Started process (PID=6869) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:19:53.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:19:53.308+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:19:53.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:19:53.321+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:19:53.354+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:19:53.353+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:19:53.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:19:53.391+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:19:53.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:20:23.572+0000] {processor.py:157} INFO - Started process (PID=6871) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:20:23.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:20:23.585+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:20:23.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:20:23.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:20:23.639+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:20:23.639+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:20:23.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:20:23.668+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:20:23.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T15:20:53.825+0000] {processor.py:157} INFO - Started process (PID=6873) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:20:53.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:20:53.826+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:20:53.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:20:53.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:20:53.870+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:20:53.870+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:20:53.898+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:20:53.898+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:20:53.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T15:21:23.976+0000] {processor.py:157} INFO - Started process (PID=6875) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:21:23.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:21:23.988+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:21:23.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:21:24.009+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:21:24.146+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:21:24.146+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:21:24.208+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:21:24.208+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:21:24.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.272 seconds
[2024-10-25T15:21:54.394+0000] {processor.py:157} INFO - Started process (PID=6877) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:21:54.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:21:54.396+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:21:54.395+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:21:54.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:21:54.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:21:54.447+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:21:54.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:21:54.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:21:54.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T15:22:24.672+0000] {processor.py:157} INFO - Started process (PID=6879) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:22:24.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:22:24.674+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:22:24.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:22:24.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:22:24.724+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:22:24.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:22:24.783+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:22:24.783+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:22:24.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.147 seconds
[2024-10-25T15:22:54.968+0000] {processor.py:157} INFO - Started process (PID=6881) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:22:54.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:22:54.972+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:22:54.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:22:55.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:22:55.046+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:22:55.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:22:55.080+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:22:55.080+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:22:55.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-25T15:23:25.246+0000] {processor.py:157} INFO - Started process (PID=6883) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:23:25.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:23:25.248+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:23:25.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:23:25.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:23:25.311+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:23:25.311+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:23:25.355+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:23:25.355+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:23:25.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-25T15:23:55.498+0000] {processor.py:157} INFO - Started process (PID=6886) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:23:55.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:23:55.500+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:23:55.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:23:55.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:23:55.546+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:23:55.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:23:55.575+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:23:55.574+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:23:55.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T15:24:25.647+0000] {processor.py:157} INFO - Started process (PID=6887) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:24:25.648+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:24:25.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:24:25.649+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:24:25.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:24:25.695+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:24:25.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:24:25.720+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:24:25.720+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:24:25.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T15:24:55.892+0000] {processor.py:157} INFO - Started process (PID=6889) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:24:55.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:24:55.893+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:24:55.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:24:55.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:24:55.945+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:24:55.945+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:24:55.973+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:24:55.973+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:24:55.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T15:25:26.157+0000] {processor.py:157} INFO - Started process (PID=6891) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:25:26.158+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:25:26.159+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:25:26.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:25:26.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:25:26.203+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:25:26.203+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:25:26.231+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:25:26.231+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:25:26.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T15:25:56.430+0000] {processor.py:157} INFO - Started process (PID=6893) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:25:56.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:25:56.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:25:56.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:25:56.450+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:25:56.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:25:56.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:25:56.515+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:25:56.514+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:25:56.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:26:26.589+0000] {processor.py:157} INFO - Started process (PID=6895) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:26:26.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:26:26.591+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:26:26.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:26:26.611+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:26:26.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:26:26.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:26:26.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:26:26.679+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:26:26.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T15:26:56.795+0000] {processor.py:157} INFO - Started process (PID=6897) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:26:56.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:26:56.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:26:56.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:26:56.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:26:56.844+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:26:56.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:26:56.910+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:26:56.909+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:26:56.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-25T15:27:26.967+0000] {processor.py:157} INFO - Started process (PID=6899) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:27:26.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:27:26.970+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:27:26.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:27:26.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:27:27.035+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:27:27.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:27:27.081+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:27:27.080+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:27:27.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.154 seconds
[2024-10-25T15:27:57.288+0000] {processor.py:157} INFO - Started process (PID=6901) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:27:57.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:27:57.290+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:27:57.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:27:57.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:27:57.351+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:27:57.351+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:27:57.377+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:27:57.377+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:27:57.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T15:28:27.449+0000] {processor.py:157} INFO - Started process (PID=6903) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:28:27.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:28:27.451+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:28:27.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:28:27.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:28:27.495+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:28:27.495+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:28:27.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:28:27.523+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:28:27.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T15:28:57.706+0000] {processor.py:157} INFO - Started process (PID=6905) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:28:57.707+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:28:57.708+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:28:57.708+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:28:57.724+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:28:57.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:28:57.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:28:57.780+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:28:57.780+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:28:57.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T15:29:27.862+0000] {processor.py:157} INFO - Started process (PID=6907) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:29:27.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:29:27.864+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:29:27.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:29:27.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:29:27.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:29:27.915+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:29:27.944+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:29:27.944+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:29:27.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T15:29:58.072+0000] {processor.py:157} INFO - Started process (PID=6909) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:29:58.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:29:58.074+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:29:58.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:29:58.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:29:58.116+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:29:58.116+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:29:58.140+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:29:58.140+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:29:58.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:30:28.236+0000] {processor.py:157} INFO - Started process (PID=6911) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:30:28.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:30:28.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:30:28.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:30:28.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:30:28.281+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:30:28.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:30:28.305+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:30:28.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:30:28.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T15:30:58.477+0000] {processor.py:157} INFO - Started process (PID=6913) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:30:58.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:30:58.479+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:30:58.479+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:30:58.494+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:30:58.524+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:30:58.524+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:30:58.554+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:30:58.554+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:30:58.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T15:31:28.625+0000] {processor.py:157} INFO - Started process (PID=6915) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:31:28.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:31:28.626+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:31:28.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:31:28.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:31:28.674+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:31:28.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:31:28.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:31:28.706+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:31:28.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T15:31:58.881+0000] {processor.py:157} INFO - Started process (PID=6917) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:31:58.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:31:58.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:31:58.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:31:58.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:31:58.935+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:31:58.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:31:58.965+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:31:58.965+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:31:58.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T15:32:29.036+0000] {processor.py:157} INFO - Started process (PID=6919) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:32:29.037+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:32:29.037+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:32:29.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:32:29.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:32:29.079+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:32:29.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:32:29.108+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:32:29.108+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:32:29.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T15:32:59.249+0000] {processor.py:157} INFO - Started process (PID=6921) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:32:59.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:32:59.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:32:59.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:32:59.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:32:59.294+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:32:59.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:32:59.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:32:59.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:32:59.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T15:33:29.400+0000] {processor.py:157} INFO - Started process (PID=6923) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:33:29.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:33:29.402+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:33:29.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:33:29.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:33:29.452+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:33:29.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:33:29.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:33:29.483+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:33:29.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:33:59.651+0000] {processor.py:157} INFO - Started process (PID=6925) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:33:59.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:33:59.664+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:33:59.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:33:59.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:33:59.706+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:33:59.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:33:59.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:33:59.734+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:33:59.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:34:29.807+0000] {processor.py:157} INFO - Started process (PID=6927) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:34:29.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:34:29.808+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:34:29.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:34:29.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:34:29.853+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:34:29.853+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:34:29.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:34:29.883+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:34:29.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T15:35:00.018+0000] {processor.py:157} INFO - Started process (PID=6929) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:35:00.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:35:00.020+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:35:00.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:35:00.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:35:00.063+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:35:00.063+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:35:00.092+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:35:00.092+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:35:00.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T15:35:30.176+0000] {processor.py:157} INFO - Started process (PID=6931) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:35:30.177+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:35:30.178+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:35:30.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:35:30.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:35:30.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:35:30.229+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:35:30.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:35:30.260+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:35:30.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T15:36:00.436+0000] {processor.py:157} INFO - Started process (PID=6933) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:36:00.437+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:36:00.438+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:36:00.438+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:36:00.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:36:00.535+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:36:00.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:36:00.583+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:36:00.583+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:36:00.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.189 seconds
[2024-10-25T15:36:30.753+0000] {processor.py:157} INFO - Started process (PID=6935) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:36:30.754+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:36:30.755+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:36:30.754+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:36:30.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:36:30.796+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:36:30.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:36:30.824+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:36:30.824+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:36:30.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:37:00.906+0000] {processor.py:157} INFO - Started process (PID=6937) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:37:00.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:37:00.908+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:37:00.908+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:37:00.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:37:00.949+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:37:00.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:37:00.976+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:37:00.976+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:37:00.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T15:37:31.109+0000] {processor.py:157} INFO - Started process (PID=6939) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:37:31.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:37:31.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:37:31.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:37:31.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:37:31.156+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:37:31.156+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:37:31.185+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:37:31.185+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:37:31.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T15:38:01.267+0000] {processor.py:157} INFO - Started process (PID=6941) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:38:01.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:38:01.269+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:38:01.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:38:01.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:38:01.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:38:01.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:38:01.341+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:38:01.341+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:38:01.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T15:38:31.514+0000] {processor.py:157} INFO - Started process (PID=6943) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:38:31.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:38:31.516+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:38:31.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:38:31.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:38:31.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:38:31.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:38:31.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:38:31.586+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:38:31.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T15:39:01.664+0000] {processor.py:157} INFO - Started process (PID=6945) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:39:01.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:39:01.677+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:39:01.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:39:01.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:39:01.716+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:39:01.716+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:39:01.742+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:39:01.741+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:39:01.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T15:39:31.866+0000] {processor.py:157} INFO - Started process (PID=6947) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:39:31.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:39:31.868+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:39:31.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:39:31.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:39:31.909+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:39:31.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:39:31.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:39:31.933+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:39:31.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T15:40:02.105+0000] {processor.py:157} INFO - Started process (PID=6949) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:40:02.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:40:02.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:40:02.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:40:02.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:40:02.151+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:40:02.150+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:40:02.175+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:40:02.174+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:40:02.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T15:40:32.367+0000] {processor.py:157} INFO - Started process (PID=6951) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:40:32.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:40:32.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:40:32.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:40:32.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:40:32.415+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:40:32.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:40:32.447+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:40:32.447+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:40:32.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T15:41:02.628+0000] {processor.py:157} INFO - Started process (PID=6953) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:41:02.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:41:02.630+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:41:02.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:41:02.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:41:02.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:41:02.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:41:02.708+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:41:02.707+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:41:02.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T15:41:32.802+0000] {processor.py:157} INFO - Started process (PID=6955) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:41:32.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:41:32.809+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:41:32.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:41:32.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:41:32.866+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:41:32.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:41:32.904+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:41:32.904+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:41:32.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T15:42:02.995+0000] {processor.py:157} INFO - Started process (PID=6957) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:42:02.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:42:02.997+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:42:02.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:42:03.013+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:42:03.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:42:03.051+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:42:03.089+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:42:03.089+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:42:03.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-25T15:42:33.271+0000] {processor.py:157} INFO - Started process (PID=6959) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:42:33.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:42:33.278+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:42:33.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:42:33.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:42:33.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:42:33.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:42:33.343+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:42:33.343+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:42:33.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T15:43:03.516+0000] {processor.py:157} INFO - Started process (PID=6961) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:43:03.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:43:03.519+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:43:03.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:43:03.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:43:03.567+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:43:03.567+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:43:03.596+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:43:03.596+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:43:03.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T15:43:33.674+0000] {processor.py:157} INFO - Started process (PID=6963) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:43:33.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:43:33.675+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:43:33.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:43:33.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:43:33.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:43:33.719+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:43:33.744+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:43:33.744+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:43:33.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T15:44:03.886+0000] {processor.py:157} INFO - Started process (PID=6965) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:44:03.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:44:03.888+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:44:03.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:44:03.902+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:44:03.932+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:44:03.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:44:03.959+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:44:03.959+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:44:03.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T15:44:34.047+0000] {processor.py:157} INFO - Started process (PID=6967) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:44:34.048+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:44:34.049+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:44:34.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:44:34.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:44:34.091+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:44:34.091+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:44:34.114+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:44:34.114+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:44:34.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T15:45:04.313+0000] {processor.py:157} INFO - Started process (PID=6969) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:45:04.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:45:04.315+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:45:04.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:45:04.330+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:45:04.386+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:45:04.386+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:45:04.414+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:45:04.414+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:45:04.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T15:45:34.576+0000] {processor.py:157} INFO - Started process (PID=6971) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:45:34.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:45:34.578+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:45:34.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:45:34.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:45:34.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:45:34.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:45:34.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:45:34.649+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:45:34.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T15:46:04.730+0000] {processor.py:157} INFO - Started process (PID=6973) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:46:04.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:46:04.731+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:46:04.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:46:04.744+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:46:04.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:46:04.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:46:04.800+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:46:04.800+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:46:04.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:46:34.941+0000] {processor.py:157} INFO - Started process (PID=6975) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:46:34.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:46:34.942+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:46:34.942+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:46:34.955+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:46:34.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:46:34.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:46:35.010+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:46:35.010+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:46:35.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:47:05.096+0000] {processor.py:157} INFO - Started process (PID=6977) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:47:05.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:47:05.098+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:47:05.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:47:05.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:47:05.141+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:47:05.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:47:05.167+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:47:05.167+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:47:05.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T15:47:35.310+0000] {processor.py:157} INFO - Started process (PID=6979) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:47:35.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:47:35.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:47:35.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:47:35.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:47:35.357+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:47:35.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:47:35.380+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:47:35.380+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:47:35.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T15:48:05.467+0000] {processor.py:157} INFO - Started process (PID=6981) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:48:05.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:48:05.469+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:48:05.468+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:48:05.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:48:05.513+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:48:05.513+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:48:05.538+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:48:05.538+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:48:05.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T15:48:35.681+0000] {processor.py:157} INFO - Started process (PID=6983) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:48:35.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:48:35.683+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:48:35.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:48:35.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:48:35.727+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:48:35.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:48:35.756+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:48:35.756+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:48:35.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T15:49:05.836+0000] {processor.py:157} INFO - Started process (PID=6985) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:49:05.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:49:05.838+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:49:05.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:49:05.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:49:05.884+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:49:05.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:49:05.910+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:49:05.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:49:05.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T15:49:36.095+0000] {processor.py:157} INFO - Started process (PID=6987) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:49:36.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:49:36.097+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:49:36.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:49:36.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:49:36.147+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:49:36.147+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:49:36.177+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:49:36.177+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:49:36.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T15:50:06.361+0000] {processor.py:157} INFO - Started process (PID=6989) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:50:06.361+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:50:06.362+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:50:06.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:50:06.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:50:06.405+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:50:06.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:50:06.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:50:06.433+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:50:06.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T15:50:36.601+0000] {processor.py:157} INFO - Started process (PID=6991) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:50:36.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:50:36.603+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:50:36.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:50:36.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:50:36.651+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:50:36.651+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:50:36.680+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:50:36.680+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:50:36.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T15:51:06.759+0000] {processor.py:157} INFO - Started process (PID=6993) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:51:06.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T15:51:06.761+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:51:06.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:51:06.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T15:51:06.805+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:51:06.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T15:51:06.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T15:51:06.835+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T15:51:06.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T17:00:36.165+0000] {processor.py:157} INFO - Started process (PID=6995) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T17:00:36.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T17:00:36.168+0000] {logging_mixin.py:149} INFO - [2024-10-25T17:00:36.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T17:00:36.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T17:00:36.867+0000] {logging_mixin.py:149} INFO - [2024-10-25T17:00:36.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T17:00:36.927+0000] {logging_mixin.py:149} INFO - [2024-10-25T17:00:36.927+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T17:00:36.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.038 seconds
[2024-10-25T18:27:06.274+0000] {processor.py:157} INFO - Started process (PID=6999) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:27:06.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:27:06.276+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:27:06.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:27:06.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:27:06.743+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:27:06.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:27:06.844+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:27:06.844+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:27:06.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.659 seconds
[2024-10-25T18:27:37.263+0000] {processor.py:157} INFO - Started process (PID=7003) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:27:37.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:27:37.265+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:27:37.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:27:37.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:27:37.320+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:27:37.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:27:37.356+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:27:37.356+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:27:37.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T18:28:07.420+0000] {processor.py:157} INFO - Started process (PID=7005) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:28:07.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:28:07.422+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:28:07.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:28:07.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:28:07.470+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:28:07.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:28:07.507+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:28:07.507+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:28:07.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T18:28:37.719+0000] {processor.py:157} INFO - Started process (PID=7007) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:28:37.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:28:37.722+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:28:37.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:28:37.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:28:37.813+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:28:37.813+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:28:37.867+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:28:37.867+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:28:37.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.179 seconds
[2024-10-25T18:29:08.015+0000] {processor.py:157} INFO - Started process (PID=7009) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:29:08.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:29:08.017+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:29:08.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:29:08.031+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:29:08.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:29:08.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:29:08.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:29:08.100+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:29:08.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T18:29:38.313+0000] {processor.py:157} INFO - Started process (PID=7011) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:29:38.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:29:38.315+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:29:38.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:29:38.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:29:38.520+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:29:38.520+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:29:38.570+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:29:38.570+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:29:38.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.282 seconds
[2024-10-25T18:30:08.763+0000] {processor.py:157} INFO - Started process (PID=7013) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:30:08.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:30:08.765+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:30:08.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:30:08.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:30:08.823+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:30:08.823+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:30:08.855+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:30:08.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:30:08.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T18:30:39.035+0000] {processor.py:157} INFO - Started process (PID=7015) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:30:39.035+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:30:39.036+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:30:39.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:30:39.056+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:30:39.096+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:30:39.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:30:39.129+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:30:39.129+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:30:39.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-25T18:31:09.310+0000] {processor.py:157} INFO - Started process (PID=7017) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:31:09.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:31:09.312+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:31:09.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:31:09.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:31:09.357+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:31:09.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:31:09.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:31:09.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:31:09.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T18:31:39.569+0000] {processor.py:157} INFO - Started process (PID=7019) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:31:39.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:31:39.571+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:31:39.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:31:39.584+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:31:39.613+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:31:39.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:31:39.641+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:31:39.641+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:31:39.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T18:32:09.732+0000] {processor.py:157} INFO - Started process (PID=7021) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:32:09.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:32:09.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:32:09.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:32:09.751+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:32:09.781+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:32:09.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:32:09.808+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:32:09.807+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:32:09.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T18:32:39.988+0000] {processor.py:157} INFO - Started process (PID=7023) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:32:39.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:32:39.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:32:39.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:32:40.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:32:40.035+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:32:40.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:32:40.065+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:32:40.064+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:32:40.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T18:33:10.143+0000] {processor.py:157} INFO - Started process (PID=7025) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:33:10.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:33:10.145+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:33:10.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:33:10.161+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:33:10.191+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:33:10.191+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:33:10.215+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:33:10.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:33:10.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T18:33:40.390+0000] {processor.py:157} INFO - Started process (PID=7027) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:33:40.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:33:40.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:33:40.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:33:40.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:33:40.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:33:40.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:33:40.458+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:33:40.458+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:33:40.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T18:34:10.551+0000] {processor.py:157} INFO - Started process (PID=7029) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:34:10.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:34:10.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:34:10.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:34:10.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:34:10.599+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:34:10.599+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:34:10.626+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:34:10.626+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:34:10.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T18:34:40.806+0000] {processor.py:157} INFO - Started process (PID=7031) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:34:40.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:34:40.808+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:34:40.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:34:40.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:34:40.853+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:34:40.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:34:40.877+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:34:40.876+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:34:40.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T18:35:11.058+0000] {processor.py:157} INFO - Started process (PID=7033) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:35:11.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:35:11.060+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:35:11.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:35:11.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:35:11.103+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:35:11.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:35:11.130+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:35:11.129+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:35:11.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T18:35:41.306+0000] {processor.py:157} INFO - Started process (PID=7035) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:35:41.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:35:41.307+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:35:41.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:35:41.322+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:35:41.352+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:35:41.352+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:35:41.378+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:35:41.378+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:35:41.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T18:36:11.461+0000] {processor.py:157} INFO - Started process (PID=7037) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:36:11.463+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:36:11.463+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:36:11.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:36:11.477+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:36:11.505+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:36:11.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:36:11.531+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:36:11.531+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:36:11.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T18:36:41.660+0000] {processor.py:157} INFO - Started process (PID=7039) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:36:41.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:36:41.661+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:36:41.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:36:41.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:36:41.705+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:36:41.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:36:41.731+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:36:41.731+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:36:41.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T18:37:11.833+0000] {processor.py:157} INFO - Started process (PID=7041) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:37:11.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:37:11.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:37:11.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:37:11.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:37:11.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:37:11.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:37:11.910+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:37:11.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:37:11.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T18:37:42.013+0000] {processor.py:157} INFO - Started process (PID=7043) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:37:42.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:37:42.015+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:37:42.014+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:37:42.027+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:37:42.060+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:37:42.060+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:37:42.086+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:37:42.086+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:37:42.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T18:38:12.193+0000] {processor.py:157} INFO - Started process (PID=7045) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:38:12.194+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:38:12.195+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:38:12.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:38:12.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:38:12.236+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:38:12.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:38:12.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:38:12.261+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:38:12.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T18:38:42.439+0000] {processor.py:157} INFO - Started process (PID=7047) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:38:42.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:38:42.440+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:38:42.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:38:42.454+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:38:42.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:38:42.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:38:42.511+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:38:42.510+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:38:42.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T18:39:12.697+0000] {processor.py:157} INFO - Started process (PID=7049) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:39:12.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:39:12.698+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:39:12.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:39:12.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:39:12.745+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:39:12.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:39:12.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:39:12.772+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:39:12.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T18:39:42.845+0000] {processor.py:157} INFO - Started process (PID=7051) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:39:42.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:39:42.846+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:39:42.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:39:42.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:39:42.890+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:39:42.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:39:42.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:39:42.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:39:42.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T18:40:13.076+0000] {processor.py:157} INFO - Started process (PID=7053) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:40:13.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:40:13.079+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:40:13.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:40:13.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:40:13.127+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:40:13.127+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:40:13.153+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:40:13.153+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:40:13.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T18:40:43.227+0000] {processor.py:157} INFO - Started process (PID=7055) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:40:43.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:40:43.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:40:43.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:40:43.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:40:43.272+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:40:43.272+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:40:43.297+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:40:43.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:40:43.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T18:41:13.470+0000] {processor.py:157} INFO - Started process (PID=7057) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:41:13.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:41:13.472+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:41:13.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:41:13.488+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:41:13.520+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:41:13.520+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:41:13.545+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:41:13.545+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:41:13.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T18:41:43.626+0000] {processor.py:157} INFO - Started process (PID=7059) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:41:43.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:41:43.628+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:41:43.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:41:43.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:41:43.673+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:41:43.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:41:43.697+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:41:43.697+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:41:43.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T18:42:13.838+0000] {processor.py:157} INFO - Started process (PID=7061) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:42:13.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:42:13.839+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:42:13.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:42:13.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:42:13.884+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:42:13.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:42:13.910+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:42:13.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:42:13.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T18:42:43.991+0000] {processor.py:157} INFO - Started process (PID=7063) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:42:43.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:42:43.992+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:42:43.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:42:44.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:42:44.037+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:42:44.036+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:42:44.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:42:44.064+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:42:44.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T18:43:14.243+0000] {processor.py:157} INFO - Started process (PID=7065) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:43:14.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:43:14.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:43:14.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:43:14.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:43:14.330+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:43:14.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:43:14.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:43:14.391+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:43:14.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.198 seconds
[2024-10-25T18:43:44.593+0000] {processor.py:157} INFO - Started process (PID=7067) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:43:44.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:43:44.595+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:43:44.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:43:44.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:43:44.646+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:43:44.646+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:43:44.680+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:43:44.680+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:43:44.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T18:44:14.750+0000] {processor.py:157} INFO - Started process (PID=7069) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:44:14.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:44:14.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:44:14.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:44:14.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:44:14.798+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:44:14.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:44:14.826+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:44:14.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:44:14.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T18:44:45.012+0000] {processor.py:157} INFO - Started process (PID=7071) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:44:45.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:44:45.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:44:45.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:44:45.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:44:45.059+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:44:45.059+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:44:45.085+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:44:45.084+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:44:45.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T18:45:15.169+0000] {processor.py:157} INFO - Started process (PID=7073) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:45:15.170+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:45:15.171+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:45:15.171+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:45:15.214+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:45:15.316+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:45:15.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:45:15.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:45:15.369+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:45:15.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.233 seconds
[2024-10-25T18:45:45.554+0000] {processor.py:157} INFO - Started process (PID=7075) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:45:45.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:45:45.556+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:45:45.556+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:45:45.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:45:45.602+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:45:45.600+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:45:45.632+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:45:45.632+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:45:45.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T18:46:15.704+0000] {processor.py:157} INFO - Started process (PID=7077) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:46:15.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:46:15.706+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:46:15.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:46:15.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:46:15.770+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:46:15.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:46:15.803+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:46:15.803+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:46:15.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-25T18:46:45.920+0000] {processor.py:157} INFO - Started process (PID=7079) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:46:45.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:46:45.922+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:46:45.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:46:45.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:46:45.965+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:46:45.965+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:46:45.999+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:46:45.999+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:46:46.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T18:47:16.344+0000] {processor.py:157} INFO - Started process (PID=7081) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:47:16.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:47:16.349+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:47:16.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:47:16.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:47:16.445+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:47:16.445+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:47:16.495+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:47:16.495+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:47:16.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.186 seconds
[2024-10-25T18:47:46.825+0000] {processor.py:157} INFO - Started process (PID=7083) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:47:46.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:47:46.827+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:47:46.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:47:46.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:47:46.888+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:47:46.888+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:47:46.921+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:47:46.921+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:47:46.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-25T18:48:17.106+0000] {processor.py:157} INFO - Started process (PID=7085) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:48:17.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:48:17.108+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:48:17.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:48:17.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:48:17.163+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:48:17.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:48:17.210+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:48:17.209+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:48:17.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-25T18:48:47.258+0000] {processor.py:157} INFO - Started process (PID=7087) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:48:47.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:48:47.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:48:47.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:48:47.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:48:47.310+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:48:47.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:48:47.340+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:48:47.340+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:48:47.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T18:49:17.498+0000] {processor.py:157} INFO - Started process (PID=7089) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:49:17.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:49:17.499+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:49:17.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:49:17.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:49:17.547+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:49:17.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:49:17.580+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:49:17.579+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:49:17.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T18:49:47.759+0000] {processor.py:157} INFO - Started process (PID=7091) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:49:47.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:49:47.761+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:49:47.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:49:47.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:49:47.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:49:47.812+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:49:47.842+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:49:47.842+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:49:47.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T18:50:18.024+0000] {processor.py:157} INFO - Started process (PID=7093) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:50:18.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:50:18.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:50:18.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:50:18.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:50:18.075+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:50:18.075+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:50:18.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:50:18.107+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:50:18.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T18:50:48.182+0000] {processor.py:157} INFO - Started process (PID=7095) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:50:48.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:50:48.183+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:50:48.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:50:48.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:50:48.224+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:50:48.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:50:48.249+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:50:48.249+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:50:48.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T18:51:18.430+0000] {processor.py:157} INFO - Started process (PID=7097) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:51:18.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:51:18.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:51:18.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:51:18.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:51:18.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:51:18.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:51:18.512+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:51:18.511+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:51:18.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T18:51:48.575+0000] {processor.py:157} INFO - Started process (PID=7099) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:51:48.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:51:48.577+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:51:48.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:51:48.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:51:48.625+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:51:48.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:51:48.653+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:51:48.652+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:51:48.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T18:52:18.786+0000] {processor.py:157} INFO - Started process (PID=7101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:52:18.787+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:52:18.788+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:52:18.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:52:18.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:52:18.833+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:52:18.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:52:18.860+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:52:18.860+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:52:18.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T18:52:48.932+0000] {processor.py:157} INFO - Started process (PID=7103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:52:48.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:52:48.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:52:48.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:52:48.951+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:52:48.984+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:52:48.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:52:49.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:52:49.012+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:52:49.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T18:53:19.192+0000] {processor.py:157} INFO - Started process (PID=7105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:53:19.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:53:19.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:53:19.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:53:19.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:53:19.244+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:53:19.243+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:53:19.275+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:53:19.275+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:53:19.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T18:53:49.458+0000] {processor.py:157} INFO - Started process (PID=7107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:53:49.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:53:49.460+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:53:49.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:53:49.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:53:49.511+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:53:49.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:53:49.543+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:53:49.543+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:53:49.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T18:54:19.607+0000] {processor.py:157} INFO - Started process (PID=7109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:54:19.608+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:54:19.608+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:54:19.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:54:19.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:54:19.651+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:54:19.650+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:54:19.676+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:54:19.676+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:54:19.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T18:54:49.860+0000] {processor.py:157} INFO - Started process (PID=7111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:54:49.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:54:49.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:54:49.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:54:49.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:54:49.905+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:54:49.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:54:49.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:54:49.934+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:54:49.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T18:55:20.120+0000] {processor.py:157} INFO - Started process (PID=7113) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:55:20.122+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:55:20.124+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:55:20.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:55:20.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:55:20.205+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:55:20.205+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:55:20.264+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:55:20.263+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:55:20.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.180 seconds
[2024-10-25T18:55:50.365+0000] {processor.py:157} INFO - Started process (PID=7115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:55:50.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:55:50.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:55:50.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:55:50.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:55:50.411+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:55:50.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:55:50.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:55:50.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:55:50.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T18:56:20.560+0000] {processor.py:157} INFO - Started process (PID=7117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:56:20.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:56:20.572+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:56:20.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:56:20.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:56:20.614+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:56:20.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:56:20.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:56:20.646+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:56:20.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T18:56:50.703+0000] {processor.py:157} INFO - Started process (PID=7119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:56:50.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:56:50.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:56:50.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:56:50.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:56:50.760+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:56:50.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:56:50.785+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:56:50.785+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:56:50.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T18:57:21.020+0000] {processor.py:157} INFO - Started process (PID=7121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:57:21.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:57:21.022+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:57:21.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:57:21.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:57:21.076+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:57:21.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:57:21.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:57:21.107+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:57:21.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T18:57:51.185+0000] {processor.py:157} INFO - Started process (PID=7123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:57:51.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:57:51.187+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:57:51.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:57:51.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:57:51.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:57:51.237+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:57:51.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:57:51.277+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:57:51.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T18:58:21.387+0000] {processor.py:157} INFO - Started process (PID=7125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:58:21.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:58:21.389+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:58:21.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:58:21.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:58:21.438+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:58:21.438+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:58:21.469+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:58:21.469+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:58:21.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-25T18:58:51.549+0000] {processor.py:157} INFO - Started process (PID=7127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:58:51.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:58:51.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:58:51.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:58:51.568+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:58:51.603+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:58:51.603+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:58:51.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:58:51.629+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:58:51.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T18:59:21.805+0000] {processor.py:157} INFO - Started process (PID=7129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:59:21.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:59:21.807+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:59:21.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:59:21.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:59:21.854+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:59:21.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:59:21.944+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:59:21.944+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:59:21.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-25T18:59:52.132+0000] {processor.py:157} INFO - Started process (PID=7131) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:59:52.134+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T18:59:52.135+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:59:52.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:59:52.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T18:59:52.223+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:59:52.222+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T18:59:52.264+0000] {logging_mixin.py:149} INFO - [2024-10-25T18:59:52.264+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T18:59:52.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.158 seconds
[2024-10-25T19:00:22.408+0000] {processor.py:157} INFO - Started process (PID=7133) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:00:22.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:00:22.421+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:00:22.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:00:22.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:00:22.462+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:00:22.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:00:22.502+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:00:22.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:00:22.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-25T19:21:41.662+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:21:41.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:21:41.666+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:21:41.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:21:41.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:21:41.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:21:41.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:21:41.743+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:21:41.743+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:21:41.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T19:22:11.871+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:22:11.872+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:22:11.873+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:22:11.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:22:11.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:22:11.908+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:22:11.908+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:22:11.932+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:22:11.932+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:22:11.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T19:22:42.055+0000] {processor.py:157} INFO - Started process (PID=33) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:22:42.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:22:42.057+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:22:42.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:22:42.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:22:42.116+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:22:42.116+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:22:42.145+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:22:42.145+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:22:42.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T19:23:12.238+0000] {processor.py:157} INFO - Started process (PID=35) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:23:12.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:23:12.239+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:23:12.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:23:12.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:23:12.283+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:23:12.282+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:23:12.310+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:23:12.310+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:23:12.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T19:23:42.515+0000] {processor.py:157} INFO - Started process (PID=37) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:23:42.527+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:23:42.528+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:23:42.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:23:42.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:23:42.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:23:42.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:23:42.580+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:23:42.580+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:23:42.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T19:24:12.700+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:24:12.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:24:12.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:24:12.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:24:12.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:24:12.741+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:24:12.741+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:24:12.762+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:24:12.762+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:24:12.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T19:24:42.939+0000] {processor.py:157} INFO - Started process (PID=41) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:24:42.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:24:42.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:24:42.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:24:42.951+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:24:42.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:24:42.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:24:43.007+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:24:43.007+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:24:43.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T19:25:13.148+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:25:13.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:25:13.161+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:25:13.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:25:13.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:25:13.197+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:25:13.197+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:25:13.218+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:25:13.218+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:25:13.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T19:25:43.374+0000] {processor.py:157} INFO - Started process (PID=45) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:25:43.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:25:43.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:25:43.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:25:43.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:25:43.414+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:25:43.414+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:25:43.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:25:43.435+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:25:43.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T19:26:13.525+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:26:13.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:26:13.527+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:26:13.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:26:13.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:26:13.566+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:26:13.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:26:13.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:26:13.586+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:26:13.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T19:26:43.776+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:26:43.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:26:43.778+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:26:43.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:26:43.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:26:43.821+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:26:43.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:26:43.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:26:43.843+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:26:43.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T19:27:13.946+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:27:13.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:27:13.948+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:27:13.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:27:13.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:27:13.988+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:27:13.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:27:14.016+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:27:14.016+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:27:14.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T19:27:44.207+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:27:44.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:27:44.208+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:27:44.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:27:44.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:27:44.257+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:27:44.257+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:27:44.282+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:27:44.282+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:27:44.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T19:28:14.387+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:28:14.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:28:14.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:28:14.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:28:14.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:28:14.430+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:28:14.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:28:14.453+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:28:14.453+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:28:14.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T19:28:44.580+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:28:44.581+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:28:44.584+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:28:44.584+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:28:44.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:28:44.668+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:28:44.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:28:44.725+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:28:44.725+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:28:44.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T19:29:14.949+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:29:14.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:29:14.950+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:29:14.950+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:29:14.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:29:14.999+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:29:14.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:29:15.152+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:29:15.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:29:15.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.223 seconds
[2024-10-25T19:29:45.328+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:29:45.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:29:45.330+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:29:45.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:29:45.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:29:45.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:29:45.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:29:45.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:29:45.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:29:45.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.199 seconds
[2024-10-25T19:30:15.652+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:30:15.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:30:15.654+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:30:15.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:30:15.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:30:15.692+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:30:15.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:30:15.831+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:30:15.831+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:30:15.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.199 seconds
[2024-10-25T19:30:45.968+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:30:45.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:30:45.970+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:30:45.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:30:45.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:30:46.139+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:30:46.138+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:30:46.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:30:46.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:30:46.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.209 seconds
[2024-10-25T19:31:16.352+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:31:16.352+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:31:16.353+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:31:16.353+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:31:16.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:31:16.390+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:31:16.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:31:16.409+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:31:16.409+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:31:16.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-25T19:31:46.573+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:31:46.574+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:31:46.575+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:31:46.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:31:46.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:31:46.612+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:31:46.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:31:46.633+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:31:46.633+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:31:46.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.163 seconds
[2024-10-25T19:32:16.792+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:32:16.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:32:16.793+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:32:16.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:32:16.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:32:16.836+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:32:16.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:32:16.949+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:32:16.949+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:32:16.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.177 seconds
[2024-10-25T19:32:47.085+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:32:47.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:32:47.097+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:32:47.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:32:47.107+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:32:47.130+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:32:47.130+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:32:47.231+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:32:47.230+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:32:47.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.165 seconds
[2024-10-25T19:33:17.348+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:33:17.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:33:17.349+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:33:17.349+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:33:17.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:33:17.385+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:33:17.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:33:17.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:33:17.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:33:17.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.163 seconds
[2024-10-25T19:33:47.619+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:33:47.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:33:47.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:33:47.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:33:47.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:33:47.739+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:33:47.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:33:47.758+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:33:47.758+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:33:47.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.158 seconds
[2024-10-25T19:34:17.855+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:34:17.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:34:17.857+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:34:17.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:34:17.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:34:17.891+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:34:17.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:34:17.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:34:17.911+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:34:17.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-25T19:34:48.059+0000] {processor.py:157} INFO - Started process (PID=81) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:34:48.060+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:34:48.061+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:34:48.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:34:48.071+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:34:48.096+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:34:48.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:34:48.116+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:34:48.116+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:34:48.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.167 seconds
[2024-10-25T19:35:18.264+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:35:18.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:35:18.266+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:35:18.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:35:18.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:35:18.303+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:35:18.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:35:18.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:35:18.418+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:35:18.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.176 seconds
[2024-10-25T19:35:48.631+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:35:48.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:35:48.632+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:35:48.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:35:48.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:35:48.672+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:35:48.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:35:48.774+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:35:48.774+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:35:48.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.163 seconds
[2024-10-25T19:36:18.834+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:36:18.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:36:18.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:36:18.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:36:18.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:36:18.872+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:36:18.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:36:18.994+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:36:18.994+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:36:19.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.179 seconds
[2024-10-25T19:36:49.224+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:36:49.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:36:49.237+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:36:49.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:36:49.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:36:49.358+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:36:49.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:36:49.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:36:49.376+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:36:49.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.171 seconds
[2024-10-25T19:37:19.432+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:37:19.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:37:19.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:37:19.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:37:19.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:37:19.468+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:37:19.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:37:19.491+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:37:19.491+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:37:19.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T19:37:49.623+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:37:49.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:37:49.625+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:37:49.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:37:49.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:37:49.665+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:37:49.665+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:37:49.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:37:49.687+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:37:49.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.172 seconds
[2024-10-25T19:38:19.859+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:38:19.860+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:38:19.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:38:19.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:38:19.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:38:19.899+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:38:19.899+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:38:20.016+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:38:20.016+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:38:20.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.177 seconds
[2024-10-25T19:38:50.252+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:38:50.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:38:50.254+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:38:50.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:38:50.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:38:50.288+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:38:50.288+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:38:50.391+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:38:50.391+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:38:50.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.158 seconds
[2024-10-25T19:39:20.453+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:39:20.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:39:20.454+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:39:20.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:39:20.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:39:20.572+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:39:20.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:39:20.593+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:39:20.593+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:39:20.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-25T19:39:50.837+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:39:50.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:39:50.840+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:39:50.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:39:50.851+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:39:50.953+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:39:50.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:39:50.970+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:39:50.970+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:39:50.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-25T19:40:21.039+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:40:21.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:40:21.040+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:40:21.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:40:21.065+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:40:21.096+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:40:21.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:40:21.135+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:40:21.135+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:40:21.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-25T19:40:51.354+0000] {processor.py:157} INFO - Started process (PID=105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:40:51.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:40:51.355+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:40:51.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:40:51.368+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:40:51.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:40:51.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:40:51.413+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:40:51.413+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:40:51.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-25T19:41:21.548+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:41:21.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:41:21.550+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:41:21.550+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:41:21.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:41:21.589+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:41:21.589+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:41:21.696+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:41:21.696+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:41:21.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-25T19:41:51.906+0000] {processor.py:157} INFO - Started process (PID=109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:41:51.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:41:51.907+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:41:51.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:41:51.918+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:41:51.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:41:51.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:41:52.043+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:41:52.043+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:41:52.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.158 seconds
[2024-10-25T19:42:22.103+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:42:22.104+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:42:22.104+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:42:22.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:42:22.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:42:22.219+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:42:22.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:42:22.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:42:22.238+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:42:22.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.155 seconds
[2024-10-25T19:42:52.447+0000] {processor.py:157} INFO - Started process (PID=113) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:42:52.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:42:52.449+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:42:52.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:42:52.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:42:52.559+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:42:52.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:42:52.577+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:42:52.577+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:42:52.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.148 seconds
[2024-10-25T19:43:22.671+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:43:22.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:43:22.673+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:43:22.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:43:22.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:43:22.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:43:22.707+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:43:22.727+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:43:22.727+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:43:22.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-25T19:43:52.878+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:43:52.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:43:52.880+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:43:52.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:43:52.891+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:43:52.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:43:52.916+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:43:52.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:43:52.943+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:43:53.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.180 seconds
[2024-10-25T19:44:23.120+0000] {processor.py:157} INFO - Started process (PID=119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:44:23.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:44:23.122+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:44:23.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:44:23.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:44:23.155+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:44:23.155+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:44:23.253+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:44:23.253+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:44:23.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-25T19:44:53.434+0000] {processor.py:157} INFO - Started process (PID=121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:44:53.435+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:44:53.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:44:53.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:44:53.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:44:53.470+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:44:53.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:44:53.563+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:44:53.563+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:44:53.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.149 seconds
[2024-10-25T19:45:23.640+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:45:23.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:45:23.641+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:45:23.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:45:23.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:45:23.763+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:45:23.763+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:45:23.782+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:45:23.781+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:45:23.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.161 seconds
[2024-10-25T19:45:53.949+0000] {processor.py:157} INFO - Started process (PID=125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:45:53.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:45:53.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:45:53.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:45:53.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:45:54.067+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:45:54.067+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:45:54.085+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:45:54.085+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:45:54.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.155 seconds
[2024-10-25T19:46:24.282+0000] {processor.py:157} INFO - Started process (PID=127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:46:24.283+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T19:46:24.284+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:46:24.284+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:46:24.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T19:46:24.416+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:46:24.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T19:46:24.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T19:46:24.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T19:46:24.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.176 seconds
[2024-10-25T20:06:08.238+0000] {processor.py:157} INFO - Started process (PID=129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:06:08.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:06:08.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:06:08.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:06:08.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:06:08.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:06:08.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:06:08.885+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:06:08.885+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:06:08.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.735 seconds
[2024-10-25T20:20:37.678+0000] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:20:37.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:20:37.681+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:20:37.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:20:37.735+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:20:37.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:20:37.915+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:20:38.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:20:38.004+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:20:38.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.446 seconds
[2024-10-25T20:21:08.214+0000] {processor.py:157} INFO - Started process (PID=137) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:21:08.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:21:08.216+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:21:08.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:21:08.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:21:08.269+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:21:08.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:21:08.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:21:08.294+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:21:08.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T20:21:38.496+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:21:38.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:21:38.497+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:21:38.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:21:38.510+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:21:38.538+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:21:38.538+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:21:38.562+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:21:38.562+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:21:38.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T20:22:08.759+0000] {processor.py:157} INFO - Started process (PID=141) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:22:08.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:22:08.761+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:22:08.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:22:08.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:22:08.798+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:22:08.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:22:08.817+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:22:08.817+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:22:08.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-25T20:22:39.051+0000] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:22:39.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:22:39.052+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:22:39.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:22:39.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:22:39.087+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:22:39.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:22:39.106+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:22:39.106+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:22:39.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.075 seconds
[2024-10-25T20:23:09.232+0000] {processor.py:157} INFO - Started process (PID=145) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:23:09.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:23:09.245+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:23:09.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:23:09.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:23:09.283+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:23:09.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:23:09.305+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:23:09.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:23:09.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T20:23:39.467+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:23:39.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:23:39.469+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:23:39.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:23:39.480+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:23:39.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:23:39.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:23:39.527+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:23:39.527+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:23:39.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-25T20:24:09.627+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:24:09.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:24:09.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:24:09.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:24:09.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:24:09.674+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:24:09.674+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:24:09.705+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:24:09.705+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:24:09.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T20:24:39.916+0000] {processor.py:157} INFO - Started process (PID=151) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:24:39.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:24:39.917+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:24:39.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:24:39.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:24:39.958+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:24:39.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:24:39.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:24:39.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:24:39.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T20:25:10.102+0000] {processor.py:157} INFO - Started process (PID=153) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:25:10.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:25:10.104+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:25:10.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:25:10.116+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:25:10.142+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:25:10.142+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:25:10.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:25:10.165+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:25:10.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T20:25:40.391+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:25:40.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:25:40.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:25:40.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:25:40.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:25:40.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:25:40.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:25:40.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:25:40.461+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:25:40.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T20:26:10.557+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:26:10.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:26:10.559+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:26:10.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:26:10.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:26:10.602+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:26:10.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:26:10.627+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:26:10.627+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:26:10.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T20:26:40.777+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:26:40.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:26:40.778+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:26:40.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:26:40.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:26:40.819+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:26:40.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:26:40.844+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:26:40.844+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:26:40.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T20:27:11.048+0000] {processor.py:157} INFO - Started process (PID=161) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:27:11.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:27:11.049+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:27:11.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:27:11.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:27:11.084+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:27:11.084+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:27:11.104+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:27:11.104+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:27:11.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-25T20:27:41.242+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:27:41.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:27:41.243+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:27:41.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:27:41.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:27:41.283+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:27:41.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:27:41.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:27:41.313+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:27:41.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T20:28:11.432+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:28:11.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:28:11.434+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:28:11.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:28:11.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:28:11.475+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:28:11.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:28:11.501+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:28:11.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:28:11.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T20:28:41.606+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:28:41.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:28:41.608+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:28:41.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:28:41.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:28:41.643+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:28:41.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:28:41.663+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:28:41.663+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:28:41.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-25T20:29:11.778+0000] {processor.py:157} INFO - Started process (PID=169) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:29:11.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:29:11.782+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:29:11.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:29:11.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:29:11.824+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:29:11.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:29:11.844+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:29:11.844+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:29:11.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T20:29:42.057+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:29:42.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:29:42.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:29:42.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:29:42.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:29:42.098+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:29:42.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:29:42.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:29:42.121+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:29:42.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T20:30:12.223+0000] {processor.py:157} INFO - Started process (PID=173) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:30:12.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:30:12.235+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:30:12.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:30:12.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:30:12.271+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:30:12.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:30:12.294+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:30:12.294+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:30:12.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T20:30:42.464+0000] {processor.py:157} INFO - Started process (PID=175) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:30:42.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:30:42.465+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:30:42.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:30:42.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:30:42.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:30:42.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:30:42.524+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:30:42.524+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:30:42.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T20:31:12.643+0000] {processor.py:157} INFO - Started process (PID=177) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:31:12.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:31:12.656+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:31:12.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:31:12.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:31:12.694+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:31:12.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:31:12.719+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:31:12.719+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:31:12.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T20:31:42.831+0000] {processor.py:157} INFO - Started process (PID=179) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:31:42.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:31:42.833+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:31:42.832+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:31:42.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:31:42.878+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:31:42.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:31:42.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:31:42.903+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:31:42.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T20:32:13.038+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:32:13.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:32:13.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:32:13.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:32:13.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:32:13.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:32:13.101+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:32:13.125+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:32:13.125+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:32:13.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-25T20:32:43.245+0000] {processor.py:157} INFO - Started process (PID=183) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:32:43.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:32:43.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:32:43.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:32:43.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:32:43.287+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:32:43.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:32:43.309+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:32:43.309+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:32:43.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T20:33:13.520+0000] {processor.py:157} INFO - Started process (PID=185) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:33:13.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:33:13.532+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:33:13.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:33:13.544+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:33:13.570+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:33:13.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:33:13.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:33:13.597+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:33:13.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T20:33:43.682+0000] {processor.py:157} INFO - Started process (PID=187) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:33:43.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:33:43.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:33:43.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:33:43.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:33:43.726+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:33:43.726+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:33:43.755+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:33:43.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:33:43.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T20:34:13.909+0000] {processor.py:157} INFO - Started process (PID=189) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:34:13.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:34:13.911+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:34:13.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:34:13.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:34:13.947+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:34:13.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:34:13.968+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:34:13.968+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:34:13.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T20:34:44.092+0000] {processor.py:157} INFO - Started process (PID=191) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:34:44.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:34:44.094+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:34:44.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:34:44.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:34:44.131+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:34:44.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:34:44.153+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:34:44.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:34:44.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T20:35:14.293+0000] {processor.py:157} INFO - Started process (PID=193) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:35:14.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:35:14.295+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:35:14.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:35:14.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:35:14.338+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:35:14.338+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:35:14.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:35:14.369+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:35:14.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T20:35:44.556+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:35:44.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:35:44.557+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:35:44.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:35:44.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:35:44.603+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:35:44.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:35:44.633+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:35:44.633+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:35:44.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T20:36:14.721+0000] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:36:14.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:36:14.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:36:14.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:36:14.745+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:36:14.772+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:36:14.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:36:14.794+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:36:14.794+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:36:14.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T20:36:44.935+0000] {processor.py:157} INFO - Started process (PID=199) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:36:44.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:36:44.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:36:44.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:36:44.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:36:44.983+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:36:44.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:36:45.010+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:36:45.010+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:36:45.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T20:37:15.193+0000] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:37:15.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:37:15.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:37:15.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:37:15.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:37:15.237+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:37:15.237+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:37:15.262+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:37:15.262+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:37:15.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T20:37:45.344+0000] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:37:45.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:37:45.346+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:37:45.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:37:45.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:37:45.384+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:37:45.384+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:37:45.407+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:37:45.407+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:37:45.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T20:38:15.546+0000] {processor.py:157} INFO - Started process (PID=205) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:38:15.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:38:15.559+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:38:15.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:38:15.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:38:15.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:38:15.597+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:38:15.618+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:38:15.618+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:38:15.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T20:38:45.697+0000] {processor.py:157} INFO - Started process (PID=207) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:38:45.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:38:45.698+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:38:45.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:38:45.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:38:45.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:38:45.734+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:38:45.759+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:38:45.759+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:38:45.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T20:39:15.944+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:39:15.946+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:39:15.946+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:39:15.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:39:15.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:39:15.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:39:15.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:39:16.017+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:39:16.016+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:39:16.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T20:39:46.184+0000] {processor.py:157} INFO - Started process (PID=211) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:39:46.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:39:46.186+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:39:46.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:39:46.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:39:46.236+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:39:46.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:39:46.261+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:39:46.261+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:39:46.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T20:40:16.327+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:40:16.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:40:16.329+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:40:16.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:40:16.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:40:16.373+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:40:16.373+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:40:16.399+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:40:16.399+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:40:16.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T20:40:46.559+0000] {processor.py:157} INFO - Started process (PID=215) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:40:46.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:40:46.561+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:40:46.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:40:46.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:40:46.606+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:40:46.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:40:46.635+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:40:46.635+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:40:46.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T20:41:16.704+0000] {processor.py:157} INFO - Started process (PID=217) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:41:16.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:41:16.706+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:41:16.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:41:16.719+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:41:16.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:41:16.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:41:16.775+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:41:16.775+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:41:16.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T20:41:46.910+0000] {processor.py:157} INFO - Started process (PID=219) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:41:46.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:41:46.912+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:41:46.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:41:46.926+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:41:46.955+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:41:46.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:41:46.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:41:46.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:41:47.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T20:42:17.051+0000] {processor.py:157} INFO - Started process (PID=221) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:42:17.063+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:42:17.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:42:17.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:42:17.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:42:17.102+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:42:17.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:42:17.125+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:42:17.125+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:42:17.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T20:42:47.259+0000] {processor.py:157} INFO - Started process (PID=223) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:42:47.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:42:47.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:42:47.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:42:47.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:42:47.300+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:42:47.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:42:47.324+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:42:47.324+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:42:47.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T20:43:17.403+0000] {processor.py:157} INFO - Started process (PID=225) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:43:17.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:43:17.416+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:43:17.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:43:17.428+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:43:17.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:43:17.457+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:43:17.479+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:43:17.479+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:43:17.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T20:43:47.602+0000] {processor.py:157} INFO - Started process (PID=227) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:43:47.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:43:47.603+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:43:47.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:43:47.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:43:47.652+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:43:47.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:43:47.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:43:47.684+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:43:47.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T20:44:17.857+0000] {processor.py:157} INFO - Started process (PID=229) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:44:17.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:44:17.859+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:44:17.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:44:17.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:44:17.906+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:44:17.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:44:17.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:44:17.934+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:44:17.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T20:44:48.106+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:44:48.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:44:48.108+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:44:48.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:44:48.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:44:48.149+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:44:48.149+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:44:48.174+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:44:48.174+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:44:48.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T20:45:18.254+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:45:18.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:45:18.256+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:45:18.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:45:18.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:45:18.299+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:45:18.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:45:18.324+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:45:18.324+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:45:18.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T20:45:48.455+0000] {processor.py:157} INFO - Started process (PID=235) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:45:48.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:45:48.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:45:48.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:45:48.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:45:48.495+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:45:48.495+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:45:48.519+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:45:48.518+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:45:48.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T20:46:18.593+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:46:18.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:46:18.595+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:46:18.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:46:18.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:46:18.634+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:46:18.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:46:18.657+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:46:18.656+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:46:18.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T20:46:48.834+0000] {processor.py:157} INFO - Started process (PID=239) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:46:48.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:46:48.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:46:48.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:46:48.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:46:48.878+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:46:48.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:46:48.900+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:46:48.900+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:46:48.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T20:47:18.972+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:47:18.973+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:47:18.974+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:47:18.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:47:18.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:47:19.017+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:47:19.017+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:47:19.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:47:19.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:47:19.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T20:47:49.179+0000] {processor.py:157} INFO - Started process (PID=243) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:47:49.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:47:49.180+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:47:49.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:47:49.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:47:49.224+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:47:49.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:47:49.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:47:49.246+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:47:49.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T20:48:19.349+0000] {processor.py:157} INFO - Started process (PID=245) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:48:19.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:48:19.352+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:48:19.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:48:19.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:48:19.387+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:48:19.387+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:48:19.411+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:48:19.410+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:48:19.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T20:48:49.571+0000] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:48:49.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:48:49.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:48:49.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:48:49.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:48:49.609+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:48:49.609+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:48:49.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:48:49.629+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:48:49.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-25T20:49:19.778+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:49:19.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:49:19.780+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:49:19.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:49:19.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:49:19.820+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:49:19.820+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:49:19.840+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:49:19.840+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:49:19.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T20:49:50.036+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:49:50.037+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:49:50.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:49:50.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:49:50.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:49:50.074+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:49:50.073+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:49:50.094+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:49:50.094+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:49:50.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T20:50:20.209+0000] {processor.py:157} INFO - Started process (PID=253) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:50:20.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:50:20.210+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:50:20.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:50:20.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:50:20.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:50:20.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:50:20.274+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:50:20.274+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:50:20.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T20:50:50.419+0000] {processor.py:157} INFO - Started process (PID=255) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:50:50.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:50:50.421+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:50:50.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:50:50.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:50:50.462+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:50:50.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:50:50.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:50:50.484+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:50:50.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T20:51:20.619+0000] {processor.py:157} INFO - Started process (PID=257) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:51:20.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:51:20.620+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:51:20.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:51:20.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:51:20.661+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:51:20.661+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:51:20.682+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:51:20.682+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:51:20.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T20:51:50.866+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:51:50.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:51:50.878+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:51:50.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:51:50.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:51:50.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:51:50.915+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:51:50.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:51:50.934+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:51:50.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T20:52:21.163+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:52:21.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:52:21.164+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:52:21.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:52:21.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:52:21.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:52:21.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:52:21.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:52:21.220+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:52:21.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T20:52:51.461+0000] {processor.py:157} INFO - Started process (PID=263) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:52:51.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:52:51.463+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:52:51.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:52:51.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:52:51.508+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:52:51.508+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:52:51.536+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:52:51.536+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:52:51.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T20:53:21.751+0000] {processor.py:157} INFO - Started process (PID=265) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:53:21.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:53:21.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:53:21.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:53:21.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:53:21.791+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:53:21.791+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:53:21.813+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:53:21.813+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:53:21.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T20:53:51.949+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:53:51.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:53:51.951+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:53:51.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:53:51.962+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:53:51.986+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:53:51.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:53:52.010+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:53:52.009+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:53:52.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T20:54:22.136+0000] {processor.py:157} INFO - Started process (PID=269) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:54:22.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:54:22.137+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:54:22.137+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:54:22.150+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:54:22.177+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:54:22.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:54:22.203+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:54:22.203+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:54:22.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T20:54:52.395+0000] {processor.py:157} INFO - Started process (PID=271) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:54:52.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:54:52.408+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:54:52.407+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:54:52.420+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:54:52.447+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:54:52.447+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:54:52.471+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:54:52.471+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:54:52.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T20:55:22.546+0000] {processor.py:157} INFO - Started process (PID=273) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:55:22.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:55:22.548+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:55:22.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:55:22.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:55:22.585+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:55:22.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:55:22.611+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:55:22.611+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:55:22.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T20:55:52.771+0000] {processor.py:157} INFO - Started process (PID=275) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:55:52.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:55:52.783+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:55:52.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:55:52.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:55:52.822+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:55:52.822+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:55:52.847+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:55:52.847+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:55:52.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T20:56:23.038+0000] {processor.py:157} INFO - Started process (PID=277) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:56:23.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:56:23.039+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:56:23.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:56:23.056+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:56:23.088+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:56:23.088+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:56:23.114+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:56:23.114+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:56:23.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T20:56:53.243+0000] {processor.py:157} INFO - Started process (PID=279) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:56:53.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:56:53.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:56:53.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:56:53.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:56:53.389+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:56:53.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:56:53.454+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:56:53.453+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:56:53.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.275 seconds
[2024-10-25T20:57:23.665+0000] {processor.py:157} INFO - Started process (PID=281) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:57:23.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:57:23.666+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:57:23.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:57:23.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:57:23.712+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:57:23.711+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:57:23.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:57:23.735+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:57:23.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T20:57:53.833+0000] {processor.py:157} INFO - Started process (PID=283) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:57:53.834+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:57:53.834+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:57:53.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:57:53.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:57:53.872+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:57:53.872+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:57:53.897+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:57:53.897+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:57:53.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T20:58:24.091+0000] {processor.py:157} INFO - Started process (PID=285) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:58:24.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:58:24.092+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:58:24.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:58:24.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:58:24.129+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:58:24.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:58:24.151+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:58:24.151+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:58:24.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T20:58:54.310+0000] {processor.py:157} INFO - Started process (PID=287) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:58:54.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:58:54.323+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:58:54.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:58:54.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:58:54.356+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:58:54.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:58:54.378+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:58:54.378+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:58:54.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T20:59:24.546+0000] {processor.py:157} INFO - Started process (PID=289) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:59:24.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:59:24.548+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:59:24.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:59:24.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:59:24.583+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:59:24.583+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:59:24.604+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:59:24.604+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:59:24.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-25T20:59:54.737+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:59:54.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T20:59:54.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:59:54.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:59:54.751+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T20:59:54.779+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:59:54.778+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T20:59:54.804+0000] {logging_mixin.py:149} INFO - [2024-10-25T20:59:54.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T20:59:54.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T21:00:25.007+0000] {processor.py:157} INFO - Started process (PID=293) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:00:25.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:00:25.020+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:00:25.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:00:25.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:00:25.056+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:00:25.056+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:00:25.080+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:00:25.079+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:00:25.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T21:00:55.167+0000] {processor.py:157} INFO - Started process (PID=295) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:00:55.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:00:55.169+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:00:55.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:00:55.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:00:55.212+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:00:55.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:00:55.237+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:00:55.237+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:00:55.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T21:01:25.365+0000] {processor.py:157} INFO - Started process (PID=297) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:01:25.377+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:01:25.377+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:01:25.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:01:25.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:01:25.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:01:25.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:01:25.442+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:01:25.441+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:01:25.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T21:01:55.640+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:01:55.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:01:55.642+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:01:55.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:01:55.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:01:55.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:01:55.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:01:55.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:01:55.701+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:01:55.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T21:02:25.801+0000] {processor.py:157} INFO - Started process (PID=301) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:02:25.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:02:25.803+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:02:25.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:02:25.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:02:25.838+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:02:25.838+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:02:25.861+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:02:25.860+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:02:25.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T21:02:56.066+0000] {processor.py:157} INFO - Started process (PID=303) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:02:56.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:02:56.068+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:02:56.068+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:02:56.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:02:56.104+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:02:56.104+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:02:56.126+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:02:56.126+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:02:56.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:03:26.254+0000] {processor.py:157} INFO - Started process (PID=305) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:03:26.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:03:26.255+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:03:26.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:03:26.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:03:26.301+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:03:26.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:03:26.358+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:03:26.358+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:03:26.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-25T21:03:56.465+0000] {processor.py:157} INFO - Started process (PID=307) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:03:56.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:03:56.466+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:03:56.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:03:56.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:03:56.505+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:03:56.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:03:56.526+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:03:56.526+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:03:56.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:04:26.679+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:04:26.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:04:26.681+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:04:26.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:04:26.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:04:26.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:04:26.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:04:26.737+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:04:26.737+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:04:26.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T21:04:56.846+0000] {processor.py:157} INFO - Started process (PID=311) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:04:56.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:04:56.848+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:04:56.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:04:56.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:04:56.900+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:04:56.900+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:04:56.935+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:04:56.935+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:04:56.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T21:05:27.102+0000] {processor.py:157} INFO - Started process (PID=313) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:05:27.104+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:05:27.105+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:05:27.105+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:05:27.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:05:27.160+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:05:27.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:05:27.194+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:05:27.193+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:05:27.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T21:05:57.246+0000] {processor.py:157} INFO - Started process (PID=315) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:05:57.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:05:57.247+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:05:57.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:05:57.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:05:57.364+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:05:57.364+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:05:57.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:05:57.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:05:57.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.318 seconds
[2024-10-25T21:06:27.772+0000] {processor.py:157} INFO - Started process (PID=317) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:06:27.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:06:27.811+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:06:27.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:06:27.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:06:27.848+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:06:27.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:06:27.869+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:06:27.869+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:06:27.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T21:06:58.108+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:06:58.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:06:58.109+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:06:58.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:06:58.124+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:06:58.155+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:06:58.155+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:06:58.182+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:06:58.182+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:06:58.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T21:07:28.302+0000] {processor.py:157} INFO - Started process (PID=321) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:07:28.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:07:28.304+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:07:28.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:07:28.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:07:28.341+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:07:28.341+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:07:28.362+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:07:28.362+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:07:28.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T21:07:58.596+0000] {processor.py:157} INFO - Started process (PID=323) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:07:58.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:07:58.598+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:07:58.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:07:58.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:07:58.633+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:07:58.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:07:58.654+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:07:58.654+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:07:58.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:08:28.805+0000] {processor.py:157} INFO - Started process (PID=325) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:08:28.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:08:28.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:08:28.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:08:28.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:08:28.852+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:08:28.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:08:28.873+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:08:28.873+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:08:28.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T21:08:59.071+0000] {processor.py:157} INFO - Started process (PID=327) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:08:59.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:08:59.073+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:08:59.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:08:59.085+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:08:59.112+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:08:59.112+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:08:59.135+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:08:59.135+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:08:59.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:09:29.240+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:09:29.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:09:29.242+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:09:29.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:09:29.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:09:29.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:09:29.277+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:09:29.299+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:09:29.299+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:09:29.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T21:09:59.537+0000] {processor.py:157} INFO - Started process (PID=331) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:09:59.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:09:59.538+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:09:59.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:09:59.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:09:59.575+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:09:59.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:09:59.595+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:09:59.595+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:09:59.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T21:10:29.711+0000] {processor.py:157} INFO - Started process (PID=333) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:10:29.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:10:29.712+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:10:29.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:10:29.726+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:10:29.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:10:29.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:10:29.774+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:10:29.774+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:10:29.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T21:10:59.904+0000] {processor.py:157} INFO - Started process (PID=335) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:10:59.905+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:10:59.905+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:10:59.905+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:10:59.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:10:59.950+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:10:59.950+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:10:59.973+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:10:59.973+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:10:59.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T21:11:30.202+0000] {processor.py:157} INFO - Started process (PID=337) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:11:30.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:11:30.204+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:11:30.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:11:30.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:11:30.242+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:11:30.242+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:11:30.265+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:11:30.265+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:11:30.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:12:00.584+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:12:00.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:12:00.585+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:12:00.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:12:01.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:12:01.400+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:12:01.400+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:12:01.878+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:12:01.878+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:12:01.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.320 seconds
[2024-10-25T21:12:32.065+0000] {processor.py:157} INFO - Started process (PID=341) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:12:32.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:12:32.067+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:12:32.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:12:32.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:12:32.123+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:12:32.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:12:32.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:12:32.201+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:12:32.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.177 seconds
[2024-10-25T21:13:02.422+0000] {processor.py:157} INFO - Started process (PID=343) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:13:02.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:13:02.423+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:13:02.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:13:02.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:13:02.459+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:13:02.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:13:02.484+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:13:02.484+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:13:02.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T21:13:32.650+0000] {processor.py:157} INFO - Started process (PID=345) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:13:32.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:13:32.663+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:13:32.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:13:32.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:13:32.706+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:13:32.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:13:32.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:13:32.735+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:13:32.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T21:14:02.832+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:14:02.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:14:02.841+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:14:02.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:14:02.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:14:02.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:14:02.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:14:03.027+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:14:03.026+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:14:03.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.239 seconds
[2024-10-25T21:14:33.232+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:14:33.233+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:14:33.234+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:14:33.233+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:14:33.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:14:33.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:14:33.277+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:14:33.307+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:14:33.307+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:14:33.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T21:15:03.508+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:15:03.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:15:03.510+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:15:03.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:15:03.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:15:03.586+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:15:03.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:15:03.615+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:15:03.615+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:15:03.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-25T21:15:33.678+0000] {processor.py:157} INFO - Started process (PID=353) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:15:33.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:15:33.680+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:15:33.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:15:33.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:15:33.723+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:15:33.723+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:15:33.751+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:15:33.750+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:15:33.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T21:16:03.950+0000] {processor.py:157} INFO - Started process (PID=355) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:16:03.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:16:03.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:16:03.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:16:03.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:16:03.998+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:16:03.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:16:04.031+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:16:04.030+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:16:04.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T21:16:34.226+0000] {processor.py:157} INFO - Started process (PID=357) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:16:34.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:16:34.239+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:16:34.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:16:34.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:16:34.298+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:16:34.297+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:16:34.322+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:16:34.321+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:16:34.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-25T21:17:04.520+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:17:04.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:17:04.522+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:17:04.521+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:17:04.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:17:04.559+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:17:04.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:17:04.581+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:17:04.581+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:17:04.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:17:34.693+0000] {processor.py:157} INFO - Started process (PID=361) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:17:34.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:17:34.706+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:17:34.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:17:34.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:17:34.744+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:17:34.744+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:17:34.768+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:17:34.768+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:17:34.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T21:18:04.905+0000] {processor.py:157} INFO - Started process (PID=363) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:18:04.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:18:04.907+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:18:04.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:18:04.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:18:04.950+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:18:04.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:18:04.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:18:04.975+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:18:04.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T21:18:35.116+0000] {processor.py:157} INFO - Started process (PID=365) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:18:35.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:18:35.118+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:18:35.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:18:35.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:18:35.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:18:35.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:18:35.181+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:18:35.181+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:18:35.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T21:19:05.350+0000] {processor.py:157} INFO - Started process (PID=367) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:19:05.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:19:05.351+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:19:05.351+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:19:05.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:19:05.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:19:05.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:19:05.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:19:05.418+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:19:05.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T21:19:35.507+0000] {processor.py:157} INFO - Started process (PID=369) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:19:35.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:19:35.509+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:19:35.509+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:19:35.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:19:35.549+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:19:35.548+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:19:35.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:19:35.574+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:19:35.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T21:20:05.748+0000] {processor.py:157} INFO - Started process (PID=371) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:20:05.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:20:05.749+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:20:05.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:20:05.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:20:05.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:20:05.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:20:05.818+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:20:05.818+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:20:05.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T21:20:35.927+0000] {processor.py:157} INFO - Started process (PID=373) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:20:35.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:20:35.929+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:20:35.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:20:35.951+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:20:35.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:20:35.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:20:36.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:20:36.011+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:20:36.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T21:21:06.139+0000] {processor.py:157} INFO - Started process (PID=375) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:21:06.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:21:06.140+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:21:06.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:21:06.157+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:21:06.189+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:21:06.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:21:06.216+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:21:06.216+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:21:06.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T21:21:36.413+0000] {processor.py:157} INFO - Started process (PID=377) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:21:36.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:21:36.426+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:21:36.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:21:36.508+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:21:36.533+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:21:36.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:21:36.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:21:36.553+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:21:36.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.161 seconds
[2024-10-25T21:22:06.611+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:22:06.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:22:06.613+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:22:06.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:22:06.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:22:06.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:22:06.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:22:06.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:22:06.684+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:22:06.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T21:22:36.920+0000] {processor.py:157} INFO - Started process (PID=381) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:22:36.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:22:36.922+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:22:36.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:22:36.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:22:37.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:22:37.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:22:37.034+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:22:37.034+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:22:37.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-25T21:23:07.103+0000] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:23:07.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:23:07.104+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:23:07.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:23:07.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:23:07.140+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:23:07.140+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:23:07.164+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:23:07.164+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:23:07.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T21:23:37.295+0000] {processor.py:157} INFO - Started process (PID=385) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:23:37.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:23:37.297+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:23:37.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:23:37.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:23:37.336+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:23:37.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:23:37.359+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:23:37.358+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:23:37.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T21:24:07.518+0000] {processor.py:157} INFO - Started process (PID=387) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:24:07.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:24:07.520+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:24:07.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:24:07.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:24:07.562+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:24:07.561+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:24:07.587+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:24:07.587+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:24:07.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T21:24:37.775+0000] {processor.py:157} INFO - Started process (PID=389) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:24:37.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:24:37.777+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:24:37.776+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:24:37.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:24:37.822+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:24:37.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:24:37.848+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:24:37.848+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:24:37.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T21:25:08.064+0000] {processor.py:157} INFO - Started process (PID=391) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:25:08.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:25:08.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:25:08.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:25:08.134+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:25:08.173+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:25:08.173+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:25:08.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:25:08.199+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:25:08.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-25T21:25:38.383+0000] {processor.py:157} INFO - Started process (PID=393) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:25:38.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:25:38.385+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:25:38.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:25:38.402+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:25:38.428+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:25:38.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:25:38.453+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:25:38.453+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:25:38.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T21:26:08.651+0000] {processor.py:157} INFO - Started process (PID=395) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:26:08.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:26:08.653+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:26:08.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:26:08.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:26:08.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:26:08.707+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:26:08.739+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:26:08.739+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:26:08.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-25T21:26:38.815+0000] {processor.py:157} INFO - Started process (PID=397) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:26:38.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:26:38.817+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:26:38.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:26:38.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:26:38.867+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:26:38.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:26:38.898+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:26:38.898+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:26:38.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T21:27:09.086+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:27:09.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:27:09.088+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:27:09.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:27:09.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:27:09.129+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:27:09.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:27:09.155+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:27:09.155+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:27:09.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T21:27:39.263+0000] {processor.py:157} INFO - Started process (PID=401) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:27:39.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:27:39.265+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:27:39.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:27:39.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:27:39.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:27:39.306+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:27:39.330+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:27:39.330+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:27:39.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T21:28:09.465+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:28:09.466+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:28:09.467+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:28:09.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:28:09.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:28:09.502+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:28:09.502+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:28:09.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:28:09.523+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:28:09.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T21:28:39.669+0000] {processor.py:157} INFO - Started process (PID=405) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:28:39.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:28:39.671+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:28:39.671+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:28:39.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:28:39.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:28:39.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:28:39.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:28:39.734+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:28:39.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T21:29:09.961+0000] {processor.py:157} INFO - Started process (PID=407) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:29:09.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:29:09.965+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:29:09.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:29:10.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:29:10.114+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:29:10.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:29:10.168+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:29:10.167+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:29:10.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.355 seconds
[2024-10-25T21:29:40.368+0000] {processor.py:157} INFO - Started process (PID=409) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:29:40.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:29:40.370+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:29:40.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:29:40.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:29:40.416+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:29:40.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:29:40.481+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:29:40.480+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:29:40.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-25T21:30:10.682+0000] {processor.py:157} INFO - Started process (PID=411) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:30:10.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:30:10.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:30:10.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:30:10.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:30:10.768+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:30:10.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:30:10.810+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:30:10.810+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:30:10.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.164 seconds
[2024-10-25T21:30:41.289+0000] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:30:41.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:30:41.291+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:30:41.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:30:41.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:30:41.502+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:30:41.502+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:30:41.526+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:30:41.525+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:30:41.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.259 seconds
[2024-10-25T21:31:11.687+0000] {processor.py:157} INFO - Started process (PID=415) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:31:11.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:31:11.690+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:31:11.690+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:31:11.707+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:31:11.733+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:31:11.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:31:11.760+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:31:11.760+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:31:11.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T21:31:41.934+0000] {processor.py:157} INFO - Started process (PID=417) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:31:41.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:31:41.948+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:31:41.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:31:41.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:31:41.990+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:31:41.990+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:31:42.018+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:31:42.017+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:31:42.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T21:32:12.100+0000] {processor.py:157} INFO - Started process (PID=419) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:32:12.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:32:12.102+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:32:12.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:32:12.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:32:12.141+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:32:12.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:32:12.165+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:32:12.165+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:32:12.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T21:32:42.318+0000] {processor.py:157} INFO - Started process (PID=421) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:32:42.319+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:32:42.319+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:32:42.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:32:42.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:32:42.458+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:32:42.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:32:42.485+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:32:42.485+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:32:42.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.190 seconds
[2024-10-25T21:33:12.659+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:33:12.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:33:12.661+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:33:12.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:33:12.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:33:12.707+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:33:12.707+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:33:12.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:33:12.738+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:33:12.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T21:33:42.935+0000] {processor.py:157} INFO - Started process (PID=425) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:33:42.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:33:42.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:33:42.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:33:42.953+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:33:42.987+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:33:42.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:33:43.014+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:33:43.014+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:33:43.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-25T21:34:13.116+0000] {processor.py:157} INFO - Started process (PID=427) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:34:13.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:34:13.118+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:34:13.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:34:13.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:34:13.155+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:34:13.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:34:13.180+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:34:13.180+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:34:13.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T21:34:43.352+0000] {processor.py:157} INFO - Started process (PID=429) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:34:43.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:34:43.354+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:34:43.354+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:34:43.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:34:43.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:34:43.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:34:43.413+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:34:43.413+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:34:43.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T21:35:13.550+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:35:13.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:35:13.552+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:35:13.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:35:13.562+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:35:13.588+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:35:13.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:35:13.611+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:35:13.611+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:35:13.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T21:35:43.770+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:35:43.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:35:43.775+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:35:43.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:35:43.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:35:43.841+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:35:43.841+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:35:43.889+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:35:43.888+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:35:43.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.144 seconds
[2024-10-25T21:36:14.006+0000] {processor.py:157} INFO - Started process (PID=435) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:36:14.007+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:36:14.008+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:36:14.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:36:14.023+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:36:14.049+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:36:14.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:36:14.070+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:36:14.069+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:36:14.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:36:44.274+0000] {processor.py:157} INFO - Started process (PID=437) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:36:44.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:36:44.276+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:36:44.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:36:44.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:36:44.320+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:36:44.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:36:44.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:36:44.345+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:36:44.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T21:37:14.518+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:37:14.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:37:14.520+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:37:14.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:37:14.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:37:14.568+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:37:14.567+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:37:14.596+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:37:14.596+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:37:14.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T21:37:44.787+0000] {processor.py:157} INFO - Started process (PID=441) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:37:44.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:37:44.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:37:44.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:37:44.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:37:44.827+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:37:44.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:37:44.850+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:37:44.850+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:37:44.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T21:38:15.033+0000] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:38:15.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:38:15.035+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:38:15.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:38:15.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:38:15.076+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:38:15.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:38:15.099+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:38:15.099+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:38:15.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T21:38:45.194+0000] {processor.py:157} INFO - Started process (PID=445) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:38:45.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:38:45.195+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:38:45.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:38:45.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:38:45.236+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:38:45.236+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:38:45.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:38:45.260+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:38:45.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T21:39:15.358+0000] {processor.py:157} INFO - Started process (PID=447) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:39:15.359+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:39:15.360+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:39:15.360+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:39:15.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:39:15.429+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:39:15.427+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:39:15.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:39:15.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:39:15.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-25T21:39:45.657+0000] {processor.py:157} INFO - Started process (PID=449) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:39:45.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:39:45.659+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:39:45.658+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:39:45.678+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:39:45.709+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:39:45.709+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:39:45.734+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:39:45.734+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:39:45.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T21:40:15.838+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:40:15.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:40:15.851+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:40:15.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:40:15.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:40:15.890+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:40:15.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:40:15.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:40:15.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:40:15.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T21:40:46.096+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:40:46.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:40:46.098+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:40:46.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:40:46.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:40:46.137+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:40:46.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:40:46.163+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:40:46.163+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:40:46.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T21:41:16.261+0000] {processor.py:157} INFO - Started process (PID=455) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:41:16.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:41:16.262+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:41:16.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:41:16.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:41:16.299+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:41:16.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:41:16.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:41:16.321+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:41:16.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T21:41:46.505+0000] {processor.py:157} INFO - Started process (PID=457) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:41:46.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:41:46.507+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:41:46.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:41:46.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:41:46.545+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:41:46.545+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:41:46.566+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:41:46.566+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:41:46.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T21:42:16.683+0000] {processor.py:157} INFO - Started process (PID=459) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:42:16.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:42:16.685+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:42:16.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:42:16.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:42:16.728+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:42:16.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:42:16.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:42:16.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:42:16.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T21:42:46.926+0000] {processor.py:157} INFO - Started process (PID=461) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:42:46.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:42:46.928+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:42:46.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:42:46.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:42:46.973+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:42:46.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:42:47.000+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:42:47.000+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:42:47.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T21:43:17.076+0000] {processor.py:157} INFO - Started process (PID=463) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:43:17.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:43:17.078+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:43:17.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:43:17.089+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:43:17.117+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:43:17.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:43:17.140+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:43:17.140+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:43:17.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T21:43:47.298+0000] {processor.py:157} INFO - Started process (PID=465) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:43:47.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:43:47.300+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:43:47.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:43:47.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:43:47.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:43:47.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:43:47.372+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:43:47.372+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:43:47.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T21:44:17.557+0000] {processor.py:157} INFO - Started process (PID=467) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:44:17.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:44:17.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:44:17.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:44:17.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:44:17.605+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:44:17.605+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:44:17.634+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:44:17.634+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:44:17.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T21:44:47.740+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:44:47.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:44:47.742+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:44:47.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:44:47.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:44:47.789+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:44:47.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:44:47.814+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:44:47.814+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:44:47.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T21:45:17.980+0000] {processor.py:157} INFO - Started process (PID=471) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:45:17.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:45:17.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:45:17.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:45:17.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:45:18.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:45:18.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:45:18.049+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:45:18.049+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:45:18.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T21:45:48.278+0000] {processor.py:157} INFO - Started process (PID=473) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:45:48.280+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:45:48.281+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:45:48.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:45:48.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:45:48.323+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:45:48.323+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:45:48.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:45:48.345+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:45:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T21:46:18.460+0000] {processor.py:157} INFO - Started process (PID=475) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:46:18.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:46:18.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:46:18.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:46:18.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:46:18.509+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:46:18.508+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:46:18.541+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:46:18.541+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:46:18.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T21:46:48.647+0000] {processor.py:157} INFO - Started process (PID=477) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:46:48.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:46:48.660+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:46:48.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:46:48.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:46:48.702+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:46:48.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:46:48.732+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:46:48.732+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:46:48.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T21:47:18.822+0000] {processor.py:157} INFO - Started process (PID=479) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:47:18.823+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:47:18.824+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:47:18.824+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:47:18.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:47:18.863+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:47:18.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:47:18.887+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:47:18.887+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:47:18.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T21:47:49.004+0000] {processor.py:157} INFO - Started process (PID=481) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:47:49.005+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:47:49.006+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:47:49.006+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:47:49.021+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:47:49.050+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:47:49.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:47:49.078+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:47:49.077+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:47:49.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T21:48:19.188+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:48:19.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:48:19.189+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:48:19.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:48:19.201+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:48:19.229+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:48:19.229+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:48:19.251+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:48:19.251+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:48:19.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:48:49.369+0000] {processor.py:157} INFO - Started process (PID=485) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:48:49.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:48:49.370+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:48:49.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:48:49.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:48:49.408+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:48:49.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:48:49.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:48:49.432+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:48:49.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:49:19.650+0000] {processor.py:157} INFO - Started process (PID=487) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:49:19.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:49:19.652+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:49:19.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:49:19.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:49:19.693+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:49:19.693+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:49:19.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:49:19.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:49:19.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T21:49:49.807+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:49:49.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:49:49.809+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:49:49.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:49:49.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:49:49.850+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:49:49.849+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:49:49.872+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:49:49.872+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:49:49.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T21:50:20.080+0000] {processor.py:157} INFO - Started process (PID=491) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:50:20.082+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:50:20.083+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:50:20.083+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:50:20.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:50:20.129+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:50:20.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:50:20.158+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:50:20.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:50:20.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T21:50:50.367+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:50:50.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:50:50.369+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:50:50.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:50:50.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:50:50.406+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:50:50.406+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:50:50.426+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:50:50.426+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:50:50.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:51:20.539+0000] {processor.py:157} INFO - Started process (PID=495) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:51:20.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:51:20.540+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:51:20.540+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:51:20.552+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:51:20.578+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:51:20.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:51:20.599+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:51:20.599+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:51:20.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:51:50.791+0000] {processor.py:157} INFO - Started process (PID=497) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:51:50.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:51:50.793+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:51:50.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:51:50.807+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:51:50.834+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:51:50.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:51:50.857+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:51:50.857+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:51:50.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T21:52:20.958+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:52:20.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:52:20.959+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:52:20.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:52:20.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:52:20.995+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:52:20.995+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:52:21.021+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:52:21.020+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:52:21.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T21:52:51.197+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:52:51.199+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:52:51.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:52:51.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:52:51.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:52:51.237+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:52:51.237+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:52:51.263+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:52:51.263+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:52:51.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T21:53:21.477+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:53:21.477+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:53:21.478+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:53:21.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:53:21.489+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:53:21.515+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:53:21.515+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:53:21.535+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:53:21.535+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:53:21.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:53:51.638+0000] {processor.py:157} INFO - Started process (PID=505) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:53:51.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:53:51.651+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:53:51.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:53:51.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:53:51.689+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:53:51.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:53:51.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:53:51.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:53:51.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T21:54:21.850+0000] {processor.py:157} INFO - Started process (PID=507) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:54:21.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:54:21.851+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:54:21.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:54:21.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:54:21.891+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:54:21.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:54:21.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:54:21.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:54:21.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T21:54:52.108+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:54:52.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:54:52.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:54:52.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:54:52.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:54:52.152+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:54:52.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:54:52.175+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:54:52.175+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:54:52.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T21:55:22.257+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:55:22.257+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:55:22.258+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:55:22.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:55:22.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:55:22.299+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:55:22.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:55:22.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:55:22.321+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:55:22.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T21:55:52.478+0000] {processor.py:157} INFO - Started process (PID=513) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:55:52.479+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:55:52.480+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:55:52.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:55:52.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:55:52.525+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:55:52.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:55:52.549+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:55:52.549+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:55:52.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T21:56:22.770+0000] {processor.py:157} INFO - Started process (PID=515) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:56:22.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:56:22.772+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:56:22.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:56:22.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:56:22.815+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:56:22.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:56:22.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:56:22.835+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:56:22.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T21:56:52.943+0000] {processor.py:157} INFO - Started process (PID=517) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:56:52.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:56:52.945+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:56:52.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:56:52.956+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:56:52.981+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:56:52.981+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:56:53.002+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:56:53.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:56:53.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T21:57:23.219+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:57:23.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:57:23.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:57:23.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:57:23.233+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:57:23.259+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:57:23.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:57:23.282+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:57:23.282+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:57:23.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T21:57:53.397+0000] {processor.py:157} INFO - Started process (PID=521) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:57:53.398+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T21:57:53.399+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:57:53.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:57:53.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T21:57:53.442+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:57:53.442+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T21:57:53.468+0000] {logging_mixin.py:149} INFO - [2024-10-25T21:57:53.468+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T21:57:53.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T22:02:20.426+0000] {processor.py:157} INFO - Started process (PID=24) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:02:20.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:02:20.429+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:02:20.428+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:02:20.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:02:20.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:02:20.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:02:20.647+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:02:20.647+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:02:20.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.240 seconds
[2024-10-25T22:02:50.818+0000] {processor.py:157} INFO - Started process (PID=26) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:02:50.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:02:50.820+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:02:50.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:02:50.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:02:50.969+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:02:50.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:02:50.992+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:02:50.992+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:02:51.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-25T22:03:21.180+0000] {processor.py:157} INFO - Started process (PID=28) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:03:21.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:03:21.181+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:03:21.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:03:21.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:03:21.347+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:03:21.347+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:03:21.372+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:03:21.372+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:03:21.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.214 seconds
[2024-10-25T22:03:51.640+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:03:51.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:03:51.642+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:03:51.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:03:51.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:03:51.678+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:03:51.678+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:03:51.699+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:03:51.699+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:03:51.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T22:04:21.880+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:04:21.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:04:21.881+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:04:21.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:04:21.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:04:21.919+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:04:21.919+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:04:21.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:04:21.943+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:04:21.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T22:04:52.046+0000] {processor.py:157} INFO - Started process (PID=34) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:04:52.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:04:52.048+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:04:52.048+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:04:52.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:04:52.099+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:04:52.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:04:52.129+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:04:52.129+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:04:52.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T22:05:22.228+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:05:22.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:05:22.230+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:05:22.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:05:22.245+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:05:22.278+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:05:22.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:05:22.300+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:05:22.300+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:05:22.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T22:05:52.433+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:05:52.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:05:52.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:05:52.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:05:52.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:05:52.478+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:05:52.477+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:05:52.498+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:05:52.498+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:05:52.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T22:06:22.622+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:06:22.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:06:22.623+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:06:22.623+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:06:22.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:06:22.671+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:06:22.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:06:22.702+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:06:22.702+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:06:22.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T22:06:52.808+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:06:52.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:06:52.811+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:06:52.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:06:52.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:06:52.849+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:06:52.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:06:52.871+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:06:52.871+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:06:52.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T22:07:23.015+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:07:23.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:07:23.017+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:07:23.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:07:23.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:07:23.060+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:07:23.060+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:07:23.087+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:07:23.087+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:07:23.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T22:07:53.261+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:07:53.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:07:53.263+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:07:53.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:07:53.276+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:07:53.302+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:07:53.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:07:53.325+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:07:53.324+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:07:53.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:08:23.434+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:08:23.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:08:23.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:08:23.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:08:23.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:08:23.475+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:08:23.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:08:23.501+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:08:23.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:08:23.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T22:08:53.630+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:08:53.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:08:53.631+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:08:53.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:08:53.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:08:53.671+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:08:53.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:08:53.694+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:08:53.694+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:08:53.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T22:09:23.801+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:09:23.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:09:23.803+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:09:23.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:09:23.818+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:09:23.849+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:09:23.849+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:09:23.874+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:09:23.874+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:09:23.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T22:09:53.997+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:09:53.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:09:53.999+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:09:53.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:09:54.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:09:54.050+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:09:54.049+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:09:54.072+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:09:54.071+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:09:54.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T22:10:24.170+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:10:24.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:10:24.171+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:10:24.171+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:10:24.186+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:10:24.214+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:10:24.213+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:10:24.240+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:10:24.240+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:10:24.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T22:10:54.375+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:10:54.377+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:10:54.378+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:10:54.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:10:54.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:10:54.423+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:10:54.423+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:10:54.446+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:10:54.446+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:10:54.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T22:11:24.640+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:11:24.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:11:24.642+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:11:24.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:11:24.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:11:24.691+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:11:24.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:11:24.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:11:24.717+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:11:24.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T22:11:54.884+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:11:54.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:11:54.887+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:11:54.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:11:54.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:11:54.931+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:11:54.931+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:11:54.964+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:11:54.964+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:11:54.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T22:12:25.056+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:12:25.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:12:25.058+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:12:25.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:12:25.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:12:25.117+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:12:25.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:12:25.149+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:12:25.149+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:12:25.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-25T22:12:55.276+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:12:55.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:12:55.277+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:12:55.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:12:55.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:12:55.318+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:12:55.318+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:12:55.342+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:12:55.342+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:12:55.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T22:13:25.548+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:13:25.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:13:25.549+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:13:25.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:13:25.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:13:25.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:13:25.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:13:25.632+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:13:25.632+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:13:25.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T22:13:55.694+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:13:55.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:13:55.696+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:13:55.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:13:55.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:13:55.738+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:13:55.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:13:55.764+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:13:55.763+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:13:55.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T22:14:25.954+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:14:25.955+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:14:25.955+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:14:25.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:14:25.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:14:25.993+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:14:25.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:14:26.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:14:26.013+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:14:26.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-25T22:14:56.226+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:14:56.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:14:56.228+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:14:56.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:14:56.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:14:56.266+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:14:56.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:14:56.287+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:14:56.287+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:14:56.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:15:26.403+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:15:26.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:15:26.405+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:15:26.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:15:26.419+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:15:26.446+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:15:26.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:15:26.470+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:15:26.470+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:15:26.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T22:15:56.650+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:15:56.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:15:56.652+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:15:56.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:15:56.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:15:56.688+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:15:56.688+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:15:56.710+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:15:56.710+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:15:56.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T22:16:26.798+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:16:26.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:16:26.800+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:16:26.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:16:26.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:16:26.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:16:26.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:16:26.867+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:16:26.867+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:16:26.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T22:16:57.009+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:16:57.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:16:57.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:16:57.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:16:57.025+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:16:57.053+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:16:57.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:16:57.076+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:16:57.076+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:16:57.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T22:17:27.179+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:17:27.179+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:17:27.180+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:17:27.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:17:27.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:17:27.218+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:17:27.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:17:27.240+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:17:27.240+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:17:27.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:17:57.411+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:17:57.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:17:57.413+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:17:57.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:17:57.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:17:57.453+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:17:57.453+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:17:57.478+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:17:57.478+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:17:57.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T22:18:27.625+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:18:27.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:18:27.627+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:18:27.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:18:27.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:18:27.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:18:27.684+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:18:27.713+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:18:27.713+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:18:27.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T22:18:57.801+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:18:57.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:18:57.803+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:18:57.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:18:57.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:18:57.840+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:18:57.840+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:18:57.862+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:18:57.862+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:18:57.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T22:19:28.007+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:19:28.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:19:28.009+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:19:28.009+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:19:28.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:19:28.047+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:19:28.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:19:28.068+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:19:28.068+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:19:28.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T22:19:58.152+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:19:58.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:19:58.154+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:19:58.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:19:58.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:19:58.193+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:19:58.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:19:58.215+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:19:58.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:19:58.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:20:20.216+0000] {processor.py:157} INFO - Started process (PID=24) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:20:20.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:20:20.218+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:20:20.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:20:20.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:20:20.291+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:20:20.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:20:20.320+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:20:20.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:20:20.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-25T22:20:50.410+0000] {processor.py:157} INFO - Started process (PID=26) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:20:50.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:20:50.414+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:20:50.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:20:50.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:20:50.468+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:20:50.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:20:50.493+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:20:50.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:20:50.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T22:21:20.662+0000] {processor.py:157} INFO - Started process (PID=28) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:21:20.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:21:20.663+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:21:20.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:21:20.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:21:20.704+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:21:20.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:21:20.730+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:21:20.730+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:21:20.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T22:21:50.826+0000] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:21:50.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:21:50.829+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:21:50.829+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:21:50.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:21:50.886+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:21:50.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:21:50.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:21:50.916+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:21:50.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-25T22:22:21.097+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:22:21.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:22:21.098+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:22:21.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:22:21.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:22:21.141+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:22:21.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:22:21.167+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:22:21.167+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:22:21.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T22:22:51.257+0000] {processor.py:157} INFO - Started process (PID=34) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:22:51.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:22:51.260+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:22:51.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:22:51.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:22:51.312+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:22:51.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:22:51.335+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:22:51.335+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:22:51.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T22:23:21.525+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:23:21.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:23:21.526+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:23:21.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:23:21.538+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:23:21.563+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:23:21.563+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:23:21.585+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:23:21.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:23:21.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T22:23:51.693+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:23:51.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:23:51.695+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:23:51.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:23:51.706+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:23:51.731+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:23:51.731+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:23:51.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:23:51.754+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:23:51.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:24:21.965+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:24:21.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:24:21.966+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:24:21.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:24:21.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:24:22.012+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:24:22.012+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:24:22.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:24:22.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:24:22.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T22:24:52.124+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:24:52.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:24:52.136+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:24:52.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:24:52.149+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:24:52.177+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:24:52.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:24:52.203+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:24:52.203+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:24:52.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T22:25:22.391+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:25:22.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:25:22.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:25:22.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:25:22.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:25:22.429+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:25:22.429+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:25:22.452+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:25:22.452+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:25:22.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T22:25:52.558+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:25:52.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:25:52.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:25:52.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:25:52.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:25:52.604+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:25:52.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:25:52.628+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:25:52.628+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:25:52.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T22:26:22.751+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:26:22.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:26:22.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:26:22.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:26:22.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:26:22.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:26:22.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:26:22.811+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:26:22.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:26:22.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:26:53.024+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:26:53.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:26:53.037+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:26:53.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:26:53.054+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:26:53.086+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:26:53.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:26:53.111+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:26:53.111+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:26:53.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T22:27:23.218+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:27:23.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:27:23.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:27:23.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:27:23.233+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:27:23.259+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:27:23.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:27:23.280+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:27:23.280+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:27:23.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T22:27:53.502+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:27:53.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:27:53.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:27:53.504+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:27:53.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:27:53.541+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:27:53.541+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:27:53.724+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:27:53.724+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:27:53.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.243 seconds
[2024-10-25T22:28:23.898+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:28:23.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:28:23.900+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:28:23.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:28:23.913+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:28:23.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:28:23.941+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:28:24.062+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:28:24.062+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:28:24.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.186 seconds
[2024-10-25T22:28:54.233+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:28:54.234+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:28:54.235+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:28:54.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:28:54.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:28:54.273+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:28:54.273+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:28:54.374+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:28:54.374+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:28:54.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-25T22:29:24.616+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:29:24.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:29:24.617+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:29:24.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:29:24.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:29:24.735+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:29:24.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:29:24.755+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:29:24.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:29:24.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-25T22:29:54.805+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:29:54.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:29:54.807+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:29:54.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:29:54.818+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:29:54.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:29:54.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:29:54.865+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:29:54.865+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:29:54.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T22:30:24.983+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:30:24.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:30:24.984+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:30:24.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:30:24.995+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:30:25.020+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:30:25.020+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:30:25.040+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:30:25.040+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:30:25.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.161 seconds
[2024-10-25T22:30:55.309+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:30:55.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:30:55.312+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:30:55.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:30:55.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:30:55.349+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:30:55.349+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:30:55.455+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:30:55.455+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:30:55.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.167 seconds
[2024-10-25T22:31:25.637+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:31:25.638+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:31:25.639+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:31:25.638+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:31:25.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:31:25.676+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:31:25.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:31:25.802+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:31:25.802+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:31:25.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-25T22:31:55.987+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:31:55.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:31:55.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:31:55.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:31:56.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:31:56.113+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:31:56.113+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:31:56.134+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:31:56.134+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:31:56.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.167 seconds
[2024-10-25T22:32:26.311+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:32:26.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:32:26.313+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:32:26.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:32:26.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:32:26.439+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:32:26.439+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:32:26.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:32:26.461+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:32:26.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.170 seconds
[2024-10-25T22:32:56.664+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:32:56.665+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:32:56.666+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:32:56.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:32:56.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:32:56.703+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:32:56.703+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:32:56.727+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:32:56.727+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:32:56.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T22:33:26.858+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:33:26.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:33:26.860+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:33:26.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:33:26.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:33:26.904+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:33:26.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:33:26.933+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:33:26.932+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:33:27.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.210 seconds
[2024-10-25T22:33:57.196+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:33:57.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:33:57.198+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:33:57.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:33:57.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:33:57.235+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:33:57.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:33:57.362+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:33:57.362+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:33:57.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.188 seconds
[2024-10-25T22:34:27.553+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:34:27.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:34:27.554+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:34:27.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:34:27.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:34:27.594+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:34:27.593+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:34:27.724+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:34:27.724+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:34:27.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-25T22:34:57.914+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:34:57.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:34:57.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:34:57.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:34:57.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:34:58.090+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:34:58.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:34:58.111+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:34:58.111+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:34:58.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.218 seconds
[2024-10-25T22:35:28.267+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:35:28.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:35:28.268+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:35:28.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:35:28.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:35:28.393+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:35:28.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:35:28.412+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:35:28.412+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:35:28.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-25T22:35:58.598+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:35:58.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:35:58.604+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:35:58.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:35:58.619+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:35:58.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:35:58.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:35:58.673+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:35:58.673+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:35:58.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-25T22:36:28.736+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:36:28.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:36:28.737+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:36:28.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:36:28.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:36:28.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:36:28.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:36:28.816+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:36:28.816+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:36:28.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-25T22:36:59.091+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:36:59.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:36:59.093+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:36:59.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:36:59.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:36:59.133+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:36:59.133+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:36:59.248+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:36:59.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:36:59.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.178 seconds
[2024-10-25T22:37:29.435+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:37:29.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:37:29.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:37:29.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:37:29.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:37:29.474+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:37:29.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:37:29.588+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:37:29.587+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:37:29.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.174 seconds
[2024-10-25T22:37:59.764+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:37:59.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:37:59.766+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:37:59.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:37:59.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:37:59.897+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:37:59.897+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:37:59.919+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:37:59.919+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:37:59.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.175 seconds
[2024-10-25T22:38:30.064+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:38:30.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:38:30.066+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:38:30.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:38:30.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:38:30.217+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:38:30.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:38:30.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:38:30.238+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:38:30.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.196 seconds
[2024-10-25T22:39:00.433+0000] {processor.py:157} INFO - Started process (PID=98) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:39:00.445+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:39:00.446+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:39:00.446+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:39:00.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:39:00.481+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:39:00.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:39:00.501+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:39:00.501+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:39:00.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T22:39:30.621+0000] {processor.py:157} INFO - Started process (PID=100) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:39:30.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:39:30.623+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:39:30.622+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:39:30.633+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:39:30.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:39:30.662+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:39:30.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:39:30.684+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:39:30.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-25T22:40:00.855+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:40:00.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:40:00.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:40:00.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:40:00.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:40:00.898+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:40:00.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:40:01.009+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:40:01.009+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:40:01.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.174 seconds
[2024-10-25T22:40:31.219+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:40:31.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:40:31.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:40:31.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:40:31.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:40:31.257+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:40:31.256+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:40:31.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:40:31.367+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:40:31.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-25T22:41:01.532+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:41:01.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:41:01.544+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:41:01.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:41:01.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:41:01.681+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:41:01.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:41:01.705+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:41:01.704+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:41:01.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T22:41:31.864+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:41:31.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:41:31.865+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:41:31.865+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:41:31.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:41:31.985+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:41:31.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:41:32.003+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:41:32.003+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:41:32.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-25T22:42:02.174+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:42:02.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:42:02.176+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:42:02.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:42:02.188+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:42:02.214+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:42:02.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:42:02.235+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:42:02.235+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:42:02.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T22:42:32.327+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:42:32.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:42:32.329+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:42:32.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:42:32.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:42:32.377+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:42:32.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:42:32.418+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:42:32.418+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:42:32.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.211 seconds
[2024-10-25T22:43:02.704+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:43:02.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:43:02.717+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:43:02.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:43:02.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:43:02.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:43:02.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:43:02.882+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:43:02.882+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:43:02.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.202 seconds
[2024-10-25T22:43:33.068+0000] {processor.py:157} INFO - Started process (PID=116) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:43:33.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:43:33.069+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:43:33.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:43:33.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:43:33.107+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:43:33.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:43:33.217+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:43:33.217+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:43:33.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.167 seconds
[2024-10-25T22:44:03.415+0000] {processor.py:157} INFO - Started process (PID=118) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:44:03.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:44:03.417+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:44:03.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:44:03.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:44:03.571+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:44:03.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:44:03.590+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:44:03.590+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:44:03.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.194 seconds
[2024-10-25T22:44:33.761+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:44:33.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:44:33.762+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:44:33.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:44:33.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:44:33.909+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:44:33.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:44:33.928+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:44:33.928+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:44:33.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.188 seconds
[2024-10-25T22:45:04.207+0000] {processor.py:157} INFO - Started process (PID=122) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:45:04.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:45:04.209+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:45:04.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:45:04.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:45:04.247+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:45:04.246+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:45:04.269+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:45:04.269+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:45:04.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T22:45:34.393+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:45:34.394+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:45:34.394+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:45:34.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:45:34.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:45:34.433+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:45:34.432+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:45:34.457+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:45:34.457+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:45:34.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T22:46:04.631+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:46:04.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:46:04.633+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:46:04.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:46:04.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:46:04.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:46:04.684+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:46:04.710+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:46:04.710+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:46:04.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T22:46:34.794+0000] {processor.py:157} INFO - Started process (PID=128) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:46:34.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:46:34.795+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:46:34.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:46:34.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:46:34.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:46:34.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:46:34.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:46:34.856+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:46:34.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T22:47:05.032+0000] {processor.py:157} INFO - Started process (PID=130) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:47:05.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:47:05.034+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:47:05.034+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:47:05.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:47:05.075+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:47:05.075+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:47:05.100+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:47:05.100+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:47:05.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T22:47:35.213+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:47:35.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:47:35.214+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:47:35.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:47:35.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:47:35.253+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:47:35.253+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:47:35.274+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:47:35.274+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:47:35.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T22:48:05.433+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:48:05.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:48:05.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:48:05.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:48:05.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:48:05.473+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:48:05.473+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:48:05.495+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:48:05.495+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:48:05.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T22:48:35.629+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:48:35.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:48:35.630+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:48:35.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:48:35.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:48:35.666+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:48:35.666+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:48:35.688+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:48:35.687+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:48:35.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T22:49:05.885+0000] {processor.py:157} INFO - Started process (PID=138) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:49:05.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:49:05.887+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:49:05.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:49:05.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:49:05.925+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:49:05.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:49:05.950+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:49:05.950+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:49:05.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T22:49:36.040+0000] {processor.py:157} INFO - Started process (PID=140) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:49:36.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:49:36.042+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:49:36.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:49:36.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:49:36.085+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:49:36.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:49:36.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:49:36.110+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:49:36.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T22:50:06.261+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:50:06.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:50:06.262+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:50:06.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:50:06.276+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:50:06.304+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:50:06.304+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:50:06.328+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:50:06.327+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:50:06.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T22:50:36.430+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:50:36.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:50:36.432+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:50:36.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:50:36.443+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:50:36.469+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:50:36.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:50:36.489+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:50:36.489+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:50:36.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T22:51:06.681+0000] {processor.py:157} INFO - Started process (PID=146) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:51:06.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:51:06.684+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:51:06.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:51:06.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:51:06.726+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:51:06.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:51:06.749+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:51:06.748+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:51:06.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T22:51:36.932+0000] {processor.py:157} INFO - Started process (PID=148) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:51:36.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:51:36.934+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:51:36.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:51:36.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:51:36.983+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:51:36.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:51:37.009+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:51:37.008+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:51:37.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T22:52:07.108+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:52:07.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:52:07.110+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:52:07.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:52:07.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:52:07.148+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:52:07.148+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:52:07.172+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:52:07.172+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:52:07.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T22:52:37.333+0000] {processor.py:157} INFO - Started process (PID=152) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:52:37.334+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:52:37.334+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:52:37.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:52:37.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:52:37.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:52:37.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:52:37.402+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:52:37.402+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:52:37.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T22:53:07.516+0000] {processor.py:157} INFO - Started process (PID=154) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:53:07.517+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:53:07.518+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:53:07.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:53:07.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:53:07.556+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:53:07.556+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:53:07.578+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:53:07.578+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:53:07.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T22:53:37.786+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:53:37.787+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:53:37.787+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:53:37.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:53:37.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:53:37.826+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:53:37.825+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:53:37.848+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:53:37.848+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:53:37.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T22:54:07.986+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:54:07.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:54:07.988+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:54:07.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:54:08.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:54:08.026+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:54:08.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:54:08.048+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:54:08.048+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:54:08.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T22:54:38.191+0000] {processor.py:157} INFO - Started process (PID=160) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:54:38.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:54:38.192+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:54:38.192+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:54:38.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:54:38.234+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:54:38.234+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:54:38.258+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:54:38.258+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:54:38.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T22:55:08.423+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:55:08.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:55:08.425+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:55:08.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:55:08.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:55:08.466+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:55:08.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:55:08.492+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:55:08.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:55:08.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T22:55:38.606+0000] {processor.py:157} INFO - Started process (PID=164) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:55:38.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:55:38.607+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:55:38.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:55:38.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:55:38.650+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:55:38.650+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:55:38.672+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:55:38.672+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:55:38.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T22:56:08.853+0000] {processor.py:157} INFO - Started process (PID=166) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:56:08.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:56:08.855+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:56:08.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:56:08.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:56:08.894+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:56:08.894+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:56:08.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:56:08.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:56:08.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T22:56:39.119+0000] {processor.py:157} INFO - Started process (PID=168) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:56:39.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:56:39.121+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:56:39.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:56:39.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:56:39.173+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:56:39.173+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:56:39.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:56:39.199+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:56:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T22:57:09.389+0000] {processor.py:157} INFO - Started process (PID=170) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:57:09.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:57:09.401+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:57:09.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:57:09.413+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:57:09.438+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:57:09.438+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:57:09.459+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:57:09.459+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:57:09.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T22:57:39.562+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:57:39.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:57:39.564+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:57:39.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:57:39.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:57:39.612+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:57:39.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:57:39.641+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:57:39.641+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:57:39.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T22:58:09.782+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:58:09.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:58:09.784+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:58:09.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:58:09.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:58:09.821+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:58:09.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:58:09.841+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:58:09.841+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:58:09.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T22:58:40.010+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:58:40.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:58:40.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:58:40.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:58:40.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:58:40.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:58:40.051+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:58:40.074+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:58:40.074+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:58:40.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T22:59:10.197+0000] {processor.py:157} INFO - Started process (PID=178) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:59:10.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:59:10.198+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:59:10.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:59:10.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:59:10.243+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:59:10.243+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:59:10.267+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:59:10.267+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:59:10.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T22:59:40.382+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:59:40.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T22:59:40.383+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:59:40.383+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:59:40.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T22:59:40.449+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:59:40.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T22:59:40.502+0000] {logging_mixin.py:149} INFO - [2024-10-25T22:59:40.502+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T22:59:40.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.149 seconds
[2024-10-25T23:00:10.688+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:00:10.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:00:10.690+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:00:10.690+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:00:10.706+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:00:10.736+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:00:10.736+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:00:10.766+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:00:10.766+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:00:10.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T23:00:40.865+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:00:40.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:00:40.866+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:00:40.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:00:40.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:00:40.917+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:00:40.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:00:40.943+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:00:40.943+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:00:40.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T23:01:11.049+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:01:11.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:01:11.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:01:11.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:01:11.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:01:11.093+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:01:11.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:01:11.114+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:01:11.114+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:01:11.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:01:41.304+0000] {processor.py:157} INFO - Started process (PID=188) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:01:41.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:01:41.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:01:41.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:01:41.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:01:41.345+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:01:41.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:01:41.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:01:41.367+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:01:41.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:02:11.447+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:02:11.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:02:11.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:02:11.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:02:11.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:02:11.488+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:02:11.488+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:02:11.516+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:02:11.515+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:02:11.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:02:41.684+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:02:41.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:02:41.686+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:02:41.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:02:41.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:02:41.729+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:02:41.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:02:41.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:02:41.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:02:41.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:03:11.842+0000] {processor.py:157} INFO - Started process (PID=194) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:03:11.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:03:11.843+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:03:11.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:03:11.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:03:11.881+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:03:11.881+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:03:11.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:03:11.903+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:03:11.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:03:42.114+0000] {processor.py:157} INFO - Started process (PID=196) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:03:42.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:03:42.127+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:03:42.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:03:42.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:03:42.162+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:03:42.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:03:42.184+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:03:42.184+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:03:42.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T23:04:12.282+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:04:12.282+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:04:12.283+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:04:12.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:04:12.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:04:12.322+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:04:12.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:04:12.343+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:04:12.343+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:04:12.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T23:04:42.508+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:04:42.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:04:42.510+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:04:42.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:04:42.525+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:04:42.557+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:04:42.557+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:04:42.584+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:04:42.584+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:04:42.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T23:05:12.764+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:05:12.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:05:12.765+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:05:12.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:05:12.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:05:12.807+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:05:12.807+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:05:12.830+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:05:12.830+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:05:12.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:05:42.995+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:05:42.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:05:42.997+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:05:42.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:05:43.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:05:43.032+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:05:43.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:05:43.052+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:05:43.052+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:05:43.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T23:06:13.179+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:06:13.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:06:13.180+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:06:13.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:06:13.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:06:13.217+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:06:13.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:06:13.240+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:06:13.239+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:06:13.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:06:43.458+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:06:43.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:06:43.461+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:06:43.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:06:43.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:06:43.501+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:06:43.501+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:06:43.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:06:43.523+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:06:43.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T23:07:13.691+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:07:13.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:07:13.692+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:07:13.692+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:07:13.705+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:07:13.732+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:07:13.732+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:07:13.753+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:07:13.753+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:07:13.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:07:43.885+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:07:43.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:07:43.898+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:07:43.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:07:43.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:07:43.936+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:07:43.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:07:43.957+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:07:43.956+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:07:43.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:08:14.115+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:08:14.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:08:14.117+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:08:14.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:08:14.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:08:14.154+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:08:14.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:08:14.175+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:08:14.175+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:08:14.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T23:08:44.385+0000] {processor.py:157} INFO - Started process (PID=216) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:08:44.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:08:44.387+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:08:44.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:08:44.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:08:44.429+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:08:44.429+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:08:44.454+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:08:44.454+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:08:44.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T23:09:14.617+0000] {processor.py:157} INFO - Started process (PID=218) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:09:14.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:09:14.618+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:09:14.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:09:14.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:09:14.662+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:09:14.662+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:09:14.692+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:09:14.692+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:09:14.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.153 seconds
[2024-10-25T23:09:44.867+0000] {processor.py:157} INFO - Started process (PID=220) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:09:44.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:09:44.869+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:09:44.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:09:44.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:09:44.905+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:09:44.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:09:44.926+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:09:44.926+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:09:44.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T23:10:15.166+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:10:15.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:10:15.168+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:10:15.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:10:15.179+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:10:15.205+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:10:15.204+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:10:15.226+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:10:15.226+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:10:15.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-25T23:10:45.364+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:10:45.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:10:45.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:10:45.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:10:45.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:10:45.410+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:10:45.410+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:10:45.436+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:10:45.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:10:45.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T23:11:15.559+0000] {processor.py:157} INFO - Started process (PID=226) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:11:15.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:11:15.560+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:11:15.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:11:15.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:11:15.601+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:11:15.601+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:11:15.629+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:11:15.628+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:11:15.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:11:45.843+0000] {processor.py:157} INFO - Started process (PID=228) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:11:45.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:11:45.855+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:11:45.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:11:45.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:11:45.913+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:11:45.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:11:45.941+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:11:45.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:11:45.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-25T23:12:16.129+0000] {processor.py:157} INFO - Started process (PID=230) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:12:16.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:12:16.130+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:12:16.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:12:16.142+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:12:16.169+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:12:16.169+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:12:16.191+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:12:16.191+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:12:16.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T23:12:46.286+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:12:46.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:12:46.288+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:12:46.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:12:46.300+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:12:46.327+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:12:46.327+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:12:46.352+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:12:46.351+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:12:46.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T23:13:16.506+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:13:16.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:13:16.507+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:13:16.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:13:16.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:13:16.550+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:13:16.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:13:16.575+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:13:16.574+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:13:16.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:13:46.747+0000] {processor.py:157} INFO - Started process (PID=236) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:13:46.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:13:46.750+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:13:46.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:13:46.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:13:46.795+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:13:46.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:13:46.826+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:13:46.826+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:13:46.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-25T23:14:16.903+0000] {processor.py:157} INFO - Started process (PID=238) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:14:16.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:14:16.905+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:14:16.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:14:16.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:14:16.952+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:14:16.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:14:16.984+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:14:16.983+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:14:17.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T23:14:47.145+0000] {processor.py:157} INFO - Started process (PID=240) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:14:47.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:14:47.148+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:14:47.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:14:47.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:14:47.192+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:14:47.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:14:47.218+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:14:47.218+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:14:47.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:15:17.433+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:15:17.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:15:17.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:15:17.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:15:17.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:15:17.476+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:15:17.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:15:17.497+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:15:17.497+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:15:17.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:15:47.604+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:15:47.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:15:47.608+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:15:47.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:15:47.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:15:47.654+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:15:47.654+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:15:47.713+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:15:47.713+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:15:47.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-25T23:16:17.921+0000] {processor.py:157} INFO - Started process (PID=246) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:16:17.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:16:17.923+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:16:17.923+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:16:17.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:16:17.961+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:16:17.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:16:17.982+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:16:17.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:16:18.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:16:48.115+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:16:48.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:16:48.127+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:16:48.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:16:48.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:16:48.166+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:16:48.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:16:48.196+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:16:48.196+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:16:48.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T23:17:18.390+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:17:18.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:17:18.392+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:17:18.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:17:18.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:17:18.435+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:17:18.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:17:18.463+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:17:18.462+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:17:18.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T23:17:48.572+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:17:48.574+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:17:48.574+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:17:48.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:17:48.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:17:48.611+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:17:48.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:17:48.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:17:48.645+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:17:48.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T23:18:18.789+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:18:18.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:18:18.791+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:18:18.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:18:18.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:18:18.830+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:18:18.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:18:18.853+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:18:18.852+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:18:18.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T23:18:48.966+0000] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:18:48.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:18:48.968+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:18:48.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:18:48.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:18:49.011+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:18:49.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:18:49.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:18:49.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:18:49.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:19:19.154+0000] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:19:19.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:19:19.156+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:19:19.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:19:19.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:19:19.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:19:19.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:19:19.232+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:19:19.232+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:19:19.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-25T23:19:49.436+0000] {processor.py:157} INFO - Started process (PID=260) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:19:49.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:19:49.437+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:19:49.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:19:49.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:19:49.474+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:19:49.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:19:49.496+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:19:49.496+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:19:49.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:20:19.640+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:20:19.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:20:19.642+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:20:19.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:20:19.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:20:19.679+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:20:19.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:20:19.701+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:20:19.701+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:20:19.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:20:49.935+0000] {processor.py:157} INFO - Started process (PID=264) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:20:49.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:20:49.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:20:49.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:20:49.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:20:49.975+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:20:49.974+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:20:49.996+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:20:49.996+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:20:50.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:21:20.143+0000] {processor.py:157} INFO - Started process (PID=266) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:21:20.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:21:20.146+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:21:20.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:21:20.156+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:21:20.183+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:21:20.183+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:21:20.207+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:21:20.207+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:21:20.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T23:21:50.387+0000] {processor.py:157} INFO - Started process (PID=268) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:21:50.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:21:50.389+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:21:50.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:21:50.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:21:50.430+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:21:50.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:21:50.451+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:21:50.451+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:21:50.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T23:22:20.577+0000] {processor.py:157} INFO - Started process (PID=270) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:22:20.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:22:20.579+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:22:20.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:22:20.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:22:20.619+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:22:20.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:22:20.656+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:22:20.656+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:22:20.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-25T23:22:50.849+0000] {processor.py:157} INFO - Started process (PID=272) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:22:50.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:22:50.852+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:22:50.852+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:22:50.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:22:50.895+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:22:50.895+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:22:50.921+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:22:50.921+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:22:50.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:23:21.039+0000] {processor.py:157} INFO - Started process (PID=274) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:23:21.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:23:21.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:23:21.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:23:21.054+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:23:21.080+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:23:21.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:23:21.100+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:23:21.100+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:23:21.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-25T23:23:51.317+0000] {processor.py:157} INFO - Started process (PID=276) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:23:51.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:23:51.319+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:23:51.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:23:51.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:23:51.355+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:23:51.355+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:23:51.376+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:23:51.376+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:23:51.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:24:21.517+0000] {processor.py:157} INFO - Started process (PID=278) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:24:21.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:24:21.519+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:24:21.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:24:21.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:24:21.556+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:24:21.556+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:24:21.580+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:24:21.580+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:24:21.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T23:24:51.701+0000] {processor.py:157} INFO - Started process (PID=280) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:24:51.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:24:51.703+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:24:51.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:24:51.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:24:51.747+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:24:51.747+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:24:51.773+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:24:51.773+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:24:51.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:25:21.953+0000] {processor.py:157} INFO - Started process (PID=282) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:25:21.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:25:21.955+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:25:21.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:25:21.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:25:22.004+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:25:22.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:25:22.038+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:25:22.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:25:22.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-25T23:25:52.134+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:25:52.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:25:52.135+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:25:52.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:25:52.149+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:25:52.178+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:25:52.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:25:52.201+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:25:52.201+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:25:52.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:26:22.368+0000] {processor.py:157} INFO - Started process (PID=286) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:26:22.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:26:22.370+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:26:22.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:26:22.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:26:22.412+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:26:22.412+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:26:22.434+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:26:22.434+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:26:22.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T23:26:52.644+0000] {processor.py:157} INFO - Started process (PID=288) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:26:52.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:26:52.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:26:52.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:26:52.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:26:52.686+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:26:52.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:26:52.709+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:26:52.709+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:26:52.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T23:27:22.835+0000] {processor.py:157} INFO - Started process (PID=290) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:27:22.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:27:22.837+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:27:22.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:27:22.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:27:22.874+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:27:22.873+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:27:22.895+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:27:22.895+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:27:22.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T23:27:53.100+0000] {processor.py:157} INFO - Started process (PID=292) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:27:53.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:27:53.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:27:53.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:27:53.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:27:53.141+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:27:53.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:27:53.166+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:27:53.166+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:27:53.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T23:28:23.257+0000] {processor.py:157} INFO - Started process (PID=294) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:28:23.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:28:23.259+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:28:23.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:28:23.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:28:23.312+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:28:23.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:28:23.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:28:23.339+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:28:23.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-25T23:28:53.480+0000] {processor.py:157} INFO - Started process (PID=296) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:28:53.481+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:28:53.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:28:53.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:28:53.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:28:53.519+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:28:53.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:28:53.540+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:28:53.540+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:28:53.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-25T23:29:23.676+0000] {processor.py:157} INFO - Started process (PID=298) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:29:23.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:29:23.678+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:29:23.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:29:23.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:29:23.720+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:29:23.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:29:23.742+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:29:23.742+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:29:23.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T23:29:53.883+0000] {processor.py:157} INFO - Started process (PID=300) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:29:53.883+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:29:53.884+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:29:53.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:29:53.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:29:53.926+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:29:53.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:29:53.948+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:29:53.947+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:29:53.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:30:24.090+0000] {processor.py:157} INFO - Started process (PID=302) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:30:24.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:30:24.092+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:30:24.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:30:24.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:30:24.131+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:30:24.130+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:30:24.155+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:30:24.154+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:30:24.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:30:54.278+0000] {processor.py:157} INFO - Started process (PID=304) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:30:54.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:30:54.279+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:30:54.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:30:54.294+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:30:54.326+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:30:54.326+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:30:54.353+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:30:54.353+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:30:54.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T23:31:24.440+0000] {processor.py:157} INFO - Started process (PID=306) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:31:24.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:31:24.442+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:31:24.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:31:24.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:31:24.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:31:24.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:31:24.509+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:31:24.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:31:24.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:31:54.686+0000] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:31:54.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:31:54.688+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:31:54.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:31:54.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:31:54.725+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:31:54.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:31:54.748+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:31:54.747+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:31:54.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T23:32:24.977+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:32:24.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:32:24.989+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:32:24.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:32:24.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:32:25.028+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:32:25.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:32:25.051+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:32:25.050+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:32:25.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:32:55.147+0000] {processor.py:157} INFO - Started process (PID=312) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:32:55.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:32:55.149+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:32:55.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:32:55.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:32:55.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:32:55.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:32:55.234+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:32:55.233+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:32:55.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T23:33:25.441+0000] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:33:25.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:33:25.443+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:33:25.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:33:25.455+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:33:25.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:33:25.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:33:25.504+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:33:25.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:33:25.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T23:33:55.631+0000] {processor.py:157} INFO - Started process (PID=316) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:33:55.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:33:55.632+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:33:55.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:33:55.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:33:55.671+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:33:55.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:33:55.694+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:33:55.694+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:33:55.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:34:25.853+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:34:25.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:34:25.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:34:25.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:34:25.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:34:25.894+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:34:25.893+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:34:25.916+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:34:25.916+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:34:25.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T23:34:56.119+0000] {processor.py:157} INFO - Started process (PID=320) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:34:56.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:34:56.120+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:34:56.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:34:56.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:34:56.161+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:34:56.161+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:34:56.183+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:34:56.183+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:34:56.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:35:26.382+0000] {processor.py:157} INFO - Started process (PID=322) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:35:26.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:35:26.384+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:35:26.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:35:26.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:35:26.426+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:35:26.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:35:26.448+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:35:26.448+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:35:26.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:35:56.562+0000] {processor.py:157} INFO - Started process (PID=324) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:35:56.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:35:56.565+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:35:56.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:35:56.584+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:35:56.618+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:35:56.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:35:56.645+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:35:56.645+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:35:56.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-25T23:36:26.749+0000] {processor.py:157} INFO - Started process (PID=326) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:36:26.750+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:36:26.751+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:36:26.750+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:36:26.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:36:26.790+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:36:26.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:36:26.812+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:36:26.812+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:36:26.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-25T23:36:56.975+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:36:56.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:36:56.976+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:36:56.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:36:56.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:36:57.017+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:36:57.017+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:36:57.041+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:36:57.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:36:57.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:37:27.237+0000] {processor.py:157} INFO - Started process (PID=330) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:37:27.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:37:27.250+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:37:27.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:37:27.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:37:27.285+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:37:27.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:37:27.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:37:27.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:37:27.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-25T23:37:57.520+0000] {processor.py:157} INFO - Started process (PID=332) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:37:57.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:37:57.523+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:37:57.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:37:57.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:37:57.567+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:37:57.567+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:37:57.589+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:37:57.589+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:37:57.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T23:38:27.686+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:38:27.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:38:27.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:38:27.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:38:27.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:38:27.729+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:38:27.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:38:27.752+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:38:27.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:38:27.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T23:38:57.897+0000] {processor.py:157} INFO - Started process (PID=336) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:38:57.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:38:57.899+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:38:57.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:38:57.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:38:57.948+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:38:57.948+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:38:57.972+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:38:57.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:38:57.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:39:28.177+0000] {processor.py:157} INFO - Started process (PID=338) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:39:28.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:39:28.179+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:39:28.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:39:28.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:39:28.220+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:39:28.220+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:39:28.241+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:39:28.241+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:39:28.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T23:39:58.424+0000] {processor.py:157} INFO - Started process (PID=340) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:39:58.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:39:58.425+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:39:58.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:39:58.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:39:58.467+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:39:58.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:39:58.490+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:39:58.490+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:39:58.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T23:40:28.725+0000] {processor.py:157} INFO - Started process (PID=342) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:40:28.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:40:28.727+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:40:28.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:40:28.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:40:28.769+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:40:28.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:40:28.795+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:40:28.794+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:40:28.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T23:40:59.011+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:40:59.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:40:59.013+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:40:59.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:40:59.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:40:59.066+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:40:59.066+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:40:59.097+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:40:59.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:40:59.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-25T23:41:29.299+0000] {processor.py:157} INFO - Started process (PID=346) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:41:29.301+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:41:29.301+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:41:29.301+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:41:29.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:41:29.342+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:41:29.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:41:29.367+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:41:29.367+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:41:29.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:41:59.546+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:41:59.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:41:59.548+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:41:59.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:41:59.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:41:59.593+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:41:59.592+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:41:59.620+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:41:59.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:41:59.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:42:29.710+0000] {processor.py:157} INFO - Started process (PID=350) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:42:29.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:42:29.711+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:42:29.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:42:29.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:42:29.750+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:42:29.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:42:29.771+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:42:29.771+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:42:29.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T23:42:59.965+0000] {processor.py:157} INFO - Started process (PID=352) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:42:59.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:42:59.967+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:42:59.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:42:59.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:43:00.028+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:43:00.027+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:43:00.068+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:43:00.068+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:43:00.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-25T23:43:30.244+0000] {processor.py:157} INFO - Started process (PID=354) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:43:30.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:43:30.246+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:43:30.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:43:30.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:43:30.306+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:43:30.305+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:43:30.334+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:43:30.334+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:43:30.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-25T23:44:00.528+0000] {processor.py:157} INFO - Started process (PID=356) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:44:00.529+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:44:00.529+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:44:00.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:44:00.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:44:00.577+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:44:00.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:44:00.602+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:44:00.602+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:44:00.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:44:30.670+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:44:30.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:44:30.672+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:44:30.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:44:30.685+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:44:30.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:44:30.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:44:30.741+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:44:30.740+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:44:30.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:45:00.894+0000] {processor.py:157} INFO - Started process (PID=360) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:45:00.895+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:45:00.896+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:45:00.896+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:45:00.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:45:00.937+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:45:00.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:45:00.960+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:45:00.960+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:45:00.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:45:31.087+0000] {processor.py:157} INFO - Started process (PID=362) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:45:31.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:45:31.090+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:45:31.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:45:31.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:45:31.199+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:45:31.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:45:31.238+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:45:31.238+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:45:31.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.173 seconds
[2024-10-25T23:46:01.284+0000] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:46:01.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:46:01.286+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:46:01.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:46:01.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:46:01.326+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:46:01.326+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:46:01.351+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:46:01.351+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:46:01.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T23:46:31.427+0000] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:46:31.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:46:31.429+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:46:31.429+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:46:31.442+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:46:31.472+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:46:31.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:46:31.496+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:46:31.496+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:46:31.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T23:47:01.657+0000] {processor.py:157} INFO - Started process (PID=368) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:47:01.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:47:01.659+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:47:01.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:47:01.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:47:01.700+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:47:01.700+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:47:01.722+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:47:01.722+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:47:01.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T23:47:31.832+0000] {processor.py:157} INFO - Started process (PID=370) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:47:31.833+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:47:31.834+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:47:31.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:47:31.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:47:31.877+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:47:31.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:47:31.903+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:47:31.902+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:47:31.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:48:02.122+0000] {processor.py:157} INFO - Started process (PID=372) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:48:02.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:48:02.124+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:48:02.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:48:02.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:48:02.163+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:48:02.163+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:48:02.184+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:48:02.184+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:48:02.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-25T23:48:32.301+0000] {processor.py:157} INFO - Started process (PID=374) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:48:32.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:48:32.303+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:48:32.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:48:32.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:48:32.339+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:48:32.339+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:48:32.361+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:48:32.360+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:48:32.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T23:49:02.551+0000] {processor.py:157} INFO - Started process (PID=376) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:49:02.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:49:02.553+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:49:02.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:49:02.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:49:02.597+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:49:02.597+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:49:02.626+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:49:02.626+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:49:02.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-25T23:49:32.713+0000] {processor.py:157} INFO - Started process (PID=378) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:49:32.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:49:32.725+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:49:32.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:49:32.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:49:32.762+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:49:32.762+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:49:32.785+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:49:32.785+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:49:32.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T23:50:02.921+0000] {processor.py:157} INFO - Started process (PID=380) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:50:02.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:50:02.922+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:50:02.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:50:02.937+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:50:02.969+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:50:02.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:50:02.992+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:50:02.992+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:50:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:50:33.220+0000] {processor.py:157} INFO - Started process (PID=382) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:50:33.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:50:33.222+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:50:33.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:50:33.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:50:33.266+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:50:33.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:50:33.290+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:50:33.290+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:50:33.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-25T23:51:03.434+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:51:03.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:51:03.437+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:51:03.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:51:03.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:51:03.482+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:51:03.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:51:03.506+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:51:03.506+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:51:03.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-25T23:51:33.636+0000] {processor.py:157} INFO - Started process (PID=386) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:51:33.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:51:33.648+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:51:33.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:51:33.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:51:33.687+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:51:33.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:51:33.710+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:51:33.710+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:51:33.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-25T23:52:03.787+0000] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:52:03.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:52:03.789+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:52:03.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:52:03.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:52:03.835+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:52:03.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:52:03.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:52:03.856+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:52:03.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-25T23:52:34.031+0000] {processor.py:157} INFO - Started process (PID=390) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:52:34.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:52:34.033+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:52:34.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:52:34.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:52:34.077+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:52:34.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:52:34.101+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:52:34.101+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:52:34.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:53:04.289+0000] {processor.py:157} INFO - Started process (PID=392) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:53:04.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:53:04.291+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:53:04.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:53:04.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:53:04.332+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:53:04.332+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:53:04.357+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:53:04.356+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:53:04.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-25T23:53:34.556+0000] {processor.py:157} INFO - Started process (PID=394) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:53:34.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:53:34.558+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:53:34.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:53:34.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:53:34.599+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:53:34.599+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:53:34.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:53:34.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:53:34.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T23:54:04.713+0000] {processor.py:157} INFO - Started process (PID=396) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:54:04.714+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:54:04.715+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:54:04.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:54:04.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:54:04.754+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:54:04.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:54:04.777+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:54:04.776+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:54:04.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:54:34.978+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:54:34.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:54:34.990+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:54:34.990+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:54:35.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:54:35.037+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:54:35.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:54:35.066+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:54:35.065+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:54:35.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-25T23:55:05.138+0000] {processor.py:157} INFO - Started process (PID=400) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:55:05.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:55:05.139+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:55:05.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:55:05.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:55:05.181+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:55:05.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:55:05.202+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:55:05.202+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:55:05.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-25T23:55:35.410+0000] {processor.py:157} INFO - Started process (PID=402) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:55:35.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:55:35.411+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:55:35.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:55:35.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:55:35.452+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:55:35.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:55:35.474+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:55:35.474+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:55:35.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-25T23:56:05.578+0000] {processor.py:157} INFO - Started process (PID=404) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:56:05.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:56:05.579+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:56:05.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:56:05.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:56:05.621+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:56:05.620+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:56:05.649+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:56:05.649+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:56:05.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-25T23:56:35.835+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:56:35.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:56:35.837+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:56:35.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:56:35.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:56:35.884+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:56:35.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:56:35.915+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:56:35.914+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:56:35.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-25T23:57:06.004+0000] {processor.py:157} INFO - Started process (PID=408) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:57:06.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:57:06.005+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:57:06.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:57:06.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:57:06.043+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:57:06.042+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:57:06.064+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:57:06.063+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:57:06.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-25T23:57:36.268+0000] {processor.py:157} INFO - Started process (PID=410) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:57:36.280+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:57:36.281+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:57:36.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:57:36.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:57:36.321+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:57:36.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:57:36.343+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:57:36.343+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:57:36.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-25T23:58:06.436+0000] {processor.py:157} INFO - Started process (PID=412) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:58:06.437+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:58:06.438+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:58:06.438+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:58:06.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:58:06.480+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:58:06.480+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:58:06.505+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:58:06.505+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:58:06.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-25T23:58:36.632+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:58:36.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:58:36.635+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:58:36.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:58:36.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:58:36.677+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:58:36.677+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:58:36.700+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:58:36.700+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:58:36.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-25T23:59:06.819+0000] {processor.py:157} INFO - Started process (PID=416) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:59:06.820+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:59:06.820+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:59:06.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:59:06.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:59:06.856+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:59:06.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:59:06.883+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:59:06.883+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:59:06.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-25T23:59:37.015+0000] {processor.py:157} INFO - Started process (PID=418) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:59:37.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-25T23:59:37.017+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:59:37.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:59:37.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-25T23:59:37.054+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:59:37.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-25T23:59:37.076+0000] {logging_mixin.py:149} INFO - [2024-10-25T23:59:37.076+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
[2024-10-25T23:59:37.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
