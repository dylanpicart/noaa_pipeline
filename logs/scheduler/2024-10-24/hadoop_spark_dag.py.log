[2024-10-24T01:41:38.224+0000] {processor.py:157} INFO - Started process (PID=2885) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T01:41:38.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T01:41:38.226+0000] {logging_mixin.py:149} INFO - [2024-10-24T01:41:38.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T01:41:38.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T01:41:38.338+0000] {logging_mixin.py:149} INFO - [2024-10-24T01:41:38.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T01:41:38.412+0000] {logging_mixin.py:149} INFO - [2024-10-24T01:41:38.412+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T01:41:38.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.303 seconds
[2024-10-24T02:53:27.630+0000] {processor.py:157} INFO - Started process (PID=2892) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:53:27.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:53:27.641+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:53:27.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:53:28.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:53:28.385+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:53:28.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:53:28.487+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:53:28.487+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:53:28.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.078 seconds
[2024-10-24T02:53:58.897+0000] {processor.py:157} INFO - Started process (PID=2895) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:53:58.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:53:58.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:53:58.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:53:58.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:53:58.948+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:53:58.948+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:53:58.974+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:53:58.974+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:53:58.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T02:54:29.047+0000] {processor.py:157} INFO - Started process (PID=2897) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:54:29.048+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:54:29.049+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:54:29.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:54:29.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:54:29.095+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:54:29.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:54:29.121+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:54:29.121+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:54:29.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T02:54:59.295+0000] {processor.py:157} INFO - Started process (PID=2899) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:54:59.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:54:59.297+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:54:59.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:54:59.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:54:59.342+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:54:59.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:54:59.364+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:54:59.364+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:54:59.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T02:55:29.470+0000] {processor.py:157} INFO - Started process (PID=2901) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:55:29.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:55:29.472+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:55:29.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:55:29.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:55:29.515+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:55:29.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:55:29.537+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:55:29.537+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:55:29.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T02:55:59.725+0000] {processor.py:157} INFO - Started process (PID=2903) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:55:59.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:55:59.726+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:55:59.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:55:59.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:55:59.763+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:55:59.763+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:55:59.785+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:55:59.785+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:55:59.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T02:56:29.986+0000] {processor.py:157} INFO - Started process (PID=2905) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:56:29.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:56:29.988+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:56:29.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:56:30.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:56:30.028+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:56:30.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:56:30.049+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:56:30.049+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:56:30.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T02:57:00.171+0000] {processor.py:157} INFO - Started process (PID=2907) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:57:00.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:57:00.172+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:57:00.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:57:00.187+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:57:00.218+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:57:00.218+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:57:00.243+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:57:00.243+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:57:00.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T02:57:30.432+0000] {processor.py:157} INFO - Started process (PID=2909) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:57:30.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:57:30.434+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:57:30.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:57:30.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:57:30.473+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:57:30.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:57:30.495+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:57:30.494+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:57:30.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T02:58:00.697+0000] {processor.py:157} INFO - Started process (PID=2911) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:58:00.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:58:00.699+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:58:00.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:58:00.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:58:00.742+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:58:00.742+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:58:00.769+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:58:00.768+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:58:00.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T02:58:30.887+0000] {processor.py:157} INFO - Started process (PID=2913) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:58:30.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:58:30.888+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:58:30.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:58:30.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:58:30.930+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:58:30.930+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:58:30.955+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:58:30.955+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:58:30.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T02:59:01.153+0000] {processor.py:157} INFO - Started process (PID=2915) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:59:01.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:59:01.154+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:59:01.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:59:01.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:59:01.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:59:01.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:59:01.214+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:59:01.214+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:59:01.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T02:59:31.421+0000] {processor.py:157} INFO - Started process (PID=2917) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:59:31.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T02:59:31.423+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:59:31.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:59:31.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T02:59:31.463+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:59:31.463+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T02:59:31.487+0000] {logging_mixin.py:149} INFO - [2024-10-24T02:59:31.486+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T02:59:31.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T03:00:01.692+0000] {processor.py:157} INFO - Started process (PID=2919) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:00:01.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:00:01.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:00:01.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:00:01.705+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:00:01.733+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:00:01.732+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:00:01.754+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:00:01.754+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:00:01.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T03:00:31.848+0000] {processor.py:157} INFO - Started process (PID=2921) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:00:31.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:00:31.850+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:00:31.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:00:31.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:00:31.892+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:00:31.892+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:00:31.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:00:31.918+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:00:31.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T03:01:02.066+0000] {processor.py:157} INFO - Started process (PID=2923) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:01:02.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:01:02.068+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:01:02.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:01:02.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:01:02.105+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:01:02.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:01:02.128+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:01:02.128+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:01:02.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T03:01:32.284+0000] {processor.py:157} INFO - Started process (PID=2925) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:01:32.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:01:32.286+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:01:32.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:01:32.299+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:01:32.324+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:01:32.324+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:01:32.348+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:01:32.348+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:01:32.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T03:02:02.546+0000] {processor.py:157} INFO - Started process (PID=2927) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:02:02.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:02:02.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:02:02.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:02:02.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:02:02.592+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:02:02.592+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:02:02.623+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:02:02.623+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:02:02.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T03:02:32.719+0000] {processor.py:157} INFO - Started process (PID=2929) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:02:32.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:02:32.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:02:32.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:02:32.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:02:32.763+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:02:32.762+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:02:32.787+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:02:32.786+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:02:32.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T03:03:02.934+0000] {processor.py:157} INFO - Started process (PID=2931) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:03:02.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:03:02.936+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:03:02.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:03:02.953+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:03:02.987+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:03:02.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:03:03.011+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:03:03.010+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:03:03.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T03:03:33.104+0000] {processor.py:157} INFO - Started process (PID=2933) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:03:33.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:03:33.106+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:03:33.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:03:33.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:03:33.152+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:03:33.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:03:33.181+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:03:33.181+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:03:33.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T03:04:03.330+0000] {processor.py:157} INFO - Started process (PID=2935) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:04:03.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:04:03.331+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:04:03.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:04:03.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:04:03.378+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:04:03.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:04:03.406+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:04:03.406+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:04:03.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T03:04:33.508+0000] {processor.py:157} INFO - Started process (PID=2937) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:04:33.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:04:33.510+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:04:33.509+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:04:33.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:04:33.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:04:33.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:04:33.575+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:04:33.575+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:04:33.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T03:05:03.788+0000] {processor.py:157} INFO - Started process (PID=2939) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:05:03.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:05:03.790+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:05:03.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:05:03.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:05:03.854+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:05:03.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:05:03.883+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:05:03.883+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:05:04.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.360 seconds
[2024-10-24T03:05:34.304+0000] {processor.py:157} INFO - Started process (PID=2941) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:05:34.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:05:34.306+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:05:34.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:05:34.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:05:34.346+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:05:34.346+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:05:34.380+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:05:34.380+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:05:34.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T03:06:04.604+0000] {processor.py:157} INFO - Started process (PID=2943) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:06:04.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:06:04.605+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:06:04.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:06:04.619+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:06:04.645+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:06:04.645+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:06:04.668+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:06:04.668+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:06:04.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:06:34.879+0000] {processor.py:157} INFO - Started process (PID=2945) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:06:34.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:06:34.881+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:06:34.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:06:34.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:06:34.926+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:06:34.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:06:34.952+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:06:34.952+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:06:34.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T03:07:05.187+0000] {processor.py:157} INFO - Started process (PID=2947) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:07:05.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:07:05.189+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:07:05.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:07:05.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:07:05.226+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:07:05.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:07:05.248+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:07:05.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:07:05.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-24T03:07:35.374+0000] {processor.py:157} INFO - Started process (PID=2949) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:07:35.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:07:35.376+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:07:35.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:07:35.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:07:35.419+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:07:35.419+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:07:35.443+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:07:35.443+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:07:35.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T03:08:05.646+0000] {processor.py:157} INFO - Started process (PID=2951) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:08:05.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:08:05.648+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:08:05.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:08:05.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:08:05.685+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:08:05.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:08:05.707+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:08:05.707+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:08:05.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-24T03:08:35.950+0000] {processor.py:157} INFO - Started process (PID=2953) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:08:35.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:08:35.951+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:08:35.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:08:35.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:08:35.995+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:08:35.994+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:08:36.016+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:08:36.016+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:08:36.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T03:09:06.228+0000] {processor.py:157} INFO - Started process (PID=2955) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:09:06.230+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:09:06.231+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:09:06.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:09:06.245+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:09:06.279+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:09:06.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:09:06.316+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:09:06.316+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:09:06.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T03:09:36.527+0000] {processor.py:157} INFO - Started process (PID=2957) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:09:36.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:09:36.528+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:09:36.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:09:36.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:09:36.570+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:09:36.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:09:36.595+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:09:36.595+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:09:36.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:10:06.809+0000] {processor.py:157} INFO - Started process (PID=2959) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:10:06.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:10:06.811+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:10:06.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:10:06.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:10:06.852+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:10:06.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:10:06.877+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:10:06.877+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:10:06.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:10:37.011+0000] {processor.py:157} INFO - Started process (PID=2961) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:10:37.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:10:37.016+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:10:37.015+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:10:37.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:10:37.073+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:10:37.073+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:10:37.102+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:10:37.102+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:10:37.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T03:11:07.201+0000] {processor.py:157} INFO - Started process (PID=2963) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:11:07.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:11:07.203+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:11:07.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:11:07.214+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:11:07.247+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:11:07.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:11:07.275+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:11:07.275+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:11:07.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T03:11:37.447+0000] {processor.py:157} INFO - Started process (PID=2965) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:11:37.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:11:37.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:11:37.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:11:37.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:11:37.496+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:11:37.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:11:37.525+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:11:37.525+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:11:37.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T03:12:07.618+0000] {processor.py:157} INFO - Started process (PID=2967) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:12:07.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:12:07.631+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:12:07.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:12:07.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:12:07.668+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:12:07.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:12:07.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:12:07.693+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:12:07.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T03:12:37.884+0000] {processor.py:157} INFO - Started process (PID=2969) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:12:37.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:12:37.885+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:12:37.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:12:37.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:12:37.926+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:12:37.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:12:37.950+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:12:37.950+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:12:37.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:13:08.082+0000] {processor.py:157} INFO - Started process (PID=2971) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:13:08.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:13:08.095+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:13:08.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:13:08.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:13:08.130+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:13:08.130+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:13:08.152+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:13:08.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:13:08.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:13:38.323+0000] {processor.py:157} INFO - Started process (PID=2973) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:13:38.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:13:38.324+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:13:38.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:13:38.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:13:38.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:13:38.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:13:38.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:13:38.392+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:13:38.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T03:14:08.612+0000] {processor.py:157} INFO - Started process (PID=2975) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:14:08.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:14:08.614+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:14:08.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:14:08.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:14:08.658+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:14:08.658+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:14:08.685+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:14:08.684+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:14:08.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T03:14:38.794+0000] {processor.py:157} INFO - Started process (PID=2977) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:14:38.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:14:38.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:14:38.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:14:38.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:14:38.836+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:14:38.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:14:38.859+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:14:38.859+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:14:38.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T03:15:09.069+0000] {processor.py:157} INFO - Started process (PID=2979) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:15:09.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:15:09.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:15:09.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:15:09.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:15:09.110+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:15:09.109+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:15:09.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:15:09.131+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:15:09.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T03:15:39.267+0000] {processor.py:157} INFO - Started process (PID=2981) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:15:39.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:15:39.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:15:39.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:15:39.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:15:39.312+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:15:39.311+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:15:39.340+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:15:39.340+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:15:39.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T03:16:09.553+0000] {processor.py:157} INFO - Started process (PID=2983) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:16:09.565+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:16:09.566+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:16:09.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:16:09.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:16:09.608+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:16:09.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:16:09.635+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:16:09.635+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:16:09.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T03:16:39.733+0000] {processor.py:157} INFO - Started process (PID=2985) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:16:39.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:16:39.735+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:16:39.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:16:39.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:16:39.772+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:16:39.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:16:39.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:16:39.793+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:16:39.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-24T03:17:10.005+0000] {processor.py:157} INFO - Started process (PID=2987) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:17:10.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:17:10.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:17:10.007+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:17:10.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:17:10.047+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:17:10.047+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:17:10.070+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:17:10.070+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:17:10.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:17:40.289+0000] {processor.py:157} INFO - Started process (PID=2989) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:17:40.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:17:40.291+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:17:40.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:17:40.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:17:40.340+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:17:40.340+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:17:40.365+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:17:40.364+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:17:40.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T03:18:10.581+0000] {processor.py:157} INFO - Started process (PID=2991) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:18:10.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:18:10.583+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:18:10.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:18:10.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:18:10.630+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:18:10.630+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:18:10.658+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:18:10.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:18:10.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T03:18:40.764+0000] {processor.py:157} INFO - Started process (PID=2993) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:18:40.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:18:40.766+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:18:40.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:18:40.777+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:18:40.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:18:40.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:18:40.825+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:18:40.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:18:40.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-24T03:19:11.027+0000] {processor.py:157} INFO - Started process (PID=2995) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:19:11.028+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:19:11.028+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:19:11.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:19:11.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:19:11.070+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:19:11.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:19:11.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:19:11.094+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:19:11.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T03:19:41.203+0000] {processor.py:157} INFO - Started process (PID=2997) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:19:41.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:19:41.204+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:19:41.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:19:41.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:19:41.248+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:19:41.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:19:41.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:19:41.274+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:19:41.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T03:20:11.464+0000] {processor.py:157} INFO - Started process (PID=2999) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:20:11.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:20:11.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:20:11.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:20:11.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:20:11.517+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:20:11.516+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:20:11.540+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:20:11.540+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:20:11.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T03:20:41.645+0000] {processor.py:157} INFO - Started process (PID=3001) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:20:41.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:20:41.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:20:41.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:20:41.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:20:41.687+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:20:41.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:20:41.711+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:20:41.710+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:20:41.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:21:11.923+0000] {processor.py:157} INFO - Started process (PID=3003) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:21:11.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:21:11.925+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:21:11.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:21:11.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:21:11.968+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:21:11.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:21:11.989+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:21:11.989+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:21:12.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T03:21:42.123+0000] {processor.py:157} INFO - Started process (PID=3005) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:21:42.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:21:42.125+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:21:42.125+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:21:42.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:21:42.169+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:21:42.169+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:21:42.196+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:21:42.196+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:21:42.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T03:22:12.347+0000] {processor.py:157} INFO - Started process (PID=3007) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:22:12.348+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:22:12.348+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:22:12.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:22:12.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:22:12.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:22:12.390+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:22:12.413+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:22:12.413+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:22:12.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T03:22:42.530+0000] {processor.py:157} INFO - Started process (PID=3009) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:22:42.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:22:42.532+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:22:42.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:22:42.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:22:42.570+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:22:42.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:22:42.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:22:42.591+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:22:42.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-24T03:23:12.789+0000] {processor.py:157} INFO - Started process (PID=3011) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:23:12.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:23:12.790+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:23:12.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:23:12.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:23:12.830+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:23:12.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:23:12.858+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:23:12.858+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:23:12.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T03:23:43.422+0000] {processor.py:157} INFO - Started process (PID=3013) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:23:43.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:23:43.427+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:23:43.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:23:43.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:23:43.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:23:43.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:23:43.731+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:23:43.731+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:23:44.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.698 seconds
[2024-10-24T03:24:14.252+0000] {processor.py:157} INFO - Started process (PID=3015) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:24:14.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:24:14.254+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:24:14.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:24:14.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:24:14.309+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:24:14.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:24:14.333+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:24:14.333+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:24:14.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T03:24:44.529+0000] {processor.py:157} INFO - Started process (PID=3017) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:24:44.530+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:24:44.531+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:24:44.531+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:24:44.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:24:44.607+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:24:44.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:24:44.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:24:44.642+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:24:44.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-24T03:25:14.868+0000] {processor.py:157} INFO - Started process (PID=3019) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:25:14.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:25:14.881+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:25:14.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:25:14.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:25:14.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:25:14.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:25:14.941+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:25:14.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:25:14.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T03:25:45.065+0000] {processor.py:157} INFO - Started process (PID=3021) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:25:45.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:25:45.067+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:25:45.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:25:45.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:25:45.106+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:25:45.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:25:45.129+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:25:45.129+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:25:45.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T03:26:15.307+0000] {processor.py:157} INFO - Started process (PID=3023) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:26:15.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:26:15.309+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:26:15.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:26:15.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:26:15.353+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:26:15.353+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:26:15.376+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:26:15.376+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:26:15.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:26:45.481+0000] {processor.py:157} INFO - Started process (PID=3025) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:26:45.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:26:45.482+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:26:45.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:26:45.494+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:26:45.522+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:26:45.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:26:45.547+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:26:45.547+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:26:45.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:27:15.762+0000] {processor.py:157} INFO - Started process (PID=3027) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:27:15.763+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:27:15.764+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:27:15.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:27:15.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:27:15.803+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:27:15.802+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:27:15.825+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:27:15.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:27:15.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T03:27:45.956+0000] {processor.py:157} INFO - Started process (PID=3029) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:27:45.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:27:45.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:27:45.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:27:45.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:27:45.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:27:45.996+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:27:46.020+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:27:46.019+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:27:46.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T03:28:16.228+0000] {processor.py:157} INFO - Started process (PID=3031) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:28:16.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:28:16.230+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:28:16.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:28:16.242+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:28:16.271+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:28:16.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:28:16.297+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:28:16.297+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:28:16.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T03:28:46.525+0000] {processor.py:157} INFO - Started process (PID=3033) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:28:46.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:28:46.526+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:28:46.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:28:46.538+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:28:46.569+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:28:46.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:28:46.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:28:46.591+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:28:46.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:29:16.717+0000] {processor.py:157} INFO - Started process (PID=3035) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:29:16.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:29:16.719+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:29:16.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:29:16.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:29:16.761+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:29:16.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:29:16.783+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:29:16.783+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:29:16.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:29:47.002+0000] {processor.py:157} INFO - Started process (PID=3037) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:29:47.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:29:47.004+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:29:47.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:29:47.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:29:47.045+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:29:47.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:29:47.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:29:47.071+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:29:47.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T03:30:17.204+0000] {processor.py:157} INFO - Started process (PID=3039) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:30:17.213+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:30:17.214+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:30:17.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:30:17.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:30:17.250+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:30:17.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:30:17.280+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:30:17.280+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:30:17.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T03:30:47.507+0000] {processor.py:157} INFO - Started process (PID=3041) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:30:47.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:30:47.509+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:30:47.509+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:30:47.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:30:47.547+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:30:47.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:30:47.570+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:30:47.570+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:30:47.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T03:31:17.695+0000] {processor.py:157} INFO - Started process (PID=3043) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:31:17.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:31:17.697+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:31:17.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:31:17.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:31:17.740+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:31:17.740+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:31:17.767+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:31:17.767+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:31:17.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:31:47.945+0000] {processor.py:157} INFO - Started process (PID=3045) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:31:47.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:31:47.947+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:31:47.947+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:31:47.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:31:47.989+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:31:47.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:31:48.012+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:31:48.012+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:31:48.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:32:18.233+0000] {processor.py:157} INFO - Started process (PID=3047) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:32:18.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:32:18.248+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:32:18.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:32:18.260+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:32:18.296+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:32:18.296+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:32:18.325+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:32:18.325+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:32:18.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T03:32:48.547+0000] {processor.py:157} INFO - Started process (PID=3049) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:32:48.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:32:48.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:32:48.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:32:48.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:32:48.590+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:32:48.589+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:32:48.613+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:32:48.613+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:32:48.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:33:18.751+0000] {processor.py:157} INFO - Started process (PID=3051) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:33:18.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:33:18.753+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:33:18.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:33:18.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:33:18.795+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:33:18.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:33:18.822+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:33:18.822+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:33:18.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T03:33:49.044+0000] {processor.py:157} INFO - Started process (PID=3053) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:33:49.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:33:49.045+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:33:49.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:33:49.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:33:49.088+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:33:49.088+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:33:49.110+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:33:49.110+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:33:49.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T03:34:19.220+0000] {processor.py:157} INFO - Started process (PID=3055) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:34:19.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:34:19.222+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:34:19.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:34:19.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:34:19.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:34:19.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:34:19.296+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:34:19.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:34:19.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T03:34:49.505+0000] {processor.py:157} INFO - Started process (PID=3057) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:34:49.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:34:49.506+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:34:49.506+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:34:49.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:34:49.550+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:34:49.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:34:49.577+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:34:49.577+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:34:49.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T03:35:19.767+0000] {processor.py:157} INFO - Started process (PID=3059) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:35:19.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:35:19.769+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:35:19.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:35:19.785+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:35:19.813+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:35:19.812+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:35:19.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:35:19.839+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:35:19.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T03:35:49.967+0000] {processor.py:157} INFO - Started process (PID=3061) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:35:49.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:35:49.968+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:35:49.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:35:49.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:35:50.011+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:35:50.011+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:35:50.035+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:35:50.035+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:35:50.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:36:20.191+0000] {processor.py:157} INFO - Started process (PID=3063) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:36:20.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:36:20.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:36:20.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:36:20.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:36:20.237+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:36:20.237+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:36:20.263+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:36:20.262+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:36:20.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T03:36:50.390+0000] {processor.py:157} INFO - Started process (PID=3065) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:36:50.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:36:50.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:36:50.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:36:50.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:36:50.434+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:36:50.434+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:36:50.460+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:36:50.460+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:36:50.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T03:37:20.675+0000] {processor.py:157} INFO - Started process (PID=3067) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:37:20.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:37:20.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:37:20.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:37:20.691+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:37:20.722+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:37:20.721+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:37:20.746+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:37:20.745+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:37:20.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:37:50.957+0000] {processor.py:157} INFO - Started process (PID=3069) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:37:50.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:37:50.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:37:50.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:37:50.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:37:51.011+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:37:51.011+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:37:51.039+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:37:51.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:37:51.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T03:38:21.141+0000] {processor.py:157} INFO - Started process (PID=3071) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:38:21.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:38:21.143+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:38:21.143+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:38:21.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:38:21.181+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:38:21.181+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:38:21.203+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:38:21.202+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:38:21.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T03:38:51.413+0000] {processor.py:157} INFO - Started process (PID=3073) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:38:51.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:38:51.415+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:38:51.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:38:51.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:38:51.453+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:38:51.453+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:38:51.475+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:38:51.475+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:38:51.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T03:39:21.682+0000] {processor.py:157} INFO - Started process (PID=3075) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:39:21.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:39:21.683+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:39:21.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:39:21.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:39:21.722+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:39:21.721+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:39:21.752+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:39:21.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:39:21.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T03:39:51.876+0000] {processor.py:157} INFO - Started process (PID=3077) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:39:51.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:39:51.877+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:39:51.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:39:51.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:39:51.928+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:39:51.928+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:39:52.008+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:39:52.008+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:39:52.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-24T03:40:22.225+0000] {processor.py:157} INFO - Started process (PID=3079) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:40:22.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:40:22.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:40:22.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:40:22.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:40:22.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:40:22.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:40:22.290+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:40:22.289+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:40:22.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:40:52.396+0000] {processor.py:157} INFO - Started process (PID=3081) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:40:52.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:40:52.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:40:52.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:40:52.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:40:52.437+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:40:52.437+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:40:52.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:40:52.459+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:40:52.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:41:22.661+0000] {processor.py:157} INFO - Started process (PID=3083) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:41:22.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:41:22.663+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:41:22.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:41:22.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:41:22.717+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:41:22.716+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:41:22.746+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:41:22.746+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:41:22.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T03:41:52.837+0000] {processor.py:157} INFO - Started process (PID=3085) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:41:52.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:41:52.838+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:41:52.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:41:52.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:41:52.891+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:41:52.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:41:52.921+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:41:52.921+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:41:52.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T03:42:23.140+0000] {processor.py:157} INFO - Started process (PID=3087) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:42:23.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:42:23.153+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:42:23.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:42:23.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:42:23.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:42:23.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:42:23.216+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:42:23.216+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:42:23.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T03:42:53.314+0000] {processor.py:157} INFO - Started process (PID=3089) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:42:53.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:42:53.315+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:42:53.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:42:53.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:42:53.357+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:42:53.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:42:53.385+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:42:53.385+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:42:53.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:43:23.570+0000] {processor.py:157} INFO - Started process (PID=3091) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:43:23.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:43:23.573+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:43:23.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:43:23.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:43:23.618+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:43:23.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:43:23.645+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:43:23.645+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:43:23.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T03:43:53.754+0000] {processor.py:157} INFO - Started process (PID=3093) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:43:53.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:43:53.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:43:53.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:43:53.769+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:43:53.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:43:53.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:43:53.821+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:43:53.821+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:43:53.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T03:44:24.026+0000] {processor.py:157} INFO - Started process (PID=3095) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:44:24.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:44:24.039+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:44:24.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:44:24.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:44:24.076+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:44:24.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:44:24.099+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:44:24.099+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:44:24.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T03:44:54.235+0000] {processor.py:157} INFO - Started process (PID=3097) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:44:54.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:44:54.236+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:44:54.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:44:54.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:44:54.277+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:44:54.277+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:44:54.300+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:44:54.300+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:44:54.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T03:45:24.493+0000] {processor.py:157} INFO - Started process (PID=3099) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:45:24.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:45:24.495+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:45:24.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:45:24.508+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:45:24.535+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:45:24.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:45:24.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:45:24.558+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:45:24.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T03:45:54.773+0000] {processor.py:157} INFO - Started process (PID=3101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:45:54.774+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:45:54.775+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:45:54.775+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:45:54.789+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:45:54.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:45:54.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:45:54.843+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:45:54.842+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:45:54.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T03:46:24.961+0000] {processor.py:157} INFO - Started process (PID=3103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:46:24.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:46:24.965+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:46:24.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:46:24.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:46:25.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:46:25.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:46:25.069+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:46:25.069+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:46:25.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-24T03:46:55.275+0000] {processor.py:157} INFO - Started process (PID=3105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:46:55.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:46:55.278+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:46:55.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:46:55.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:46:55.330+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:46:55.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:46:55.363+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:46:55.363+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:46:55.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T03:47:25.569+0000] {processor.py:157} INFO - Started process (PID=3107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:47:25.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:47:25.571+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:47:25.571+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:47:25.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:47:25.613+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:47:25.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:47:25.639+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:47:25.638+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:47:25.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:47:55.857+0000] {processor.py:157} INFO - Started process (PID=3109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:47:55.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:47:55.859+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:47:55.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:47:55.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:47:55.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:47:55.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:47:55.924+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:47:55.923+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:47:55.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:48:26.046+0000] {processor.py:157} INFO - Started process (PID=3111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:48:26.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:48:26.047+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:48:26.047+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:48:26.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:48:26.090+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:48:26.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:48:26.115+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:48:26.115+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:48:26.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T03:48:56.275+0000] {processor.py:157} INFO - Started process (PID=3113) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:48:56.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:48:56.277+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:48:56.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:48:56.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:48:56.320+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:48:56.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:48:56.342+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:48:56.342+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:48:56.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:49:26.551+0000] {processor.py:157} INFO - Started process (PID=3115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:49:26.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:49:26.553+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:49:26.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:49:26.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:49:26.595+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:49:26.595+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:49:26.617+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:49:26.617+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:49:26.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:49:56.738+0000] {processor.py:157} INFO - Started process (PID=3117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:49:56.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:49:56.741+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:49:56.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:49:56.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:49:56.791+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:49:56.791+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:49:56.823+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:49:56.823+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:49:56.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T03:50:27.022+0000] {processor.py:157} INFO - Started process (PID=3119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:50:27.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:50:27.024+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:50:27.024+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:50:27.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:50:27.065+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:50:27.065+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:50:27.087+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:50:27.087+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:50:27.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:50:57.292+0000] {processor.py:157} INFO - Started process (PID=3121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:50:57.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:50:57.294+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:50:57.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:50:57.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:50:57.334+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:50:57.334+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:50:57.358+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:50:57.358+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:50:57.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:51:27.623+0000] {processor.py:157} INFO - Started process (PID=3123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:51:27.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:51:27.624+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:51:27.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:51:27.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:51:27.664+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:51:27.663+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:51:27.690+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:51:27.690+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:51:27.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:51:57.812+0000] {processor.py:157} INFO - Started process (PID=3125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:51:57.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:51:57.813+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:51:57.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:51:57.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:51:57.852+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:51:57.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:51:57.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:51:57.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:51:57.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T03:52:28.079+0000] {processor.py:157} INFO - Started process (PID=3127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:52:28.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:52:28.080+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:52:28.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:52:28.094+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:52:28.124+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:52:28.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:52:28.148+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:52:28.148+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:52:28.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T03:52:58.249+0000] {processor.py:157} INFO - Started process (PID=3129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:52:58.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:52:58.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:52:58.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:52:58.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:52:58.289+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:52:58.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:52:58.312+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:52:58.312+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:52:58.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T03:53:28.483+0000] {processor.py:157} INFO - Started process (PID=3131) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:53:28.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:53:28.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:53:28.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:53:28.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:53:28.527+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:53:28.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:53:28.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:53:28.549+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:53:28.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:53:58.686+0000] {processor.py:157} INFO - Started process (PID=3133) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:53:58.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:53:58.688+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:53:58.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:53:58.700+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:53:58.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:53:58.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:53:58.752+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:53:58.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:53:58.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T03:54:28.943+0000] {processor.py:157} INFO - Started process (PID=3135) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:54:28.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:54:28.945+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:54:28.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:54:28.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:54:28.994+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:54:28.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:54:29.019+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:54:29.018+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:54:29.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T03:54:59.221+0000] {processor.py:157} INFO - Started process (PID=3137) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:54:59.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:54:59.223+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:54:59.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:54:59.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:54:59.270+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:54:59.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:54:59.296+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:54:59.295+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:54:59.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T03:55:29.396+0000] {processor.py:157} INFO - Started process (PID=3139) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:55:29.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:55:29.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:55:29.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:55:29.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:55:29.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:55:29.449+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:55:29.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:55:29.474+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:55:29.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T03:55:59.673+0000] {processor.py:157} INFO - Started process (PID=3141) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:55:59.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:55:59.675+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:55:59.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:55:59.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:55:59.724+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:55:59.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:55:59.752+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:55:59.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:55:59.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T03:56:29.867+0000] {processor.py:157} INFO - Started process (PID=3143) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:56:29.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:56:29.868+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:56:29.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:56:29.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:56:29.907+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:56:29.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:56:29.931+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:56:29.931+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:56:29.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:57:00.159+0000] {processor.py:157} INFO - Started process (PID=3145) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:57:00.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:57:00.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:57:00.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:57:00.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:57:00.199+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:57:00.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:57:00.222+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:57:00.222+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:57:00.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T03:57:30.335+0000] {processor.py:157} INFO - Started process (PID=3147) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:57:30.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:57:30.336+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:57:30.336+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:57:30.349+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:57:30.378+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:57:30.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:57:30.405+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:57:30.405+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:57:30.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T03:58:00.611+0000] {processor.py:157} INFO - Started process (PID=3149) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:58:00.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:58:00.613+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:58:00.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:58:00.633+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:58:00.676+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:58:00.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:58:00.712+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:58:00.712+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:58:00.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-24T03:58:30.768+0000] {processor.py:157} INFO - Started process (PID=3151) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:58:30.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:58:30.770+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:58:30.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:58:30.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:58:30.822+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:58:30.822+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:58:30.852+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:58:30.852+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:58:30.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T03:59:01.066+0000] {processor.py:157} INFO - Started process (PID=3153) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:59:01.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:59:01.068+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:59:01.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:59:01.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:59:01.106+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:59:01.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:59:01.128+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:59:01.127+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:59:01.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T03:59:31.336+0000] {processor.py:157} INFO - Started process (PID=3155) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:59:31.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T03:59:31.338+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:59:31.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:59:31.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T03:59:31.378+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:59:31.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T03:59:31.403+0000] {logging_mixin.py:149} INFO - [2024-10-24T03:59:31.403+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T03:59:31.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:00:01.514+0000] {processor.py:157} INFO - Started process (PID=3157) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:00:01.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:00:01.516+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:00:01.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:00:01.530+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:00:01.560+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:00:01.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:00:01.586+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:00:01.586+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:00:01.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T04:00:31.785+0000] {processor.py:157} INFO - Started process (PID=3159) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:00:31.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:00:31.787+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:00:31.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:00:31.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:00:31.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:00:31.829+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:00:31.852+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:00:31.852+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:00:31.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T04:01:01.973+0000] {processor.py:157} INFO - Started process (PID=3161) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:01:01.974+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:01:01.975+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:01:01.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:01:01.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:01:02.013+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:01:02.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:01:02.034+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:01:02.034+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:01:02.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T04:01:32.244+0000] {processor.py:157} INFO - Started process (PID=3163) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:01:32.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:01:32.246+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:01:32.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:01:32.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:01:32.282+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:01:32.282+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:01:32.303+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:01:32.303+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:01:32.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-24T04:02:02.439+0000] {processor.py:157} INFO - Started process (PID=3165) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:02:02.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:02:02.441+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:02:02.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:02:02.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:02:02.479+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:02:02.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:02:02.502+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:02:02.502+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:02:02.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T04:02:32.655+0000] {processor.py:157} INFO - Started process (PID=3167) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:02:32.656+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:02:32.657+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:02:32.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:02:32.670+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:02:32.695+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:02:32.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:02:32.717+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:02:32.717+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:02:32.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:03:02.925+0000] {processor.py:157} INFO - Started process (PID=3169) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:03:02.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:03:02.927+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:03:02.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:03:02.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:03:02.966+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:03:02.965+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:03:02.990+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:03:02.990+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:03:03.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:03:33.196+0000] {processor.py:157} INFO - Started process (PID=3171) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:03:33.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:03:33.197+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:03:33.197+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:03:33.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:03:33.236+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:03:33.236+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:03:33.260+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:03:33.260+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:03:33.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T04:04:03.392+0000] {processor.py:157} INFO - Started process (PID=3173) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:04:03.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:04:03.394+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:04:03.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:04:03.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:04:03.432+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:04:03.432+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:04:03.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:04:03.457+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:04:03.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:04:33.609+0000] {processor.py:157} INFO - Started process (PID=3175) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:04:33.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:04:33.610+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:04:33.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:04:33.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:04:33.651+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:04:33.651+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:04:33.673+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:04:33.673+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:04:33.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:05:03.812+0000] {processor.py:157} INFO - Started process (PID=3177) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:05:03.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:05:03.814+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:05:03.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:05:03.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:05:03.862+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:05:03.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:05:03.891+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:05:03.891+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:05:03.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T04:05:33.995+0000] {processor.py:157} INFO - Started process (PID=3179) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:05:33.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:05:33.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:05:33.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:05:34.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:05:34.034+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:05:34.034+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:05:34.057+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:05:34.057+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:05:34.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T04:06:04.268+0000] {processor.py:157} INFO - Started process (PID=3181) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:06:04.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:06:04.270+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:06:04.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:06:04.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:06:04.309+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:06:04.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:06:04.332+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:06:04.332+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:06:04.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T04:06:34.455+0000] {processor.py:157} INFO - Started process (PID=3183) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:06:34.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:06:34.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:06:34.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:06:34.472+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:06:34.500+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:06:34.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:06:34.520+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:06:34.520+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:06:34.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:07:04.684+0000] {processor.py:157} INFO - Started process (PID=3185) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:07:04.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:07:04.691+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:07:04.691+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:07:04.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:07:04.728+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:07:04.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:07:04.752+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:07:04.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:07:04.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:07:34.883+0000] {processor.py:157} INFO - Started process (PID=3187) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:07:34.883+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:07:34.884+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:07:34.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:07:34.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:07:34.925+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:07:34.924+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:07:34.954+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:07:34.954+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:07:34.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T04:08:05.172+0000] {processor.py:157} INFO - Started process (PID=3189) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:08:05.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:08:05.174+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:08:05.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:08:05.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:08:05.212+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:08:05.211+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:08:05.232+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:08:05.232+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:08:05.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T04:08:35.444+0000] {processor.py:157} INFO - Started process (PID=3191) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:08:35.445+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:08:35.446+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:08:35.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:08:35.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:08:35.483+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:08:35.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:08:35.505+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:08:35.505+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:08:35.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T04:09:05.636+0000] {processor.py:157} INFO - Started process (PID=3193) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:09:05.637+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:09:05.638+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:09:05.638+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:09:05.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:09:05.677+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:09:05.677+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:09:05.703+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:09:05.703+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:09:05.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:09:35.881+0000] {processor.py:157} INFO - Started process (PID=3195) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:09:35.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:09:35.883+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:09:35.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:09:35.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:09:35.920+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:09:35.920+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:09:35.942+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:09:35.942+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:09:35.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:10:06.150+0000] {processor.py:157} INFO - Started process (PID=3197) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:10:06.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:10:06.152+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:10:06.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:10:06.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:10:06.189+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:10:06.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:10:06.215+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:10:06.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:10:06.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T04:10:36.340+0000] {processor.py:157} INFO - Started process (PID=3199) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:10:36.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:10:36.341+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:10:36.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:10:36.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:10:36.393+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:10:36.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:10:36.427+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:10:36.427+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:10:36.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-24T04:11:06.660+0000] {processor.py:157} INFO - Started process (PID=3201) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:11:06.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:11:06.662+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:11:06.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:11:06.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:11:06.700+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:11:06.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:11:06.727+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:11:06.727+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:11:06.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:11:36.841+0000] {processor.py:157} INFO - Started process (PID=3203) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:11:36.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:11:36.842+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:11:36.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:11:36.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:11:36.880+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:11:36.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:11:36.905+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:11:36.905+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:11:36.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:12:07.119+0000] {processor.py:157} INFO - Started process (PID=3205) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:12:07.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:12:07.121+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:12:07.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:12:07.133+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:12:07.159+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:12:07.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:12:07.181+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:12:07.181+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:12:07.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:12:37.313+0000] {processor.py:157} INFO - Started process (PID=3207) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:12:37.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:12:37.315+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:12:37.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:12:37.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:12:37.352+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:12:37.352+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:12:37.373+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:12:37.373+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:12:37.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-24T04:13:07.598+0000] {processor.py:157} INFO - Started process (PID=3209) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:13:07.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:13:07.600+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:13:07.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:13:07.614+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:13:07.641+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:13:07.641+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:13:07.663+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:13:07.663+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:13:07.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:13:37.803+0000] {processor.py:157} INFO - Started process (PID=3211) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:13:37.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:13:37.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:13:37.804+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:13:37.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:13:37.841+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:13:37.841+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:13:37.862+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:13:37.862+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:13:37.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-24T04:30:16.781+0000] {processor.py:157} INFO - Started process (PID=3213) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:30:16.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:30:16.811+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:30:16.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:30:16.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:30:16.990+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:30:16.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:30:17.218+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:30:17.218+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:30:17.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.632 seconds
[2024-10-24T04:30:47.600+0000] {processor.py:157} INFO - Started process (PID=3217) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:30:47.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:30:47.606+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:30:47.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:30:47.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:30:47.657+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:30:47.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:30:47.681+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:30:47.680+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:30:47.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T04:31:17.861+0000] {processor.py:157} INFO - Started process (PID=3219) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:31:17.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:31:17.863+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:31:17.863+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:31:17.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:31:17.928+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:31:17.928+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:31:17.954+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:31:17.954+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:31:17.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T04:31:48.160+0000] {processor.py:157} INFO - Started process (PID=3221) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:31:48.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:31:48.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:31:48.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:31:48.173+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:31:48.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:31:48.200+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:31:48.225+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:31:48.225+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:31:48.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:32:18.423+0000] {processor.py:157} INFO - Started process (PID=3223) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:32:18.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:32:18.425+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:32:18.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:32:18.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:32:18.470+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:32:18.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:32:18.499+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:32:18.498+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:32:18.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T04:32:48.719+0000] {processor.py:157} INFO - Started process (PID=3225) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:32:48.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:32:48.720+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:32:48.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:32:48.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:32:48.760+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:32:48.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:32:48.784+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:32:48.784+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:32:48.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-24T04:33:18.919+0000] {processor.py:157} INFO - Started process (PID=3227) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:33:18.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:33:18.922+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:33:18.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:33:18.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:33:18.971+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:33:18.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:33:19.003+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:33:19.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:33:19.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-24T04:33:49.248+0000] {processor.py:157} INFO - Started process (PID=3229) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:33:49.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:33:49.249+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:33:49.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:33:49.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:33:49.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:33:49.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:33:49.310+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:33:49.310+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:33:49.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T04:34:19.528+0000] {processor.py:157} INFO - Started process (PID=3231) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:34:19.529+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:34:19.529+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:34:19.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:34:19.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:34:19.568+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:34:19.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:34:19.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:34:19.591+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:34:19.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:34:49.716+0000] {processor.py:157} INFO - Started process (PID=3233) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:34:49.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:34:49.717+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:34:49.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:34:49.730+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:34:49.763+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:34:49.763+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:34:49.786+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:34:49.786+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:34:49.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T04:35:20.023+0000] {processor.py:157} INFO - Started process (PID=3235) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:35:20.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:35:20.025+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:35:20.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:35:20.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:35:20.069+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:35:20.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:35:20.093+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:35:20.092+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:35:20.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T04:35:50.210+0000] {processor.py:157} INFO - Started process (PID=3237) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:35:50.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:35:50.212+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:35:50.212+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:35:50.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:35:50.261+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:35:50.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:35:50.284+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:35:50.283+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:35:50.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T04:36:20.510+0000] {processor.py:157} INFO - Started process (PID=3239) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:36:20.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:36:20.528+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:36:20.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:36:20.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:36:20.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:36:20.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:36:20.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:36:20.756+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:36:20.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.307 seconds
[2024-10-24T04:36:50.942+0000] {processor.py:157} INFO - Started process (PID=3241) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:36:50.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:36:50.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:36:50.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:36:50.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:36:50.998+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:36:50.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:36:51.023+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:36:51.023+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:36:51.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T04:37:21.239+0000] {processor.py:157} INFO - Started process (PID=3243) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:37:21.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:37:21.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:37:21.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:37:21.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:37:21.279+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:37:21.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:37:21.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:37:21.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:37:21.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:37:51.515+0000] {processor.py:157} INFO - Started process (PID=3245) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:37:51.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:37:51.516+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:37:51.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:37:51.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:37:51.560+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:37:51.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:37:51.581+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:37:51.580+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:37:51.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T04:38:21.782+0000] {processor.py:157} INFO - Started process (PID=3247) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:38:21.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:38:21.791+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:38:21.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:38:21.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:38:21.831+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:38:21.831+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:38:21.853+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:38:21.853+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:38:21.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T04:38:52.068+0000] {processor.py:157} INFO - Started process (PID=3249) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:38:52.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:38:52.069+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:38:52.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:38:52.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:38:52.107+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:38:52.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:38:52.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:38:52.130+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:38:52.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T04:39:22.242+0000] {processor.py:157} INFO - Started process (PID=3251) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:39:22.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:39:22.244+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:39:22.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:39:22.258+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:39:22.290+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:39:22.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:39:22.314+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:39:22.314+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:39:22.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T04:39:52.501+0000] {processor.py:157} INFO - Started process (PID=3253) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:39:52.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:39:52.502+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:39:52.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:39:52.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:39:52.544+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:39:52.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:39:52.570+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:39:52.569+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:39:52.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:40:22.764+0000] {processor.py:157} INFO - Started process (PID=3255) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:40:22.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:40:22.779+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:40:22.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:40:22.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:40:22.825+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:40:22.825+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:40:22.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:40:22.846+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:40:22.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T04:40:53.063+0000] {processor.py:157} INFO - Started process (PID=3257) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:40:53.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:40:53.064+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:40:53.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:40:53.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:40:53.107+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:40:53.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:40:53.132+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:40:53.131+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:40:53.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:41:23.348+0000] {processor.py:157} INFO - Started process (PID=3259) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:41:23.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:41:23.350+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:41:23.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:41:23.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:41:23.391+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:41:23.391+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:41:23.416+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:41:23.416+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:41:23.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T04:41:53.632+0000] {processor.py:157} INFO - Started process (PID=3261) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:41:53.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:41:53.633+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:41:53.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:41:53.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:41:53.671+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:41:53.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:41:53.696+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:41:53.696+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:41:53.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T04:42:23.888+0000] {processor.py:157} INFO - Started process (PID=3263) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:42:23.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:42:23.890+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:42:23.890+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:42:23.905+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:42:23.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:42:23.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:42:23.972+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:42:23.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:42:23.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T04:42:54.189+0000] {processor.py:157} INFO - Started process (PID=3265) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:42:54.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:42:54.190+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:42:54.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:42:54.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:42:54.235+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:42:54.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:42:54.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:42:54.266+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:42:54.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T04:43:24.463+0000] {processor.py:157} INFO - Started process (PID=3267) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:43:24.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:43:24.464+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:43:24.464+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:43:24.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:43:24.506+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:43:24.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:43:24.528+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:43:24.527+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:43:24.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T04:43:54.723+0000] {processor.py:157} INFO - Started process (PID=3269) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:43:54.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:43:54.725+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:43:54.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:43:54.739+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:43:54.767+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:43:54.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:43:54.790+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:43:54.790+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:43:54.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T04:44:24.910+0000] {processor.py:157} INFO - Started process (PID=3271) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:44:24.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:44:24.911+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:44:24.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:44:24.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:44:24.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:44:24.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:44:24.986+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:44:24.986+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:44:25.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T04:44:55.198+0000] {processor.py:157} INFO - Started process (PID=3273) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:44:55.199+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:44:55.200+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:44:55.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:44:55.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:44:55.243+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:44:55.243+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:44:55.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:44:55.266+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:44:55.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:45:25.384+0000] {processor.py:157} INFO - Started process (PID=3275) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:45:25.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:45:25.385+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:45:25.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:45:25.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:45:25.430+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:45:25.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:45:25.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:45:25.457+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:45:25.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T04:45:55.613+0000] {processor.py:157} INFO - Started process (PID=3277) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:45:55.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:45:55.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:45:55.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:45:55.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:45:55.660+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:45:55.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:45:55.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:45:55.689+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:45:55.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T04:46:25.870+0000] {processor.py:157} INFO - Started process (PID=3279) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:46:25.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:46:25.872+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:46:25.872+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:46:25.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:46:25.941+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:46:25.941+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:46:25.977+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:46:25.977+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:46:25.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-24T04:46:56.190+0000] {processor.py:157} INFO - Started process (PID=3281) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:46:56.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:46:56.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:46:56.192+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:46:56.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:46:56.235+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:46:56.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:46:56.256+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:46:56.256+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:46:56.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T04:47:26.364+0000] {processor.py:157} INFO - Started process (PID=3283) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:47:26.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:47:26.365+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:47:26.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:47:26.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:47:26.408+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:47:26.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:47:26.431+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:47:26.431+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:47:26.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T04:47:56.577+0000] {processor.py:157} INFO - Started process (PID=3285) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:47:56.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:47:56.585+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:47:56.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:47:56.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:47:56.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:47:56.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:47:56.675+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:47:56.675+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:47:56.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T04:48:26.756+0000] {processor.py:157} INFO - Started process (PID=3287) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:48:26.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:48:26.758+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:48:26.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:48:26.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:48:26.808+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:48:26.808+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:48:26.834+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:48:26.834+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:48:26.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T04:48:56.980+0000] {processor.py:157} INFO - Started process (PID=3289) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:48:56.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:48:56.981+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:48:56.981+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:48:57.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:48:57.030+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:48:57.030+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:48:57.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:48:57.055+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:48:57.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T04:49:27.264+0000] {processor.py:157} INFO - Started process (PID=3291) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:49:27.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:49:27.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:49:27.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:49:27.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:49:27.310+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:49:27.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:49:27.337+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:49:27.337+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:49:27.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T04:49:57.556+0000] {processor.py:157} INFO - Started process (PID=3293) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:49:57.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:49:57.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:49:57.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:49:57.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:49:57.598+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:49:57.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:49:57.622+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:49:57.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:49:57.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T04:50:27.748+0000] {processor.py:157} INFO - Started process (PID=3295) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:50:27.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:50:27.750+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:50:27.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:50:27.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:50:27.797+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:50:27.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:50:27.822+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:50:27.822+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:50:27.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T04:50:57.966+0000] {processor.py:157} INFO - Started process (PID=3297) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:50:57.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:50:57.978+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:50:57.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:50:57.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:50:58.016+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:50:58.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:50:58.041+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:50:58.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:50:58.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T04:51:28.266+0000] {processor.py:157} INFO - Started process (PID=3299) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:51:28.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:51:28.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:51:28.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:51:28.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:51:28.314+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:51:28.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:51:28.339+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:51:28.339+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:51:28.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T04:51:58.531+0000] {processor.py:157} INFO - Started process (PID=3301) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:51:58.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:51:58.536+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:51:58.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:51:58.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:51:58.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:51:58.641+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:51:58.719+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:51:58.719+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:51:58.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.238 seconds
[2024-10-24T04:52:28.926+0000] {processor.py:157} INFO - Started process (PID=3303) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:52:28.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:52:28.929+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:52:28.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:52:28.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:52:28.976+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:52:28.976+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:52:29.002+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:52:29.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:52:29.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T04:52:59.206+0000] {processor.py:157} INFO - Started process (PID=3305) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:52:59.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:52:59.207+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:52:59.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:52:59.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:52:59.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:52:59.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:52:59.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:52:59.274+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:52:59.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T04:53:29.392+0000] {processor.py:157} INFO - Started process (PID=3307) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:53:29.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:53:29.394+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:53:29.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:53:29.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:53:29.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:53:29.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:53:29.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:53:29.459+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:53:29.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T04:53:59.585+0000] {processor.py:157} INFO - Started process (PID=3309) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:53:59.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:53:59.587+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:53:59.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:53:59.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:53:59.625+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:53:59.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:53:59.652+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:53:59.652+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:53:59.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T04:54:29.839+0000] {processor.py:157} INFO - Started process (PID=3311) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:54:29.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:54:29.842+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:54:29.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:54:29.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:54:29.883+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:54:29.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:54:29.909+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:54:29.909+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:54:29.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T04:54:59.998+0000] {processor.py:157} INFO - Started process (PID=3313) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:54:59.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:55:00.000+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:55:00.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:55:00.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:55:00.054+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:55:00.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:55:00.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:55:00.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:55:00.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T04:55:30.301+0000] {processor.py:157} INFO - Started process (PID=3315) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:55:30.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:55:30.303+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:55:30.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:55:30.317+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:55:30.347+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:55:30.347+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:55:30.373+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:55:30.373+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:55:30.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T04:56:00.475+0000] {processor.py:157} INFO - Started process (PID=3317) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:56:00.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:56:00.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:56:00.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:56:00.488+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:56:00.513+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:56:00.512+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:56:00.534+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:56:00.533+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:56:00.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-24T04:56:30.722+0000] {processor.py:157} INFO - Started process (PID=3319) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:56:30.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:56:30.724+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:56:30.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:56:30.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:56:30.769+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:56:30.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:56:30.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:56:30.793+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:56:30.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T04:57:00.904+0000] {processor.py:157} INFO - Started process (PID=3321) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:57:00.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:57:00.905+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:57:00.905+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:57:00.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:57:00.949+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:57:00.948+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:57:00.980+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:57:00.980+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:57:01.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T04:57:31.186+0000] {processor.py:157} INFO - Started process (PID=3323) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:57:31.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:57:31.187+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:57:31.187+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:57:31.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:57:31.233+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:57:31.233+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:57:31.258+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:57:31.258+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:57:31.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T04:58:01.456+0000] {processor.py:157} INFO - Started process (PID=3325) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:58:01.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:58:01.458+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:58:01.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:58:01.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:58:01.499+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:58:01.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:58:01.521+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:58:01.521+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:58:01.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T04:58:31.634+0000] {processor.py:157} INFO - Started process (PID=3327) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:58:31.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:58:31.636+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:58:31.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:58:31.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:58:31.683+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:58:31.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:58:31.708+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:58:31.708+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:58:31.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T04:59:01.890+0000] {processor.py:157} INFO - Started process (PID=3329) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:59:01.892+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:59:01.892+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:59:01.892+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:59:01.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:59:01.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:59:01.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:59:01.977+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:59:01.977+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:59:02.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T04:59:32.053+0000] {processor.py:157} INFO - Started process (PID=3331) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:59:32.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T04:59:32.055+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:59:32.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:59:32.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T04:59:32.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:59:32.094+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T04:59:32.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T04:59:32.119+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T04:59:32.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T05:00:02.321+0000] {processor.py:157} INFO - Started process (PID=3333) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:00:02.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:00:02.323+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:00:02.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:00:02.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:00:02.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:00:02.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:00:02.394+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:00:02.394+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:00:02.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T05:00:32.632+0000] {processor.py:157} INFO - Started process (PID=3335) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:00:32.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:00:32.634+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:00:32.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:00:32.650+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:00:32.683+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:00:32.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:00:32.713+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:00:32.713+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:00:32.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T05:01:02.798+0000] {processor.py:157} INFO - Started process (PID=3337) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:01:02.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:01:02.800+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:01:02.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:01:02.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:01:02.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:01:02.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:01:02.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:01:02.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:01:02.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T05:01:33.055+0000] {processor.py:157} INFO - Started process (PID=3339) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:01:33.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:01:33.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:01:33.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:01:33.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:01:33.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:01:33.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:01:33.114+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:01:33.114+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:01:33.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.081 seconds
[2024-10-24T05:02:03.308+0000] {processor.py:157} INFO - Started process (PID=3341) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:02:03.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:02:03.310+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:02:03.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:02:03.322+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:02:03.350+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:02:03.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:02:03.373+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:02:03.373+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:02:03.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T05:02:33.472+0000] {processor.py:157} INFO - Started process (PID=3343) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:02:33.473+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:02:33.473+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:02:33.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:02:33.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:02:33.517+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:02:33.517+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:02:33.545+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:02:33.545+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:02:33.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T05:03:03.759+0000] {processor.py:157} INFO - Started process (PID=3345) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:03:03.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:03:03.761+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:03:03.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:03:03.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:03:03.802+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:03:03.802+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:03:03.826+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:03:03.826+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:03:03.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T05:03:33.958+0000] {processor.py:157} INFO - Started process (PID=3347) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:03:33.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:03:33.960+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:03:33.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:03:33.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:03:34.009+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:03:34.009+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:03:34.038+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:03:34.038+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:03:34.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T05:04:04.232+0000] {processor.py:157} INFO - Started process (PID=3349) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:04:04.233+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:04:04.234+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:04:04.234+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:04:04.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:04:04.275+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:04:04.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:04:04.303+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:04:04.303+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:04:04.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T05:04:34.398+0000] {processor.py:157} INFO - Started process (PID=3351) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:04:34.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:04:34.399+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:04:34.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:04:34.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:04:34.447+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:04:34.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:04:34.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:04:34.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:04:34.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T05:05:04.616+0000] {processor.py:157} INFO - Started process (PID=3353) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:05:04.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:05:04.619+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:05:04.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:05:04.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:05:04.665+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:05:04.665+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:05:04.702+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:05:04.701+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:05:04.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T05:05:34.808+0000] {processor.py:157} INFO - Started process (PID=3355) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:05:34.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:05:34.810+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:05:34.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:05:34.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:05:34.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:05:34.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:05:34.885+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:05:34.885+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:05:34.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T05:06:05.075+0000] {processor.py:157} INFO - Started process (PID=3357) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:06:05.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:06:05.077+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:06:05.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:06:05.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:06:05.122+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:06:05.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:06:05.147+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:06:05.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:06:05.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T05:06:35.261+0000] {processor.py:157} INFO - Started process (PID=3359) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:06:35.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:06:35.262+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:06:35.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:06:35.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:06:35.300+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:06:35.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:06:35.327+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:06:35.327+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:06:35.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T05:07:05.519+0000] {processor.py:157} INFO - Started process (PID=3361) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:07:05.520+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:07:05.521+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:07:05.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:07:05.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:07:05.562+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:07:05.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:07:05.588+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:07:05.588+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:07:05.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T05:07:35.797+0000] {processor.py:157} INFO - Started process (PID=3363) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:07:35.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:07:35.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:07:35.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:07:35.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:07:35.838+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:07:35.838+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:07:35.862+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:07:35.862+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:07:35.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T05:08:05.989+0000] {processor.py:157} INFO - Started process (PID=3365) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:08:05.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:08:05.996+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:08:05.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:08:06.026+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:08:06.089+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:08:06.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:08:06.134+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:08:06.134+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:08:06.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.179 seconds
[2024-10-24T05:08:36.356+0000] {processor.py:157} INFO - Started process (PID=3367) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:08:36.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:08:36.375+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:08:36.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:08:36.420+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:08:36.471+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:08:36.471+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:08:36.545+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:08:36.545+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:08:36.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.235 seconds
[2024-10-24T05:09:06.749+0000] {processor.py:157} INFO - Started process (PID=3369) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:09:06.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:09:06.751+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:09:06.751+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:09:06.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:09:06.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:09:06.793+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:09:06.822+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:09:06.822+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:09:06.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T05:09:36.931+0000] {processor.py:157} INFO - Started process (PID=3371) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:09:36.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:09:36.933+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:09:36.932+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:09:36.953+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:09:36.983+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:09:36.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:09:37.008+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:09:37.008+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:09:37.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T05:10:07.170+0000] {processor.py:157} INFO - Started process (PID=3373) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:10:07.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:10:07.172+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:10:07.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:10:07.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:10:07.209+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:10:07.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:10:07.230+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:10:07.229+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:10:07.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T05:10:37.440+0000] {processor.py:157} INFO - Started process (PID=3375) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:10:37.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:10:37.441+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:10:37.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:10:37.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:10:37.489+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:10:37.489+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:10:37.513+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:10:37.513+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:10:37.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T05:11:07.632+0000] {processor.py:157} INFO - Started process (PID=3377) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:11:07.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:11:07.643+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:11:07.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:11:07.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:11:07.685+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:11:07.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:11:07.707+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:11:07.706+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:11:07.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T05:11:37.895+0000] {processor.py:157} INFO - Started process (PID=3379) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:11:37.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:11:37.896+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:11:37.896+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:11:37.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:11:37.936+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:11:37.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:11:37.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:11:37.958+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:11:37.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T05:12:08.169+0000] {processor.py:157} INFO - Started process (PID=3381) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:12:08.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:12:08.172+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:12:08.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:12:08.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:12:08.208+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:12:08.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:12:08.230+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:12:08.230+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:12:08.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-24T05:12:38.354+0000] {processor.py:157} INFO - Started process (PID=3383) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:12:38.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:12:38.356+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:12:38.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:12:38.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:12:38.395+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:12:38.395+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:12:38.419+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:12:38.419+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:12:38.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T05:13:08.580+0000] {processor.py:157} INFO - Started process (PID=3385) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:13:08.583+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:13:08.584+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:13:08.584+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:13:08.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:13:08.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:13:08.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:13:08.780+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:13:08.780+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:13:08.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.264 seconds
[2024-10-24T05:13:39.037+0000] {processor.py:157} INFO - Started process (PID=3387) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:13:39.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:13:39.038+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:13:39.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:13:39.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:13:39.079+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:13:39.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:13:39.103+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:13:39.103+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:13:39.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T05:14:09.230+0000] {processor.py:157} INFO - Started process (PID=3389) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:14:09.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:14:09.232+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:14:09.232+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:14:09.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:14:09.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:14:09.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:14:09.292+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:14:09.292+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:14:09.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T05:14:39.502+0000] {processor.py:157} INFO - Started process (PID=3391) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:14:39.503+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:14:39.504+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:14:39.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:14:39.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:14:39.545+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:14:39.545+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:14:39.574+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:14:39.574+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:14:39.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T05:15:09.748+0000] {processor.py:157} INFO - Started process (PID=3393) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:15:09.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:15:09.750+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:15:09.750+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:15:09.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:15:09.800+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:15:09.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:15:09.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:15:09.828+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:15:09.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T05:15:40.031+0000] {processor.py:157} INFO - Started process (PID=3395) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:15:40.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:15:40.033+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:15:40.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:15:40.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:15:40.074+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:15:40.074+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:15:40.096+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:15:40.096+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:15:40.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T05:16:10.211+0000] {processor.py:157} INFO - Started process (PID=3397) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:16:10.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:16:10.224+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:16:10.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:16:10.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:16:10.262+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:16:10.262+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:16:10.287+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:16:10.287+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:16:10.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T05:16:40.431+0000] {processor.py:157} INFO - Started process (PID=3399) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:16:40.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:16:40.432+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:16:40.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:16:40.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:16:40.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:16:40.484+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:16:40.513+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:16:40.513+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:16:40.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T05:17:10.609+0000] {processor.py:157} INFO - Started process (PID=3401) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:17:10.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:17:10.611+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:17:10.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:17:10.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:17:10.656+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:17:10.656+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:17:10.686+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:17:10.686+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:17:10.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T05:17:40.841+0000] {processor.py:157} INFO - Started process (PID=3403) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:17:40.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:17:40.844+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:17:40.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:17:40.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:17:40.889+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:17:40.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:17:40.917+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:17:40.916+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:17:40.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T05:18:11.017+0000] {processor.py:157} INFO - Started process (PID=3405) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:18:11.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:18:11.019+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:18:11.019+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:18:11.031+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:18:11.060+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:18:11.060+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:18:11.082+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:18:11.082+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:18:11.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T05:18:41.258+0000] {processor.py:157} INFO - Started process (PID=3407) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:18:41.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:18:41.260+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:18:41.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:18:41.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:18:41.298+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:18:41.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:18:41.320+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:18:41.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:18:41.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T05:19:11.440+0000] {processor.py:157} INFO - Started process (PID=3409) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:19:11.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:19:11.442+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:19:11.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:19:11.455+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:19:11.483+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:19:11.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:19:11.509+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:19:11.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:19:11.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T05:19:41.654+0000] {processor.py:157} INFO - Started process (PID=3411) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:19:41.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:19:41.656+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:19:41.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:19:41.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:19:41.697+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:19:41.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:19:41.722+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:19:41.722+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:19:41.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T05:20:11.928+0000] {processor.py:157} INFO - Started process (PID=3413) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:20:11.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:20:11.929+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:20:11.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:20:11.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:20:11.965+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:20:11.965+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:20:11.991+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:20:11.991+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:20:12.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T05:20:42.199+0000] {processor.py:157} INFO - Started process (PID=3415) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:20:42.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:20:42.202+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:20:42.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:20:42.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:20:42.326+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:20:42.325+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:20:42.375+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:20:42.374+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:20:42.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.211 seconds
[2024-10-24T05:21:12.582+0000] {processor.py:157} INFO - Started process (PID=3417) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:21:12.583+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:21:12.584+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:21:12.584+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:21:12.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:21:12.670+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:21:12.670+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:21:12.717+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:21:12.717+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:21:12.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.166 seconds
[2024-10-24T05:21:42.933+0000] {processor.py:157} INFO - Started process (PID=3419) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:21:42.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:21:42.936+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:21:42.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:21:42.953+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:21:42.991+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:21:42.991+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:21:43.019+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:21:43.019+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:21:43.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T05:22:13.236+0000] {processor.py:157} INFO - Started process (PID=3421) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:22:13.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:22:13.238+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:22:13.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:22:13.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:22:13.283+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:22:13.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:22:13.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:22:13.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:22:13.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T05:22:43.506+0000] {processor.py:157} INFO - Started process (PID=3423) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:22:43.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:22:43.519+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:22:43.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:22:43.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:22:43.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:22:43.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:22:43.581+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:22:43.581+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:22:43.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T05:23:13.668+0000] {processor.py:157} INFO - Started process (PID=3425) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:23:13.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:23:13.670+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:23:13.670+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:23:13.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:23:13.724+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:23:13.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:23:13.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:23:13.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:23:13.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T05:23:44.037+0000] {processor.py:157} INFO - Started process (PID=3427) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:23:44.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:23:44.039+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:23:44.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:23:44.053+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:23:44.077+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:23:44.077+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:23:44.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:23:44.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:23:44.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-24T05:24:14.222+0000] {processor.py:157} INFO - Started process (PID=3429) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:24:14.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:24:14.224+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:24:14.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:24:14.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:24:14.270+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:24:14.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:24:14.296+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:24:14.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:24:14.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T05:24:44.499+0000] {processor.py:157} INFO - Started process (PID=3431) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:24:44.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:24:44.509+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:24:44.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:24:44.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:24:44.972+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:24:44.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:24:45.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:24:45.316+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:24:45.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.983 seconds
[2024-10-24T05:25:16.302+0000] {processor.py:157} INFO - Started process (PID=3433) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:25:16.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:25:16.307+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:25:16.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:25:16.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:25:16.425+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:25:16.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:25:16.497+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:25:16.497+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:25:16.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.220 seconds
[2024-10-24T05:25:46.676+0000] {processor.py:157} INFO - Started process (PID=3435) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:25:46.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:25:46.682+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:25:46.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:25:46.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:25:46.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:25:46.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:25:46.743+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:25:46.743+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:25:46.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T05:26:16.936+0000] {processor.py:157} INFO - Started process (PID=3437) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:26:16.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:26:16.938+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:26:16.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:26:16.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:26:17.016+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:26:17.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:26:17.054+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:26:17.054+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:26:17.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-24T05:26:47.286+0000] {processor.py:157} INFO - Started process (PID=3439) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:26:47.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:26:47.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:26:47.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:26:47.304+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:26:47.347+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:26:47.347+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:26:47.382+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:26:47.382+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:26:47.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-24T05:27:17.583+0000] {processor.py:157} INFO - Started process (PID=3441) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:27:17.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:27:17.584+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:27:17.584+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:27:17.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:27:17.625+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:27:17.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:27:17.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:27:17.647+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:27:17.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T05:27:47.781+0000] {processor.py:157} INFO - Started process (PID=3443) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:27:47.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:27:47.784+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:27:47.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:27:47.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:27:47.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:27:47.829+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:27:47.854+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:27:47.854+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:27:47.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T05:28:18.040+0000] {processor.py:157} INFO - Started process (PID=3445) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:28:18.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:28:18.047+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:28:18.047+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:28:18.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:28:18.099+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:28:18.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:28:18.124+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:28:18.124+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:28:18.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T05:28:48.224+0000] {processor.py:157} INFO - Started process (PID=3447) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:28:48.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:28:48.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:28:48.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:28:48.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:28:48.301+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:28:48.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:28:48.344+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:28:48.344+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:28:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-24T05:29:18.547+0000] {processor.py:157} INFO - Started process (PID=3449) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:29:18.665+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:29:18.666+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:29:18.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:29:18.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:29:18.720+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:29:18.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:29:18.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:29:18.757+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:29:18.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.235 seconds
[2024-10-24T05:29:48.938+0000] {processor.py:157} INFO - Started process (PID=3451) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:29:48.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:29:48.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:29:48.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:29:49.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:29:49.199+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:29:49.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:29:49.402+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:29:49.401+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:29:49.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.573 seconds
[2024-10-24T05:30:19.745+0000] {processor.py:157} INFO - Started process (PID=3453) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:30:19.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:30:19.746+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:30:19.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:30:19.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:30:19.789+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:30:19.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:30:19.815+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:30:19.815+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:30:19.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T05:30:50.024+0000] {processor.py:157} INFO - Started process (PID=3455) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:30:50.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:30:50.026+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:30:50.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:30:50.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:30:50.072+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:30:50.072+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:30:50.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:30:50.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:30:50.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T05:31:20.291+0000] {processor.py:157} INFO - Started process (PID=3457) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:31:20.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:31:20.293+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:31:20.293+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:31:20.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:31:20.339+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:31:20.339+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:31:20.365+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:31:20.365+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:31:20.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T05:31:50.583+0000] {processor.py:157} INFO - Started process (PID=3459) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:31:50.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:31:50.596+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:31:50.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:31:50.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:31:50.646+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:31:50.646+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:31:50.680+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:31:50.680+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:31:50.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-24T05:32:20.755+0000] {processor.py:157} INFO - Started process (PID=3461) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:32:20.756+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:32:20.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:32:20.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:32:20.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:32:20.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:32:20.804+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:32:20.833+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:32:20.833+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:32:20.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T05:32:51.023+0000] {processor.py:157} INFO - Started process (PID=3463) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:32:51.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:32:51.026+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:32:51.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:32:51.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:32:51.084+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:32:51.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:32:51.108+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:32:51.108+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:32:51.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T05:33:21.216+0000] {processor.py:157} INFO - Started process (PID=3465) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:33:21.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:33:21.219+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:33:21.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:33:21.249+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:33:21.281+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:33:21.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:33:21.308+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:33:21.308+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:33:21.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T05:33:51.443+0000] {processor.py:157} INFO - Started process (PID=3467) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:33:51.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:33:51.456+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:33:51.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:33:51.469+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:33:51.502+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:33:51.502+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:33:51.531+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:33:51.531+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:33:51.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T05:34:21.721+0000] {processor.py:157} INFO - Started process (PID=3469) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:34:21.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:34:21.723+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:34:21.723+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:34:21.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:34:21.770+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:34:21.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:34:21.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:34:21.793+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:34:21.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T05:34:51.950+0000] {processor.py:157} INFO - Started process (PID=3471) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:34:51.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:34:51.952+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:34:51.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:34:51.964+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:34:52.041+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:34:52.041+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:34:52.105+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:34:52.105+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:34:52.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.200 seconds
[2024-10-24T05:35:22.323+0000] {processor.py:157} INFO - Started process (PID=3473) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:35:22.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:35:22.329+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:35:22.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:35:22.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:35:22.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:35:22.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:35:22.567+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:35:22.567+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:35:22.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.306 seconds
[2024-10-24T05:35:52.816+0000] {processor.py:157} INFO - Started process (PID=3475) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:35:52.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:35:52.819+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:35:52.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:35:52.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:35:52.869+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:35:52.869+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:35:52.894+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:35:52.893+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:35:52.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T05:36:23.093+0000] {processor.py:157} INFO - Started process (PID=3477) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:36:23.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:36:23.095+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:36:23.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:36:23.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:36:23.139+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:36:23.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:36:23.163+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:36:23.163+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:36:23.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T05:36:53.356+0000] {processor.py:157} INFO - Started process (PID=3479) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:36:53.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:36:53.357+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:36:53.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:36:53.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:36:53.397+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:36:53.397+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:36:53.426+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:36:53.426+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:36:53.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T05:37:23.536+0000] {processor.py:157} INFO - Started process (PID=3481) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:37:23.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:37:23.537+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:37:23.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:37:23.562+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:37:23.595+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:37:23.595+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:37:23.626+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:37:23.626+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:37:23.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T05:37:53.831+0000] {processor.py:157} INFO - Started process (PID=3483) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:37:53.831+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:37:53.832+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:37:53.832+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:37:53.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:37:53.878+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:37:53.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:37:53.903+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:37:53.902+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:37:53.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T05:38:23.997+0000] {processor.py:157} INFO - Started process (PID=3485) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:38:23.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:38:24.000+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:38:24.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:38:24.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:38:24.060+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:38:24.060+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:38:24.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:38:24.094+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:38:24.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T05:38:54.279+0000] {processor.py:157} INFO - Started process (PID=3487) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:38:54.280+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:38:54.281+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:38:54.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:38:54.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:38:54.338+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:38:54.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:38:54.365+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:38:54.364+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:38:54.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T05:39:24.588+0000] {processor.py:157} INFO - Started process (PID=3489) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:39:24.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:39:24.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:39:24.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:39:24.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:39:24.643+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:39:24.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:39:24.673+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:39:24.673+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:39:24.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T05:39:54.763+0000] {processor.py:157} INFO - Started process (PID=3491) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:39:54.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T05:39:54.765+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:39:54.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:39:54.777+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T05:39:54.805+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:39:54.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T05:39:54.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T05:39:54.829+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T05:39:54.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T13:00:25.870+0000] {processor.py:157} INFO - Started process (PID=3493) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:00:25.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:00:25.928+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:00:25.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:00:26.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:00:27.225+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:00:27.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:00:27.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:00:27.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:00:27.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 2.198 seconds
[2024-10-24T13:00:58.135+0000] {processor.py:157} INFO - Started process (PID=3497) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:00:58.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:00:58.140+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:00:58.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:00:58.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:00:58.421+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:00:58.421+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:00:58.524+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:00:58.524+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:00:58.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.461 seconds
[2024-10-24T13:01:28.731+0000] {processor.py:157} INFO - Started process (PID=3499) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:01:28.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:01:28.734+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:01:28.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:01:28.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:01:28.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:01:28.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:01:28.940+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:01:28.940+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:01:28.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.245 seconds
[2024-10-24T13:01:59.124+0000] {processor.py:157} INFO - Started process (PID=3501) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:01:59.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:01:59.126+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:01:59.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:01:59.143+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:01:59.186+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:01:59.185+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:01:59.220+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:01:59.219+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:01:59.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-24T13:02:29.398+0000] {processor.py:157} INFO - Started process (PID=3503) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:02:29.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:02:29.403+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:02:29.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:02:29.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:02:29.475+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:02:29.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:02:29.538+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:02:29.538+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:02:29.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.191 seconds
[2024-10-24T13:02:59.756+0000] {processor.py:157} INFO - Started process (PID=3505) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:02:59.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:02:59.758+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:02:59.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:02:59.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:02:59.799+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:02:59.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:02:59.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:02:59.838+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:02:59.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T13:03:30.052+0000] {processor.py:157} INFO - Started process (PID=3507) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:03:30.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:03:30.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:03:30.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:03:30.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:03:30.156+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:03:30.155+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:03:30.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:03:30.201+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:03:30.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.180 seconds
[2024-10-24T13:04:00.408+0000] {processor.py:157} INFO - Started process (PID=3509) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:04:00.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:04:00.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:04:00.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:04:00.428+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:04:00.461+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:04:00.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:04:00.490+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:04:00.490+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:04:00.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T13:04:30.681+0000] {processor.py:157} INFO - Started process (PID=3511) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:04:30.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:04:30.683+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:04:30.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:04:30.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:04:30.730+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:04:30.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:04:30.753+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:04:30.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:04:30.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T13:05:00.838+0000] {processor.py:157} INFO - Started process (PID=3513) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:05:00.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:05:00.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:05:00.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:05:00.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:05:00.883+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:05:00.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:05:00.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:05:00.918+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:05:00.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T13:05:31.125+0000] {processor.py:157} INFO - Started process (PID=3515) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:05:31.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:05:31.127+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:05:31.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:05:31.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:05:31.168+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:05:31.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:05:31.190+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:05:31.190+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:05:31.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T13:06:01.375+0000] {processor.py:157} INFO - Started process (PID=3517) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:06:01.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:06:01.379+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:06:01.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:06:01.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:06:01.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:06:01.444+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:06:01.504+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:06:01.504+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:06:01.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.195 seconds
[2024-10-24T13:06:31.648+0000] {processor.py:157} INFO - Started process (PID=3519) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:06:31.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:06:31.650+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:06:31.650+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:06:31.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:06:31.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:06:31.693+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:06:31.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:06:31.720+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:06:31.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T13:07:01.912+0000] {processor.py:157} INFO - Started process (PID=3521) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:07:01.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:07:01.915+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:07:01.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:07:01.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:07:01.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:07:01.957+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:07:01.981+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:07:01.981+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:07:02.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T13:07:32.187+0000] {processor.py:157} INFO - Started process (PID=3523) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:07:32.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:07:32.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:07:32.192+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:07:32.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:07:32.268+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:07:32.268+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:07:32.307+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:07:32.307+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:07:32.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.170 seconds
[2024-10-24T13:08:02.498+0000] {processor.py:157} INFO - Started process (PID=3525) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:08:02.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:08:02.500+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:08:02.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:08:02.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:08:02.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:08:02.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:08:02.668+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:08:02.667+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:08:02.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.207 seconds
[2024-10-24T13:08:32.889+0000] {processor.py:157} INFO - Started process (PID=3527) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:08:32.890+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:08:32.891+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:08:32.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:08:32.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:08:32.960+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:08:32.960+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:08:33.001+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:08:33.000+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:08:33.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-24T13:09:03.214+0000] {processor.py:157} INFO - Started process (PID=3529) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:09:03.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:09:03.216+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:09:03.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:09:03.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:09:03.258+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:09:03.258+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:09:03.285+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:09:03.285+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:09:03.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T13:09:33.479+0000] {processor.py:157} INFO - Started process (PID=3531) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:09:33.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:09:33.481+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:09:33.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:09:33.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:09:33.530+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:09:33.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:09:33.553+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:09:33.553+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:09:33.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T13:10:03.643+0000] {processor.py:157} INFO - Started process (PID=3533) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:10:03.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:10:03.645+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:10:03.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:10:03.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:10:03.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:10:03.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:10:03.714+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:10:03.713+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:10:03.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T13:10:33.943+0000] {processor.py:157} INFO - Started process (PID=3535) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:10:33.945+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:10:33.946+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:10:33.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:10:33.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:10:33.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:10:33.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:10:34.030+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:10:34.030+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:10:34.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T13:11:04.316+0000] {processor.py:157} INFO - Started process (PID=3537) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:11:04.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:11:04.318+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:11:04.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:11:04.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:11:04.365+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:11:04.364+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:11:04.395+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:11:04.395+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:11:04.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T13:11:34.482+0000] {processor.py:157} INFO - Started process (PID=3539) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:11:34.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:11:34.495+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:11:34.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:11:34.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:11:34.546+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:11:34.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:11:34.573+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:11:34.573+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:11:34.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T13:12:04.774+0000] {processor.py:157} INFO - Started process (PID=3541) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:12:04.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:12:04.776+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:12:04.775+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:12:04.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:12:04.815+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:12:04.814+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:12:04.835+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:12:04.835+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:12:04.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T13:12:34.952+0000] {processor.py:157} INFO - Started process (PID=3543) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:12:34.969+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:12:34.970+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:12:34.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:12:34.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:12:35.008+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:12:35.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:12:35.029+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:12:35.029+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:12:35.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T13:13:05.179+0000] {processor.py:157} INFO - Started process (PID=3545) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:13:05.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:13:05.180+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:13:05.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:13:05.197+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:13:05.226+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:13:05.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:13:05.249+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:13:05.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:13:05.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T13:13:35.357+0000] {processor.py:157} INFO - Started process (PID=3547) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:13:35.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:13:35.359+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:13:35.359+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:13:35.372+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:13:35.399+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:13:35.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:13:35.423+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:13:35.423+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:13:35.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T13:14:05.613+0000] {processor.py:157} INFO - Started process (PID=3549) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:14:05.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:14:05.615+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:14:05.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:14:05.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:14:05.653+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:14:05.653+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:14:05.675+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:14:05.675+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:14:05.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T13:14:35.787+0000] {processor.py:157} INFO - Started process (PID=3551) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:14:35.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:14:35.789+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:14:35.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:14:35.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:14:35.831+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:14:35.831+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:14:35.855+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:14:35.855+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:14:35.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T13:15:06.030+0000] {processor.py:157} INFO - Started process (PID=3553) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:15:06.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:15:06.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:15:06.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:15:06.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:15:06.076+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:15:06.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:15:06.103+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:15:06.103+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:15:06.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T13:15:36.310+0000] {processor.py:157} INFO - Started process (PID=3555) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:15:36.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:15:36.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:15:36.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:15:36.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:15:36.361+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:15:36.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:15:36.385+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:15:36.385+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:15:36.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T13:16:06.474+0000] {processor.py:157} INFO - Started process (PID=3557) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:16:06.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:16:06.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:16:06.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:16:06.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:16:06.521+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:16:06.521+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:16:06.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:16:06.548+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:16:06.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T13:16:36.731+0000] {processor.py:157} INFO - Started process (PID=3559) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:16:36.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:16:36.733+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:16:36.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:16:36.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:16:36.773+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:16:36.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:16:36.800+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:16:36.799+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:16:36.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T13:17:06.950+0000] {processor.py:157} INFO - Started process (PID=3561) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:17:06.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:17:06.962+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:17:06.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:17:06.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:17:06.999+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:17:06.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:17:07.021+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:17:07.021+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:17:07.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T13:17:37.158+0000] {processor.py:157} INFO - Started process (PID=3563) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:17:37.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:17:37.159+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:17:37.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:17:37.171+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:17:37.198+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:17:37.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:17:37.221+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:17:37.221+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:17:37.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T13:18:07.333+0000] {processor.py:157} INFO - Started process (PID=3565) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:18:07.334+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:18:07.334+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:18:07.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:18:07.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:18:07.370+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:18:07.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:18:07.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:18:07.392+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:18:07.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-24T13:18:37.608+0000] {processor.py:157} INFO - Started process (PID=3567) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:18:37.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:18:37.610+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:18:37.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:18:37.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:18:37.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:18:37.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:18:37.669+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:18:37.669+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:18:37.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T13:19:07.768+0000] {processor.py:157} INFO - Started process (PID=3569) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:19:07.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:19:07.770+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:19:07.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:19:07.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:19:07.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:19:07.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:19:07.848+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:19:07.848+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:19:07.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T13:19:37.993+0000] {processor.py:157} INFO - Started process (PID=3571) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:19:37.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:19:37.995+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:19:37.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:19:38.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:19:38.036+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:19:38.036+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:19:38.060+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:19:38.060+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:19:38.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T13:20:08.180+0000] {processor.py:157} INFO - Started process (PID=3573) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:20:08.181+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:20:08.182+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:20:08.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:20:08.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:20:08.226+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:20:08.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:20:08.248+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:20:08.248+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:20:08.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T13:20:38.383+0000] {processor.py:157} INFO - Started process (PID=3575) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:20:38.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:20:38.384+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:20:38.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:20:38.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:20:38.423+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:20:38.423+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:20:38.445+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:20:38.445+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:20:38.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.083 seconds
[2024-10-24T13:21:08.559+0000] {processor.py:157} INFO - Started process (PID=3577) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:21:08.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:21:08.560+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:21:08.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:21:08.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:21:08.603+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:21:08.603+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:21:08.629+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:21:08.629+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:21:08.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T13:21:38.816+0000] {processor.py:157} INFO - Started process (PID=3579) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:21:38.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:21:38.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:21:38.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:21:38.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:21:38.883+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:21:38.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:21:38.922+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:21:38.921+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:21:38.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-24T13:22:09.007+0000] {processor.py:157} INFO - Started process (PID=3581) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:22:09.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:22:09.011+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:22:09.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:22:09.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:22:09.177+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:22:09.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:22:09.312+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:22:09.312+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:22:09.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.403 seconds
[2024-10-24T13:22:39.619+0000] {processor.py:157} INFO - Started process (PID=3583) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:22:39.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:22:39.621+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:22:39.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:22:39.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:22:39.697+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:22:39.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:22:39.726+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:22:39.726+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:22:39.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.144 seconds
[2024-10-24T13:23:09.924+0000] {processor.py:157} INFO - Started process (PID=3585) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:23:09.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:23:09.927+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:23:09.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:23:09.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:23:10.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:23:10.006+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:23:10.042+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:23:10.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:23:10.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.148 seconds
[2024-10-24T13:23:40.204+0000] {processor.py:157} INFO - Started process (PID=3587) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:23:40.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:23:40.206+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:23:40.206+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:23:40.222+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:23:40.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:23:40.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:23:40.300+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:23:40.300+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:23:40.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T13:24:10.472+0000] {processor.py:157} INFO - Started process (PID=3589) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:24:10.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:24:10.475+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:24:10.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:24:10.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:24:10.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:24:10.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:24:10.605+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:24:10.605+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:24:10.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-24T13:24:40.798+0000] {processor.py:157} INFO - Started process (PID=3591) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:24:40.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:24:40.800+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:24:40.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:24:40.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:24:40.850+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:24:40.849+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:24:40.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:24:40.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:24:40.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T13:25:11.098+0000] {processor.py:157} INFO - Started process (PID=3593) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:25:11.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:25:11.099+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:25:11.099+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:25:11.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:25:11.137+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:25:11.136+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:25:11.159+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:25:11.159+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:25:11.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T13:25:41.377+0000] {processor.py:157} INFO - Started process (PID=3595) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:25:41.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:25:41.379+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:25:41.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:25:41.391+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:25:41.418+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:25:41.418+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:25:41.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:25:41.444+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:25:41.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T13:26:11.540+0000] {processor.py:157} INFO - Started process (PID=3597) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:26:11.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:26:11.541+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:26:11.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:26:11.556+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:26:11.589+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:26:11.589+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:26:11.619+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:26:11.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:26:11.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T13:26:41.802+0000] {processor.py:157} INFO - Started process (PID=3599) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:26:41.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:26:41.806+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:26:41.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:26:41.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:26:41.864+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:26:41.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:26:41.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:26:41.898+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:26:41.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T13:27:11.950+0000] {processor.py:157} INFO - Started process (PID=3601) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:27:11.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:27:11.951+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:27:11.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:27:11.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:27:11.998+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:27:11.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:27:12.025+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:27:12.025+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:27:12.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T13:27:42.219+0000] {processor.py:157} INFO - Started process (PID=3603) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:27:42.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:27:42.220+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:27:42.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:27:42.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:27:42.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:27:42.267+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:27:42.292+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:27:42.292+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:27:42.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T13:28:12.397+0000] {processor.py:157} INFO - Started process (PID=3605) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:28:12.398+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:28:12.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:28:12.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:28:12.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:28:12.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:28:12.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:28:12.462+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:28:12.461+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:28:12.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T13:28:42.642+0000] {processor.py:157} INFO - Started process (PID=3607) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:28:42.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:28:42.644+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:28:42.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:28:42.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:28:42.683+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:28:42.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:28:42.709+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:28:42.709+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:28:42.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T13:29:12.811+0000] {processor.py:157} INFO - Started process (PID=3609) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:29:12.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:29:12.815+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:29:12.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:29:12.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:29:12.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:29:12.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:29:12.914+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:29:12.914+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:29:12.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-24T13:29:43.021+0000] {processor.py:157} INFO - Started process (PID=3611) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:29:43.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:29:43.023+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:29:43.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:29:43.042+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:29:43.075+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:29:43.074+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:29:43.109+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:29:43.108+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:29:43.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-24T13:30:13.327+0000] {processor.py:157} INFO - Started process (PID=3613) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:30:13.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:30:13.328+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:30:13.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:30:13.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:30:13.388+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:30:13.388+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:30:13.424+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:30:13.424+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:30:13.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-24T13:30:43.564+0000] {processor.py:157} INFO - Started process (PID=3615) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:30:43.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:30:43.803+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:30:43.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:30:43.819+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:30:43.857+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:30:43.857+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:30:43.904+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:30:43.904+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:30:43.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.376 seconds
[2024-10-24T13:31:14.107+0000] {processor.py:157} INFO - Started process (PID=3617) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:31:14.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:31:14.109+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:31:14.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:31:14.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:31:14.208+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:31:14.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:31:14.253+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:31:14.253+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:31:14.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.189 seconds
[2024-10-24T13:31:44.480+0000] {processor.py:157} INFO - Started process (PID=3619) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:31:44.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:31:44.482+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:31:44.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:31:44.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:31:44.530+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:31:44.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:31:44.566+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:31:44.566+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:31:44.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T13:32:14.661+0000] {processor.py:157} INFO - Started process (PID=3621) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:32:14.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:32:14.662+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:32:14.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:32:14.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:32:14.713+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:32:14.713+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:32:14.740+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:32:14.740+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:32:14.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T13:32:44.864+0000] {processor.py:157} INFO - Started process (PID=3623) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:32:44.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:32:44.866+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:32:44.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:32:44.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:32:44.922+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:32:44.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:32:44.953+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:32:44.953+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:32:44.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T13:33:15.029+0000] {processor.py:157} INFO - Started process (PID=3625) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:33:15.030+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:33:15.031+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:33:15.031+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:33:15.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:33:15.081+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:33:15.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:33:15.117+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:33:15.116+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:33:15.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T13:33:45.297+0000] {processor.py:157} INFO - Started process (PID=3627) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:33:45.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:33:45.301+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:33:45.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:33:45.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:33:45.367+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:33:45.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:33:45.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:33:45.397+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:33:45.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T13:34:15.590+0000] {processor.py:157} INFO - Started process (PID=3629) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:34:15.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:34:15.595+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:34:15.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:34:15.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:34:15.738+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:34:15.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:34:15.782+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:34:15.782+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:34:15.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.235 seconds
[2024-10-24T13:34:45.937+0000] {processor.py:157} INFO - Started process (PID=3631) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:34:45.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:34:45.939+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:34:45.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:34:45.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:34:46.024+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:34:46.023+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:34:46.061+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:34:46.061+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:34:46.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-24T13:35:16.236+0000] {processor.py:157} INFO - Started process (PID=3633) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:35:16.238+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:35:16.240+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:35:16.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:35:16.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:35:16.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:35:16.317+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:35:16.345+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:35:16.345+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:35:16.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-24T13:35:46.423+0000] {processor.py:157} INFO - Started process (PID=3635) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:35:46.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:35:46.425+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:35:46.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:35:46.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:35:46.499+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:35:46.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:35:46.534+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:35:46.534+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:35:46.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.141 seconds
[2024-10-24T13:36:16.619+0000] {processor.py:157} INFO - Started process (PID=3637) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:36:16.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:36:16.621+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:36:16.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:36:16.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:36:16.672+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:36:16.672+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:36:16.699+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:36:16.699+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:36:16.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T13:36:46.870+0000] {processor.py:157} INFO - Started process (PID=3639) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:36:46.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:36:46.871+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:36:46.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:36:46.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:36:46.916+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:36:46.916+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:36:46.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:36:46.943+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:36:46.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T13:37:17.119+0000] {processor.py:157} INFO - Started process (PID=3641) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:37:17.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:37:17.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:37:17.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:37:17.153+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:37:17.225+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:37:17.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:37:17.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:37:17.269+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:37:17.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.172 seconds
[2024-10-24T13:37:47.444+0000] {processor.py:157} INFO - Started process (PID=3643) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:37:47.449+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:37:47.451+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:37:47.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:37:47.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:37:47.577+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:37:47.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:37:47.626+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:37:47.625+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:37:47.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.233 seconds
[2024-10-24T13:38:17.846+0000] {processor.py:157} INFO - Started process (PID=3645) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:38:17.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:38:17.848+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:38:17.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:38:17.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:38:17.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:38:17.899+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:38:17.928+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:38:17.928+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:38:17.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T13:38:48.096+0000] {processor.py:157} INFO - Started process (PID=3647) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:38:48.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:38:48.098+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:38:48.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:38:48.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:38:48.146+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:38:48.145+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:38:48.172+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:38:48.172+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:38:48.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T13:39:18.242+0000] {processor.py:157} INFO - Started process (PID=3649) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:39:18.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:39:18.244+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:39:18.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:39:18.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:39:18.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:39:18.288+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:39:18.319+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:39:18.319+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:39:18.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T13:39:48.499+0000] {processor.py:157} INFO - Started process (PID=3651) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:39:48.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:39:48.501+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:39:48.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:39:48.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:39:48.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:39:48.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:39:48.581+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:39:48.581+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:39:48.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T13:40:18.752+0000] {processor.py:157} INFO - Started process (PID=3653) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:40:18.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:40:18.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:40:18.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:40:18.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:40:18.806+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:40:18.806+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:40:18.838+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:40:18.838+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:40:18.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T13:40:48.945+0000] {processor.py:157} INFO - Started process (PID=3655) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:40:48.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:40:48.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:40:48.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:40:48.977+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:40:49.013+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:40:49.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:40:49.048+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:40:49.048+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:40:49.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-24T13:41:19.223+0000] {processor.py:157} INFO - Started process (PID=3657) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:41:19.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:41:19.225+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:41:19.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:41:19.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:41:19.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:41:19.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:41:19.296+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:41:19.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:41:19.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T13:41:49.377+0000] {processor.py:157} INFO - Started process (PID=3659) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:41:49.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:41:49.379+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:41:49.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:41:49.398+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:41:49.430+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:41:49.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:41:49.458+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:41:49.458+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:41:49.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T13:42:19.632+0000] {processor.py:157} INFO - Started process (PID=3661) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:42:19.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:42:19.634+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:42:19.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:42:19.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:42:19.686+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:42:19.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:42:19.750+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:42:19.750+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:42:19.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.138 seconds
[2024-10-24T13:42:49.897+0000] {processor.py:157} INFO - Started process (PID=3663) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:42:49.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:42:49.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:42:49.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:42:49.913+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:42:49.945+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:42:49.945+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:42:49.975+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:42:49.975+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:42:49.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T13:43:20.147+0000] {processor.py:157} INFO - Started process (PID=3665) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:43:20.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:43:20.149+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:43:20.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:43:20.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:43:20.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:43:20.193+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:43:20.218+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:43:20.218+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:43:20.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T13:43:50.395+0000] {processor.py:157} INFO - Started process (PID=3667) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:43:50.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:43:50.397+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:43:50.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:43:50.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:43:50.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:43:50.449+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:43:50.479+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:43:50.479+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:43:50.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T13:44:20.540+0000] {processor.py:157} INFO - Started process (PID=3669) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:44:20.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:44:20.543+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:44:20.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:44:20.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:44:20.586+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:44:20.586+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:44:20.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:44:20.616+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:44:20.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T13:44:50.746+0000] {processor.py:157} INFO - Started process (PID=3671) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:44:50.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:44:50.748+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:44:50.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:44:50.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:44:50.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:44:50.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:44:50.823+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:44:50.823+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:44:50.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T13:45:20.893+0000] {processor.py:157} INFO - Started process (PID=3673) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:45:20.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:45:20.896+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:45:20.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:45:20.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:45:20.949+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:45:20.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:45:20.976+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:45:20.975+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:45:21.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T13:45:51.183+0000] {processor.py:157} INFO - Started process (PID=3675) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:45:51.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:45:51.185+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:45:51.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:45:51.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:45:51.228+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:45:51.228+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:45:51.259+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:45:51.258+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:45:51.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T13:46:21.446+0000] {processor.py:157} INFO - Started process (PID=3677) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:46:21.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:46:21.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:46:21.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:46:21.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:46:21.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:46:21.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:46:21.589+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:46:21.589+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:46:21.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.171 seconds
[2024-10-24T13:46:51.770+0000] {processor.py:157} INFO - Started process (PID=3679) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:46:51.772+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:46:51.773+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:46:51.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:46:51.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:46:51.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:46:51.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:46:51.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:46:51.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:46:51.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-24T13:47:22.053+0000] {processor.py:157} INFO - Started process (PID=3681) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:47:22.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:47:22.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:47:22.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:47:22.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:47:22.116+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:47:22.116+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:47:22.156+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:47:22.155+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:47:22.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-24T13:47:52.358+0000] {processor.py:157} INFO - Started process (PID=3683) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:47:52.359+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:47:52.361+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:47:52.360+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:47:52.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:47:52.441+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:47:52.440+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:47:52.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:47:52.476+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:47:52.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.148 seconds
[2024-10-24T13:48:22.625+0000] {processor.py:157} INFO - Started process (PID=3685) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:48:22.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:48:22.627+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:48:22.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:48:22.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:48:22.675+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:48:22.675+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:48:22.703+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:48:22.703+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:48:22.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T13:48:52.879+0000] {processor.py:157} INFO - Started process (PID=3687) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:48:52.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:48:52.881+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:48:52.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:48:52.896+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:48:52.934+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:48:52.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:48:52.973+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:48:52.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:48:52.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T13:49:23.076+0000] {processor.py:157} INFO - Started process (PID=3689) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:49:23.088+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:49:23.089+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:49:23.089+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:49:23.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:49:23.145+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:49:23.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:49:23.170+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:49:23.169+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:49:23.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T13:49:53.336+0000] {processor.py:157} INFO - Started process (PID=3691) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:49:53.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:49:53.338+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:49:53.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:49:53.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:49:53.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:49:53.390+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:49:53.422+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:49:53.422+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:49:53.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T13:50:23.485+0000] {processor.py:157} INFO - Started process (PID=3693) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:50:23.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:50:23.487+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:50:23.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:50:23.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:50:23.537+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:50:23.537+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:50:23.566+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:50:23.566+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:50:23.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T13:50:53.755+0000] {processor.py:157} INFO - Started process (PID=3695) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:50:53.756+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:50:53.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:50:53.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:50:53.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:50:53.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:50:53.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:50:53.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:50:53.828+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:50:53.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T13:51:23.908+0000] {processor.py:157} INFO - Started process (PID=3697) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:51:23.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:51:23.911+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:51:23.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:51:23.932+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:51:23.968+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:51:23.968+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:51:24.005+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:51:24.005+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:51:24.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T13:51:54.116+0000] {processor.py:157} INFO - Started process (PID=3699) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:51:54.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:51:54.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:51:54.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:51:54.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:51:54.178+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:51:54.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:51:54.210+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:51:54.210+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:51:54.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T13:52:24.286+0000] {processor.py:157} INFO - Started process (PID=3701) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:52:24.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:52:24.287+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:52:24.287+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:52:24.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:52:24.333+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:52:24.332+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:52:24.361+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:52:24.361+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:52:24.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T13:52:54.540+0000] {processor.py:157} INFO - Started process (PID=3703) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:52:54.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:52:54.542+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:52:54.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:52:54.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:52:54.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:52:54.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:52:54.617+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:52:54.617+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:52:54.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T13:53:24.691+0000] {processor.py:157} INFO - Started process (PID=3705) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:53:24.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:53:24.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:53:24.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:53:24.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:53:24.739+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:53:24.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:53:24.767+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:53:24.767+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:53:24.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T13:53:54.902+0000] {processor.py:157} INFO - Started process (PID=3707) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:53:54.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:53:54.905+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:53:54.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:53:54.918+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:53:54.949+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:53:54.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:53:54.973+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:53:54.972+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:53:54.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T13:54:25.048+0000] {processor.py:157} INFO - Started process (PID=3709) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:54:25.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:54:25.049+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:54:25.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:54:25.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:54:25.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:54:25.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:54:25.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:54:25.119+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:54:25.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T13:54:55.286+0000] {processor.py:157} INFO - Started process (PID=3711) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:54:55.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:54:55.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:54:55.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:54:55.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:54:55.331+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:54:55.331+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:54:55.357+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:54:55.357+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:54:55.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T13:55:25.532+0000] {processor.py:157} INFO - Started process (PID=3713) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:55:25.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:55:25.539+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:55:25.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:55:25.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:55:25.615+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:55:25.615+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:55:25.652+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:55:25.651+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:55:25.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.147 seconds
[2024-10-24T13:55:55.845+0000] {processor.py:157} INFO - Started process (PID=3715) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:55:55.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:55:55.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:55:55.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:55:55.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:55:55.927+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:55:55.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:55:55.977+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:55:55.977+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:55:56.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-24T13:56:26.163+0000] {processor.py:157} INFO - Started process (PID=3717) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:56:26.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:56:26.165+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:56:26.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:56:26.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:56:26.226+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:56:26.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:56:26.256+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:56:26.256+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:56:26.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T13:56:56.322+0000] {processor.py:157} INFO - Started process (PID=3719) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:56:56.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:56:56.328+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:56:56.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:56:56.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:56:56.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:56:56.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:56:56.479+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:56:56.478+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:56:56.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-24T13:57:26.665+0000] {processor.py:157} INFO - Started process (PID=3721) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:57:26.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:57:26.666+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:57:26.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:57:26.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:57:26.716+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:57:26.716+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:57:26.745+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:57:26.745+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:57:26.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T13:57:56.920+0000] {processor.py:157} INFO - Started process (PID=3723) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:57:56.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:57:56.922+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:57:56.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:57:56.937+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:57:56.970+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:57:56.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:57:56.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:57:56.997+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:57:57.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T13:58:27.068+0000] {processor.py:157} INFO - Started process (PID=3725) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:58:27.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:58:27.069+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:58:27.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:58:27.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:58:27.114+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:58:27.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:58:27.140+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:58:27.140+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:58:27.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T13:58:57.311+0000] {processor.py:157} INFO - Started process (PID=3727) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:58:57.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:58:57.313+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:58:57.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:58:57.328+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:58:57.356+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:58:57.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:58:57.384+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:58:57.384+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:58:57.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T13:59:27.571+0000] {processor.py:157} INFO - Started process (PID=3729) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:59:27.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:59:27.572+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:59:27.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:59:27.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:59:27.617+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:59:27.617+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:59:27.639+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:59:27.639+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:59:27.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T13:59:57.813+0000] {processor.py:157} INFO - Started process (PID=3731) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:59:57.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T13:59:57.826+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:59:57.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:59:57.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T13:59:57.874+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:59:57.873+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T13:59:57.897+0000] {logging_mixin.py:149} INFO - [2024-10-24T13:59:57.897+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T13:59:57.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T14:00:27.973+0000] {processor.py:157} INFO - Started process (PID=3733) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:00:27.974+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:00:27.975+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:00:27.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:00:27.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:00:28.027+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:00:28.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:00:28.054+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:00:28.054+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:00:28.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T14:00:58.240+0000] {processor.py:157} INFO - Started process (PID=3735) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:00:58.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:00:58.242+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:00:58.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:00:58.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:00:58.287+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:00:58.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:00:58.312+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:00:58.312+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:00:58.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:01:28.387+0000] {processor.py:157} INFO - Started process (PID=3737) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:01:28.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:01:28.389+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:01:28.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:01:28.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:01:28.435+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:01:28.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:01:28.460+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:01:28.459+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:01:28.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T14:01:58.630+0000] {processor.py:157} INFO - Started process (PID=3739) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:01:58.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:01:58.633+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:01:58.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:01:58.650+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:01:58.682+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:01:58.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:01:58.708+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:01:58.708+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:01:58.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:02:28.779+0000] {processor.py:157} INFO - Started process (PID=3741) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:02:28.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:02:28.780+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:02:28.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:02:28.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:02:28.832+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:02:28.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:02:28.872+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:02:28.872+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:02:28.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T14:02:58.983+0000] {processor.py:157} INFO - Started process (PID=3743) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:02:58.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:02:58.985+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:02:58.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:02:59.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:02:59.037+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:02:59.036+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:02:59.065+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:02:59.065+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:02:59.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T14:03:29.239+0000] {processor.py:157} INFO - Started process (PID=3745) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:03:29.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:03:29.240+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:03:29.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:03:29.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:03:29.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:03:29.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:03:29.318+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:03:29.318+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:03:29.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:03:59.493+0000] {processor.py:157} INFO - Started process (PID=3747) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:03:59.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:03:59.496+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:03:59.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:03:59.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:03:59.554+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:03:59.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:03:59.585+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:03:59.584+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:03:59.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T14:04:29.651+0000] {processor.py:157} INFO - Started process (PID=3749) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:04:29.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:04:29.652+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:04:29.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:04:29.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:04:29.698+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:04:29.698+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:04:29.727+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:04:29.727+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:04:29.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:04:59.898+0000] {processor.py:157} INFO - Started process (PID=3751) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:04:59.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:04:59.900+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:04:59.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:04:59.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:04:59.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:04:59.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:04:59.974+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:04:59.974+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:04:59.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:05:30.039+0000] {processor.py:157} INFO - Started process (PID=3753) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:05:30.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:05:30.041+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:05:30.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:05:30.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:05:30.086+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:05:30.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:05:30.111+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:05:30.111+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:05:30.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T14:06:00.253+0000] {processor.py:157} INFO - Started process (PID=3755) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:06:00.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:06:00.254+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:06:00.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:06:00.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:06:00.301+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:06:00.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:06:00.328+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:06:00.328+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:06:00.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T14:06:30.501+0000] {processor.py:157} INFO - Started process (PID=3757) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:06:30.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:06:30.503+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:06:30.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:06:30.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:06:30.551+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:06:30.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:06:30.581+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:06:30.581+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:06:30.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T14:07:00.757+0000] {processor.py:157} INFO - Started process (PID=3759) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:07:00.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:07:00.759+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:07:00.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:07:00.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:07:00.810+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:07:00.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:07:00.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:07:00.840+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:07:00.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T14:07:30.906+0000] {processor.py:157} INFO - Started process (PID=3761) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:07:30.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:07:30.908+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:07:30.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:07:30.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:07:30.952+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:07:30.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:07:30.981+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:07:30.981+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:07:31.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:08:01.163+0000] {processor.py:157} INFO - Started process (PID=3763) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:08:01.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:08:01.165+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:08:01.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:08:01.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:08:01.234+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:08:01.234+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:08:01.264+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:08:01.263+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:08:01.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T14:08:31.308+0000] {processor.py:157} INFO - Started process (PID=3765) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:08:31.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:08:31.310+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:08:31.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:08:31.322+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:08:31.351+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:08:31.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:08:31.376+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:08:31.376+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:08:31.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T14:09:01.561+0000] {processor.py:157} INFO - Started process (PID=3767) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:09:01.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:09:01.563+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:09:01.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:09:01.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:09:01.610+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:09:01.610+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:09:01.634+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:09:01.634+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:09:01.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:09:31.797+0000] {processor.py:157} INFO - Started process (PID=3769) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:09:31.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:09:31.799+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:09:31.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:09:31.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:09:31.843+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:09:31.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:09:31.868+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:09:31.868+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:09:31.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:10:02.035+0000] {processor.py:157} INFO - Started process (PID=3771) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:10:02.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:10:02.036+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:10:02.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:10:02.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:10:02.078+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:10:02.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:10:02.105+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:10:02.105+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:10:02.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:10:32.192+0000] {processor.py:157} INFO - Started process (PID=3773) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:10:32.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:10:32.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:10:32.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:10:32.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:10:32.236+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:10:32.236+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:10:32.264+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:10:32.264+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:10:32.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:11:02.437+0000] {processor.py:157} INFO - Started process (PID=3775) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:11:02.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:11:02.441+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:11:02.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:11:02.477+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:11:02.533+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:11:02.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:11:02.570+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:11:02.570+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:11:02.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.165 seconds
[2024-10-24T14:11:32.727+0000] {processor.py:157} INFO - Started process (PID=3777) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:11:32.728+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:11:32.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:11:32.729+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:11:32.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:11:32.810+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:11:32.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:11:32.850+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:11:32.849+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:11:32.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.154 seconds
[2024-10-24T14:12:03.002+0000] {processor.py:157} INFO - Started process (PID=3779) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:12:03.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:12:03.004+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:12:03.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:12:03.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:12:03.069+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:12:03.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:12:03.107+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:12:03.107+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:12:03.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-24T14:12:33.145+0000] {processor.py:157} INFO - Started process (PID=3781) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:12:33.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:12:33.146+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:12:33.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:12:33.159+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:12:33.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:12:33.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:12:33.228+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:12:33.228+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:12:33.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T14:13:03.399+0000] {processor.py:157} INFO - Started process (PID=3783) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:13:03.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:13:03.401+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:13:03.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:13:03.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:13:03.451+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:13:03.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:13:03.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:13:03.474+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:13:03.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:13:33.645+0000] {processor.py:157} INFO - Started process (PID=3785) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:13:33.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:13:33.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:13:33.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:13:33.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:13:33.694+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:13:33.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:13:33.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:13:33.729+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:13:33.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T14:14:03.791+0000] {processor.py:157} INFO - Started process (PID=3787) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:14:03.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:14:03.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:14:03.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:14:03.806+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:14:03.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:14:03.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:14:03.867+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:14:03.867+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:14:03.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:14:34.040+0000] {processor.py:157} INFO - Started process (PID=3789) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:14:34.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:14:34.042+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:14:34.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:14:34.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:14:34.087+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:14:34.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:14:34.115+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:14:34.115+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:14:34.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T14:15:04.190+0000] {processor.py:157} INFO - Started process (PID=3791) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:15:04.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:15:04.191+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:15:04.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:15:04.205+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:15:04.236+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:15:04.236+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:15:04.265+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:15:04.265+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:15:04.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:15:34.398+0000] {processor.py:157} INFO - Started process (PID=3793) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:15:34.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:15:34.411+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:15:34.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:15:34.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:15:34.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:15:34.449+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:15:34.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:15:34.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:15:34.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:16:04.543+0000] {processor.py:157} INFO - Started process (PID=3795) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:16:04.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:16:04.545+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:16:04.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:16:04.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:16:04.585+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:16:04.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:16:04.609+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:16:04.608+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:16:04.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:16:34.753+0000] {processor.py:157} INFO - Started process (PID=3797) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:16:34.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:16:34.765+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:16:34.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:16:34.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:16:34.808+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:16:34.807+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:16:34.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:16:34.839+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:16:34.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T14:17:04.897+0000] {processor.py:157} INFO - Started process (PID=3799) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:17:04.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:17:04.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:17:04.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:17:04.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:17:04.940+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:17:04.939+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:17:04.966+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:17:04.966+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:17:04.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:17:35.150+0000] {processor.py:157} INFO - Started process (PID=3801) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:17:35.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:17:35.153+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:17:35.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:17:35.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:17:35.195+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:17:35.195+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:17:35.221+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:17:35.221+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:17:35.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:18:05.402+0000] {processor.py:157} INFO - Started process (PID=3803) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:18:05.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:18:05.403+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:18:05.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:18:05.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:18:05.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:18:05.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:18:05.468+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:18:05.468+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:18:05.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T14:18:35.644+0000] {processor.py:157} INFO - Started process (PID=3805) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:18:35.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:18:35.646+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:18:35.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:18:35.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:18:35.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:18:35.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:18:35.715+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:18:35.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:18:35.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:19:05.806+0000] {processor.py:157} INFO - Started process (PID=3807) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:19:05.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:19:05.807+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:19:05.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:19:05.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:19:05.856+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:19:05.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:19:05.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:19:05.885+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:19:05.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T14:19:35.982+0000] {processor.py:157} INFO - Started process (PID=3809) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:19:35.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:19:35.984+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:19:35.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:19:35.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:19:36.029+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:19:36.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:19:36.051+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:19:36.051+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:19:36.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T14:20:06.174+0000] {processor.py:157} INFO - Started process (PID=3811) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:20:06.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:20:06.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:20:06.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:20:06.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:20:06.269+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:20:06.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:20:06.308+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:20:06.308+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:20:06.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.160 seconds
[2024-10-24T14:20:36.498+0000] {processor.py:157} INFO - Started process (PID=3813) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:20:36.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:20:36.500+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:20:36.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:20:36.513+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:20:36.543+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:20:36.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:20:36.571+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:20:36.571+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:20:36.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T14:21:06.767+0000] {processor.py:157} INFO - Started process (PID=3815) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:21:06.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:21:06.769+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:21:06.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:21:06.783+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:21:06.815+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:21:06.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:21:06.843+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:21:06.843+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:21:06.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:21:36.927+0000] {processor.py:157} INFO - Started process (PID=3817) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:21:36.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:21:36.930+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:21:36.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:21:36.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:21:36.982+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:21:36.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:21:37.006+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:21:37.006+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:21:37.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:22:07.127+0000] {processor.py:157} INFO - Started process (PID=3819) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:22:07.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:22:07.128+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:22:07.128+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:22:07.142+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:22:07.172+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:22:07.172+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:22:07.197+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:22:07.197+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:22:07.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T14:22:37.287+0000] {processor.py:157} INFO - Started process (PID=3821) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:22:37.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:22:37.290+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:22:37.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:22:37.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:22:37.341+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:22:37.341+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:22:37.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:22:37.367+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:22:37.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T14:23:07.548+0000] {processor.py:157} INFO - Started process (PID=3823) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:23:07.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:23:07.550+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:23:07.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:23:07.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:23:07.605+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:23:07.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:23:07.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:23:07.642+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:23:07.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-24T14:23:37.865+0000] {processor.py:157} INFO - Started process (PID=3825) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:23:37.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:23:37.867+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:23:37.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:23:37.882+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:23:37.914+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:23:37.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:23:37.941+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:23:37.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:23:37.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:24:08.025+0000] {processor.py:157} INFO - Started process (PID=3827) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:24:08.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:24:08.026+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:24:08.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:24:08.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:24:08.068+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:24:08.067+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:24:08.093+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:24:08.093+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:24:08.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T14:24:38.265+0000] {processor.py:157} INFO - Started process (PID=3829) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:24:38.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:24:38.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:24:38.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:24:38.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:24:38.307+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:24:38.307+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:24:38.330+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:24:38.330+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:24:38.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T14:25:08.510+0000] {processor.py:157} INFO - Started process (PID=3831) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:25:08.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:25:08.511+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:25:08.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:25:08.525+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:25:08.555+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:25:08.555+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:25:08.582+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:25:08.581+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:25:08.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T14:25:38.765+0000] {processor.py:157} INFO - Started process (PID=3833) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:25:38.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:25:38.767+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:25:38.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:25:38.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:25:38.816+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:25:38.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:25:38.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:25:38.861+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:25:38.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T14:26:09.033+0000] {processor.py:157} INFO - Started process (PID=3835) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:26:09.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:26:09.035+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:26:09.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:26:09.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:26:09.076+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:26:09.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:26:09.101+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:26:09.101+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:26:09.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T14:26:39.279+0000] {processor.py:157} INFO - Started process (PID=3837) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:26:39.280+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:26:39.281+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:26:39.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:26:39.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:26:39.327+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:26:39.327+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:26:39.352+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:26:39.352+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:26:39.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:27:09.435+0000] {processor.py:157} INFO - Started process (PID=3839) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:27:09.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:27:09.437+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:27:09.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:27:09.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:27:09.482+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:27:09.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:27:09.510+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:27:09.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:27:09.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:27:39.682+0000] {processor.py:157} INFO - Started process (PID=3841) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:27:39.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:27:39.684+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:27:39.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:27:39.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:27:39.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:27:39.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:27:39.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:27:39.757+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:27:39.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T14:28:09.827+0000] {processor.py:157} INFO - Started process (PID=3843) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:28:09.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:28:09.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:28:09.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:28:09.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:28:09.870+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:28:09.870+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:28:09.900+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:28:09.899+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:28:09.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:28:40.071+0000] {processor.py:157} INFO - Started process (PID=3845) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:28:40.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:28:40.073+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:28:40.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:28:40.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:28:40.114+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:28:40.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:28:40.140+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:28:40.140+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:28:40.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:29:10.221+0000] {processor.py:157} INFO - Started process (PID=3847) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:29:10.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:29:10.223+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:29:10.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:29:10.240+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:29:10.271+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:29:10.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:29:10.304+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:29:10.304+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:29:10.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T14:29:40.407+0000] {processor.py:157} INFO - Started process (PID=3849) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:29:40.408+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:29:40.409+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:29:40.409+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:29:40.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:29:40.450+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:29:40.450+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:29:40.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:29:40.473+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:29:40.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T14:30:10.644+0000] {processor.py:157} INFO - Started process (PID=3851) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:30:10.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:30:10.646+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:30:10.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:30:10.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:30:10.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:30:10.693+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:30:10.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:30:10.721+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:30:10.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:30:40.916+0000] {processor.py:157} INFO - Started process (PID=3853) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:30:40.917+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:30:40.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:30:40.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:30:40.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:30:40.970+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:30:40.970+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:30:40.998+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:30:40.998+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:30:41.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T14:31:11.087+0000] {processor.py:157} INFO - Started process (PID=3855) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:31:11.088+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:31:11.088+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:31:11.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:31:11.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:31:11.138+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:31:11.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:31:11.166+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:31:11.165+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:31:11.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T14:31:41.339+0000] {processor.py:157} INFO - Started process (PID=3857) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:31:41.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:31:41.341+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:31:41.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:31:41.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:31:41.388+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:31:41.387+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:31:41.420+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:31:41.420+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:31:41.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T14:32:11.597+0000] {processor.py:157} INFO - Started process (PID=3859) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:32:11.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:32:11.600+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:32:11.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:32:11.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:32:11.660+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:32:11.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:32:11.690+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:32:11.690+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:32:11.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T14:32:41.755+0000] {processor.py:157} INFO - Started process (PID=3861) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:32:41.756+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:32:41.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:32:41.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:32:41.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:32:41.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:32:41.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:32:41.824+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:32:41.824+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:32:41.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:33:11.993+0000] {processor.py:157} INFO - Started process (PID=3863) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:33:11.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:33:11.994+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:33:11.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:33:12.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:33:12.037+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:33:12.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:33:12.067+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:33:12.067+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:33:12.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T14:33:42.234+0000] {processor.py:157} INFO - Started process (PID=3865) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:33:42.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:33:42.236+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:33:42.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:33:42.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:33:42.284+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:33:42.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:33:42.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:33:42.311+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:33:42.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:34:12.387+0000] {processor.py:157} INFO - Started process (PID=3867) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:34:12.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:34:12.389+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:34:12.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:34:12.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:34:12.432+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:34:12.432+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:34:12.458+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:34:12.458+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:34:12.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T14:34:42.565+0000] {processor.py:157} INFO - Started process (PID=3869) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:34:42.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:34:42.577+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:34:42.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:34:42.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:34:42.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:34:42.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:34:42.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:34:42.647+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:34:42.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T14:35:12.737+0000] {processor.py:157} INFO - Started process (PID=3871) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:35:12.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:35:12.738+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:35:12.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:35:12.755+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:35:12.783+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:35:12.783+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:35:12.810+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:35:12.810+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:35:12.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:35:42.999+0000] {processor.py:157} INFO - Started process (PID=3873) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:35:43.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:35:43.001+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:35:43.001+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:35:43.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:35:43.047+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:35:43.047+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:35:43.074+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:35:43.074+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:35:43.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T14:36:13.247+0000] {processor.py:157} INFO - Started process (PID=3875) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:36:13.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:36:13.248+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:36:13.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:36:13.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:36:13.294+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:36:13.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:36:13.320+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:36:13.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:36:13.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:36:43.405+0000] {processor.py:157} INFO - Started process (PID=3877) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:36:43.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:36:43.408+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:36:43.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:36:43.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:36:43.463+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:36:43.463+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:36:43.492+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:36:43.492+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:36:43.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T14:37:13.665+0000] {processor.py:157} INFO - Started process (PID=3879) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:37:13.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:37:13.667+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:37:13.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:37:13.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:37:13.711+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:37:13.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:37:13.740+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:37:13.740+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:37:13.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:37:43.915+0000] {processor.py:157} INFO - Started process (PID=3881) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:37:43.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:37:43.917+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:37:43.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:37:43.935+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:37:43.966+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:37:43.966+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:37:43.993+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:37:43.993+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:37:44.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T14:38:14.173+0000] {processor.py:157} INFO - Started process (PID=3883) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:38:14.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:38:14.185+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:38:14.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:38:14.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:38:14.229+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:38:14.229+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:38:14.259+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:38:14.259+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:38:14.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T14:38:44.426+0000] {processor.py:157} INFO - Started process (PID=3885) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:38:44.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:38:44.427+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:38:44.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:38:44.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:38:44.471+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:38:44.471+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:38:44.497+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:38:44.496+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:38:44.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T14:39:14.669+0000] {processor.py:157} INFO - Started process (PID=3887) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:39:14.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:39:14.682+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:39:14.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:39:14.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:39:14.728+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:39:14.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:39:14.760+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:39:14.760+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:39:14.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T14:39:44.816+0000] {processor.py:157} INFO - Started process (PID=3889) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:39:44.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:39:44.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:39:44.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:39:44.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:39:44.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:39:44.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:39:44.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:39:44.886+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:39:44.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:40:15.069+0000] {processor.py:157} INFO - Started process (PID=3891) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:40:15.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:40:15.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:40:15.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:40:15.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:40:15.125+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:40:15.124+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:40:15.158+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:40:15.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:40:15.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T14:40:45.237+0000] {processor.py:157} INFO - Started process (PID=3893) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:40:45.238+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:40:45.239+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:40:45.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:40:45.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:40:45.290+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:40:45.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:40:45.323+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:40:45.323+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:40:45.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T14:41:15.538+0000] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:41:15.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:41:15.539+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:41:15.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:41:15.556+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:41:15.588+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:41:15.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:41:15.621+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:41:15.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:41:15.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T14:41:45.688+0000] {processor.py:157} INFO - Started process (PID=3897) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:41:45.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:41:45.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:41:45.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:41:45.705+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:41:45.736+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:41:45.736+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:41:45.765+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:41:45.765+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:41:45.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:42:15.938+0000] {processor.py:157} INFO - Started process (PID=3899) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:42:15.939+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:42:15.939+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:42:15.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:42:15.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:42:15.984+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:42:15.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:42:16.008+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:42:16.008+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:42:16.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T14:42:46.178+0000] {processor.py:157} INFO - Started process (PID=3901) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:42:46.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:42:46.179+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:42:46.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:42:46.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:42:46.223+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:42:46.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:42:46.249+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:42:46.249+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:42:46.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:43:16.328+0000] {processor.py:157} INFO - Started process (PID=3903) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:43:16.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:43:16.330+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:43:16.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:43:16.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:43:16.370+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:43:16.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:43:16.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:43:16.397+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:43:16.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T14:43:46.574+0000] {processor.py:157} INFO - Started process (PID=3905) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:43:46.575+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:43:46.575+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:43:46.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:43:46.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:43:46.621+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:43:46.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:43:46.651+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:43:46.651+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:43:46.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:44:16.826+0000] {processor.py:157} INFO - Started process (PID=3907) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:44:16.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:44:16.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:44:16.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:44:16.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:44:16.882+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:44:16.881+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:44:16.913+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:44:16.913+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:44:16.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T14:44:47.090+0000] {processor.py:157} INFO - Started process (PID=3909) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:44:47.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:44:47.091+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:44:47.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:44:47.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:44:47.133+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:44:47.133+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:44:47.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:44:47.162+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:44:47.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:45:17.345+0000] {processor.py:157} INFO - Started process (PID=3911) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:45:17.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:45:17.346+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:45:17.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:45:17.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:45:17.394+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:45:17.394+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:45:17.421+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:45:17.421+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:45:17.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:45:47.596+0000] {processor.py:157} INFO - Started process (PID=3913) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:45:47.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:45:47.598+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:45:47.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:45:47.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:45:47.644+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:45:47.644+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:45:47.670+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:45:47.669+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:45:47.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T14:46:17.845+0000] {processor.py:157} INFO - Started process (PID=3915) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:46:17.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:46:17.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:46:17.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:46:17.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:46:17.893+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:46:17.893+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:46:17.924+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:46:17.924+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:46:17.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T14:46:47.985+0000] {processor.py:157} INFO - Started process (PID=3917) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:46:47.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:46:47.986+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:46:47.986+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:46:48.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:46:48.033+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:46:48.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:46:48.063+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:46:48.063+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:46:48.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T14:47:18.208+0000] {processor.py:157} INFO - Started process (PID=3919) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:47:18.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:47:18.210+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:47:18.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:47:18.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:47:18.253+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:47:18.253+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:47:18.277+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:47:18.276+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:47:18.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:47:48.352+0000] {processor.py:157} INFO - Started process (PID=3921) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:47:48.353+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:47:48.354+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:47:48.354+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:47:48.370+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:47:48.400+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:47:48.400+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:47:48.425+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:47:48.425+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:47:48.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:48:18.543+0000] {processor.py:157} INFO - Started process (PID=3923) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:48:18.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:48:18.544+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:48:18.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:48:18.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:48:18.588+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:48:18.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:48:18.611+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:48:18.611+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:48:18.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:48:48.685+0000] {processor.py:157} INFO - Started process (PID=3925) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:48:48.686+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:48:48.687+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:48:48.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:48:48.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:48:48.731+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:48:48.730+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:48:48.761+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:48:48.761+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:48:48.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T14:49:18.883+0000] {processor.py:157} INFO - Started process (PID=3927) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:49:18.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:49:18.885+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:49:18.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:49:18.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:49:18.932+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:49:18.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:49:18.969+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:49:18.969+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:49:18.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T14:49:49.036+0000] {processor.py:157} INFO - Started process (PID=3929) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:49:49.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:49:49.039+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:49:49.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:49:49.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:49:49.084+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:49:49.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:49:49.107+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:49:49.107+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:49:49.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:50:19.282+0000] {processor.py:157} INFO - Started process (PID=3931) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:50:19.283+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:50:19.283+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:50:19.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:50:19.297+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:50:19.327+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:50:19.326+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:50:19.351+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:50:19.351+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:50:19.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T14:50:49.438+0000] {processor.py:157} INFO - Started process (PID=3933) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:50:49.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:50:49.440+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:50:49.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:50:49.454+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:50:49.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:50:49.484+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:50:49.507+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:50:49.506+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:50:49.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:51:19.676+0000] {processor.py:157} INFO - Started process (PID=3935) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:51:19.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:51:19.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:51:19.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:51:19.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:51:19.725+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:51:19.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:51:19.748+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:51:19.748+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:51:19.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T14:51:49.825+0000] {processor.py:157} INFO - Started process (PID=3937) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:51:49.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:51:49.827+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:51:49.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:51:49.842+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:51:49.871+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:51:49.870+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:51:49.897+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:51:49.897+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:51:49.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:52:20.024+0000] {processor.py:157} INFO - Started process (PID=3939) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:52:20.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:52:20.026+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:52:20.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:52:20.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:52:20.068+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:52:20.068+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:52:20.092+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:52:20.092+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:52:20.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:52:50.174+0000] {processor.py:157} INFO - Started process (PID=3941) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:52:50.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:52:50.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:52:50.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:52:50.190+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:52:50.223+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:52:50.222+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:52:50.252+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:52:50.252+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:52:50.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:53:20.432+0000] {processor.py:157} INFO - Started process (PID=3943) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:53:20.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:53:20.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:53:20.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:53:20.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:53:20.485+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:53:20.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:53:20.509+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:53:20.509+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:53:20.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:53:50.581+0000] {processor.py:157} INFO - Started process (PID=3945) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:53:50.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:53:50.583+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:53:50.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:53:50.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:53:50.626+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:53:50.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:53:50.656+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:53:50.656+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:53:50.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T14:54:20.834+0000] {processor.py:157} INFO - Started process (PID=3947) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:54:20.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:54:20.836+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:54:20.836+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:54:20.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:54:20.879+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:54:20.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:54:20.901+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:54:20.901+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:54:20.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T14:54:50.981+0000] {processor.py:157} INFO - Started process (PID=3949) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:54:50.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:54:50.983+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:54:50.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:54:50.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:54:51.026+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:54:51.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:54:51.050+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:54:51.050+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:54:51.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T14:55:21.173+0000] {processor.py:157} INFO - Started process (PID=3951) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:55:21.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:55:21.175+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:55:21.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:55:21.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:55:21.219+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:55:21.218+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:55:21.244+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:55:21.244+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:55:21.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:55:51.442+0000] {processor.py:157} INFO - Started process (PID=3953) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:55:51.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:55:51.443+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:55:51.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:55:51.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:55:51.490+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:55:51.490+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:55:51.517+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:55:51.517+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:55:51.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:56:21.603+0000] {processor.py:157} INFO - Started process (PID=3955) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:56:21.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:56:21.606+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:56:21.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:56:21.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:56:21.656+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:56:21.656+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:56:21.681+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:56:21.681+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:56:21.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T14:56:51.814+0000] {processor.py:157} INFO - Started process (PID=3957) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:56:51.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:56:51.815+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:56:51.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:56:51.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:56:51.869+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:56:51.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:56:51.907+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:56:51.907+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:56:51.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T14:57:22.084+0000] {processor.py:157} INFO - Started process (PID=3959) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:57:22.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:57:22.086+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:57:22.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:57:22.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:57:22.129+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:57:22.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:57:22.155+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:57:22.155+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:57:22.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T14:57:52.337+0000] {processor.py:157} INFO - Started process (PID=3961) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:57:52.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:57:52.338+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:57:52.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:57:52.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:57:52.381+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:57:52.381+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:57:52.405+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:57:52.405+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:57:52.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T14:58:22.482+0000] {processor.py:157} INFO - Started process (PID=3963) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:58:22.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:58:22.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:58:22.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:58:22.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:58:22.526+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:58:22.526+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:58:22.551+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:58:22.551+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:58:22.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T14:58:52.733+0000] {processor.py:157} INFO - Started process (PID=3965) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:58:52.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:58:52.735+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:58:52.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:58:52.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:58:52.777+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:58:52.776+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:58:52.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:58:52.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:58:52.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T14:59:22.889+0000] {processor.py:157} INFO - Started process (PID=3967) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:59:22.901+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:59:22.902+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:59:22.902+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:59:22.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:59:22.942+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:59:22.942+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:59:22.967+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:59:22.966+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:59:22.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T14:59:53.074+0000] {processor.py:157} INFO - Started process (PID=3969) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:59:53.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T14:59:53.075+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:59:53.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:59:53.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T14:59:53.118+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:59:53.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T14:59:53.142+0000] {logging_mixin.py:149} INFO - [2024-10-24T14:59:53.142+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T14:59:53.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T15:00:23.240+0000] {processor.py:157} INFO - Started process (PID=3971) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:00:23.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:00:23.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:00:23.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:00:23.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:00:23.285+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:00:23.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:00:23.312+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:00:23.311+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:00:23.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T15:00:53.501+0000] {processor.py:157} INFO - Started process (PID=3973) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:00:53.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:00:53.502+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:00:53.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:00:53.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:00:53.553+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:00:53.553+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:00:53.580+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:00:53.580+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:00:53.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T15:01:23.657+0000] {processor.py:157} INFO - Started process (PID=3975) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:01:23.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:01:23.659+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:01:23.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:01:23.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:01:23.710+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:01:23.709+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:01:23.755+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:01:23.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:01:23.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T15:01:53.922+0000] {processor.py:157} INFO - Started process (PID=3977) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:01:53.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:01:53.924+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:01:53.923+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:01:53.937+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:01:53.965+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:01:53.965+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:01:53.989+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:01:53.989+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:01:54.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:02:24.070+0000] {processor.py:157} INFO - Started process (PID=3979) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:02:24.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:02:24.072+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:02:24.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:02:24.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:02:24.132+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:02:24.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:02:24.185+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:02:24.184+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:02:24.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.170 seconds
[2024-10-24T15:02:54.408+0000] {processor.py:157} INFO - Started process (PID=3981) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:02:54.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:02:54.409+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:02:54.409+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:02:54.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:02:54.456+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:02:54.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:02:54.481+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:02:54.481+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:02:54.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T15:03:24.559+0000] {processor.py:157} INFO - Started process (PID=3983) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:03:24.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:03:24.561+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:03:24.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:03:24.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:03:24.599+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:03:24.599+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:03:24.621+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:03:24.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:03:24.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T15:03:54.790+0000] {processor.py:157} INFO - Started process (PID=3985) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:03:54.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:03:54.791+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:03:54.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:03:54.807+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:03:54.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:03:54.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:03:54.863+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:03:54.863+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:03:54.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T15:04:24.942+0000] {processor.py:157} INFO - Started process (PID=3987) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:04:24.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:04:24.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:04:24.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:04:24.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:04:24.985+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:04:24.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:04:25.011+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:04:25.010+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:04:25.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T15:04:55.184+0000] {processor.py:157} INFO - Started process (PID=3989) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:04:55.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:04:55.186+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:04:55.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:04:55.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:04:55.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:04:55.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:04:55.252+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:04:55.252+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:04:55.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:05:25.425+0000] {processor.py:157} INFO - Started process (PID=3991) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:05:25.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:05:25.427+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:05:25.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:05:25.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:05:25.469+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:05:25.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:05:25.493+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:05:25.493+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:05:25.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T15:05:55.668+0000] {processor.py:157} INFO - Started process (PID=3993) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:05:55.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:05:55.669+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:05:55.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:05:55.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:05:55.713+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:05:55.713+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:05:55.738+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:05:55.738+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:05:55.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T15:06:25.827+0000] {processor.py:157} INFO - Started process (PID=3995) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:06:25.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:06:25.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:06:25.829+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:06:25.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:06:25.884+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:06:25.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:06:25.927+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:06:25.927+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:06:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-24T15:06:56.106+0000] {processor.py:157} INFO - Started process (PID=3997) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:06:56.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:06:56.107+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:06:56.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:06:56.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:06:56.151+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:06:56.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:06:56.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:06:56.176+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:06:56.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T15:07:26.253+0000] {processor.py:157} INFO - Started process (PID=3999) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:07:26.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:07:26.255+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:07:26.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:07:26.267+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:07:26.295+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:07:26.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:07:26.319+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:07:26.319+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:07:26.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T15:07:56.483+0000] {processor.py:157} INFO - Started process (PID=4001) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:07:56.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:07:56.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:07:56.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:07:56.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:07:56.525+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:07:56.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:07:56.550+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:07:56.550+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:07:56.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:08:26.628+0000] {processor.py:157} INFO - Started process (PID=4003) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:08:26.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:08:26.630+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:08:26.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:08:26.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:08:26.673+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:08:26.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:08:26.702+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:08:26.702+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:08:26.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T15:08:56.874+0000] {processor.py:157} INFO - Started process (PID=4005) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:08:56.875+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:08:56.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:08:56.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:08:56.891+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:08:56.917+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:08:56.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:08:56.941+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:08:56.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:08:56.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:09:27.114+0000] {processor.py:157} INFO - Started process (PID=4007) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:09:27.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:09:27.115+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:09:27.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:09:27.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:09:27.157+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:09:27.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:09:27.181+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:09:27.181+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:09:27.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T15:09:57.271+0000] {processor.py:157} INFO - Started process (PID=4009) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:09:57.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:09:57.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:09:57.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:09:57.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:09:57.322+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:09:57.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:09:57.346+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:09:57.346+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:09:57.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T15:10:27.526+0000] {processor.py:157} INFO - Started process (PID=4011) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:10:27.527+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:10:27.527+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:10:27.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:10:27.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:10:27.571+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:10:27.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:10:27.598+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:10:27.597+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:10:27.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T15:10:57.692+0000] {processor.py:157} INFO - Started process (PID=4013) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:10:57.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:10:57.703+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:10:57.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:10:57.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:10:57.746+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:10:57.746+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:10:57.771+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:10:57.771+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:10:57.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T15:11:27.858+0000] {processor.py:157} INFO - Started process (PID=4015) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:11:27.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:11:27.860+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:11:27.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:11:27.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:11:27.911+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:11:27.910+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:11:27.941+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:11:27.941+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:11:27.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T15:11:58.031+0000] {processor.py:157} INFO - Started process (PID=4017) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:11:58.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:11:58.033+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:11:58.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:11:58.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:11:58.085+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:11:58.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:11:58.113+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:11:58.113+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:11:58.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T15:12:28.288+0000] {processor.py:157} INFO - Started process (PID=4019) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:12:28.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:12:28.290+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:12:28.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:12:28.306+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:12:28.336+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:12:28.336+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:12:28.366+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:12:28.365+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:12:28.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T15:12:58.536+0000] {processor.py:157} INFO - Started process (PID=4021) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:12:58.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:12:58.537+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:12:58.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:12:58.552+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:12:58.581+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:12:58.581+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:12:58.605+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:12:58.605+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:12:58.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T15:13:28.964+0000] {processor.py:157} INFO - Started process (PID=4023) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:13:28.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:13:29.010+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:13:29.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:13:29.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:13:29.686+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:13:29.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:13:29.777+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:13:29.776+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:13:29.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.041 seconds
[2024-10-24T15:13:59.993+0000] {processor.py:157} INFO - Started process (PID=4025) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:14:00.035+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:14:00.036+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:14:00.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:14:00.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:14:00.141+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:14:00.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:14:00.320+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:14:00.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:14:00.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.401 seconds
[2024-10-24T15:14:30.555+0000] {processor.py:157} INFO - Started process (PID=4027) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:14:30.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:14:30.557+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:14:30.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:14:30.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:14:30.908+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:14:30.908+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:14:30.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:14:30.958+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:14:30.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.446 seconds
[2024-10-24T15:15:01.127+0000] {processor.py:157} INFO - Started process (PID=4029) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:15:01.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:15:01.129+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:15:01.129+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:15:01.146+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:15:01.179+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:15:01.179+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:15:01.234+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:15:01.234+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:15:01.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-24T15:15:31.420+0000] {processor.py:157} INFO - Started process (PID=4031) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:15:31.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:15:31.427+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:15:31.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:15:31.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:15:31.588+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:15:31.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:15:31.660+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:15:31.660+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:15:31.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.272 seconds
[2024-10-24T15:16:01.842+0000] {processor.py:157} INFO - Started process (PID=4033) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:16:01.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:16:01.844+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:16:01.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:16:01.858+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:16:01.885+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:16:01.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:16:01.909+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:16:01.908+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:16:01.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T15:16:31.996+0000] {processor.py:157} INFO - Started process (PID=4035) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:16:31.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:16:31.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:16:31.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:16:32.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:16:32.052+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:16:32.052+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:16:32.080+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:16:32.080+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:16:32.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T15:17:02.254+0000] {processor.py:157} INFO - Started process (PID=4037) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:17:02.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:17:02.256+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:17:02.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:17:02.268+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:17:02.298+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:17:02.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:17:02.323+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:17:02.322+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:17:02.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T15:17:32.499+0000] {processor.py:157} INFO - Started process (PID=4039) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:17:32.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:17:32.501+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:17:32.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:17:32.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:17:32.544+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:17:32.544+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:17:32.570+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:17:32.570+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:17:32.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T15:18:02.653+0000] {processor.py:157} INFO - Started process (PID=4041) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:18:02.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:18:02.655+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:18:02.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:18:02.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:18:02.704+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:18:02.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:18:02.730+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:18:02.730+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:18:02.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T15:18:32.848+0000] {processor.py:157} INFO - Started process (PID=4043) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:18:32.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:18:32.851+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:18:32.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:18:32.863+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:18:32.901+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:18:32.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:18:32.929+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:18:32.929+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:18:32.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T15:19:03.103+0000] {processor.py:157} INFO - Started process (PID=4045) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:19:03.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:19:03.125+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:19:03.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:19:03.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:19:03.177+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:19:03.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:19:03.207+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:19:03.207+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:19:03.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T15:19:33.373+0000] {processor.py:157} INFO - Started process (PID=4047) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:19:33.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:19:33.374+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:19:33.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:19:33.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:19:33.411+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:19:33.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:19:33.434+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:19:33.434+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:19:33.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-24T15:20:03.601+0000] {processor.py:157} INFO - Started process (PID=4049) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:20:03.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:20:03.603+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:20:03.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:20:03.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:20:03.640+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:20:03.640+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:20:03.661+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:20:03.661+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:20:03.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-24T15:20:33.832+0000] {processor.py:157} INFO - Started process (PID=4051) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:20:33.833+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:20:33.833+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:20:33.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:20:33.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:20:33.879+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:20:33.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:20:33.906+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:20:33.906+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:20:33.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T15:21:03.991+0000] {processor.py:157} INFO - Started process (PID=4053) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:21:03.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:21:03.993+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:21:03.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:21:04.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:21:04.034+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:21:04.034+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:21:04.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:21:04.056+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:21:04.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T15:21:34.225+0000] {processor.py:157} INFO - Started process (PID=4055) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:21:34.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:21:34.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:21:34.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:21:34.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:21:34.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:21:34.274+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:21:34.295+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:21:34.295+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:21:34.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T15:22:04.475+0000] {processor.py:157} INFO - Started process (PID=4057) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:22:04.477+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:22:04.477+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:22:04.477+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:22:04.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:22:04.524+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:22:04.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:22:04.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:22:04.549+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:22:04.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T15:22:34.736+0000] {processor.py:157} INFO - Started process (PID=4059) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:22:34.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:22:34.737+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:22:34.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:22:34.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:22:34.775+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:22:34.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:22:34.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:22:34.798+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:22:34.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T15:23:04.965+0000] {processor.py:157} INFO - Started process (PID=4061) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:23:04.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:23:04.978+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:23:04.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:23:04.993+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:23:05.024+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:23:05.024+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:23:05.047+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:23:05.047+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:23:05.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T15:23:35.216+0000] {processor.py:157} INFO - Started process (PID=4063) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:23:35.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:23:35.218+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:23:35.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:23:35.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:23:35.258+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:23:35.257+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:23:35.281+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:23:35.281+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:23:35.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T15:24:05.447+0000] {processor.py:157} INFO - Started process (PID=4065) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:24:05.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:24:05.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:24:05.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:24:05.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:24:05.489+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:24:05.489+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:24:05.512+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:24:05.512+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:24:05.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T15:24:35.685+0000] {processor.py:157} INFO - Started process (PID=4067) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:24:35.686+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:24:35.687+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:24:35.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:24:35.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:24:35.734+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:24:35.734+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:24:35.759+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:24:35.759+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:24:35.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T15:25:05.952+0000] {processor.py:157} INFO - Started process (PID=4069) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:25:05.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:25:05.974+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:25:05.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:25:06.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:25:06.281+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:25:06.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:25:06.330+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:25:06.329+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:25:06.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.409 seconds
[2024-10-24T15:25:36.381+0000] {processor.py:157} INFO - Started process (PID=4071) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:25:36.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:25:36.382+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:25:36.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:25:36.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:25:36.424+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:25:36.424+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:25:36.454+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:25:36.454+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:25:36.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T15:26:06.529+0000] {processor.py:157} INFO - Started process (PID=4073) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:26:06.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:26:06.532+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:26:06.531+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:26:06.549+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:26:06.581+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:26:06.581+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:26:06.603+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:26:06.603+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:26:06.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T15:26:36.778+0000] {processor.py:157} INFO - Started process (PID=4075) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:26:36.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:26:36.780+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:26:36.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:26:36.794+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:26:36.824+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:26:36.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:26:36.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:26:36.847+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:26:36.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T15:27:07.012+0000] {processor.py:157} INFO - Started process (PID=4077) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:27:07.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:27:07.013+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:27:07.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:27:07.026+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:27:07.050+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:27:07.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:27:07.073+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:27:07.073+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:27:07.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-24T15:27:37.237+0000] {processor.py:157} INFO - Started process (PID=4079) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:27:37.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:27:37.240+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:27:37.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:27:37.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:27:37.280+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:27:37.280+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:27:37.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:27:37.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:27:37.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:28:07.477+0000] {processor.py:157} INFO - Started process (PID=4081) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:28:07.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:28:07.479+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:28:07.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:28:07.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:28:07.517+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:28:07.516+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:28:07.539+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:28:07.539+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:28:07.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.080 seconds
[2024-10-24T15:28:37.703+0000] {processor.py:157} INFO - Started process (PID=4083) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:28:37.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:28:37.705+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:28:37.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:28:37.719+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:28:37.745+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:28:37.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:28:37.767+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:28:37.767+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:28:37.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T15:29:07.933+0000] {processor.py:157} INFO - Started process (PID=4085) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:29:07.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:29:07.934+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:29:07.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:29:07.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:29:07.972+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:29:07.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:29:07.994+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:29:07.994+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:29:08.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-24T15:29:38.160+0000] {processor.py:157} INFO - Started process (PID=4087) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:29:38.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:29:38.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:29:38.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:29:38.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:29:38.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:29:38.201+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:29:38.222+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:29:38.221+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:29:38.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-24T15:30:08.386+0000] {processor.py:157} INFO - Started process (PID=4089) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:30:08.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:30:08.387+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:30:08.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:30:08.399+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:30:08.424+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:30:08.424+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:30:08.446+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:30:08.445+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:30:08.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.077 seconds
[2024-10-24T15:30:38.629+0000] {processor.py:157} INFO - Started process (PID=4091) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:30:38.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:30:38.631+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:30:38.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:30:38.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:30:38.672+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:30:38.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:30:38.696+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:30:38.696+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:30:38.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T15:31:08.865+0000] {processor.py:157} INFO - Started process (PID=4093) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:31:08.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:31:08.867+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:31:08.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:31:08.882+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:31:08.910+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:31:08.910+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:31:08.934+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:31:08.934+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:31:08.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T15:31:39.117+0000] {processor.py:157} INFO - Started process (PID=4095) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:31:39.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:31:39.120+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:31:39.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:31:39.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:31:39.178+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:31:39.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:31:39.204+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:31:39.204+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:31:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T15:32:09.264+0000] {processor.py:157} INFO - Started process (PID=4097) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:32:09.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:32:09.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:32:09.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:32:09.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:32:09.310+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:32:09.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:32:09.332+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:32:09.332+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:32:09.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:32:39.501+0000] {processor.py:157} INFO - Started process (PID=4099) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:32:39.503+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:32:39.503+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:32:39.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:32:39.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:32:39.541+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:32:39.541+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:32:39.564+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:32:39.564+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:32:39.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.084 seconds
[2024-10-24T15:33:09.730+0000] {processor.py:157} INFO - Started process (PID=4101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:33:09.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:33:09.731+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:33:09.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:33:09.742+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:33:09.766+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:33:09.766+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:33:09.786+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:33:09.786+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:33:09.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.078 seconds
[2024-10-24T15:33:39.953+0000] {processor.py:157} INFO - Started process (PID=4103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:33:39.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:33:39.955+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:33:39.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:33:39.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:33:39.992+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:33:39.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:33:40.016+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:33:40.015+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:33:40.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T15:34:10.181+0000] {processor.py:157} INFO - Started process (PID=4105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:34:10.181+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:34:10.182+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:34:10.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:34:10.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:34:10.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:34:10.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:34:10.255+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:34:10.255+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:34:10.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T15:34:40.428+0000] {processor.py:157} INFO - Started process (PID=4107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:34:40.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:34:40.431+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:34:40.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:34:40.447+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:34:40.527+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:34:40.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:34:40.550+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:34:40.550+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:34:40.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.142 seconds
[2024-10-24T15:35:10.645+0000] {processor.py:157} INFO - Started process (PID=4109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:35:10.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:35:10.648+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:35:10.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:35:10.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:35:10.715+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:35:10.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:35:10.745+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:35:10.744+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:35:10.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T15:35:40.942+0000] {processor.py:157} INFO - Started process (PID=4111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:35:40.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:35:40.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:35:40.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:35:40.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:35:40.994+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:35:40.994+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:35:41.025+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:35:41.025+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:35:41.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-24T15:36:11.105+0000] {processor.py:157} INFO - Started process (PID=4113) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:36:11.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:36:11.106+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:36:11.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:36:11.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:36:11.147+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:36:11.147+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:36:11.173+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:36:11.173+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:36:11.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T15:36:41.369+0000] {processor.py:157} INFO - Started process (PID=4115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:36:41.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:36:41.371+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:36:41.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:36:41.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:36:41.431+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:36:41.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:36:41.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:36:41.457+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:36:41.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T15:37:11.632+0000] {processor.py:157} INFO - Started process (PID=4117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:37:11.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:37:11.635+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:37:11.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:37:11.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:37:11.680+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:37:11.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:37:11.707+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:37:11.707+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:37:11.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T15:37:41.878+0000] {processor.py:157} INFO - Started process (PID=4119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:37:41.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:37:41.880+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:37:41.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:37:41.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:37:41.921+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:37:41.921+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:37:41.948+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:37:41.948+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:37:41.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T15:38:12.116+0000] {processor.py:157} INFO - Started process (PID=4121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:38:12.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:38:12.118+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:38:12.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:38:12.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:38:12.159+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:38:12.159+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:38:12.183+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:38:12.182+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:38:12.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T15:38:42.355+0000] {processor.py:157} INFO - Started process (PID=4123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:38:42.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:38:42.367+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:38:42.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:38:42.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:38:42.408+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:38:42.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:38:42.430+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:38:42.430+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:38:42.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T15:39:12.607+0000] {processor.py:157} INFO - Started process (PID=4125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:39:12.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:39:12.608+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:39:12.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:39:12.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:39:12.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:39:12.647+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:39:12.670+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:39:12.670+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:39:12.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T15:39:42.842+0000] {processor.py:157} INFO - Started process (PID=4127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:39:42.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:39:42.843+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:39:42.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:39:42.858+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:39:42.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:39:42.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:39:42.907+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:39:42.907+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:39:42.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T15:40:13.070+0000] {processor.py:157} INFO - Started process (PID=4129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:40:13.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:40:13.073+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:40:13.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:40:13.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:40:13.112+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:40:13.112+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:40:13.133+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:40:13.133+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:40:13.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.082 seconds
[2024-10-24T15:40:43.314+0000] {processor.py:157} INFO - Started process (PID=4131) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:40:43.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:40:43.327+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:40:43.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:40:43.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:40:43.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:40:43.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:40:43.388+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:40:43.388+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:40:43.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T15:41:13.456+0000] {processor.py:157} INFO - Started process (PID=4133) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:41:13.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:41:13.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:41:13.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:41:13.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:41:13.502+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:41:13.501+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:41:13.532+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:41:13.532+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:41:13.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T15:41:43.709+0000] {processor.py:157} INFO - Started process (PID=4135) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:41:43.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:41:43.711+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:41:43.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:41:43.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:41:43.761+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:41:43.761+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:41:43.791+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:41:43.790+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:41:43.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T15:42:13.966+0000] {processor.py:157} INFO - Started process (PID=4137) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:42:13.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:42:13.967+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:42:13.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:42:13.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:42:14.008+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:42:14.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:42:14.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:42:14.032+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:42:14.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T15:42:44.204+0000] {processor.py:157} INFO - Started process (PID=4139) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:42:44.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:42:44.205+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:42:44.205+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:42:44.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:42:44.243+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:42:44.243+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:42:44.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:42:44.267+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:42:44.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T15:43:14.435+0000] {processor.py:157} INFO - Started process (PID=4141) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:43:14.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:43:14.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:43:14.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:43:14.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:43:14.477+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:43:14.477+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:43:14.502+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:43:14.502+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:43:14.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T15:43:44.675+0000] {processor.py:157} INFO - Started process (PID=4143) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:43:44.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:43:44.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:43:44.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:43:44.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:43:44.717+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:43:44.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:43:44.740+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:43:44.739+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:43:44.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T15:44:14.906+0000] {processor.py:157} INFO - Started process (PID=4145) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:44:14.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:44:14.907+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:44:14.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:44:14.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:44:14.946+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:44:14.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:44:14.971+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:44:14.971+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:44:14.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.087 seconds
[2024-10-24T15:44:45.134+0000] {processor.py:157} INFO - Started process (PID=4147) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:44:45.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:44:45.136+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:44:45.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:44:45.149+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:44:45.177+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:44:45.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:44:45.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:44:45.201+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:44:45.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.088 seconds
[2024-10-24T15:45:15.366+0000] {processor.py:157} INFO - Started process (PID=4149) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:45:15.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:45:15.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:45:15.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:45:15.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:45:15.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:45:15.410+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:45:15.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:45:15.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:45:15.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T15:45:45.618+0000] {processor.py:157} INFO - Started process (PID=4151) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:45:45.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:45:45.620+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:45:45.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:45:45.633+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:45:45.663+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:45:45.662+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:45:45.687+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:45:45.687+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:45:45.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T15:46:15.855+0000] {processor.py:157} INFO - Started process (PID=4153) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:46:15.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:46:15.856+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:46:15.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:46:15.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:46:15.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:46:15.899+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:46:15.920+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:46:15.920+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:46:15.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.085 seconds
[2024-10-24T15:46:46.092+0000] {processor.py:157} INFO - Started process (PID=4155) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:46:46.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:46:46.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:46:46.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:46:46.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:46:46.145+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:46:46.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:46:46.181+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:46:46.181+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:46:46.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T15:47:16.240+0000] {processor.py:157} INFO - Started process (PID=4157) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:47:16.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:47:16.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:47:16.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:47:16.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:47:16.279+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:47:16.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:47:16.299+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:47:16.299+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:47:16.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.079 seconds
[2024-10-24T15:47:46.610+0000] {processor.py:157} INFO - Started process (PID=4159) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:47:46.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:47:46.632+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:47:46.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:47:46.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:47:46.858+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:47:46.858+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:47:46.892+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:47:46.892+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:47:46.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.381 seconds
[2024-10-24T15:48:16.957+0000] {processor.py:157} INFO - Started process (PID=4161) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:48:16.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:48:16.969+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:48:16.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:48:17.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:48:17.166+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:48:17.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:48:17.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:48:17.201+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:48:17.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.292 seconds
[2024-10-24T15:48:48.085+0000] {processor.py:157} INFO - Started process (PID=4163) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:48:48.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:48:48.096+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:48:48.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:48:48.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:48:48.187+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:48:48.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:48:48.223+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:48:48.223+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:48:48.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.163 seconds
[2024-10-24T15:49:18.315+0000] {processor.py:157} INFO - Started process (PID=4165) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:49:18.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:49:18.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:49:18.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:49:18.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:49:18.370+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:49:18.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:49:18.411+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:49:18.411+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:49:18.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-24T15:49:48.598+0000] {processor.py:157} INFO - Started process (PID=4167) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:49:48.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:49:48.600+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:49:48.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:49:48.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:49:48.652+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:49:48.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:49:48.677+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:49:48.677+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:49:48.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T15:50:18.857+0000] {processor.py:157} INFO - Started process (PID=4169) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:50:18.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:50:18.859+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:50:18.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:50:18.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:50:18.909+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:50:18.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:50:18.953+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:50:18.952+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:50:18.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T15:50:49.144+0000] {processor.py:157} INFO - Started process (PID=4171) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:50:49.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:50:49.146+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:50:49.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:50:49.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:50:49.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:50:49.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:50:49.217+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:50:49.216+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:50:49.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T15:51:19.297+0000] {processor.py:157} INFO - Started process (PID=4173) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:51:19.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:51:19.299+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:51:19.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:51:19.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:51:19.342+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:51:19.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:51:19.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:51:19.368+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:51:19.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T15:51:49.541+0000] {processor.py:157} INFO - Started process (PID=4175) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:51:49.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T15:51:49.543+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:51:49.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:51:49.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T15:51:49.590+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:51:49.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T15:51:49.619+0000] {logging_mixin.py:149} INFO - [2024-10-24T15:51:49.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T15:51:49.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T16:22:24.300+0000] {processor.py:157} INFO - Started process (PID=4177) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T16:22:24.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T16:22:24.364+0000] {logging_mixin.py:149} INFO - [2024-10-24T16:22:24.364+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T16:22:24.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T16:22:24.624+0000] {logging_mixin.py:149} INFO - [2024-10-24T16:22:24.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T16:22:24.732+0000] {logging_mixin.py:149} INFO - [2024-10-24T16:22:24.731+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T16:22:25.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.079 seconds
[2024-10-24T18:23:59.588+0000] {processor.py:157} INFO - Started process (PID=4181) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:23:59.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:23:59.687+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:23:59.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:23:59.724+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:24:00.046+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:24:00.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:24:00.130+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:24:00.130+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:24:00.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.046 seconds
[2024-10-24T18:24:30.408+0000] {processor.py:157} INFO - Started process (PID=4185) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:24:30.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:24:30.415+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:24:30.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:24:30.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:24:30.488+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:24:30.487+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:24:30.518+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:24:30.518+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:24:30.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.154 seconds
[2024-10-24T18:25:00.574+0000] {processor.py:157} INFO - Started process (PID=4187) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:25:00.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:25:00.578+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:25:00.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:25:00.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:25:00.668+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:25:00.667+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:25:00.731+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:25:00.731+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:25:00.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.200 seconds
[2024-10-24T18:25:30.941+0000] {processor.py:157} INFO - Started process (PID=4189) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:25:30.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:25:30.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:25:30.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:25:30.962+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:25:31.003+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:25:31.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:25:31.046+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:25:31.045+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:25:31.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-24T18:26:01.239+0000] {processor.py:157} INFO - Started process (PID=4191) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:26:01.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:26:01.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:26:01.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:26:01.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:26:01.407+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:26:01.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:26:01.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:26:01.436+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:26:01.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.224 seconds
[2024-10-24T18:26:31.612+0000] {processor.py:157} INFO - Started process (PID=4193) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:26:31.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:26:31.613+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:26:31.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:26:31.626+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:26:31.656+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:26:31.656+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:26:31.682+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:26:31.681+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:26:31.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T18:27:01.778+0000] {processor.py:157} INFO - Started process (PID=4195) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:27:01.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:27:01.780+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:27:01.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:27:01.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:27:01.827+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:27:01.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:27:01.858+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:27:01.857+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:27:01.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T18:27:32.031+0000] {processor.py:157} INFO - Started process (PID=4197) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:27:32.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:27:32.066+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:27:32.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:27:32.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:27:32.285+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:27:32.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:27:32.315+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:27:32.315+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:27:32.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.320 seconds
[2024-10-24T18:28:02.485+0000] {processor.py:157} INFO - Started process (PID=4199) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:28:02.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:28:02.487+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:28:02.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:28:02.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:28:02.556+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:28:02.555+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:28:02.586+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:28:02.586+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:28:02.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T18:28:32.632+0000] {processor.py:157} INFO - Started process (PID=4201) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:28:32.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:28:32.635+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:28:32.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:28:32.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:28:32.712+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:28:32.712+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:28:32.755+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:28:32.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:28:32.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.155 seconds
[2024-10-24T18:29:02.966+0000] {processor.py:157} INFO - Started process (PID=4203) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:29:02.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:29:02.970+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:29:02.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:29:02.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:29:03.044+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:29:03.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:29:03.087+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:29:03.086+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:29:03.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.162 seconds
[2024-10-24T18:29:33.278+0000] {processor.py:157} INFO - Started process (PID=4205) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:29:33.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:29:33.282+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:29:33.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:29:33.318+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:29:33.354+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:29:33.354+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:29:33.383+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:29:33.383+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:29:33.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T18:30:03.572+0000] {processor.py:157} INFO - Started process (PID=4207) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:30:03.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:30:03.574+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:30:03.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:30:03.591+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:30:03.624+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:30:03.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:30:03.651+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:30:03.651+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:30:03.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T18:30:33.728+0000] {processor.py:157} INFO - Started process (PID=4209) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:30:33.729+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:30:33.730+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:30:33.730+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:30:33.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:30:33.791+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:30:33.791+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:30:33.824+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:30:33.824+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:30:33.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T18:31:04.440+0000] {processor.py:157} INFO - Started process (PID=4211) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:31:04.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:31:04.451+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:31:04.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:31:04.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:31:04.756+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:31:04.755+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:31:04.819+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:31:04.819+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:31:04.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.448 seconds
[2024-10-24T18:31:35.048+0000] {processor.py:157} INFO - Started process (PID=4213) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:31:35.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:31:35.051+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:31:35.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:31:35.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:31:35.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:31:35.161+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:31:35.205+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:31:35.205+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:31:35.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.193 seconds
[2024-10-24T18:32:05.415+0000] {processor.py:157} INFO - Started process (PID=4215) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:32:05.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:32:05.422+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:32:05.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:32:05.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:32:05.524+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:32:05.524+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:32:05.561+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:32:05.561+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:32:05.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.196 seconds
[2024-10-24T18:32:35.729+0000] {processor.py:157} INFO - Started process (PID=4217) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:32:35.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:32:35.730+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:32:35.730+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:32:35.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:32:35.775+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:32:35.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:32:35.799+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:32:35.799+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:32:35.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T18:33:06.049+0000] {processor.py:157} INFO - Started process (PID=4219) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:33:06.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:33:06.053+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:33:06.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:33:06.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:33:06.121+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:33:06.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:33:06.152+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:33:06.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:33:06.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-24T18:33:36.224+0000] {processor.py:157} INFO - Started process (PID=4221) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:33:36.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:33:36.226+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:33:36.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:33:36.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:33:36.287+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:33:36.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:33:36.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:33:36.316+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:33:36.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-24T18:34:06.494+0000] {processor.py:157} INFO - Started process (PID=4223) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:34:06.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:34:06.496+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:34:06.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:34:06.513+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:34:06.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:34:06.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:34:06.580+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:34:06.579+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:34:06.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T18:34:36.760+0000] {processor.py:157} INFO - Started process (PID=4225) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:34:36.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:34:36.763+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:34:36.763+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:34:36.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:34:36.823+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:34:36.823+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:34:36.853+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:34:36.852+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:34:36.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-24T18:35:06.930+0000] {processor.py:157} INFO - Started process (PID=4227) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:35:06.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:35:06.933+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:35:06.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:35:06.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:35:07.035+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:35:07.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:35:07.069+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:35:07.068+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:35:07.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.174 seconds
[2024-10-24T18:35:37.157+0000] {processor.py:157} INFO - Started process (PID=4229) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:35:37.158+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:35:37.159+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:35:37.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:35:37.172+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:35:37.213+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:35:37.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:35:37.250+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:35:37.250+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:35:37.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T18:36:07.422+0000] {processor.py:157} INFO - Started process (PID=4231) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:36:07.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:36:07.424+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:36:07.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:36:07.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:36:07.488+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:36:07.488+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:36:07.527+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:36:07.526+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:36:07.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.141 seconds
[2024-10-24T18:36:37.695+0000] {processor.py:157} INFO - Started process (PID=4234) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:36:37.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:36:37.697+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:36:37.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:36:37.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:36:37.737+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:36:37.737+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:36:37.762+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:36:37.762+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:36:37.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.086 seconds
[2024-10-24T18:37:07.838+0000] {processor.py:157} INFO - Started process (PID=4235) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:37:07.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:37:07.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:37:07.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:37:07.855+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:37:07.885+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:37:07.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:37:07.912+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:37:07.912+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:37:07.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T18:37:38.085+0000] {processor.py:157} INFO - Started process (PID=4237) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:37:38.086+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:37:38.086+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:37:38.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:37:38.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:37:38.130+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:37:38.130+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:37:38.177+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:37:38.177+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:37:38.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T18:38:08.363+0000] {processor.py:157} INFO - Started process (PID=4239) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:38:08.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:38:08.366+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:38:08.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:38:08.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:38:08.415+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:38:08.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:38:08.440+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:38:08.440+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:38:08.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T18:38:38.632+0000] {processor.py:157} INFO - Started process (PID=4241) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:38:38.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:38:38.634+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:38:38.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:38:38.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:38:38.698+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:38:38.698+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:38:38.734+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:38:38.734+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:38:38.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-24T18:39:08.805+0000] {processor.py:157} INFO - Started process (PID=4243) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:39:08.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:39:08.807+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:39:08.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:39:08.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:39:08.862+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:39:08.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:39:08.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:39:08.886+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:39:08.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T18:39:39.067+0000] {processor.py:157} INFO - Started process (PID=4245) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:39:39.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:39:39.070+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:39:39.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:39:39.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:39:39.118+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:39:39.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:39:39.145+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:39:39.144+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:39:39.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T18:40:09.225+0000] {processor.py:157} INFO - Started process (PID=4247) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:40:09.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:40:09.238+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:40:09.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:40:09.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:40:09.289+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:40:09.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:40:09.314+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:40:09.313+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:40:09.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T18:40:39.491+0000] {processor.py:157} INFO - Started process (PID=4249) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:40:39.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:40:39.494+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:40:39.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:40:39.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:40:39.563+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:40:39.563+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:40:39.598+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:40:39.598+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:40:39.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-24T18:41:09.784+0000] {processor.py:157} INFO - Started process (PID=4251) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:41:09.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:41:09.787+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:41:09.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:41:09.805+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:41:09.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:41:09.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:41:09.869+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:41:09.869+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:41:09.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T18:41:39.945+0000] {processor.py:157} INFO - Started process (PID=4253) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:41:39.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:41:39.948+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:41:39.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:41:39.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:41:40.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:41:40.007+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:41:40.034+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:41:40.034+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:41:40.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T18:42:10.157+0000] {processor.py:157} INFO - Started process (PID=4255) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:42:10.158+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:42:10.160+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:42:10.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:42:10.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:42:10.211+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:42:10.211+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:42:10.242+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:42:10.242+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:42:10.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T18:42:40.418+0000] {processor.py:157} INFO - Started process (PID=4257) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:42:40.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:42:40.420+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:42:40.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:42:40.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:42:40.497+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:42:40.497+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:42:40.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:42:40.548+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:42:40.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.155 seconds
[2024-10-24T18:43:10.744+0000] {processor.py:157} INFO - Started process (PID=4259) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:43:10.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:43:10.745+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:43:10.745+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:43:10.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:43:10.790+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:43:10.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:43:10.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:43:10.818+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:43:10.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T18:43:40.896+0000] {processor.py:157} INFO - Started process (PID=4261) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:43:40.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:43:40.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:43:40.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:43:40.913+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:43:40.944+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:43:40.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:43:40.971+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:43:40.971+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:43:40.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T18:44:11.107+0000] {processor.py:157} INFO - Started process (PID=4263) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:44:11.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:44:11.109+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:44:11.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:44:11.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:44:11.177+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:44:11.176+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:44:11.206+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:44:11.206+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:44:11.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T18:44:41.378+0000] {processor.py:157} INFO - Started process (PID=4265) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:44:41.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:44:41.380+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:44:41.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:44:41.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:44:41.428+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:44:41.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:44:41.466+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:44:41.466+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:44:41.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T18:45:11.535+0000] {processor.py:157} INFO - Started process (PID=4267) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:45:11.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:45:11.538+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:45:11.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:45:11.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:45:11.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:45:11.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:45:11.619+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:45:11.618+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:45:11.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T18:45:43.557+0000] {processor.py:157} INFO - Started process (PID=4269) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:45:43.780+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:45:44.024+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:45:44.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:45:46.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:45:47.817+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:45:47.817+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:45:48.409+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:45:48.408+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:45:48.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 5.170 seconds
[2024-10-24T18:46:18.738+0000] {processor.py:157} INFO - Started process (PID=4271) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:46:18.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:46:18.740+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:46:18.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:46:18.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:46:18.808+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:46:18.807+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:46:18.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:46:18.840+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:46:18.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-24T18:46:49.115+0000] {processor.py:157} INFO - Started process (PID=4273) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:46:49.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:46:49.117+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:46:49.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:46:49.153+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:46:49.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:46:49.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:46:49.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:46:49.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:46:49.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.283 seconds
[2024-10-24T18:47:19.500+0000] {processor.py:157} INFO - Started process (PID=4275) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:47:19.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:47:19.533+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:47:19.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:47:19.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:47:20.010+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:47:20.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:47:20.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:47:20.094+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:47:20.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.615 seconds
[2024-10-24T18:47:50.405+0000] {processor.py:157} INFO - Started process (PID=4277) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:47:50.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:47:50.411+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:47:50.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:47:50.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:47:50.556+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:47:50.555+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:47:50.624+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:47:50.623+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:47:50.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.294 seconds
[2024-10-24T18:48:20.852+0000] {processor.py:157} INFO - Started process (PID=4279) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:48:20.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:48:20.855+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:48:20.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:48:20.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:48:20.914+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:48:20.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:48:20.952+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:48:20.952+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:48:20.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.131 seconds
[2024-10-24T18:48:51.001+0000] {processor.py:157} INFO - Started process (PID=4281) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:48:51.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:48:51.004+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:48:51.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:48:51.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:48:51.054+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:48:51.054+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:48:51.080+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:48:51.080+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:48:51.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T18:49:21.315+0000] {processor.py:157} INFO - Started process (PID=4283) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:49:21.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:49:21.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:49:21.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:49:21.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:49:21.381+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:49:21.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:49:21.413+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:49:21.413+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:49:21.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.134 seconds
[2024-10-24T18:49:51.474+0000] {processor.py:157} INFO - Started process (PID=4285) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:49:51.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:49:51.477+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:49:51.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:49:51.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:49:51.524+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:49:51.524+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:49:51.552+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:49:51.552+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:49:51.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T18:50:21.735+0000] {processor.py:157} INFO - Started process (PID=4287) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:50:21.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:50:21.738+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:50:21.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:50:21.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:50:21.784+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:50:21.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:50:21.811+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:50:21.811+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:50:21.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T18:50:51.988+0000] {processor.py:157} INFO - Started process (PID=4289) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:50:51.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:50:51.990+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:50:51.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:50:52.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:50:52.037+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:50:52.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:50:52.062+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:50:52.061+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:50:52.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T18:51:22.150+0000] {processor.py:157} INFO - Started process (PID=4291) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:51:22.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:51:22.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:51:22.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:51:22.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:51:22.203+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:51:22.203+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:51:22.230+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:51:22.229+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:51:22.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T18:51:52.349+0000] {processor.py:157} INFO - Started process (PID=4293) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:51:52.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:51:52.350+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:51:52.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:51:52.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:51:52.396+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:51:52.395+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:51:52.421+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:51:52.420+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:51:52.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T18:52:22.596+0000] {processor.py:157} INFO - Started process (PID=4295) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:52:22.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:52:22.599+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:52:22.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:52:22.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:52:22.649+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:52:22.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:52:22.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:52:22.678+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:52:22.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T18:52:52.785+0000] {processor.py:157} INFO - Started process (PID=4297) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:52:52.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:52:52.789+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:52:52.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:52:52.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:52:52.950+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:52:52.950+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:52:53.041+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:52:53.040+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:52:53.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.341 seconds
[2024-10-24T18:53:23.303+0000] {processor.py:157} INFO - Started process (PID=4299) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:53:23.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:53:23.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:53:23.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:53:23.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:53:23.362+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:53:23.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:53:23.395+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:53:23.395+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:53:23.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T18:53:53.460+0000] {processor.py:157} INFO - Started process (PID=4301) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:53:53.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:53:53.462+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:53:53.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:53:53.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:53:53.505+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:53:53.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:53:53.531+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:53:53.531+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:53:53.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T18:54:23.742+0000] {processor.py:157} INFO - Started process (PID=4303) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:54:23.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:54:23.766+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:54:23.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:54:23.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:54:23.871+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:54:23.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:54:23.900+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:54:23.900+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:54:23.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.182 seconds
[2024-10-24T18:54:54.058+0000] {processor.py:157} INFO - Started process (PID=4305) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:54:54.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:54:54.059+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:54:54.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:54:54.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:54:54.106+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:54:54.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:54:54.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:54:54.131+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:54:54.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T18:55:24.341+0000] {processor.py:157} INFO - Started process (PID=4307) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:55:24.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:55:24.347+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:55:24.347+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:55:24.392+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:55:24.467+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:55:24.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:55:24.513+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:55:24.512+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:55:24.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.230 seconds
[2024-10-24T18:55:54.664+0000] {processor.py:157} INFO - Started process (PID=4309) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:55:54.665+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:55:54.665+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:55:54.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:55:54.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:55:54.710+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:55:54.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:55:54.734+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:55:54.733+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:55:54.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T18:56:24.803+0000] {processor.py:157} INFO - Started process (PID=4311) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:56:24.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:56:24.805+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:56:24.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:56:24.820+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:56:24.851+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:56:24.851+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:56:24.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:56:24.875+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:56:24.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T18:56:55.071+0000] {processor.py:157} INFO - Started process (PID=4313) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:56:55.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:56:55.076+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:56:55.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:56:55.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:56:55.188+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:56:55.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:56:55.291+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:56:55.291+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:56:55.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.300 seconds
[2024-10-24T18:57:25.537+0000] {processor.py:157} INFO - Started process (PID=4315) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:57:25.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:57:25.590+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:57:25.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:57:26.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:57:26.219+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:57:26.218+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:57:26.258+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:57:26.258+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:57:26.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.766 seconds
[2024-10-24T18:57:56.438+0000] {processor.py:157} INFO - Started process (PID=4317) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:57:56.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:57:56.440+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:57:56.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:57:56.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:57:56.523+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:57:56.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:57:56.564+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:57:56.564+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:57:56.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.152 seconds
[2024-10-24T18:58:26.739+0000] {processor.py:157} INFO - Started process (PID=4319) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:58:26.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:58:26.741+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:58:26.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:58:26.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:58:26.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:58:26.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:58:26.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:58:26.828+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:58:26.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T18:58:56.888+0000] {processor.py:157} INFO - Started process (PID=4321) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:58:56.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:58:56.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:58:56.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:58:56.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:58:56.961+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:58:56.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:58:57.003+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:58:57.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:58:57.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-24T18:59:27.190+0000] {processor.py:157} INFO - Started process (PID=4323) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:59:27.200+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:59:27.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:59:27.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:59:27.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:59:27.252+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:59:27.252+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:59:27.285+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:59:27.285+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:59:27.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T18:59:57.341+0000] {processor.py:157} INFO - Started process (PID=4325) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:59:57.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T18:59:57.343+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:59:57.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:59:57.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T18:59:57.395+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:59:57.395+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T18:59:57.433+0000] {logging_mixin.py:149} INFO - [2024-10-24T18:59:57.433+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T18:59:57.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T19:00:27.557+0000] {processor.py:157} INFO - Started process (PID=4327) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:00:27.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:00:27.559+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:00:27.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:00:27.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:00:27.607+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:00:27.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:00:27.636+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:00:27.636+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:00:27.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T19:00:57.713+0000] {processor.py:157} INFO - Started process (PID=4329) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:00:57.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:00:57.715+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:00:57.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:00:57.729+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:00:57.760+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:00:57.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:00:57.789+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:00:57.789+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:00:57.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T19:01:27.921+0000] {processor.py:157} INFO - Started process (PID=4331) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:01:27.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:01:27.922+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:01:27.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:01:27.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:01:27.966+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:01:27.965+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:01:27.990+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:01:27.990+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:01:28.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T19:01:58.075+0000] {processor.py:157} INFO - Started process (PID=4333) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:01:58.086+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:01:58.087+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:01:58.087+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:01:58.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:01:58.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:01:58.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:01:58.160+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:01:58.160+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:01:58.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T19:02:28.337+0000] {processor.py:157} INFO - Started process (PID=4335) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:02:28.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:02:28.338+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:02:28.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:02:28.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:02:28.382+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:02:28.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:02:28.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:02:28.410+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:02:28.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T19:02:58.487+0000] {processor.py:157} INFO - Started process (PID=4337) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:02:58.488+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:02:58.489+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:02:58.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:02:58.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:02:58.534+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:02:58.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:02:58.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:02:58.558+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:02:58.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T19:03:28.696+0000] {processor.py:157} INFO - Started process (PID=4339) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:03:28.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:03:28.698+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:03:28.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:03:28.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:03:28.742+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:03:28.742+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:03:28.770+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:03:28.770+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:03:28.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T19:03:58.850+0000] {processor.py:157} INFO - Started process (PID=4341) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:03:58.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:03:58.852+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:03:58.852+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:03:58.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:03:58.897+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:03:58.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:03:58.927+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:03:58.926+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:03:58.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T19:04:29.069+0000] {processor.py:157} INFO - Started process (PID=4343) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:04:29.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:04:29.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:04:29.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:04:29.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:04:29.115+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:04:29.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:04:29.143+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:04:29.143+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:04:29.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T19:04:59.221+0000] {processor.py:157} INFO - Started process (PID=4345) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:04:59.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:04:59.222+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:04:59.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:04:59.233+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:04:59.264+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:04:59.263+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:04:59.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:04:59.288+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:04:59.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T19:05:29.448+0000] {processor.py:157} INFO - Started process (PID=4347) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:05:29.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:05:29.451+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:05:29.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:05:29.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:05:29.508+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:05:29.508+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:05:29.537+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:05:29.537+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:05:29.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T19:05:59.614+0000] {processor.py:157} INFO - Started process (PID=4349) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:05:59.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:05:59.615+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:05:59.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:05:59.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:05:59.657+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:05:59.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:05:59.681+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:05:59.681+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:05:59.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T19:06:29.856+0000] {processor.py:157} INFO - Started process (PID=4351) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:06:29.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:06:29.859+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:06:29.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:06:29.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:06:29.900+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:06:29.900+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:06:29.924+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:06:29.924+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:06:29.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T19:07:00.006+0000] {processor.py:157} INFO - Started process (PID=4353) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:07:00.007+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:07:00.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:07:00.007+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:07:00.023+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:07:00.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:07:00.055+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:07:00.084+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:07:00.084+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:07:00.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T19:07:30.218+0000] {processor.py:157} INFO - Started process (PID=4355) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:07:30.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:07:30.220+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:07:30.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:07:30.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:07:30.265+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:07:30.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:07:30.297+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:07:30.297+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:07:30.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T19:08:00.480+0000] {processor.py:157} INFO - Started process (PID=4357) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:08:00.481+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:08:00.482+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:08:00.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:08:00.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:08:00.526+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:08:00.526+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:08:00.553+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:08:00.553+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:08:00.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T19:08:30.741+0000] {processor.py:157} INFO - Started process (PID=4359) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:08:30.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:08:30.744+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:08:30.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:08:30.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:08:30.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:08:30.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:08:30.823+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:08:30.823+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:08:30.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T19:09:00.898+0000] {processor.py:157} INFO - Started process (PID=4361) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:09:00.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:09:00.899+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:09:00.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:09:00.918+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:09:00.949+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:09:00.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:09:00.978+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:09:00.978+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:09:00.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T19:09:31.152+0000] {processor.py:157} INFO - Started process (PID=4363) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:09:31.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:09:31.154+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:09:31.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:09:31.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:09:31.198+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:09:31.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:09:31.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:09:31.227+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:09:31.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T19:10:01.311+0000] {processor.py:157} INFO - Started process (PID=4365) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:10:01.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:10:01.313+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:10:01.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:10:01.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:10:01.358+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:10:01.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:10:01.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:10:01.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:10:01.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T19:10:31.517+0000] {processor.py:157} INFO - Started process (PID=4367) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:10:31.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:10:31.519+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:10:31.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:10:31.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:10:31.574+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:10:31.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:10:31.606+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:10:31.606+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:10:31.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T19:11:01.686+0000] {processor.py:157} INFO - Started process (PID=4369) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:11:01.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:11:01.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:11:01.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:11:01.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:11:01.733+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:11:01.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:11:01.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:11:01.757+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:11:01.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T19:11:31.928+0000] {processor.py:157} INFO - Started process (PID=4371) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:11:31.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:11:31.932+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:11:31.932+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:11:31.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:11:31.985+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:11:31.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:11:32.014+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:11:32.014+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:11:32.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T19:12:02.192+0000] {processor.py:157} INFO - Started process (PID=4373) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:12:02.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:12:02.194+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:12:02.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:12:02.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:12:02.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:12:02.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:12:02.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:12:02.266+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:12:02.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T19:12:32.345+0000] {processor.py:157} INFO - Started process (PID=4375) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:12:32.347+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:12:32.347+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:12:32.347+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:12:32.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:12:32.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:12:32.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:12:32.419+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:12:32.419+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:12:32.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T19:13:02.597+0000] {processor.py:157} INFO - Started process (PID=4377) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:13:02.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:13:02.598+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:13:02.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:13:02.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:13:02.643+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:13:02.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:13:02.672+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:13:02.672+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:13:02.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T19:13:32.851+0000] {processor.py:157} INFO - Started process (PID=4379) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:13:32.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:13:32.853+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:13:32.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:13:32.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:13:32.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:13:32.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:13:32.923+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:13:32.923+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:13:32.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T19:14:03.106+0000] {processor.py:157} INFO - Started process (PID=4381) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:14:03.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:14:03.108+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:14:03.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:14:03.120+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:14:03.151+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:14:03.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:14:03.174+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:14:03.174+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:14:03.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T19:14:33.347+0000] {processor.py:157} INFO - Started process (PID=4383) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:14:33.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:14:33.363+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:14:33.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:14:33.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:14:33.416+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:14:33.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:14:33.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:14:33.449+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:14:33.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T19:15:03.507+0000] {processor.py:157} INFO - Started process (PID=4385) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:15:03.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:15:03.508+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:15:03.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:15:03.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:15:03.551+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:15:03.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:15:03.577+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:15:03.576+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:15:03.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T19:15:33.734+0000] {processor.py:157} INFO - Started process (PID=4387) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:15:33.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T19:15:33.737+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:15:33.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:15:33.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T19:15:33.786+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:15:33.786+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T19:15:33.814+0000] {logging_mixin.py:149} INFO - [2024-10-24T19:15:33.814+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T19:15:33.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T20:20:01.789+0000] {processor.py:157} INFO - Started process (PID=4389) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:20:01.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:20:01.946+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:20:01.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:20:02.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:20:02.744+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:20:02.744+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:20:02.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:20:02.847+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:20:02.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 1.331 seconds
[2024-10-24T20:21:10.178+0000] {processor.py:157} INFO - Started process (PID=4395) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:21:10.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:21:10.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:21:10.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:21:10.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:21:10.645+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:21:10.645+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:21:10.719+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:21:10.719+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:21:10.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.660 seconds
[2024-10-24T20:21:40.869+0000] {processor.py:157} INFO - Started process (PID=4397) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:21:40.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:21:40.871+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:21:40.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:21:40.903+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:21:40.945+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:21:40.945+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:21:40.983+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:21:40.983+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:21:41.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-24T20:22:11.125+0000] {processor.py:157} INFO - Started process (PID=4399) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:22:11.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:22:11.129+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:22:11.129+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:22:11.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:22:11.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:22:11.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:22:11.306+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:22:11.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:22:11.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.327 seconds
[2024-10-24T20:22:41.545+0000] {processor.py:157} INFO - Started process (PID=4401) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:22:41.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:22:41.547+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:22:41.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:22:41.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:22:41.602+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:22:41.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:22:41.634+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:22:41.633+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:22:41.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T20:23:12.325+0000] {processor.py:157} INFO - Started process (PID=4403) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:23:12.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:23:12.327+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:23:12.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:23:12.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:23:12.379+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:23:12.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:23:12.408+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:23:12.407+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:23:12.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T20:23:42.501+0000] {processor.py:157} INFO - Started process (PID=4405) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:23:42.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:23:42.503+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:23:42.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:23:42.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:23:42.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:23:42.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:23:42.587+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:23:42.587+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:23:42.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T20:24:12.762+0000] {processor.py:157} INFO - Started process (PID=4407) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:24:12.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:24:12.765+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:24:12.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:24:12.783+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:24:12.817+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:24:12.816+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:24:12.842+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:24:12.842+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:24:12.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T20:24:42.926+0000] {processor.py:157} INFO - Started process (PID=4409) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:24:42.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:24:42.929+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:24:42.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:24:42.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:24:42.985+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:24:42.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:24:43.011+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:24:43.011+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:24:43.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T20:25:13.138+0000] {processor.py:157} INFO - Started process (PID=4411) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:25:13.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:25:13.140+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:25:13.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:25:13.157+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:25:13.187+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:25:13.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:25:13.215+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:25:13.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:25:13.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T20:25:43.311+0000] {processor.py:157} INFO - Started process (PID=4413) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:25:43.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:25:43.312+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:25:43.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:25:43.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:25:43.362+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:25:43.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:25:43.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:25:43.391+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:25:43.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T20:26:13.576+0000] {processor.py:157} INFO - Started process (PID=4415) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:26:13.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:26:13.579+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:26:13.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:26:13.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:26:13.627+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:26:13.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:26:13.654+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:26:13.653+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:26:13.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T20:26:43.829+0000] {processor.py:157} INFO - Started process (PID=4417) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:26:43.830+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:26:43.831+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:26:43.831+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:26:43.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:26:43.878+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:26:43.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:26:43.903+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:26:43.902+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:26:43.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T20:27:14.073+0000] {processor.py:157} INFO - Started process (PID=4419) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:27:14.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:27:14.075+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:27:14.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:27:14.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:27:14.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:27:14.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:27:14.146+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:27:14.146+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:27:14.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T20:27:44.319+0000] {processor.py:157} INFO - Started process (PID=4421) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:27:44.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:27:44.321+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:27:44.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:27:44.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:27:44.369+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:27:44.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:27:44.396+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:27:44.396+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:27:44.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T20:28:14.578+0000] {processor.py:157} INFO - Started process (PID=4423) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:28:14.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:28:14.580+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:28:14.580+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:28:14.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:28:14.633+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:28:14.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:28:14.664+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:28:14.663+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:28:14.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T20:28:44.849+0000] {processor.py:157} INFO - Started process (PID=4425) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:28:44.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:28:44.851+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:28:44.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:28:44.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:28:44.903+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:28:44.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:28:44.936+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:28:44.936+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:28:44.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T20:29:15.129+0000] {processor.py:157} INFO - Started process (PID=4427) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:29:15.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:29:15.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:29:15.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:29:15.148+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:29:15.183+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:29:15.183+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:29:15.214+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:29:15.213+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:29:15.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T20:29:45.286+0000] {processor.py:157} INFO - Started process (PID=4429) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:29:45.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:29:45.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:29:45.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:29:45.305+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:29:45.339+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:29:45.338+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:29:45.377+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:29:45.376+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:29:45.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-24T20:30:15.523+0000] {processor.py:157} INFO - Started process (PID=4431) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:30:15.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:30:15.525+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:30:15.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:30:15.546+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:30:15.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:30:15.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:30:15.617+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:30:15.617+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:30:15.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T20:30:45.775+0000] {processor.py:157} INFO - Started process (PID=4433) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:30:45.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:30:45.777+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:30:45.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:30:45.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:30:45.822+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:30:45.822+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:30:45.849+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:30:45.849+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:30:45.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T20:31:16.029+0000] {processor.py:157} INFO - Started process (PID=4435) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:31:16.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:31:16.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:31:16.031+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:31:16.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:31:16.081+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:31:16.081+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:31:16.110+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:31:16.110+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:31:16.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T20:31:46.185+0000] {processor.py:157} INFO - Started process (PID=4437) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:31:46.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:31:46.187+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:31:46.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:31:46.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:31:46.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:31:46.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:31:46.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:31:46.273+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:31:46.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T20:32:16.394+0000] {processor.py:157} INFO - Started process (PID=4439) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:32:16.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:32:16.396+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:32:16.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:32:16.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:32:16.455+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:32:16.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:32:16.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:32:16.484+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:32:16.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T20:32:46.655+0000] {processor.py:157} INFO - Started process (PID=4441) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:32:46.656+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:32:46.657+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:32:46.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:32:46.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:32:46.703+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:32:46.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:32:46.736+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:32:46.735+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:32:46.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T20:33:16.816+0000] {processor.py:157} INFO - Started process (PID=4443) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:33:16.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:33:16.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:33:16.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:33:16.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:33:16.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:33:16.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:33:16.889+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:33:16.889+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:33:16.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T20:33:47.028+0000] {processor.py:157} INFO - Started process (PID=4445) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:33:47.028+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:33:47.029+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:33:47.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:33:47.043+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:33:47.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:33:47.070+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:33:47.095+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:33:47.095+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:33:47.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T20:34:17.281+0000] {processor.py:157} INFO - Started process (PID=4447) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:34:17.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:34:17.285+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:34:17.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:34:17.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:34:17.326+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:34:17.326+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:34:17.352+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:34:17.352+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:34:17.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T20:34:47.532+0000] {processor.py:157} INFO - Started process (PID=4449) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:34:47.533+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:34:47.534+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:34:47.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:34:47.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:34:47.579+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:34:47.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:34:47.605+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:34:47.605+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:34:47.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T20:35:17.794+0000] {processor.py:157} INFO - Started process (PID=4451) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:35:17.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:35:17.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:35:17.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:35:17.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:35:17.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:35:17.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:35:17.868+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:35:17.868+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:35:17.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T20:35:48.050+0000] {processor.py:157} INFO - Started process (PID=4453) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:35:48.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:35:48.052+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:35:48.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:35:48.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:35:48.099+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:35:48.099+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:35:48.130+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:35:48.129+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:35:48.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T20:36:18.202+0000] {processor.py:157} INFO - Started process (PID=4455) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:36:18.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:36:18.203+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:36:18.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:36:18.217+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:36:18.252+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:36:18.251+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:36:18.285+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:36:18.285+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:36:18.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T20:36:48.412+0000] {processor.py:157} INFO - Started process (PID=4457) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:36:48.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:36:48.414+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:36:48.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:36:48.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:36:48.479+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:36:48.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:36:48.582+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:36:48.582+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:36:48.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.197 seconds
[2024-10-24T20:37:18.771+0000] {processor.py:157} INFO - Started process (PID=4459) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:37:18.772+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:37:18.773+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:37:18.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:37:18.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:37:18.869+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:37:18.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:37:18.947+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:37:18.946+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:37:18.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.223 seconds
[2024-10-24T20:37:49.173+0000] {processor.py:157} INFO - Started process (PID=4461) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:37:49.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:37:49.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:37:49.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:37:49.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:37:49.242+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:37:49.242+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:37:49.272+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:37:49.271+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:37:49.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-24T20:38:19.511+0000] {processor.py:157} INFO - Started process (PID=4463) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:38:19.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:38:19.512+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:38:19.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:38:19.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:38:19.568+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:38:19.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:38:19.599+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:38:19.599+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:38:19.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T20:38:49.792+0000] {processor.py:157} INFO - Started process (PID=4465) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:38:49.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:38:49.795+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:38:49.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:38:49.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:38:49.843+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:38:49.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:38:49.869+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:38:49.869+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:38:49.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T20:39:20.048+0000] {processor.py:157} INFO - Started process (PID=4467) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:39:20.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:39:20.050+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:39:20.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:39:20.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:39:20.110+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:39:20.110+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:39:20.141+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:39:20.141+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:39:20.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.137 seconds
[2024-10-24T20:39:50.343+0000] {processor.py:157} INFO - Started process (PID=4469) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:39:50.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:39:50.345+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:39:50.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:39:50.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:39:50.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:39:50.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:39:50.434+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:39:50.434+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:39:50.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T20:40:20.645+0000] {processor.py:157} INFO - Started process (PID=4471) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:40:20.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:40:20.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:40:20.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:40:20.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:40:20.694+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:40:20.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:40:20.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:40:20.721+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:40:20.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T20:40:50.907+0000] {processor.py:157} INFO - Started process (PID=4473) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:40:50.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:40:50.910+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:40:50.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:40:50.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:40:50.969+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:40:50.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:40:51.004+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:40:51.004+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:40:51.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-24T20:41:21.198+0000] {processor.py:157} INFO - Started process (PID=4475) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:41:21.199+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:41:21.200+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:41:21.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:41:21.218+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:41:21.249+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:41:21.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:41:21.282+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:41:21.282+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:41:21.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T20:41:51.481+0000] {processor.py:157} INFO - Started process (PID=4477) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:41:51.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:41:51.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:41:51.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:41:51.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:41:51.574+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:41:51.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:41:51.638+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:41:51.638+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:41:51.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.212 seconds
[2024-10-24T20:42:21.856+0000] {processor.py:157} INFO - Started process (PID=4479) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:42:21.857+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:42:21.858+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:42:21.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:42:21.874+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:42:21.917+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:42:21.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:42:21.961+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:42:21.961+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:42:22.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.175 seconds
[2024-10-24T20:42:52.212+0000] {processor.py:157} INFO - Started process (PID=4481) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:42:52.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:42:52.215+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:42:52.215+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:42:52.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:42:52.283+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:42:52.282+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:42:52.314+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:42:52.314+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:42:52.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-24T20:43:22.367+0000] {processor.py:157} INFO - Started process (PID=4483) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:43:22.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:43:22.370+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:43:22.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:43:22.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:43:22.416+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:43:22.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:43:22.443+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:43:22.443+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:43:22.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T20:43:52.622+0000] {processor.py:157} INFO - Started process (PID=4485) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:43:52.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:43:52.624+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:43:52.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:43:52.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:43:52.686+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:43:52.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:43:52.719+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:43:52.719+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:43:52.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.151 seconds
[2024-10-24T20:44:22.924+0000] {processor.py:157} INFO - Started process (PID=4487) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:44:22.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:44:22.926+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:44:22.926+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:44:22.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:44:22.968+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:44:22.968+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:44:23.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:44:23.006+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:44:23.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T20:44:53.181+0000] {processor.py:157} INFO - Started process (PID=4489) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:44:53.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:44:53.182+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:44:53.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:44:53.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:44:53.244+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:44:53.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:44:53.275+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:44:53.275+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:44:53.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T20:45:23.375+0000] {processor.py:157} INFO - Started process (PID=4491) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:45:23.380+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:45:23.381+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:45:23.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:45:23.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:45:23.468+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:45:23.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:45:23.512+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:45:23.512+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:45:23.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.171 seconds
[2024-10-24T20:45:53.585+0000] {processor.py:157} INFO - Started process (PID=4493) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:45:53.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:45:53.586+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:45:53.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:45:53.600+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:45:53.636+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:45:53.636+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:45:53.671+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:45:53.671+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:45:53.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T20:46:23.809+0000] {processor.py:157} INFO - Started process (PID=4495) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:46:23.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:46:23.811+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:46:23.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:46:23.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:46:23.859+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:46:23.858+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:46:23.884+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:46:23.884+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:46:23.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T20:46:54.060+0000] {processor.py:157} INFO - Started process (PID=4497) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:46:54.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:46:54.062+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:46:54.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:46:54.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:46:54.108+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:46:54.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:46:54.138+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:46:54.137+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:46:54.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T20:47:24.216+0000] {processor.py:157} INFO - Started process (PID=4499) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:47:24.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:47:24.218+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:47:24.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:47:24.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:47:24.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:47:24.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:47:24.295+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:47:24.295+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:47:24.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T20:47:54.470+0000] {processor.py:157} INFO - Started process (PID=4501) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:47:54.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:47:54.471+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:47:54.471+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:47:54.485+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:47:54.518+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:47:54.518+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:47:54.545+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:47:54.545+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:47:54.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T20:48:24.719+0000] {processor.py:157} INFO - Started process (PID=4503) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:48:24.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:48:24.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:48:24.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:48:24.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:48:24.768+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:48:24.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:48:24.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:48:24.795+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:48:24.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T20:48:54.971+0000] {processor.py:157} INFO - Started process (PID=4505) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:48:54.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:48:54.972+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:48:54.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:48:54.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:48:55.036+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:48:55.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:48:55.066+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:48:55.066+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:48:55.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T20:49:25.235+0000] {processor.py:157} INFO - Started process (PID=4507) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:49:25.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:49:25.247+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:49:25.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:49:25.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:49:25.291+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:49:25.291+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:49:25.319+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:49:25.318+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:49:25.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T20:49:55.385+0000] {processor.py:157} INFO - Started process (PID=4509) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:49:55.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:49:55.387+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:49:55.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:49:55.402+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:49:55.433+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:49:55.433+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:49:55.460+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:49:55.460+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:49:55.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T20:50:25.662+0000] {processor.py:157} INFO - Started process (PID=4511) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:50:25.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:50:25.664+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:50:25.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:50:25.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:50:25.719+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:50:25.719+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:50:25.750+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:50:25.749+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:50:25.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T20:50:55.820+0000] {processor.py:157} INFO - Started process (PID=4513) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:50:55.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:50:55.821+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:50:55.821+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:50:55.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:50:55.879+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:50:55.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:50:55.906+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:50:55.906+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:50:55.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T20:51:26.083+0000] {processor.py:157} INFO - Started process (PID=4515) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:51:26.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:51:26.085+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:51:26.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:51:26.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:51:26.132+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:51:26.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:51:26.162+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:51:26.162+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:51:26.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T20:51:56.338+0000] {processor.py:157} INFO - Started process (PID=4517) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:51:56.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:51:56.339+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:51:56.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:51:56.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:51:56.389+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:51:56.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:51:56.417+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:51:56.417+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:51:56.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T20:52:26.598+0000] {processor.py:157} INFO - Started process (PID=4519) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:52:26.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:52:26.604+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:52:26.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:52:26.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:52:26.758+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:52:26.758+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:52:26.806+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:52:26.806+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:52:26.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.238 seconds
[2024-10-24T20:52:56.969+0000] {processor.py:157} INFO - Started process (PID=4521) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:52:56.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:52:56.972+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:52:56.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:52:56.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:52:57.022+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:52:57.022+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:52:57.057+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:52:57.057+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:52:57.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T20:53:27.248+0000] {processor.py:157} INFO - Started process (PID=4523) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:53:27.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:53:27.249+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:53:27.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:53:27.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:53:27.294+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:53:27.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:53:27.325+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:53:27.325+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:53:27.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T20:53:57.401+0000] {processor.py:157} INFO - Started process (PID=4525) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:53:57.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:53:57.403+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:53:57.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:53:57.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:53:57.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:53:57.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:53:57.490+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:53:57.490+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:53:57.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T20:54:27.677+0000] {processor.py:157} INFO - Started process (PID=4527) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:54:27.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:54:27.679+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:54:27.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:54:27.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:54:27.728+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:54:27.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:54:27.753+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:54:27.752+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:54:27.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T20:54:57.926+0000] {processor.py:157} INFO - Started process (PID=4529) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:54:57.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:54:57.928+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:54:57.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:54:57.946+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:54:57.979+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:54:57.978+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:54:58.003+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:54:58.003+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:54:58.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T20:55:28.089+0000] {processor.py:157} INFO - Started process (PID=4531) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:55:28.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:55:28.090+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:55:28.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:55:28.103+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:55:28.134+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:55:28.134+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:55:28.164+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:55:28.164+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:55:28.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T20:55:58.346+0000] {processor.py:157} INFO - Started process (PID=4533) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:55:58.348+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:55:58.349+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:55:58.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:55:58.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:55:58.397+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:55:58.397+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:55:58.424+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:55:58.423+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:55:58.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T20:56:28.498+0000] {processor.py:157} INFO - Started process (PID=4535) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:56:28.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:56:28.499+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:56:28.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:56:28.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:56:28.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:56:28.548+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:56:28.576+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:56:28.576+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:56:28.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T20:56:58.760+0000] {processor.py:157} INFO - Started process (PID=4537) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:56:58.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:56:58.762+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:56:58.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:56:58.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:56:58.810+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:56:58.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:56:58.835+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:56:58.835+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:56:58.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T20:57:28.933+0000] {processor.py:157} INFO - Started process (PID=4539) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:57:28.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:57:28.936+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:57:28.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:57:28.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:57:28.993+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:57:28.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:57:29.024+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:57:29.023+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:57:29.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T20:57:59.203+0000] {processor.py:157} INFO - Started process (PID=4541) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:57:59.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:57:59.206+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:57:59.206+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:57:59.228+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:57:59.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:57:59.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:57:59.298+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:57:59.298+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:57:59.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-24T20:58:29.361+0000] {processor.py:157} INFO - Started process (PID=4543) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:58:29.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:58:29.363+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:58:29.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:58:29.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:58:29.415+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:58:29.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:58:29.448+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:58:29.448+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:58:29.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T20:58:59.629+0000] {processor.py:157} INFO - Started process (PID=4545) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:58:59.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:58:59.630+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:58:59.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:58:59.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:58:59.685+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:58:59.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:58:59.715+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:58:59.715+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:58:59.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T20:59:29.898+0000] {processor.py:157} INFO - Started process (PID=4547) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:59:29.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T20:59:29.901+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:59:29.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:59:29.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T20:59:29.951+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:59:29.951+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T20:59:29.977+0000] {logging_mixin.py:149} INFO - [2024-10-24T20:59:29.977+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T20:59:29.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T21:00:00.153+0000] {processor.py:157} INFO - Started process (PID=4549) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:00:00.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:00:00.155+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:00:00.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:00:00.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:00:00.217+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:00:00.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:00:00.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:00:00.250+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:00:00.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T21:00:30.445+0000] {processor.py:157} INFO - Started process (PID=4551) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:00:30.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:00:30.447+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:00:30.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:00:30.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:00:30.492+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:00:30.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:00:30.516+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:00:30.516+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:00:30.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T21:01:00.698+0000] {processor.py:157} INFO - Started process (PID=4553) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:01:00.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:01:00.701+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:01:00.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:01:00.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:01:00.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:01:00.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:01:00.835+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:01:00.835+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:01:00.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.169 seconds
[2024-10-24T21:01:31.003+0000] {processor.py:157} INFO - Started process (PID=4555) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:01:31.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:01:31.008+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:01:31.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:01:31.065+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:01:31.111+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:01:31.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:01:31.140+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:01:31.139+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:01:31.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.164 seconds
[2024-10-24T21:02:01.315+0000] {processor.py:157} INFO - Started process (PID=4557) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:02:01.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:02:01.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:02:01.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:02:01.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:02:01.362+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:02:01.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:02:01.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:02:01.390+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:02:01.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T21:02:31.466+0000] {processor.py:157} INFO - Started process (PID=4559) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:02:31.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:02:31.467+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:02:31.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:02:31.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:02:31.515+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:02:31.515+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:02:31.541+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:02:31.541+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:02:31.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T21:03:01.669+0000] {processor.py:157} INFO - Started process (PID=4561) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:03:01.670+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:03:01.671+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:03:01.671+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:03:01.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:03:01.720+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:03:01.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:03:01.744+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:03:01.744+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:03:01.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T21:03:31.819+0000] {processor.py:157} INFO - Started process (PID=4563) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:03:31.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:03:31.822+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:03:31.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:03:31.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:03:31.882+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:03:31.882+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:03:31.914+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:03:31.914+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:03:31.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T21:04:02.022+0000] {processor.py:157} INFO - Started process (PID=4565) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:04:02.022+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:04:02.023+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:04:02.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:04:02.040+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:04:02.072+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:04:02.072+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:04:02.098+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:04:02.098+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:04:02.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T21:04:32.284+0000] {processor.py:157} INFO - Started process (PID=4567) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:04:32.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:04:32.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:04:32.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:04:32.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:04:32.354+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:04:32.354+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:04:32.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:04:32.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:04:32.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.137 seconds
[2024-10-24T21:05:02.441+0000] {processor.py:157} INFO - Started process (PID=4569) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:05:02.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:05:02.443+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:05:02.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:05:02.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:05:02.492+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:05:02.491+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:05:02.527+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:05:02.527+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:05:02.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T21:05:32.718+0000] {processor.py:157} INFO - Started process (PID=4571) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:05:32.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:05:32.731+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:05:32.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:05:32.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:05:32.789+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:05:32.788+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:05:32.825+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:05:32.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:05:32.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-24T21:06:02.865+0000] {processor.py:157} INFO - Started process (PID=4573) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:06:02.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:06:02.867+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:06:02.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:06:02.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:06:02.924+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:06:02.924+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:06:02.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:06:02.959+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:06:02.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T21:06:33.145+0000] {processor.py:157} INFO - Started process (PID=4575) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:06:33.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:06:33.148+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:06:33.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:06:33.176+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:06:33.209+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:06:33.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:06:33.238+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:06:33.238+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:06:33.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.371 seconds
[2024-10-24T21:07:03.657+0000] {processor.py:157} INFO - Started process (PID=4577) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:07:03.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:07:03.659+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:07:03.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:07:03.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:07:03.711+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:07:03.711+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:07:03.742+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:07:03.741+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:07:03.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-24T21:07:33.937+0000] {processor.py:157} INFO - Started process (PID=4579) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:07:33.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:07:33.939+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:07:33.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:07:33.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:07:33.988+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:07:33.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:07:34.020+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:07:34.020+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:07:34.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T21:08:04.198+0000] {processor.py:157} INFO - Started process (PID=4581) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:08:04.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:08:04.199+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:08:04.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:08:04.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:08:04.240+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:08:04.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:08:04.266+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:08:04.265+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:08:04.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T21:08:34.443+0000] {processor.py:157} INFO - Started process (PID=4583) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:08:34.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:08:34.445+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:08:34.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:08:34.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:08:34.487+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:08:34.486+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:08:34.513+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:08:34.513+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:08:34.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T21:09:04.603+0000] {processor.py:157} INFO - Started process (PID=4585) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:09:04.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:09:04.605+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:09:04.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:09:04.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:09:04.661+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:09:04.661+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:09:04.687+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:09:04.687+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:09:04.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T21:09:34.869+0000] {processor.py:157} INFO - Started process (PID=4587) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:09:34.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:09:34.871+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:09:34.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:09:34.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:09:34.923+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:09:34.923+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:09:34.952+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:09:34.952+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:09:34.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:10:05.027+0000] {processor.py:157} INFO - Started process (PID=4589) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:10:05.028+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:10:05.029+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:10:05.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:10:05.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:10:05.089+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:10:05.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:10:05.125+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:10:05.124+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:10:05.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T21:10:35.315+0000] {processor.py:157} INFO - Started process (PID=4591) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:10:35.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:10:35.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:10:35.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:10:35.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:10:35.369+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:10:35.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:10:35.402+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:10:35.402+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:10:35.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T21:11:05.519+0000] {processor.py:157} INFO - Started process (PID=4593) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:11:05.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:11:05.522+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:11:05.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:11:05.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:11:05.575+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:11:05.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:11:05.604+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:11:05.603+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:11:05.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T21:11:35.790+0000] {processor.py:157} INFO - Started process (PID=4595) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:11:35.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:11:35.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:11:35.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:11:35.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:11:35.837+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:11:35.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:11:35.866+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:11:35.866+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:11:35.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T21:12:06.045+0000] {processor.py:157} INFO - Started process (PID=4597) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:12:06.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:12:06.048+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:12:06.047+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:12:06.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:12:06.122+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:12:06.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:12:06.163+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:12:06.163+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:12:06.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.145 seconds
[2024-10-24T21:12:36.217+0000] {processor.py:157} INFO - Started process (PID=4599) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:12:36.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:12:36.220+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:12:36.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:12:36.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:12:36.271+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:12:36.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:12:36.301+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:12:36.301+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:12:36.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T21:13:06.474+0000] {processor.py:157} INFO - Started process (PID=4601) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:13:06.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:13:06.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:13:06.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:13:06.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:13:06.524+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:13:06.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:13:06.550+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:13:06.550+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:13:06.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T21:13:36.628+0000] {processor.py:157} INFO - Started process (PID=4603) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:13:36.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:13:36.629+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:13:36.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:13:36.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:13:36.675+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:13:36.675+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:13:36.714+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:13:36.714+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:13:36.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T21:14:06.830+0000] {processor.py:157} INFO - Started process (PID=4605) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:14:06.831+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:14:06.832+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:14:06.832+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:14:06.850+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:14:06.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:14:06.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:14:06.915+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:14:06.915+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:14:06.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T21:14:37.096+0000] {processor.py:157} INFO - Started process (PID=4607) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:14:37.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:14:37.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:14:37.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:14:37.116+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:14:37.154+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:14:37.153+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:14:37.186+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:14:37.186+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:14:37.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T21:15:07.393+0000] {processor.py:157} INFO - Started process (PID=4609) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:15:07.394+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:15:07.396+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:15:07.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:15:07.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:15:07.449+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:15:07.449+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:15:07.477+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:15:07.477+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:15:07.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T21:15:37.553+0000] {processor.py:157} INFO - Started process (PID=4611) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:15:37.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:15:37.554+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:15:37.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:15:37.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:15:37.600+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:15:37.600+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:15:37.628+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:15:37.628+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:15:37.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T21:16:07.806+0000] {processor.py:157} INFO - Started process (PID=4613) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:16:07.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:16:07.808+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:16:07.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:16:07.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:16:07.854+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:16:07.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:16:07.882+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:16:07.882+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:16:07.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T21:16:37.957+0000] {processor.py:157} INFO - Started process (PID=4615) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:16:37.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:16:37.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:16:37.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:16:37.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:16:38.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:16:38.006+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:16:38.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:16:38.032+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:16:38.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T21:17:08.258+0000] {processor.py:157} INFO - Started process (PID=4617) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:17:08.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:17:08.260+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:17:08.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:17:08.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:17:08.316+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:17:08.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:17:08.346+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:17:08.346+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:17:08.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T21:17:38.409+0000] {processor.py:157} INFO - Started process (PID=4619) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:17:38.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:17:38.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:17:38.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:17:38.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:17:38.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:17:38.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:17:38.492+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:17:38.491+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:17:38.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T21:18:08.678+0000] {processor.py:157} INFO - Started process (PID=4621) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:18:08.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:18:08.680+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:18:08.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:18:08.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:18:08.735+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:18:08.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:18:08.768+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:18:08.767+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:18:08.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T21:18:38.941+0000] {processor.py:157} INFO - Started process (PID=4623) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:18:38.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:18:38.943+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:18:38.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:18:38.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:18:38.988+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:18:38.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:18:39.017+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:18:39.017+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:18:39.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T21:19:09.095+0000] {processor.py:157} INFO - Started process (PID=4625) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:19:09.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:19:09.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:19:09.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:19:09.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:19:09.144+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:19:09.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:19:09.178+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:19:09.177+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:19:09.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T21:19:39.364+0000] {processor.py:157} INFO - Started process (PID=4627) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:19:39.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:19:39.366+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:19:39.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:19:39.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:19:39.412+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:19:39.412+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:19:39.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:19:39.444+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:19:39.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:20:09.540+0000] {processor.py:157} INFO - Started process (PID=4629) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:20:09.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:20:09.542+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:20:09.542+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:20:09.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:20:09.602+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:20:09.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:20:09.626+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:20:09.626+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:20:09.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T21:20:39.750+0000] {processor.py:157} INFO - Started process (PID=4631) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:20:39.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:20:39.752+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:20:39.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:20:39.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:20:39.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:20:39.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:20:39.825+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:20:39.825+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:20:39.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T21:21:10.001+0000] {processor.py:157} INFO - Started process (PID=4633) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:21:10.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:21:10.004+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:21:10.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:21:10.021+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:21:10.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:21:10.056+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:21:10.088+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:21:10.088+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:21:10.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T21:21:40.271+0000] {processor.py:157} INFO - Started process (PID=4635) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:21:40.272+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:21:40.273+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:21:40.272+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:21:40.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:21:40.321+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:21:40.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:21:40.347+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:21:40.347+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:21:40.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T21:22:10.431+0000] {processor.py:157} INFO - Started process (PID=4637) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:22:10.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:22:10.433+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:22:10.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:22:10.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:22:10.479+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:22:10.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:22:10.503+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:22:10.503+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:22:10.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T21:22:40.689+0000] {processor.py:157} INFO - Started process (PID=4639) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:22:40.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:22:40.690+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:22:40.690+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:22:40.706+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:22:40.736+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:22:40.736+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:22:40.760+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:22:40.760+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:22:40.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T21:23:10.848+0000] {processor.py:157} INFO - Started process (PID=4641) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:23:10.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:23:10.851+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:23:10.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:23:10.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:23:10.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:23:10.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:23:10.949+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:23:10.949+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:23:10.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T21:23:41.051+0000] {processor.py:157} INFO - Started process (PID=4643) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:23:41.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:23:41.053+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:23:41.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:23:41.069+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:23:41.103+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:23:41.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:23:41.132+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:23:41.132+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:23:41.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:24:11.238+0000] {processor.py:157} INFO - Started process (PID=4645) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:24:11.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:24:11.243+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:24:11.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:24:11.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:24:11.302+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:24:11.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:24:11.329+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:24:11.328+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:24:11.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T21:24:41.513+0000] {processor.py:157} INFO - Started process (PID=4647) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:24:41.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:24:41.515+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:24:41.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:24:41.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:24:41.573+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:24:41.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:24:41.608+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:24:41.608+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:24:41.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T21:25:11.795+0000] {processor.py:157} INFO - Started process (PID=4649) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:25:11.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:25:11.796+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:25:11.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:25:11.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:25:11.849+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:25:11.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:25:11.880+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:25:11.880+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:25:11.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:25:42.054+0000] {processor.py:157} INFO - Started process (PID=4651) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:25:42.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:25:42.067+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:25:42.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:25:42.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:25:42.113+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:25:42.113+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:25:42.143+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:25:42.143+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:25:42.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T21:26:12.212+0000] {processor.py:157} INFO - Started process (PID=4653) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:26:12.213+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:26:12.214+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:26:12.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:26:12.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:26:12.263+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:26:12.263+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:26:12.288+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:26:12.288+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:26:12.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T21:26:42.465+0000] {processor.py:157} INFO - Started process (PID=4655) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:26:42.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:26:42.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:26:42.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:26:42.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:26:42.551+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:26:42.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:26:42.589+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:26:42.589+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:26:42.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-24T21:27:12.727+0000] {processor.py:157} INFO - Started process (PID=4657) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:27:12.728+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:27:12.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:27:12.728+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:27:12.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:27:12.770+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:27:12.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:27:12.795+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:27:12.795+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:27:12.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.089 seconds
[2024-10-24T21:27:42.971+0000] {processor.py:157} INFO - Started process (PID=4659) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:27:42.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:27:42.973+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:27:42.973+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:27:42.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:27:43.016+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:27:43.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:27:43.041+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:27:43.041+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:27:43.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T21:28:13.118+0000] {processor.py:157} INFO - Started process (PID=4661) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:28:13.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:28:13.120+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:28:13.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:28:13.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:28:13.164+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:28:13.164+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:28:13.189+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:28:13.189+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:28:13.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T21:28:43.368+0000] {processor.py:157} INFO - Started process (PID=4663) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:28:43.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:28:43.376+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:28:43.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:28:43.393+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:28:43.429+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:28:43.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:28:43.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:28:43.457+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:28:43.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T21:29:13.629+0000] {processor.py:157} INFO - Started process (PID=4665) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:29:13.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:29:13.630+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:29:13.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:29:13.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:29:13.673+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:29:13.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:29:13.699+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:29:13.698+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:29:13.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T21:29:43.783+0000] {processor.py:157} INFO - Started process (PID=4667) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:29:43.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:29:43.786+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:29:43.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:29:43.798+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:29:43.827+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:29:43.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:29:43.854+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:29:43.854+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:29:43.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T21:30:14.041+0000] {processor.py:157} INFO - Started process (PID=4669) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:30:14.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:30:14.042+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:30:14.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:30:14.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:30:14.096+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:30:14.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:30:14.122+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:30:14.122+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:30:14.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T21:30:44.197+0000] {processor.py:157} INFO - Started process (PID=4671) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:30:44.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:30:44.209+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:30:44.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:30:44.223+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:30:44.253+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:30:44.253+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:30:44.279+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:30:44.279+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:30:44.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T21:31:14.408+0000] {processor.py:157} INFO - Started process (PID=4673) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:31:14.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:31:14.412+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:31:14.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:31:14.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:31:14.460+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:31:14.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:31:14.500+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:31:14.500+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:31:14.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T21:31:44.679+0000] {processor.py:157} INFO - Started process (PID=4675) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:31:44.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:31:44.682+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:31:44.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:31:44.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:31:44.728+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:31:44.727+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:31:44.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:31:44.757+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:31:44.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T21:32:14.929+0000] {processor.py:157} INFO - Started process (PID=4677) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:32:14.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:32:14.930+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:32:14.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:32:14.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:32:14.980+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:32:14.980+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:32:15.013+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:32:15.012+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:32:15.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T21:32:45.086+0000] {processor.py:157} INFO - Started process (PID=4679) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:32:45.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:32:45.088+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:32:45.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:32:45.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:32:45.134+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:32:45.134+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:32:45.160+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:32:45.160+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:32:45.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T21:33:15.337+0000] {processor.py:157} INFO - Started process (PID=4681) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:33:15.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:33:15.339+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:33:15.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:33:15.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:33:15.387+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:33:15.387+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:33:15.416+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:33:15.416+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:33:15.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T21:33:45.608+0000] {processor.py:157} INFO - Started process (PID=4683) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:33:45.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:33:45.613+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:33:45.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:33:45.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:33:45.718+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:33:45.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:33:45.765+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:33:45.765+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:33:45.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.205 seconds
[2024-10-24T21:34:15.912+0000] {processor.py:157} INFO - Started process (PID=4685) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:34:15.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:34:15.914+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:34:15.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:34:15.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:34:15.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:34:15.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:34:15.996+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:34:15.996+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:34:16.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:34:46.067+0000] {processor.py:157} INFO - Started process (PID=4687) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:34:46.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:34:46.072+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:34:46.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:34:46.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:34:46.151+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:34:46.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:34:46.220+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:34:46.220+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:34:46.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.187 seconds
[2024-10-24T21:35:16.422+0000] {processor.py:157} INFO - Started process (PID=4689) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:35:16.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:35:16.423+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:35:16.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:35:16.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:35:16.466+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:35:16.465+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:35:16.494+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:35:16.494+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:35:16.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T21:35:46.675+0000] {processor.py:157} INFO - Started process (PID=4691) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:35:46.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:35:46.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:35:46.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:35:46.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:35:46.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:35:46.721+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:35:46.744+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:35:46.744+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:35:46.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T21:36:16.825+0000] {processor.py:157} INFO - Started process (PID=4693) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:36:16.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:36:16.827+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:36:16.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:36:16.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:36:16.870+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:36:16.870+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:36:16.895+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:36:16.894+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:36:16.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T21:36:47.071+0000] {processor.py:157} INFO - Started process (PID=4695) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:36:47.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:36:47.073+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:36:47.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:36:47.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:36:47.117+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:36:47.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:36:47.145+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:36:47.145+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:36:47.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T21:37:17.326+0000] {processor.py:157} INFO - Started process (PID=4697) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:37:17.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:37:17.328+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:37:17.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:37:17.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:37:17.385+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:37:17.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:37:17.417+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:37:17.417+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:37:17.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T21:37:47.483+0000] {processor.py:157} INFO - Started process (PID=4699) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:37:47.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:37:47.490+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:37:47.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:37:47.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:37:47.580+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:37:47.580+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:37:47.634+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:37:47.633+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:37:47.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.192 seconds
[2024-10-24T21:38:17.845+0000] {processor.py:157} INFO - Started process (PID=4701) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:38:17.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:38:17.847+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:38:17.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:38:17.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:38:17.912+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:38:17.912+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:38:17.948+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:38:17.948+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:38:17.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-24T21:38:48.134+0000] {processor.py:157} INFO - Started process (PID=4703) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:38:48.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:38:48.137+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:38:48.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:38:48.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:38:48.198+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:38:48.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:38:48.238+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:38:48.237+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:38:48.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-24T21:39:18.419+0000] {processor.py:157} INFO - Started process (PID=4705) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:39:18.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:39:18.421+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:39:18.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:39:18.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:39:18.471+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:39:18.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:39:18.498+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:39:18.498+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:39:18.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T21:39:48.682+0000] {processor.py:157} INFO - Started process (PID=4707) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:39:48.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:39:48.684+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:39:48.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:39:48.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:39:48.733+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:39:48.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:39:48.762+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:39:48.762+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:39:48.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T21:40:18.844+0000] {processor.py:157} INFO - Started process (PID=4709) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:40:18.845+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:40:18.846+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:40:18.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:40:18.859+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:40:18.887+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:40:18.887+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:40:18.917+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:40:18.917+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:40:18.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T21:40:49.093+0000] {processor.py:157} INFO - Started process (PID=4711) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:40:49.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:40:49.096+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:40:49.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:40:49.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:40:49.146+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:40:49.145+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:40:49.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:40:49.176+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:40:49.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T21:41:19.348+0000] {processor.py:157} INFO - Started process (PID=4713) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:41:19.348+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:41:19.349+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:41:19.349+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:41:19.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:41:19.393+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:41:19.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:41:19.417+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:41:19.417+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:41:19.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T21:41:49.595+0000] {processor.py:157} INFO - Started process (PID=4715) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:41:49.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:41:49.597+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:41:49.597+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:41:49.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:41:49.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:41:49.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:41:49.672+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:41:49.672+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:41:49.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T21:42:19.847+0000] {processor.py:157} INFO - Started process (PID=4717) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:42:19.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:42:19.848+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:42:19.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:42:19.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:42:19.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:42:19.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:42:19.926+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:42:19.926+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:42:19.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T21:42:50.101+0000] {processor.py:157} INFO - Started process (PID=4719) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:42:50.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:42:50.104+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:42:50.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:42:50.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:42:50.151+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:42:50.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:42:50.183+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:42:50.183+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:42:50.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:43:20.254+0000] {processor.py:157} INFO - Started process (PID=4721) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:43:20.256+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:43:20.257+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:43:20.257+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:43:20.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:43:20.302+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:43:20.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:43:20.332+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:43:20.332+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:43:20.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T21:43:50.514+0000] {processor.py:157} INFO - Started process (PID=4723) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:43:50.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:43:50.517+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:43:50.517+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:43:50.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:43:50.560+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:43:50.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:43:50.585+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:43:50.585+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:43:50.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T21:44:20.868+0000] {processor.py:157} INFO - Started process (PID=4725) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:44:20.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:44:20.870+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:44:20.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:44:20.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:44:20.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:44:20.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:44:20.948+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:44:20.948+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:44:20.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T21:44:51.016+0000] {processor.py:157} INFO - Started process (PID=4727) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:44:51.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:44:51.018+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:44:51.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:44:51.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:44:51.067+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:44:51.067+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:44:51.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:44:51.097+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:44:51.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T21:45:21.285+0000] {processor.py:157} INFO - Started process (PID=4729) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:45:21.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:45:21.287+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:45:21.287+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:45:21.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:45:21.348+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:45:21.348+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:45:21.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:45:21.390+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:45:21.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-24T21:45:51.601+0000] {processor.py:157} INFO - Started process (PID=4731) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:45:51.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:45:51.602+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:45:51.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:45:51.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:45:51.652+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:45:51.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:45:51.684+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:45:51.684+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:45:51.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T21:46:21.751+0000] {processor.py:157} INFO - Started process (PID=4733) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:46:21.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:46:21.761+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:46:21.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:46:21.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:46:21.809+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:46:21.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:46:21.833+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:46:21.833+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:46:21.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T21:46:51.961+0000] {processor.py:157} INFO - Started process (PID=4735) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:46:51.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:46:51.963+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:46:51.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:46:51.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:46:52.012+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:46:52.012+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:46:52.037+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:46:52.037+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:46:52.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T21:47:22.221+0000] {processor.py:157} INFO - Started process (PID=4737) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:47:22.227+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:47:22.229+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:47:22.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:47:22.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:47:22.282+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:47:22.282+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:47:22.315+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:47:22.315+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:47:22.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-24T21:47:52.396+0000] {processor.py:157} INFO - Started process (PID=4739) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:47:52.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:47:52.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:47:52.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:47:52.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:47:52.458+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:47:52.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:47:52.495+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:47:52.495+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:47:52.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T21:48:22.703+0000] {processor.py:157} INFO - Started process (PID=4741) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:48:22.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:48:22.706+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:48:22.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:48:22.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:48:22.760+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:48:22.759+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:48:22.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:48:22.798+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:48:22.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T21:48:52.861+0000] {processor.py:157} INFO - Started process (PID=4743) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:48:52.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:48:52.863+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:48:52.863+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:48:52.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:48:52.911+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:48:52.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:48:52.937+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:48:52.937+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:48:52.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T21:49:23.113+0000] {processor.py:157} INFO - Started process (PID=4745) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:49:23.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:49:23.115+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:49:23.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:49:23.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:49:23.167+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:49:23.167+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:49:23.190+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:49:23.190+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:49:23.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T21:49:53.369+0000] {processor.py:157} INFO - Started process (PID=4747) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:49:53.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:49:53.371+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:49:53.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:49:53.393+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:49:53.428+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:49:53.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:49:53.454+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:49:53.454+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:49:53.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T21:50:23.578+0000] {processor.py:157} INFO - Started process (PID=4749) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:50:23.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:50:23.580+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:50:23.580+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:50:23.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:50:23.622+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:50:23.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:50:23.661+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:50:23.661+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:50:23.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T21:50:53.821+0000] {processor.py:157} INFO - Started process (PID=4751) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:50:53.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:50:53.823+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:50:53.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:50:53.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:50:53.907+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:50:53.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:50:53.939+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:50:53.939+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:50:53.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.142 seconds
[2024-10-24T21:51:24.103+0000] {processor.py:157} INFO - Started process (PID=4753) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:51:24.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:51:24.105+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:51:24.105+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:51:24.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:51:24.160+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:51:24.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:51:24.195+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:51:24.195+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:51:24.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T21:51:54.272+0000] {processor.py:157} INFO - Started process (PID=4755) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:51:54.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:51:54.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:51:54.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:51:54.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:51:54.323+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:51:54.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:51:54.350+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:51:54.350+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:51:54.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T21:52:24.480+0000] {processor.py:157} INFO - Started process (PID=4757) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:52:24.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:52:24.485+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:52:24.485+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:52:24.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:52:24.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:52:24.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:52:24.583+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:52:24.582+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:52:24.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.129 seconds
[2024-10-24T21:52:54.658+0000] {processor.py:157} INFO - Started process (PID=4759) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:52:54.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:52:54.659+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:52:54.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:52:54.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:52:54.709+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:52:54.709+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:52:54.739+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:52:54.739+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:52:54.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T21:53:24.915+0000] {processor.py:157} INFO - Started process (PID=4761) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:53:24.917+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:53:24.917+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:53:24.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:53:24.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:53:24.971+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:53:24.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:53:25.001+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:53:25.001+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:53:25.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:53:55.174+0000] {processor.py:157} INFO - Started process (PID=4763) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:53:55.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:53:55.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:53:55.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:53:55.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:53:55.224+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:53:55.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:53:55.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:53:55.251+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:53:55.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T21:54:25.328+0000] {processor.py:157} INFO - Started process (PID=4765) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:54:25.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:54:25.330+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:54:25.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:54:25.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:54:25.385+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:54:25.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:54:25.413+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:54:25.413+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:54:25.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T21:54:55.539+0000] {processor.py:157} INFO - Started process (PID=4767) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:54:55.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:54:55.541+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:54:55.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:54:55.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:54:55.593+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:54:55.593+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:54:55.628+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:54:55.627+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:54:55.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T21:55:25.701+0000] {processor.py:157} INFO - Started process (PID=4769) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:55:25.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:55:25.702+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:55:25.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:55:25.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:55:25.755+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:55:25.755+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:55:25.781+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:55:25.781+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:55:25.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T21:55:55.896+0000] {processor.py:157} INFO - Started process (PID=4771) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:55:55.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:55:55.897+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:55:55.897+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:55:55.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:55:55.939+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:55:55.939+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:55:55.963+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:55:55.963+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:55:55.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.090 seconds
[2024-10-24T21:56:26.137+0000] {processor.py:157} INFO - Started process (PID=4773) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:56:26.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:56:26.173+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:56:26.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:56:26.222+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:56:26.284+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:56:26.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:56:26.309+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:56:26.309+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:56:27.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.994 seconds
[2024-10-24T21:56:57.295+0000] {processor.py:157} INFO - Started process (PID=4775) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:56:57.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:56:57.296+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:56:57.296+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:56:57.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:56:57.349+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:56:57.349+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:56:57.378+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:56:57.378+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:56:57.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T21:57:27.483+0000] {processor.py:157} INFO - Started process (PID=4777) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:57:27.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:57:27.485+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:57:27.485+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:57:27.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:57:27.533+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:57:27.532+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:57:27.563+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:57:27.563+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:57:27.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T21:57:57.650+0000] {processor.py:157} INFO - Started process (PID=4779) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:57:57.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:57:57.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:57:57.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:57:57.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:57:57.721+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:57:57.721+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:57:57.746+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:57:57.746+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:57:57.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T21:58:27.928+0000] {processor.py:157} INFO - Started process (PID=4781) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:58:27.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:58:27.930+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:58:27.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:58:27.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:58:27.975+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:58:27.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:58:28.002+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:58:28.002+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:58:28.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T21:58:58.191+0000] {processor.py:157} INFO - Started process (PID=4783) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:58:58.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:58:58.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:58:58.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:58:58.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:58:58.249+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:58:58.249+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:58:58.277+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:58:58.277+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:58:58.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T21:59:28.344+0000] {processor.py:157} INFO - Started process (PID=4785) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:59:28.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:59:28.356+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:59:28.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:59:28.370+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:59:28.399+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:59:28.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:59:28.421+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:59:28.421+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:59:28.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T21:59:58.675+0000] {processor.py:157} INFO - Started process (PID=4787) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:59:58.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T21:59:58.681+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:59:58.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:59:58.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T21:59:58.753+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:59:58.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T21:59:58.784+0000] {logging_mixin.py:149} INFO - [2024-10-24T21:59:58.784+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T21:59:58.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-24T22:00:28.862+0000] {processor.py:157} INFO - Started process (PID=4789) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:00:28.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:00:28.864+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:00:28.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:00:28.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:00:28.908+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:00:28.908+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:00:28.938+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:00:28.937+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:00:28.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T22:00:59.063+0000] {processor.py:157} INFO - Started process (PID=4791) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:00:59.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:00:59.065+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:00:59.065+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:00:59.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:00:59.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:00:59.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:00:59.158+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:00:59.158+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:00:59.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T22:01:29.328+0000] {processor.py:157} INFO - Started process (PID=4793) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:01:29.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:01:29.330+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:01:29.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:01:29.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:01:29.384+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:01:29.383+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:01:29.415+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:01:29.415+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:01:29.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T22:01:59.592+0000] {processor.py:157} INFO - Started process (PID=4795) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:01:59.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:01:59.594+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:01:59.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:01:59.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:01:59.637+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:01:59.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:01:59.665+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:01:59.665+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:01:59.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T22:02:29.740+0000] {processor.py:157} INFO - Started process (PID=4797) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:02:29.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:02:29.742+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:02:29.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:02:29.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:02:29.786+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:02:29.785+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:02:29.813+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:02:29.813+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:02:29.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T22:02:59.982+0000] {processor.py:157} INFO - Started process (PID=4799) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:02:59.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:02:59.995+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:02:59.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:03:00.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:03:00.035+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:03:00.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:03:00.059+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:03:00.059+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:03:00.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:03:30.130+0000] {processor.py:157} INFO - Started process (PID=4801) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:03:30.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:03:30.142+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:03:30.142+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:03:30.157+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:03:30.184+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:03:30.184+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:03:30.211+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:03:30.211+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:03:30.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T22:04:00.335+0000] {processor.py:157} INFO - Started process (PID=4803) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:04:00.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:04:00.336+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:04:00.336+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:04:00.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:04:00.382+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:04:00.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:04:00.407+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:04:00.406+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:04:00.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.093 seconds
[2024-10-24T22:04:30.480+0000] {processor.py:157} INFO - Started process (PID=4805) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:04:30.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:04:30.493+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:04:30.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:04:30.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:04:30.536+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:04:30.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:04:30.566+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:04:30.565+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:04:30.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T22:05:00.685+0000] {processor.py:157} INFO - Started process (PID=4807) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:05:00.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:05:00.686+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:05:00.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:05:00.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:05:00.737+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:05:00.736+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:05:00.765+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:05:00.765+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:05:00.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T22:05:30.849+0000] {processor.py:157} INFO - Started process (PID=4809) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:05:30.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:05:30.851+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:05:30.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:05:30.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:05:30.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:05:30.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:05:30.925+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:05:30.925+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:05:30.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T22:06:01.103+0000] {processor.py:157} INFO - Started process (PID=4811) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:06:01.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:06:01.104+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:06:01.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:06:01.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:06:01.161+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:06:01.161+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:06:01.187+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:06:01.187+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:06:01.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T22:06:31.361+0000] {processor.py:157} INFO - Started process (PID=4813) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:06:31.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:06:31.363+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:06:31.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:06:31.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:06:31.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:06:31.410+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:06:31.440+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:06:31.439+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:06:31.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:07:01.601+0000] {processor.py:157} INFO - Started process (PID=4815) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:07:01.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:07:01.603+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:07:01.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:07:01.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:07:01.657+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:07:01.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:07:01.685+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:07:01.685+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:07:01.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:07:31.870+0000] {processor.py:157} INFO - Started process (PID=4817) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:07:31.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:07:31.872+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:07:31.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:07:31.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:07:31.918+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:07:31.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:07:31.946+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:07:31.946+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:07:31.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:08:02.156+0000] {processor.py:157} INFO - Started process (PID=4819) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:08:02.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:08:02.158+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:08:02.158+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:08:02.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:08:02.207+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:08:02.206+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:08:02.236+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:08:02.235+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:08:02.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T22:08:32.310+0000] {processor.py:157} INFO - Started process (PID=4821) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:08:32.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:08:32.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:08:32.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:08:32.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:08:32.359+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:08:32.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:08:32.389+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:08:32.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:08:32.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T22:09:02.519+0000] {processor.py:157} INFO - Started process (PID=4823) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:09:02.520+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:09:02.521+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:09:02.521+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:09:02.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:09:02.578+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:09:02.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:09:02.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:09:02.616+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:09:02.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T22:09:32.687+0000] {processor.py:157} INFO - Started process (PID=4825) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:09:32.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:09:32.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:09:32.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:09:32.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:09:32.750+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:09:32.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:09:32.784+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:09:32.784+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:09:32.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T22:10:02.976+0000] {processor.py:157} INFO - Started process (PID=4827) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:10:02.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:10:02.977+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:10:02.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:10:02.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:10:03.029+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:10:03.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:10:03.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:10:03.070+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:10:03.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-24T22:10:33.126+0000] {processor.py:157} INFO - Started process (PID=4829) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:10:33.127+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:10:33.128+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:10:33.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:10:33.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:10:33.187+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:10:33.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:10:33.221+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:10:33.221+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:10:33.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T22:11:03.393+0000] {processor.py:157} INFO - Started process (PID=4831) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:11:03.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:11:03.394+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:11:03.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:11:03.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:11:03.441+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:11:03.441+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:11:03.467+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:11:03.467+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:11:03.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:11:33.644+0000] {processor.py:157} INFO - Started process (PID=4833) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:11:33.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:11:33.646+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:11:33.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:11:33.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:11:33.693+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:11:33.693+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:11:33.719+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:11:33.719+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:11:33.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T22:12:03.790+0000] {processor.py:157} INFO - Started process (PID=4835) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:12:03.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:12:03.792+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:12:03.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:12:03.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:12:03.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:12:03.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:12:03.867+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:12:03.867+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:12:03.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T22:12:34.138+0000] {processor.py:157} INFO - Started process (PID=4837) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:12:34.141+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:12:34.142+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:12:34.142+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:12:34.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:12:34.188+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:12:34.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:12:34.215+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:12:34.215+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:12:34.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-24T22:13:04.396+0000] {processor.py:157} INFO - Started process (PID=4839) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:13:04.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:13:04.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:13:04.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:13:04.413+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:13:04.448+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:13:04.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:13:04.477+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:13:04.477+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:13:04.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:13:34.643+0000] {processor.py:157} INFO - Started process (PID=4841) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:13:34.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:13:34.646+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:13:34.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:13:34.660+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:13:34.694+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:13:34.693+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:13:34.722+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:13:34.722+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:13:34.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:14:04.906+0000] {processor.py:157} INFO - Started process (PID=4843) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:14:04.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:14:04.908+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:14:04.908+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:14:04.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:14:04.956+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:14:04.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:14:04.987+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:14:04.987+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:14:05.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:14:35.055+0000] {processor.py:157} INFO - Started process (PID=4845) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:14:35.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:14:35.057+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:14:35.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:14:35.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:14:35.114+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:14:35.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:14:35.147+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:14:35.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:14:35.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T22:15:05.265+0000] {processor.py:157} INFO - Started process (PID=4847) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:15:05.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:15:05.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:15:05.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:15:05.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:15:05.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:15:05.317+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:15:05.353+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:15:05.352+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:15:05.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T22:15:35.547+0000] {processor.py:157} INFO - Started process (PID=4849) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:15:35.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:15:35.549+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:15:35.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:15:35.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:15:35.604+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:15:35.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:15:35.638+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:15:35.637+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:15:35.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T22:16:06.471+0000] {processor.py:157} INFO - Started process (PID=4851) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:16:06.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:16:06.473+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:16:06.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:16:06.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:16:06.664+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:16:06.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:16:06.691+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:16:06.691+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:16:06.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.243 seconds
[2024-10-24T22:16:36.859+0000] {processor.py:157} INFO - Started process (PID=4853) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:16:36.860+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:16:36.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:16:36.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:16:36.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:16:36.903+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:16:36.902+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:16:36.928+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:16:36.928+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:16:36.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.094 seconds
[2024-10-24T22:17:07.100+0000] {processor.py:157} INFO - Started process (PID=4855) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:17:07.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:17:07.102+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:17:07.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:17:07.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:17:07.148+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:17:07.147+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:17:07.178+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:17:07.178+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:17:07.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T22:17:37.348+0000] {processor.py:157} INFO - Started process (PID=4857) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:17:37.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:17:37.350+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:17:37.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:17:37.366+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:17:37.413+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:17:37.412+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:17:37.440+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:17:37.440+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:17:37.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T22:18:07.609+0000] {processor.py:157} INFO - Started process (PID=4859) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:18:07.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:18:07.611+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:18:07.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:18:07.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:18:07.659+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:18:07.659+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:18:07.685+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:18:07.685+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:18:07.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T22:18:37.750+0000] {processor.py:157} INFO - Started process (PID=4861) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:18:37.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:18:37.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:18:37.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:18:37.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:18:37.805+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:18:37.804+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:18:37.836+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:18:37.836+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:18:37.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T22:19:08.011+0000] {processor.py:157} INFO - Started process (PID=4863) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:19:08.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:19:08.014+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:19:08.014+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:19:08.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:19:08.064+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:19:08.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:19:08.091+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:19:08.090+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:19:08.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T22:19:38.265+0000] {processor.py:157} INFO - Started process (PID=4865) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:19:38.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:19:38.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:19:38.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:19:38.286+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:19:38.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:19:38.317+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:19:38.348+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:19:38.348+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:19:38.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:20:08.419+0000] {processor.py:157} INFO - Started process (PID=4867) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:20:08.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:20:08.420+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:20:08.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:20:08.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:20:08.470+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:20:08.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:20:08.498+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:20:08.497+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:20:08.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:20:38.635+0000] {processor.py:157} INFO - Started process (PID=4869) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:20:38.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:20:38.647+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:20:38.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:20:38.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:20:38.688+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:20:38.688+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:20:38.716+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:20:38.716+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:20:38.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T22:21:08.905+0000] {processor.py:157} INFO - Started process (PID=4871) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:21:08.905+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:21:08.906+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:21:08.906+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:21:08.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:21:08.955+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:21:08.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:21:08.982+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:21:08.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:21:09.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T22:21:39.042+0000] {processor.py:157} INFO - Started process (PID=4873) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:21:39.043+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:21:39.044+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:21:39.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:21:39.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:21:39.101+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:21:39.100+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:21:39.135+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:21:39.135+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:21:39.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T22:22:09.309+0000] {processor.py:157} INFO - Started process (PID=4875) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:22:09.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:22:09.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:22:09.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:22:09.328+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:22:09.358+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:22:09.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:22:09.382+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:22:09.381+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:22:09.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T22:22:39.461+0000] {processor.py:157} INFO - Started process (PID=4877) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:22:39.463+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:22:39.464+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:22:39.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:22:39.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:22:39.512+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:22:39.512+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:22:39.540+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:22:39.540+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:22:39.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T22:23:09.724+0000] {processor.py:157} INFO - Started process (PID=4879) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:23:09.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:23:09.726+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:23:09.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:23:09.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:23:09.834+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:23:09.834+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:23:09.914+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:23:09.914+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:23:09.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.255 seconds
[2024-10-24T22:23:40.148+0000] {processor.py:157} INFO - Started process (PID=4881) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:23:40.150+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:23:40.151+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:23:40.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:23:40.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:23:40.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:23:40.201+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:23:40.228+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:23:40.228+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:23:40.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T22:24:10.403+0000] {processor.py:157} INFO - Started process (PID=4883) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:24:10.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:24:10.406+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:24:10.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:24:10.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:24:10.453+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:24:10.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:24:10.480+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:24:10.480+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:24:10.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:24:40.557+0000] {processor.py:157} INFO - Started process (PID=4885) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:24:40.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:24:40.559+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:24:40.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:24:40.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:24:40.612+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:24:40.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:24:40.644+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:24:40.644+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:24:40.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T22:25:10.777+0000] {processor.py:157} INFO - Started process (PID=4887) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:25:10.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:25:10.778+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:25:10.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:25:10.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:25:10.830+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:25:10.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:25:10.858+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:25:10.857+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:25:10.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T22:25:40.927+0000] {processor.py:157} INFO - Started process (PID=4889) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:25:40.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:25:40.929+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:25:40.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:25:40.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:25:40.970+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:25:40.970+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:25:40.996+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:25:40.996+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:25:41.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.092 seconds
[2024-10-24T22:26:11.173+0000] {processor.py:157} INFO - Started process (PID=4891) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:26:11.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:26:11.174+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:26:11.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:26:11.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:26:11.280+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:26:11.280+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:26:11.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:26:11.305+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:26:11.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.157 seconds
[2024-10-24T22:26:41.445+0000] {processor.py:157} INFO - Started process (PID=4893) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:26:41.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:26:41.447+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:26:41.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:26:41.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:26:41.496+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:26:41.495+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:26:41.527+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:26:41.526+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:26:41.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T22:27:11.709+0000] {processor.py:157} INFO - Started process (PID=4895) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:27:11.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:27:11.712+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:27:11.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:27:11.729+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:27:11.773+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:27:11.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:27:11.807+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:27:11.807+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:27:11.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T22:27:41.993+0000] {processor.py:157} INFO - Started process (PID=4897) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:27:41.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:27:41.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:27:41.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:27:42.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:27:42.052+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:27:42.052+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:27:42.083+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:27:42.083+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:27:42.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T22:28:12.146+0000] {processor.py:157} INFO - Started process (PID=4899) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:28:12.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:28:12.148+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:28:12.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:28:12.161+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:28:12.197+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:28:12.197+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:28:12.225+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:28:12.224+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:28:12.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T22:28:42.421+0000] {processor.py:157} INFO - Started process (PID=4901) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:28:42.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:28:42.423+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:28:42.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:28:42.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:28:42.473+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:28:42.473+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:28:42.503+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:28:42.503+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:28:42.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:29:12.677+0000] {processor.py:157} INFO - Started process (PID=4903) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:29:12.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:29:12.678+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:29:12.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:29:12.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:29:12.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:29:12.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:29:12.757+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:29:12.756+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:29:12.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T22:29:42.826+0000] {processor.py:157} INFO - Started process (PID=4905) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:29:42.827+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:29:42.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:29:42.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:29:42.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:29:42.880+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:29:42.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:29:42.909+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:29:42.909+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:29:42.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T22:30:13.111+0000] {processor.py:157} INFO - Started process (PID=4907) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:30:13.114+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:30:13.116+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:30:13.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:30:13.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:30:13.172+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:30:13.171+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:30:13.201+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:30:13.201+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:30:13.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.125 seconds
[2024-10-24T22:30:43.375+0000] {processor.py:157} INFO - Started process (PID=4909) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:30:43.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:30:43.378+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:30:43.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:30:43.398+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:30:43.436+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:30:43.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:30:43.466+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:30:43.466+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:30:43.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T22:31:13.526+0000] {processor.py:157} INFO - Started process (PID=4911) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:31:13.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:31:13.538+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:31:13.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:31:13.554+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:31:13.585+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:31:13.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:31:13.612+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:31:13.612+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:31:13.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T22:31:43.791+0000] {processor.py:157} INFO - Started process (PID=4913) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:31:43.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:31:43.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:31:43.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:31:43.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:31:43.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:31:43.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:31:43.868+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:31:43.868+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:31:43.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T22:32:13.942+0000] {processor.py:157} INFO - Started process (PID=4915) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:32:13.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:32:13.954+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:32:13.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:32:13.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:32:13.999+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:32:13.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:32:14.027+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:32:14.026+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:32:14.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:32:44.222+0000] {processor.py:157} INFO - Started process (PID=4917) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:32:44.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:32:44.224+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:32:44.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:32:44.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:32:44.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:32:44.274+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:32:44.307+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:32:44.307+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:32:44.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T22:33:14.387+0000] {processor.py:157} INFO - Started process (PID=4919) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:33:14.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:33:14.392+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:33:14.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:33:14.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:33:14.446+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:33:14.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:33:14.475+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:33:14.475+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:33:14.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T22:33:44.665+0000] {processor.py:157} INFO - Started process (PID=4921) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:33:44.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:33:44.667+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:33:44.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:33:44.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:33:44.718+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:33:44.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:33:44.749+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:33:44.749+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:33:44.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:34:14.826+0000] {processor.py:157} INFO - Started process (PID=4923) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:34:14.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:34:14.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:34:14.829+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:34:14.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:34:14.886+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:34:14.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:34:14.916+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:34:14.916+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:34:14.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.121 seconds
[2024-10-24T22:34:45.038+0000] {processor.py:157} INFO - Started process (PID=4925) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:34:45.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:34:45.041+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:34:45.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:34:45.069+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:34:45.132+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:34:45.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:34:45.169+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:34:45.169+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:34:45.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.164 seconds
[2024-10-24T22:35:15.361+0000] {processor.py:157} INFO - Started process (PID=4927) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:35:15.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:35:15.367+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:35:15.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:35:15.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:35:15.416+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:35:15.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:35:15.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:35:15.444+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:35:15.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T22:35:45.640+0000] {processor.py:157} INFO - Started process (PID=4929) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:35:45.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:35:45.641+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:35:45.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:35:45.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:35:45.699+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:35:45.698+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:35:45.733+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:35:45.733+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:35:45.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.146 seconds
[2024-10-24T22:36:15.783+0000] {processor.py:157} INFO - Started process (PID=4931) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:36:15.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:36:15.785+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:36:15.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:36:15.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:36:15.839+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:36:15.839+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:36:15.880+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:36:15.879+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:36:15.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T22:36:46.054+0000] {processor.py:157} INFO - Started process (PID=4933) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:36:46.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:36:46.055+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:36:46.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:36:46.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:36:46.104+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:36:46.104+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:36:46.135+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:36:46.135+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:36:46.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:37:16.315+0000] {processor.py:157} INFO - Started process (PID=4935) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:37:16.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:37:16.317+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:37:16.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:37:16.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:37:16.368+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:37:16.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:37:16.399+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:37:16.399+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:37:16.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T22:37:46.465+0000] {processor.py:157} INFO - Started process (PID=4937) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:37:46.466+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:37:46.467+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:37:46.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:37:46.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:37:46.518+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:37:46.518+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:37:46.546+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:37:46.546+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:37:46.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:38:16.724+0000] {processor.py:157} INFO - Started process (PID=4939) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:38:16.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:38:16.727+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:38:16.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:38:16.742+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:38:16.773+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:38:16.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:38:16.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:38:16.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:38:16.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T22:38:46.876+0000] {processor.py:157} INFO - Started process (PID=4941) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:38:46.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:38:46.877+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:38:46.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:38:46.891+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:38:46.925+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:38:46.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:38:46.958+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:38:46.958+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:38:46.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T22:39:17.077+0000] {processor.py:157} INFO - Started process (PID=4943) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:39:17.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:39:17.080+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:39:17.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:39:17.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:39:17.128+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:39:17.128+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:39:17.157+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:39:17.157+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:39:17.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T22:39:47.331+0000] {processor.py:157} INFO - Started process (PID=4945) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:39:47.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:39:47.332+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:39:47.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:39:47.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:39:47.386+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:39:47.386+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:39:47.417+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:39:47.417+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:39:47.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T22:40:17.489+0000] {processor.py:157} INFO - Started process (PID=4947) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:40:17.490+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:40:17.491+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:40:17.491+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:40:17.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:40:17.533+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:40:17.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:40:17.562+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:40:17.562+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:40:17.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.095 seconds
[2024-10-24T22:40:47.732+0000] {processor.py:157} INFO - Started process (PID=4949) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:40:47.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:40:47.734+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:40:47.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:40:47.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:40:47.777+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:40:47.777+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:40:47.806+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:40:47.806+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:40:47.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.097 seconds
[2024-10-24T22:41:17.982+0000] {processor.py:157} INFO - Started process (PID=4951) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:41:17.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:41:17.983+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:41:17.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:41:18.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:41:18.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:41:18.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:41:18.062+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:41:18.062+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:41:18.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T22:41:48.235+0000] {processor.py:157} INFO - Started process (PID=4953) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:41:48.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:41:48.237+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:41:48.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:41:48.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:41:48.289+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:41:48.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:41:48.320+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:41:48.320+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:41:48.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T22:42:18.387+0000] {processor.py:157} INFO - Started process (PID=4955) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:42:18.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:42:18.390+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:42:18.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:42:18.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:42:18.454+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:42:18.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:42:18.490+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:42:18.490+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:42:18.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T22:42:48.612+0000] {processor.py:157} INFO - Started process (PID=4957) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:42:48.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:42:48.615+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:42:48.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:42:48.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:42:48.672+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:42:48.672+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:42:48.705+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:42:48.704+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:42:48.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T22:43:18.769+0000] {processor.py:157} INFO - Started process (PID=4959) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:43:18.780+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:43:18.781+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:43:18.781+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:43:18.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:43:18.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:43:18.828+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:43:18.858+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:43:18.857+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:43:18.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T22:43:48.992+0000] {processor.py:157} INFO - Started process (PID=4961) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:43:48.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:43:48.994+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:43:48.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:43:49.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:43:49.043+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:43:49.043+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:43:49.073+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:43:49.072+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:43:49.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T22:44:19.142+0000] {processor.py:157} INFO - Started process (PID=4963) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:44:19.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:44:19.144+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:44:19.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:44:19.159+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:44:19.189+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:44:19.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:44:19.219+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:44:19.219+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:44:19.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T22:44:49.393+0000] {processor.py:157} INFO - Started process (PID=4965) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:44:49.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:44:49.394+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:44:49.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:44:49.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:44:49.442+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:44:49.442+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:44:49.469+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:44:49.469+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:44:49.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T22:45:19.553+0000] {processor.py:157} INFO - Started process (PID=4967) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:45:19.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:45:19.555+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:45:19.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:45:19.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:45:19.610+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:45:19.610+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:45:19.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:45:19.642+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:45:19.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T22:45:49.741+0000] {processor.py:157} INFO - Started process (PID=4969) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:45:49.742+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:45:49.743+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:45:49.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:45:49.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:45:49.791+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:45:49.791+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:45:49.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:45:49.818+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:45:49.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T22:46:19.994+0000] {processor.py:157} INFO - Started process (PID=4971) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:46:19.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:46:19.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:46:19.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:46:20.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:46:20.052+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:46:20.052+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:46:20.079+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:46:20.079+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:46:20.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:46:50.249+0000] {processor.py:157} INFO - Started process (PID=4973) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:46:50.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:46:50.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:46:50.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:46:50.268+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:46:50.299+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:46:50.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:46:50.326+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:46:50.326+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:46:50.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T22:47:20.393+0000] {processor.py:157} INFO - Started process (PID=4975) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:47:20.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:47:20.402+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:47:20.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:47:20.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:47:20.447+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:47:20.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:47:20.478+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:47:20.478+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:47:20.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T22:47:50.652+0000] {processor.py:157} INFO - Started process (PID=4977) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:47:50.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:47:50.654+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:47:50.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:47:50.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:47:50.702+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:47:50.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:47:50.736+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:47:50.736+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:47:50.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:48:20.805+0000] {processor.py:157} INFO - Started process (PID=4979) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:48:20.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:48:20.808+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:48:20.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:48:20.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:48:20.857+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:48:20.857+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:48:20.888+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:48:20.887+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:48:20.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T22:48:51.067+0000] {processor.py:157} INFO - Started process (PID=4981) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:48:51.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:48:51.068+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:48:51.068+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:48:51.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:48:51.120+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:48:51.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:48:51.147+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:48:51.146+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:48:51.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:49:21.326+0000] {processor.py:157} INFO - Started process (PID=4983) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:49:21.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:49:21.328+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:49:21.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:49:21.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:49:21.377+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:49:21.377+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:49:21.404+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:49:21.403+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:49:21.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:49:51.577+0000] {processor.py:157} INFO - Started process (PID=4985) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:49:51.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:49:51.578+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:49:51.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:49:51.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:49:51.628+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:49:51.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:49:51.658+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:49:51.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:49:51.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:50:21.879+0000] {processor.py:157} INFO - Started process (PID=4987) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:50:21.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:50:21.881+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:50:21.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:50:21.896+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:50:21.927+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:50:21.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:50:21.954+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:50:21.954+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:50:21.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T22:50:52.049+0000] {processor.py:157} INFO - Started process (PID=4989) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:50:52.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:50:52.051+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:50:52.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:50:52.065+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:50:52.115+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:50:52.115+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:50:52.147+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:50:52.146+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:50:52.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.147 seconds
[2024-10-24T22:51:22.321+0000] {processor.py:157} INFO - Started process (PID=4991) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:51:22.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:51:22.323+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:51:22.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:51:22.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:51:22.372+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:51:22.372+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:51:22.402+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:51:22.402+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:51:22.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T22:51:52.471+0000] {processor.py:157} INFO - Started process (PID=4993) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:51:52.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:51:52.473+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:51:52.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:51:52.494+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:51:52.539+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:51:52.539+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:51:52.579+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:51:52.578+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:51:52.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.133 seconds
[2024-10-24T22:52:22.758+0000] {processor.py:157} INFO - Started process (PID=4995) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:52:22.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:52:22.760+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:52:22.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:52:22.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:52:22.812+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:52:22.812+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:52:22.853+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:52:22.853+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:52:22.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.126 seconds
[2024-10-24T22:52:53.037+0000] {processor.py:157} INFO - Started process (PID=4997) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:52:53.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:52:53.038+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:52:53.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:52:53.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:52:53.097+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:52:53.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:52:53.127+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:52:53.127+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:52:53.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T22:53:23.308+0000] {processor.py:157} INFO - Started process (PID=4999) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:53:23.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:53:23.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:53:23.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:53:23.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:53:23.360+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:53:23.360+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:53:23.393+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:53:23.393+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:53:23.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T22:53:53.571+0000] {processor.py:157} INFO - Started process (PID=5001) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:53:53.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:53:53.572+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:53:53.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:53:53.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:53:53.626+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:53:53.626+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:53:53.659+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:53:53.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:53:53.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T22:54:23.835+0000] {processor.py:157} INFO - Started process (PID=5003) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:54:23.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:54:23.837+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:54:23.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:54:23.855+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:54:23.891+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:54:23.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:54:23.921+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:54:23.921+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:54:23.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T22:54:54.101+0000] {processor.py:157} INFO - Started process (PID=5005) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:54:54.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:54:54.102+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:54:54.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:54:54.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:54:54.155+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:54:54.155+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:54:54.188+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:54:54.188+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:54:54.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.111 seconds
[2024-10-24T22:55:24.375+0000] {processor.py:157} INFO - Started process (PID=5007) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:55:24.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:55:24.377+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:55:24.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:55:24.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:55:24.429+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:55:24.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:55:24.454+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:55:24.454+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:55:24.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:55:54.635+0000] {processor.py:157} INFO - Started process (PID=5009) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:55:54.636+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:55:54.637+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:55:54.637+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:55:54.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:55:54.688+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:55:54.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:55:54.720+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:55:54.720+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:55:54.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T22:56:24.786+0000] {processor.py:157} INFO - Started process (PID=5011) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:56:24.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:56:24.788+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:56:24.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:56:24.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:56:24.845+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:56:24.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:56:24.872+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:56:24.872+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:56:24.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T22:56:55.048+0000] {processor.py:157} INFO - Started process (PID=5013) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:56:55.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:56:55.049+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:56:55.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:56:55.071+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:56:55.101+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:56:55.101+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:56:55.132+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:56:55.132+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:56:55.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T22:57:25.195+0000] {processor.py:157} INFO - Started process (PID=5015) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:57:25.196+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:57:25.197+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:57:25.197+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:57:25.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:57:25.248+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:57:25.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:57:25.274+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:57:25.274+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:57:25.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:57:55.449+0000] {processor.py:157} INFO - Started process (PID=5017) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:57:55.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:57:55.450+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:57:55.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:57:55.469+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:57:55.506+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:57:55.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:57:55.533+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:57:55.533+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:57:55.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T22:58:25.604+0000] {processor.py:157} INFO - Started process (PID=5019) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:58:25.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:58:25.606+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:58:25.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:58:25.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:58:25.649+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:58:25.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:58:25.679+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:58:25.679+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:58:25.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:58:55.855+0000] {processor.py:157} INFO - Started process (PID=5021) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:58:55.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:58:55.857+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:58:55.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:58:55.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:58:55.910+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:58:55.910+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:58:55.943+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:58:55.942+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:58:55.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T22:59:26.117+0000] {processor.py:157} INFO - Started process (PID=5023) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:59:26.118+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:59:26.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:59:26.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:59:26.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:59:26.165+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:59:26.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:59:26.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:59:26.192+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:59:26.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T22:59:56.368+0000] {processor.py:157} INFO - Started process (PID=5025) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:59:56.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T22:59:56.369+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:59:56.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:59:56.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T22:59:56.433+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:59:56.433+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T22:59:56.466+0000] {logging_mixin.py:149} INFO - [2024-10-24T22:59:56.466+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T22:59:56.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T23:00:26.531+0000] {processor.py:157} INFO - Started process (PID=5027) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:00:26.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:00:26.533+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:00:26.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:00:26.549+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:00:26.587+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:00:26.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:00:26.619+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:00:26.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:00:26.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T23:00:56.799+0000] {processor.py:157} INFO - Started process (PID=5029) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:00:56.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:00:56.800+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:00:56.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:00:56.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:00:56.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:00:56.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:00:56.892+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:00:56.892+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:00:56.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T23:01:27.069+0000] {processor.py:157} INFO - Started process (PID=5031) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:01:27.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:01:27.071+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:01:27.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:01:27.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:01:27.116+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:01:27.116+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:01:27.147+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:01:27.147+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:01:27.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T23:01:57.317+0000] {processor.py:157} INFO - Started process (PID=5033) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:01:57.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:01:57.319+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:01:57.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:01:57.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:01:57.377+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:01:57.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:01:57.409+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:01:57.409+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:01:57.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T23:02:27.466+0000] {processor.py:157} INFO - Started process (PID=5035) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:02:27.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:02:27.475+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:02:27.474+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:02:27.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:02:27.522+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:02:27.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:02:27.551+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:02:27.551+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:02:27.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T23:02:57.731+0000] {processor.py:157} INFO - Started process (PID=5037) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:02:57.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:02:57.739+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:02:57.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:02:57.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:02:57.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:02:57.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:02:57.829+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:02:57.829+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:02:57.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.124 seconds
[2024-10-24T23:03:27.892+0000] {processor.py:157} INFO - Started process (PID=5039) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:03:27.895+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:03:27.896+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:03:27.896+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:03:27.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:03:27.947+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:03:27.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:03:27.975+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:03:27.975+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:03:27.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T23:03:58.100+0000] {processor.py:157} INFO - Started process (PID=5041) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:03:58.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:03:58.101+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:03:58.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:03:58.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:03:58.163+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:03:58.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:03:58.194+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:03:58.194+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:03:58.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.119 seconds
[2024-10-24T23:04:28.256+0000] {processor.py:157} INFO - Started process (PID=5043) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:04:28.257+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:04:28.258+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:04:28.257+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:04:28.273+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:04:28.305+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:04:28.305+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:04:28.334+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:04:28.334+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:04:28.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T23:04:58.505+0000] {processor.py:157} INFO - Started process (PID=5045) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:04:58.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:04:58.507+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:04:58.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:04:58.523+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:04:58.558+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:04:58.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:04:58.587+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:04:58.586+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:04:58.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:05:28.782+0000] {processor.py:157} INFO - Started process (PID=5047) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:05:28.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:05:28.785+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:05:28.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:05:28.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:05:28.840+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:05:28.840+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:05:28.881+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:05:28.881+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:05:28.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.147 seconds
[2024-10-24T23:05:59.056+0000] {processor.py:157} INFO - Started process (PID=5049) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:05:59.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:05:59.058+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:05:59.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:05:59.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:05:59.110+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:05:59.109+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:05:59.141+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:05:59.141+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:05:59.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T23:06:29.203+0000] {processor.py:157} INFO - Started process (PID=5051) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:06:29.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:06:29.216+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:06:29.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:06:29.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:06:29.261+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:06:29.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:06:29.294+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:06:29.294+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:06:29.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T23:06:59.415+0000] {processor.py:157} INFO - Started process (PID=5053) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:06:59.416+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:06:59.417+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:06:59.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:06:59.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:06:59.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:06:59.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:06:59.485+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:06:59.485+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:06:59.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T23:07:29.659+0000] {processor.py:157} INFO - Started process (PID=5055) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:07:29.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:07:29.661+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:07:29.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:07:29.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:07:29.711+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:07:29.711+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:07:29.738+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:07:29.737+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:07:29.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T23:07:59.905+0000] {processor.py:157} INFO - Started process (PID=5057) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:07:59.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:07:59.907+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:07:59.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:07:59.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:07:59.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:07:59.959+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:07:59.987+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:07:59.987+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:08:00.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T23:08:30.165+0000] {processor.py:157} INFO - Started process (PID=5059) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:08:30.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:08:30.167+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:08:30.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:08:30.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:08:30.215+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:08:30.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:08:30.240+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:08:30.239+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:08:30.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T23:09:00.310+0000] {processor.py:157} INFO - Started process (PID=5061) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:09:00.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:09:00.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:09:00.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:09:00.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:09:00.361+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:09:00.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:09:00.389+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:09:00.389+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:09:00.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T23:09:30.565+0000] {processor.py:157} INFO - Started process (PID=5063) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:09:30.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:09:30.567+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:09:30.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:09:30.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:09:30.624+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:09:30.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:09:30.652+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:09:30.652+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:09:30.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T23:10:00.718+0000] {processor.py:157} INFO - Started process (PID=5065) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:10:00.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:10:00.720+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:10:00.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:10:00.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:10:00.768+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:10:00.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:10:00.804+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:10:00.804+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:10:00.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T23:10:30.990+0000] {processor.py:157} INFO - Started process (PID=5067) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:10:30.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:10:30.992+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:10:30.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:10:31.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:10:31.037+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:10:31.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:10:31.067+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:10:31.067+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:10:31.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T23:11:01.234+0000] {processor.py:157} INFO - Started process (PID=5069) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:11:01.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:11:01.235+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:11:01.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:11:01.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:11:01.284+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:11:01.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:11:01.314+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:11:01.314+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:11:01.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T23:11:31.495+0000] {processor.py:157} INFO - Started process (PID=5071) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:11:31.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:11:31.497+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:11:31.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:11:31.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:11:31.545+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:11:31.545+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:11:31.575+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:11:31.575+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:11:31.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T23:12:01.743+0000] {processor.py:157} INFO - Started process (PID=5073) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:12:01.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:12:01.745+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:12:01.745+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:12:01.761+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:12:01.792+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:12:01.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:12:01.818+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:12:01.818+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:12:01.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T23:12:31.995+0000] {processor.py:157} INFO - Started process (PID=5075) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:12:31.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:12:31.997+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:12:31.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:12:32.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:12:32.049+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:12:32.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:12:32.075+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:12:32.075+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:12:32.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T23:13:02.141+0000] {processor.py:157} INFO - Started process (PID=5077) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:13:02.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:13:02.142+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:13:02.142+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:13:02.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:13:02.189+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:13:02.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:13:02.222+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:13:02.222+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:13:02.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:13:32.397+0000] {processor.py:157} INFO - Started process (PID=5079) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:13:32.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:13:32.399+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:13:32.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:13:32.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:13:32.448+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:13:32.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:13:32.476+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:13:32.475+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:13:32.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:14:02.659+0000] {processor.py:157} INFO - Started process (PID=5081) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:14:02.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:14:02.661+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:14:02.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:14:02.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:14:02.712+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:14:02.712+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:14:02.742+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:14:02.741+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:14:02.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T23:14:32.912+0000] {processor.py:157} INFO - Started process (PID=5083) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:14:32.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:14:32.915+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:14:32.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:14:32.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:14:32.962+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:14:32.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:14:32.992+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:14:32.992+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:14:33.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:15:03.165+0000] {processor.py:157} INFO - Started process (PID=5085) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:15:03.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:15:03.166+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:15:03.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:15:03.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:15:03.208+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:15:03.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:15:03.232+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:15:03.232+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:15:03.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.091 seconds
[2024-10-24T23:15:33.419+0000] {processor.py:157} INFO - Started process (PID=5087) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:15:33.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:15:33.421+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:15:33.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:15:33.441+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:15:33.474+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:15:33.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:15:33.503+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:15:33.502+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:15:33.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T23:16:03.575+0000] {processor.py:157} INFO - Started process (PID=5089) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:16:03.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:16:03.577+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:16:03.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:16:03.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:16:03.625+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:16:03.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:16:03.655+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:16:03.654+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:16:03.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:16:33.790+0000] {processor.py:157} INFO - Started process (PID=5091) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:16:33.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:16:33.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:16:33.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:16:33.817+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:16:33.854+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:16:33.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:16:33.898+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:16:33.897+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:16:33.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.143 seconds
[2024-10-24T23:17:04.100+0000] {processor.py:157} INFO - Started process (PID=5093) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:17:04.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:17:04.102+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:17:04.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:17:04.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:17:04.153+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:17:04.153+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:17:04.184+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:17:04.184+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:17:04.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T23:17:34.360+0000] {processor.py:157} INFO - Started process (PID=5095) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:17:34.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:17:34.362+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:17:34.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:17:34.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:17:34.408+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:17:34.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:17:34.435+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:17:34.434+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:17:34.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T23:18:04.518+0000] {processor.py:157} INFO - Started process (PID=5097) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:18:04.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:18:04.520+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:18:04.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:18:04.544+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:18:04.578+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:18:04.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:18:04.610+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:18:04.609+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:18:04.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T23:18:34.792+0000] {processor.py:157} INFO - Started process (PID=5099) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:18:34.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:18:34.793+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:18:34.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:18:34.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:18:34.837+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:18:34.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:18:34.869+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:18:34.869+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:18:34.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T23:19:05.043+0000] {processor.py:157} INFO - Started process (PID=5101) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:19:05.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:19:05.046+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:19:05.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:19:05.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:19:05.102+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:19:05.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:19:05.139+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:19:05.139+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:19:05.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.123 seconds
[2024-10-24T23:19:35.322+0000] {processor.py:157} INFO - Started process (PID=5103) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:19:35.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:19:35.324+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:19:35.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:19:35.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:19:35.370+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:19:35.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:19:35.396+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:19:35.396+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:19:35.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T23:20:05.483+0000] {processor.py:157} INFO - Started process (PID=5105) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:20:05.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:20:05.485+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:20:05.485+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:20:05.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:20:05.535+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:20:05.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:20:05.563+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:20:05.563+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:20:05.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T23:20:35.681+0000] {processor.py:157} INFO - Started process (PID=5107) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:20:35.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:20:35.683+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:20:35.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:20:35.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:20:35.725+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:20:35.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:20:35.755+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:20:35.755+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:20:35.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T23:21:05.926+0000] {processor.py:157} INFO - Started process (PID=5109) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:21:05.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:21:05.929+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:21:05.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:21:05.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:21:05.979+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:21:05.979+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:21:06.009+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:21:06.009+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:21:06.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:21:36.192+0000] {processor.py:157} INFO - Started process (PID=5111) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:21:36.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:21:36.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:21:36.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:21:36.215+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:21:36.256+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:21:36.256+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:21:36.301+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:21:36.301+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:21:36.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.154 seconds
[2024-10-24T23:22:06.491+0000] {processor.py:157} INFO - Started process (PID=5114) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:22:06.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:22:06.493+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:22:06.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:22:06.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:22:06.536+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:22:06.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:22:06.563+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:22:06.563+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:22:06.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.096 seconds
[2024-10-24T23:22:36.645+0000] {processor.py:157} INFO - Started process (PID=5115) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:22:36.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:22:36.646+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:22:36.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:22:36.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:22:36.696+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:22:36.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:22:36.729+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:22:36.729+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:22:36.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T23:23:07.067+0000] {processor.py:157} INFO - Started process (PID=5117) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:23:07.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:23:07.173+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:23:07.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:23:07.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:23:07.271+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:23:07.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:23:07.297+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:23:07.296+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:23:07.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.252 seconds
[2024-10-24T23:23:37.442+0000] {processor.py:157} INFO - Started process (PID=5119) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:23:37.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:23:37.444+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:23:37.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:23:37.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:23:37.495+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:23:37.494+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:23:37.525+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:23:37.525+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:23:37.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T23:24:07.699+0000] {processor.py:157} INFO - Started process (PID=5121) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:24:07.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:24:07.701+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:24:07.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:24:07.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:24:07.761+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:24:07.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:24:07.797+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:24:07.795+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:24:07.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.144 seconds
[2024-10-24T23:24:37.965+0000] {processor.py:157} INFO - Started process (PID=5123) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:24:37.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:24:37.967+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:24:37.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:24:37.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:24:38.013+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:24:38.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:24:38.042+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:24:38.042+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:24:38.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T23:25:08.225+0000] {processor.py:157} INFO - Started process (PID=5125) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:25:08.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:25:08.227+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:25:08.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:25:08.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:25:08.270+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:25:08.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:25:08.298+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:25:08.298+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:25:08.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T23:25:38.393+0000] {processor.py:157} INFO - Started process (PID=5127) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:25:38.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:25:38.398+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:25:38.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:25:38.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:25:38.461+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:25:38.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:25:38.500+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:25:38.500+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:25:38.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-24T23:26:08.699+0000] {processor.py:157} INFO - Started process (PID=5129) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:26:08.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:26:08.702+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:26:08.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:26:08.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:26:08.775+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:26:08.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:26:08.814+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:26:08.814+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:26:08.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-24T23:26:38.957+0000] {processor.py:157} INFO - Started process (PID=5131) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:26:38.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:26:38.959+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:26:38.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:26:38.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:26:39.005+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:26:39.005+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:26:39.030+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:26:39.030+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:26:39.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T23:27:09.100+0000] {processor.py:157} INFO - Started process (PID=5133) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:27:09.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:27:09.101+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:27:09.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:27:09.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:27:09.152+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:27:09.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:27:09.190+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:27:09.190+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:27:09.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T23:27:39.377+0000] {processor.py:157} INFO - Started process (PID=5135) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:27:39.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:27:39.379+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:27:39.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:27:39.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:27:39.428+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:27:39.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:27:39.467+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:27:39.465+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:27:39.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.132 seconds
[2024-10-24T23:28:09.527+0000] {processor.py:157} INFO - Started process (PID=5137) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:28:09.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:28:09.529+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:28:09.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:28:09.546+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:28:09.579+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:28:09.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:28:09.622+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:28:09.621+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:28:09.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-24T23:28:39.768+0000] {processor.py:157} INFO - Started process (PID=5139) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:28:39.770+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:28:39.771+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:28:39.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:28:39.794+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:28:39.825+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:28:39.825+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:28:39.852+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:28:39.852+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:28:39.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T23:29:10.020+0000] {processor.py:157} INFO - Started process (PID=5141) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:29:10.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:29:10.021+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:29:10.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:29:10.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:29:10.072+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:29:10.072+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:29:10.102+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:29:10.102+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:29:10.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T23:29:40.172+0000] {processor.py:157} INFO - Started process (PID=5143) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:29:40.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:29:40.174+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:29:40.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:29:40.188+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:29:40.221+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:29:40.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:29:40.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:29:40.251+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:29:40.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:30:10.386+0000] {processor.py:157} INFO - Started process (PID=5145) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:30:10.387+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:30:10.388+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:30:10.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:30:10.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:30:10.439+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:30:10.438+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:30:10.470+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:30:10.470+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:30:10.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T23:30:40.672+0000] {processor.py:157} INFO - Started process (PID=5147) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:30:40.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:30:40.674+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:30:40.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:30:40.690+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:30:40.723+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:30:40.723+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:30:40.754+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:30:40.754+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:30:40.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
[2024-10-24T23:31:10.953+0000] {processor.py:157} INFO - Started process (PID=5149) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:31:10.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:31:10.957+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:31:10.957+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:31:10.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:31:11.003+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:31:11.002+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:31:11.032+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:31:11.032+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:31:11.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.117 seconds
[2024-10-24T23:31:41.199+0000] {processor.py:157} INFO - Started process (PID=5151) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:31:41.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:31:41.202+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:31:41.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:31:41.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:31:41.251+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:31:41.251+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:31:41.281+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:31:41.281+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:31:41.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.104 seconds
[2024-10-24T23:32:11.458+0000] {processor.py:157} INFO - Started process (PID=5153) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:32:11.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:32:11.462+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:32:11.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:32:11.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:32:11.512+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:32:11.512+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:32:11.548+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:32:11.548+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:32:11.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.115 seconds
[2024-10-24T23:32:41.737+0000] {processor.py:157} INFO - Started process (PID=5155) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:32:41.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:32:41.750+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:32:41.750+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:32:41.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:32:41.798+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:32:41.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:32:41.828+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:32:41.828+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:32:41.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T23:33:11.883+0000] {processor.py:157} INFO - Started process (PID=5157) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:33:11.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:33:11.885+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:33:11.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:33:11.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:33:11.933+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:33:11.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:33:11.961+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:33:11.961+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:33:11.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:33:42.191+0000] {processor.py:157} INFO - Started process (PID=5159) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:33:42.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:33:42.193+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:33:42.192+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:33:42.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:33:42.242+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:33:42.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:33:42.275+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:33:42.274+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:33:42.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:34:12.340+0000] {processor.py:157} INFO - Started process (PID=5161) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:34:12.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:34:12.341+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:34:12.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:34:12.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:34:12.388+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:34:12.387+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:34:12.417+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:34:12.417+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:34:12.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T23:34:42.596+0000] {processor.py:157} INFO - Started process (PID=5163) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:34:42.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:34:42.598+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:34:42.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:34:42.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:34:42.653+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:34:42.653+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:34:42.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:34:42.688+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:34:42.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.118 seconds
[2024-10-24T23:35:12.740+0000] {processor.py:157} INFO - Started process (PID=5165) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:35:12.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:35:12.742+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:35:12.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:35:12.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:35:12.794+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:35:12.794+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:35:12.835+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:35:12.835+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:35:12.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.138 seconds
[2024-10-24T23:35:43.058+0000] {processor.py:157} INFO - Started process (PID=5167) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:35:43.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:35:43.070+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:35:43.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:35:43.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:35:43.119+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:35:43.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:35:43.158+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:35:43.157+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:35:43.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.128 seconds
[2024-10-24T23:36:13.210+0000] {processor.py:157} INFO - Started process (PID=5169) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:36:13.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:36:13.212+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:36:13.212+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:36:13.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:36:13.267+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:36:13.267+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:36:13.301+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:36:13.301+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:36:13.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.120 seconds
[2024-10-24T23:36:43.486+0000] {processor.py:157} INFO - Started process (PID=5171) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:36:43.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:36:43.499+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:36:43.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:36:43.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:36:43.542+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:36:43.542+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:36:43.567+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:36:43.567+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:36:43.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:37:13.640+0000] {processor.py:157} INFO - Started process (PID=5173) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:37:13.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:37:13.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:37:13.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:37:13.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:37:13.712+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:37:13.711+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:37:13.751+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:37:13.751+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:37:13.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-24T23:37:43.981+0000] {processor.py:157} INFO - Started process (PID=5175) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:37:43.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:37:43.993+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:37:43.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:37:44.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:37:44.150+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:37:44.150+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:37:44.196+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:37:44.195+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:37:44.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.268 seconds
[2024-10-24T23:38:14.345+0000] {processor.py:157} INFO - Started process (PID=5177) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:38:14.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:38:14.347+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:38:14.347+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:38:14.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:38:14.405+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:38:14.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:38:14.468+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:38:14.468+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:38:14.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.148 seconds
[2024-10-24T23:38:44.639+0000] {processor.py:157} INFO - Started process (PID=5179) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:38:44.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:38:44.642+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:38:44.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:38:44.660+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:38:44.689+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:38:44.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:38:44.714+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:38:44.714+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:38:44.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T23:39:14.902+0000] {processor.py:157} INFO - Started process (PID=5181) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:39:14.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:39:14.904+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:39:14.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:39:14.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:39:14.980+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:39:14.980+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:39:15.007+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:39:15.007+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:39:15.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.130 seconds
[2024-10-24T23:39:45.172+0000] {processor.py:157} INFO - Started process (PID=5183) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:39:45.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:39:45.174+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:39:45.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:39:45.190+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:39:45.223+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:39:45.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:39:45.254+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:39:45.254+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:39:45.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T23:40:15.457+0000] {processor.py:157} INFO - Started process (PID=5185) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:40:15.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:40:15.459+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:40:15.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:40:15.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:40:15.524+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:40:15.524+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:40:15.561+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:40:15.561+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:40:15.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.135 seconds
[2024-10-24T23:40:45.614+0000] {processor.py:157} INFO - Started process (PID=5187) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:40:45.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:40:45.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:40:45.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:40:45.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:40:45.672+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:40:45.672+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:40:45.705+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:40:45.705+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:40:45.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.127 seconds
[2024-10-24T23:41:15.898+0000] {processor.py:157} INFO - Started process (PID=5189) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:41:15.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:41:15.900+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:41:15.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:41:15.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:41:15.952+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:41:15.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:41:15.980+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:41:15.980+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:41:16.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.107 seconds
[2024-10-24T23:41:46.158+0000] {processor.py:157} INFO - Started process (PID=5191) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:41:46.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:41:46.160+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:41:46.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:41:46.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:41:46.212+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:41:46.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:41:46.241+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:41:46.241+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:41:46.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:42:16.409+0000] {processor.py:157} INFO - Started process (PID=5193) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:42:16.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:42:16.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:42:16.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:42:16.424+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:42:16.457+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:42:16.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:42:16.484+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:42:16.484+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:42:16.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T23:42:46.560+0000] {processor.py:157} INFO - Started process (PID=5195) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:42:46.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:42:46.561+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:42:46.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:42:46.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:42:46.622+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:42:46.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:42:46.655+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:42:46.655+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:42:46.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.122 seconds
[2024-10-24T23:43:16.828+0000] {processor.py:157} INFO - Started process (PID=5197) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:43:16.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:43:16.830+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:43:16.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:43:16.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:43:16.875+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:43:16.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:43:16.904+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:43:16.904+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:43:16.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T23:43:47.084+0000] {processor.py:157} INFO - Started process (PID=5199) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:43:47.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:43:47.086+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:43:47.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:43:47.107+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:43:47.143+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:43:47.143+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:43:47.176+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:43:47.176+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:43:47.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T23:44:17.351+0000] {processor.py:157} INFO - Started process (PID=5201) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:44:17.352+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:44:17.353+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:44:17.353+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:44:17.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:44:17.405+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:44:17.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:44:17.433+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:44:17.432+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:44:17.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:44:47.612+0000] {processor.py:157} INFO - Started process (PID=5203) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:44:47.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:44:47.613+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:44:47.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:44:47.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:44:47.668+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:44:47.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:44:47.699+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:44:47.698+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:44:47.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T23:45:17.783+0000] {processor.py:157} INFO - Started process (PID=5205) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:45:17.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:45:17.785+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:45:17.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:45:17.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:45:17.833+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:45:17.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:45:17.861+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:45:17.860+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:45:17.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:45:48.037+0000] {processor.py:157} INFO - Started process (PID=5207) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:45:48.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:45:48.047+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:45:48.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:45:48.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:45:48.094+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:45:48.094+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:45:48.127+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:45:48.126+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:45:48.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T23:46:18.187+0000] {processor.py:157} INFO - Started process (PID=5209) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:46:18.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:46:18.189+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:46:18.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:46:18.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:46:18.239+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:46:18.239+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:46:18.273+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:46:18.273+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:46:18.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T23:46:48.448+0000] {processor.py:157} INFO - Started process (PID=5211) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:46:48.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:46:48.450+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:46:48.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:46:48.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:46:48.499+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:46:48.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:46:48.526+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:46:48.526+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:46:48.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T23:47:18.698+0000] {processor.py:157} INFO - Started process (PID=5213) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:47:18.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:47:18.701+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:47:18.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:47:18.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:47:18.752+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:47:18.751+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:47:18.786+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:47:18.786+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:47:18.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.110 seconds
[2024-10-24T23:47:48.844+0000] {processor.py:157} INFO - Started process (PID=5215) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:47:48.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:47:48.848+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:47:48.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:47:48.863+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:47:48.896+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:47:48.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:47:48.923+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:47:48.923+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:47:48.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T23:48:19.055+0000] {processor.py:157} INFO - Started process (PID=5217) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:48:19.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:48:19.056+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:48:19.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:48:19.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:48:19.106+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:48:19.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:48:19.134+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:48:19.134+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:48:19.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T23:48:49.309+0000] {processor.py:157} INFO - Started process (PID=5219) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:48:49.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:48:49.311+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:48:49.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:48:49.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:48:49.357+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:48:49.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:48:49.383+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:48:49.382+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:48:49.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.098 seconds
[2024-10-24T23:49:19.557+0000] {processor.py:157} INFO - Started process (PID=5221) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:49:19.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:49:19.559+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:49:19.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:49:19.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:49:19.610+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:49:19.610+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:49:19.640+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:49:19.640+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:49:19.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:49:49.811+0000] {processor.py:157} INFO - Started process (PID=5223) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:49:49.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:49:49.813+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:49:49.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:49:49.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:49:49.862+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:49:49.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:49:49.889+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:49:49.888+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:49:49.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T23:50:20.077+0000] {processor.py:157} INFO - Started process (PID=5225) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:50:20.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:50:20.079+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:50:20.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:50:20.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:50:20.126+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:50:20.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:50:20.153+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:50:20.152+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:50:20.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.100 seconds
[2024-10-24T23:50:50.324+0000] {processor.py:157} INFO - Started process (PID=5227) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:50:50.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:50:50.326+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:50:50.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:50:50.342+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:50:50.378+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:50:50.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:50:50.406+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:50:50.406+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:50:50.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.108 seconds
[2024-10-24T23:51:20.581+0000] {processor.py:157} INFO - Started process (PID=5229) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:51:20.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:51:20.583+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:51:20.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:51:20.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:51:20.628+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:51:20.628+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:51:20.658+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:51:20.658+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:51:20.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.102 seconds
[2024-10-24T23:51:50.831+0000] {processor.py:157} INFO - Started process (PID=5231) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:51:50.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:51:50.833+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:51:50.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:51:50.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:51:50.879+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:51:50.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:51:50.910+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:51:50.910+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:51:50.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T23:52:21.082+0000] {processor.py:157} INFO - Started process (PID=5233) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:52:21.083+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:52:21.083+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:52:21.083+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:52:21.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:52:21.131+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:52:21.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:52:21.157+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:52:21.157+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:52:21.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T23:52:51.391+0000] {processor.py:157} INFO - Started process (PID=5235) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:52:51.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:52:51.393+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:52:51.393+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:52:51.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:52:51.440+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:52:51.440+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:52:51.470+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:52:51.470+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:52:51.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.149 seconds
[2024-10-24T23:53:21.538+0000] {processor.py:157} INFO - Started process (PID=5237) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:53:21.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:53:21.539+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:53:21.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:53:21.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:53:21.591+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:53:21.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:53:21.619+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:53:21.619+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:53:21.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:53:51.793+0000] {processor.py:157} INFO - Started process (PID=5239) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:53:51.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:53:51.795+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:53:51.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:53:51.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:53:51.845+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:53:51.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:53:51.878+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:53:51.877+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:53:51.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.109 seconds
[2024-10-24T23:54:21.943+0000] {processor.py:157} INFO - Started process (PID=5241) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:54:21.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:54:21.945+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:54:21.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:54:21.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:54:21.990+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:54:21.990+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:54:22.017+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:54:22.017+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:54:22.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.105 seconds
[2024-10-24T23:54:52.189+0000] {processor.py:157} INFO - Started process (PID=5243) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:54:52.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:54:52.192+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:54:52.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:54:52.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:54:52.238+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:54:52.238+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:54:52.270+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:54:52.270+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:54:52.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.106 seconds
[2024-10-24T23:55:22.454+0000] {processor.py:157} INFO - Started process (PID=5245) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:55:22.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:55:22.456+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:55:22.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:55:22.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:55:22.505+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:55:22.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:55:22.529+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:55:22.529+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:55:22.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T23:55:52.603+0000] {processor.py:157} INFO - Started process (PID=5247) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:55:52.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:55:52.616+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:55:52.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:55:52.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:55:52.664+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:55:52.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:55:52.691+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:55:52.690+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:55:52.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.112 seconds
[2024-10-24T23:56:22.812+0000] {processor.py:157} INFO - Started process (PID=5249) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:56:22.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:56:22.813+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:56:22.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:56:22.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:56:22.862+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:56:22.861+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:56:22.889+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:56:22.889+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:56:22.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.101 seconds
[2024-10-24T23:56:52.966+0000] {processor.py:157} INFO - Started process (PID=5251) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:56:52.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:56:52.968+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:56:52.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:56:52.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:56:53.020+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:56:53.020+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:56:53.057+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:56:53.056+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:56:53.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.116 seconds
[2024-10-24T23:57:23.164+0000] {processor.py:157} INFO - Started process (PID=5253) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:57:23.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:57:23.165+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:57:23.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:57:23.179+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:57:23.213+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:57:23.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:57:23.239+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:57:23.239+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:57:23.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.099 seconds
[2024-10-24T23:57:53.422+0000] {processor.py:157} INFO - Started process (PID=5255) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:57:53.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:57:53.431+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:57:53.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:57:53.450+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:57:53.486+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:57:53.486+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:57:53.528+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:57:53.527+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:57:53.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.136 seconds
[2024-10-24T23:58:23.713+0000] {processor.py:157} INFO - Started process (PID=5257) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:58:23.713+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:58:23.714+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:58:23.714+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:58:23.731+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:58:23.767+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:58:23.766+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:58:23.802+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:58:23.801+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:58:23.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.114 seconds
[2024-10-24T23:58:53.876+0000] {processor.py:157} INFO - Started process (PID=5259) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:58:53.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:58:53.883+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:58:53.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:58:53.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:58:53.941+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:58:53.941+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:58:53.982+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:58:53.982+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:58:54.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.140 seconds
[2024-10-24T23:59:24.165+0000] {processor.py:157} INFO - Started process (PID=5261) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:59:24.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:59:24.167+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:59:24.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:59:24.182+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:59:24.217+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:59:24.217+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:59:24.244+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:59:24.243+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:59:24.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.103 seconds
[2024-10-24T23:59:54.320+0000] {processor.py:157} INFO - Started process (PID=5263) to work on /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:59:54.321+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/hadoop_spark_dag.py for tasks to queue
[2024-10-24T23:59:54.322+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:59:54.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:59:54.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['hadoop_spark_pipeline']) retrieved from /opt/airflow/dags/hadoop_spark_dag.py
[2024-10-24T23:59:54.372+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:59:54.372+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2024-10-24T23:59:54.410+0000] {logging_mixin.py:149} INFO - [2024-10-24T23:59:54.410+0000] {dag.py:3490} INFO - Setting next_dagrun for hadoop_spark_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
[2024-10-24T23:59:54.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/hadoop_spark_dag.py took 0.113 seconds
